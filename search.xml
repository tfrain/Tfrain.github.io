<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>MySQL面试问题:假设创建一个复合索引(a, b, c)，如果查询字段a和c，会使用这个复合索引吗?</title>
      <link href="/zh-cn/mysql-interview19/"/>
      <url>/zh-cn/mysql-interview19/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>让我们创建一个以MySQL为重点的课程计划，特别是理解复合索引的应用</p><p><img src="https://images.unsplash.com/reserve/d1Ntvq9mSVmV0RcnWN1Y_23rd%20Studios%20Photography%20Boulder%20Colorado.jpg?crop=entropy&amp;cs=srgb&amp;fm=jpg&amp;ixid=M3wzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE3MTU1MTAxMjl8&amp;ixlib=rb-4.0.3&amp;q=85&amp;w=500&amp;h=500" alt="photo by Paul Talbot on Unsplash"></p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：1-1-MySQL的复合索引介绍"><a href="#主题：1-1-MySQL的复合索引介绍" class="headerlink" title="主题：1.1 MySQL的复合索引介绍"></a><strong>主题：1.1 MySQL的复合索引介绍</strong></h1><p>复合索引，也称为联合或多列索引，是数据库表中两个或多个列组成的索引。这些列按照特定的顺序排列，并由此列的顺序所导向。</p><p>以图书馆为例，单列索引就像根据作者的名字来排列书籍。而复合索引就像根据作者和书名来排列书籍。</p><p>在 MySQL 中，复合索引起着非常重要的作用，帮助提高数据库操作的效率。要了解的是，MySQL 可以使用复合索引来加速包含任何列的查询，但是它的效率最高是在使用左侧前缀的索引列表中。</p><p>MySQL 复合索引的一个重要特性是“左侧前缀”。在复合索引中，列的顺序很重要。例如，在复合索引 (a, b, c) 中，MySQL 可以使用这个索引来加速包含 ‘a’ 或 ‘a 和 b’ 的查询，但不能使用 ‘b 和 c’，因为 ‘b 和 c’ 不是复合索引的左侧前缀。</p><p>复合索引可以大大提高查询的性能，但是它们的有效使用取决于如何查询数据。</p><h1 id="主题：1-2-创建复合索引"><a href="#主题：1-2-创建复合索引" class="headerlink" title="主题：1.2 创建复合索引"></a><strong>主题：1.2 创建复合索引</strong></h1><p>在 MySQL 中创建复合索引与创建单列索引的语法有些差异。</p><p>下面是创建复合索引的基本语法：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX index_name  </span><br><span class="line">ON table_name(col1, col2, ...);</span><br></pre></td></tr></tbody></table></figure><ul><li><code>index_name</code> 是您想要为索引命名的名称。</li><li><code>table_name</code> 是要创建索引的表的名称。</li><li><code>(col1, col2, …)</code> 是要包含在索引中的列的名称，按照您希望它们出现的顺序排列。</li></ul><p>让我们考虑一个具体的例子。 假设有一个 <code>sales</code> 表，其中包含 <code>ProductID</code>、<code>OrderDate</code> 和 <code>Region</code> 列。 如果您经常执行过滤或排序操作，并使用 <code>ProductID</code> 和 <code>OrderDate</code>，复合索引将会有所帮助。 下面是如何创建它：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX idx_sales  </span><br><span class="line">ON sales(ProductID, OrderDate);</span><br></pre></td></tr></tbody></table></figure><p>在上面的例子中，<code>idx_sales</code> 是一个复合索引，在 <code>sales</code> 表上包含 <code>ProductID</code> 和 <code>OrderDate</code>。 索引的顺序很重要，因为 MySQL 将使用索引来加速包含 <code>ProductID</code> 的查询，或者包含 <code>ProductID</code> 和 <code>OrderDate</code> 的查询，但不是 <code>OrderDate</code> 的查询。</p><p>要记住的是，使用复合索引来提高查询性能是有代价的。 虽然它们可以大大提高查询性能，但它们可能会慢下来写操作（例如，INSERT、UPDATE、DELETE），因为 MySQL 必须更新索引。 要优化数据库性能，需要找到一个合理的平衡。</p><h1 id="主题：1-3-查询字段-A-和-C"><a href="#主题：1-3-查询字段-A-和-C" class="headerlink" title="主题：1.3 查询字段 A 和 C"></a><strong>主题：1.3 查询字段 A 和 C</strong></h1><p>本主题讨论了一个重要的问题：如果你只查询字段 A 和 C，MySQL 会使用复合索引 (a, b, c)？</p><p>答案主要取决于 SQL 查询和索引的结构。如果 WHERE 子句中使用的列是复合索引的前 N 个连续列，则可以使用索引。因此，如果你在复合 (a, b, c) 索引中查询字段 A 和 C，但不查询字段 B，索引可能不会很有效。</p><p>例如，考虑下面的复合索引：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX comp_index  </span><br><span class="line">ON table(a, b, c);</span><br></pre></td></tr></tbody></table></figure><p>并且假设我们有这样的查询：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT *  </span><br><span class="line">FROM table  </span><br><span class="line">WHERE a = 1 AND c = 3;</span><br></pre></td></tr></tbody></table></figure><p>在这种情况下，MySQL 将只使用字段 a 的索引，并忽略字段 c 的索引，因为字段 c 不是与字段 a 在复合索引的左侧前缀中连续的。</p><p>为了确保字段 a 和 c 的索引被使用，您可以重构复合索引为 (a, c, b) 或 (c, a, b)，并相应地调整查询。主要是 WHERE 子句中的字段应该与复合索引的左侧前缀中的字段对齐。</p><p>请记，总是一个好主意定期分析查询的性能并根据需要调整索引。MySQL 的 EXPLAIN 语句是一个有用的工具来了解如何查询与索引的交互。</p><p>在下一节中，我们将学习如何优化 MySQL 中的复合索引来获取更好的结果。</p><h1 id="主题：1-4-复合索引优化"><a href="#主题：1-4-复合索引优化" class="headerlink" title="主题：1.4 复合索引优化"></a><strong>主题：1.4 复合索引优化</strong></h1><p>优化 MySQL 中的复合索引可以显著提高数据库查询的效率和速度。记住，有效地实现索引可以节省时间、资源并提高整个应用的性能。</p><p>下面是优化复合索引的几个关键点：</p><ol><li><strong>索引列的顺序：</strong> 索引列的顺序可能会有显著的差异。如果 WHERE 子句中使用的列与复合索引的左侧前缀中的列对齐，MySQL 可以高效地使用索引。如果 WHERE 子句中使用了多个列，您可能会得到多个索引或复合索引，选择这些选项取决于特定的应用要求。</li><li><strong>索引卡 Cardinality：</strong> 索引卡 Cardinality 是索引值的多样性。索引列中具有更高卡 Cardinality 的列会导致更少的行扫描并提高查询性能。因此，在复合索引中，列的优先级应该是从左到右的。</li><li><strong>等式与范围条件：</strong> 在复合索引中，MySQL 可以对所有列进行等式检查，并对最后一列进行范围检查。如果 WHERE 子句中的范围条件位于中间，MySQL 不能使用右侧的索引部分。</li><li><strong>过度索引：</strong> 虽然索引可以加速数据检索，但它会慢下数据修改操作（如 INSERT、UPDATE 和 DELETE）的速度，因为每次修改索引列数据都需要更新索引结构。确保您不会过度索引表格——每个索引都应该有目的。</li><li><strong>使用 EXPLAIN：</strong> MySQL 的 EXPLAIN 关键字显示优化器如何选择索引来执行查询。定期使用 EXPLAIN 来了解如何查询与索引的交互。</li></ol><h1 id="主题：1-5-回顾和评估"><a href="#主题：1-5-回顾和评估" class="headerlink" title="主题：1.5 回顾和评估"></a><strong>主题：1.5 回顾和评估</strong></h1><p>在会话中，我们学习了 MySQL 中的复合索引的结构和区别，并学习了创建复合索引的语法并演示了一个例子。我们然后探讨了如何通过特定的字段，例如 A 和 C，来查询复合索引。我们进一步深入了解了如何优化使用复合索引的方法。</p><p>我们学习的关键概念包括：</p><ol><li><strong>复合索引</strong>：它是多列的索引，可以显著加快查询执行的速度。</li><li><strong>创建复合索引</strong>：我们学习了语法并演示了一个例子。</li><li><strong>查询 A 和 C 字段</strong>：我们观察到 MySQL 只能使用索引中的列的左到右的部分，并且不会跳过任何列，只要 WHERE 子句中的列被引用。</li><li><strong>复合索引优化</strong>：我们学习了优化复合索引的有效技巧和技巧，包括索引列的顺序、索引卡inal性、区分等式和范围条件、避免过索引和使用 EXPLAIN 关键字。</li></ol><p>现在是时候评估你对复合索引的了解了。</p><p>例子问题：</p><p>假设你是运营一个线上书店，书库中有千千本书。主要的 <code>books</code> 表在 MySQL 数据库中具有以下列：<code>id, title, author, genre, publication_year 和 price</code>。你发现自己经常执行以下查询：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT *  </span><br><span class="line">FROM books  </span><br><span class="line">WHERE genre = '科幻' AND publication_year = 2018;</span><br></pre></td></tr></tbody></table></figure><p>为了优化这个查询，你创建了以下复合索引：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX genre_year_index  </span><br><span class="line">ON books (genre, publication_year);</span><br></pre></td></tr></tbody></table></figure><p>这个复合索引应该会使你的常用查询变得更快。</p><p>现在，它是你的回合！</p><p>问题：圣诞节到来了，你的商店正在为许多书籍提供折扣。你打算通过电子邮件向所有购买了《科幻》书籍发表后 2010 年的用户发送邮件。从 <code>orders</code> 表中获取用户 ID 列表，该表具有以下列：<code>order_id, user_id, book_id, order_date</code>。假设还有一个名为 <code>orders_books</code> 的中间表具有 <code>order_id, book_id</code>。</p><hr><p>要从 <code>orders</code> 表中获取购买了《科幻》书籍发表后 2010 年的用户 ID，我们可以使用 JOIN 来合并 <code>orders</code>、<code>orders_books</code> 和 <code>books</code> 表中的信息。</p><p>您的 SQL 查询可能会像下面这样：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT DISTINCT o.user_id  </span><br><span class="line">FROM orders AS o  </span><br><span class="line">JOIN orders_books AS ob ON o.order_id = ob.order_id  </span><br><span class="line">JOIN books AS b ON ob.book_id = b.id  </span><br><span class="line">WHERE b.genre = '科幻' AND b.publication_year &gt; 2010;</span><br></pre></td></tr></tbody></table></figure><p>这个查询检查每个订单中的书的类别和出版年份，并返回用户 ID，其中匹配了条件。 <code>DISTINCT</code> 关键字用于删除结果集中的重复 <code>user_id</code>。</p><p>记住，了解数据的结构和如何相互关联是在使用 SQL 和数据库时至关重要的。同时，确保为您的查询设置了正确的索引是至关重要的。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview19/">https://programmerscareer.com/mysql-interview19/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL面试问题:MySQL常用的存储引擎有哪些?有什么区别?</title>
      <link href="/zh-cn/mysql-interview18/"/>
      <url>/zh-cn/mysql-interview18/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>这里是MySQL存储引擎学习计划的详细课程</p><p><img src="https://images.unsplash.com/photo-1515595967223-f9fa59af5a3b?crop=entropy&amp;cs=srgb&amp;fm=jpg&amp;ixid=M3wzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE3MTU1MTAwNjJ8&amp;ixlib=rb-4.0.3&amp;q=85&amp;w=500&amp;h=500" alt="photo by Chua Bing Quan on Unsplash"></p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：1-1-MySQL存储引擎简介"><a href="#主题：1-1-MySQL存储引擎简介" class="headerlink" title="主题：1.1 MySQL存储引擎简介"></a><strong>主题：1.1 MySQL存储引擎简介</strong></h1><p>在 MySQL 中，存储引擎是数据库管理系统使用的底层软件组件，负责创建、读取、更新和删除（CRUD）数据的管理。简单来说，它就是负责数据库中信息的管理。您可以将其视为与磁盘上的文件系统类似的组件。</p><p>每个 MySQL 数据库中的表都是使用特定的存储引擎创建的。 MySQL 提供了多种存储引擎，例如 InnoDB、MyISAM、MEMORY 等，可帮助我们选择最合适的一种。</p><p>与数据库交互时，我们主要不需要关心存储引擎——我们可以只关注写 SQL 查询。但是，存储引擎的选择会影响数据库的各种特性，例如：</p><ul><li><strong>事务支持：</strong> 事务允许多次数据修改在数据库中处理为一个单元的工作，或者所有数据修改都被提交到数据库中，或者未被提交。 InnoDB 支持事务，MyISAM 不支持。</li><li><strong>锁定级别：</strong> 锁定防止多个进程相互干扰。不同的存储引擎使用不同的锁定机制，从行级到表级锁定。</li><li><strong>数据持久性和崩溃恢复：</strong> 这是数据库在崩溃或电源失败时的恢复能力。 InnoDB 具有强的数据持久性和崩溃恢复能力。</li></ul><p>您可能正在问：<em>可以在一个数据库中使用多个存储引擎吗？</em> 是的！事实上，每张表可以使用不同的存储引擎。</p><h1 id="主题：1-2-了解-InnoDB-引擎"><a href="#主题：1-2-了解-InnoDB-引擎" class="headerlink" title="主题：1.2 了解 InnoDB 引擎"></a><strong>主题：1.2 了解 InnoDB 引擎</strong></h1><p>InnoDB 是 MySQL 的默认存储引擎。它提供了标准的 ACID 事务特性，并且具有行级锁定和外键关系。这些是为什么它在数据完整性和性能方面非常受欢迎的原因。</p><p>让我们来详细了解这些特性：</p><ul><li><strong>ACID 兼容性：</strong> ACID 是事务处理的关键概念。它保证数据的完整性和可靠性，并且确保数据在所有操作中保持一致和可靠。</li><li><strong>行级锁定：</strong> 与 MyISAM 中的表级锁定相比，InnoDB 使用行级锁定，其中每行被修改的过程中锁定该特定行，并允许其他进程修改其他行。</li><li><strong>外键关系：</strong> 外键强制在数据库中相关的表之间维护引用完整性。换句话说，它帮助防止破坏链接之间的表。</li></ul><p>InnoDB 还具有崩溃恢复能力。这意味着 InnoDB 可以自动修正因预 mature 关闭或主要故障而导致的任何不一致性。</p><p>在性能方面，InnoDB 使用多版本并发控制（MVCC）来避免在执行 SELECT 语句时需要读锁定。这是在具有忙站点的繁忙网站上非常有帮助的，因为 SELECT 语句非常常见，并且数据完整性是至关重要的。</p><h1 id="主题：1-3-了解-MyISAM-引擎"><a href="#主题：1-3-了解-MyISAM-引擎" class="headerlink" title="主题：1.3 了解 MyISAM 引擎"></a><strong>主题：1.3 了解 MyISAM 引擎</strong></h1><p>MyISAM 是 MySQL 中最早的存储引擎之一，在 MySQL 版本 5.5 之前，MyISAM 是默认的存储引擎。MyISAM 有一些特别的特性和用例，使它在特定的场景中非常有效。</p><p>MyISAM 使用完整的表级锁定来处理 INSERT、UPDATE 和 DELETE 操作。这意味着当行被写入或更新时，整个表，该行是一部分，被锁定，并且其他操作不能在同一表上写入，直到写入或更新过程完成。</p><p>虽然这可能被看作是 InnoDB 所提供的行级锁定的缺点，但在读操作远远多于写操作的场景中，表级锁定是完美的。例如，在博客或网站上，大多数时间你只是显示数据，并且数据更新非常少频。</p><p>另一项重要特性是 MyISAM 支持全文搜索索引，允许自然语言搜索在字符字段中。虽然 InnoDB 现在也支持这个特性了，但 MyISAM 曾经是全文搜索的主要选择很长时间。</p><p>然而，MyISAM 不支持事务和外键约束，这可能是某些应用的重大缺点。此外，它缺少崩溃恢复，因此崩溃可能会导致数据丢失或数据损坏。</p><h1 id="主题：1-4-其他-MySQL-存储引擎"><a href="#主题：1-4-其他-MySQL-存储引擎" class="headerlink" title="主题：1.4 其他 MySQL 存储引擎"></a><strong>主题：1.4 其他 MySQL 存储引擎</strong></h1><p>除了 InnoDB 和 MyISAM 之外，MySQL 还提供了其他存储引擎，每个引擎都有其特别的优势和最佳使用案例。让我们来了解一下：</p><ul><li><strong>MEMORY 引擎：</strong> 名字就说明了，这个引擎保存所有数据在内存中，提供了非常快的数据访问时间。但是，请记住，使用 MEMORY 引擎的表中的数据在服务器关闭或崩溃时会丢失。它非常适合存储会话或临时数据。</li><li><strong>CSV 引擎：</strong> 这个引擎允许您以逗号分隔值 (CSV) 格式访问数据。您甚至可以使用任何文本编辑器来查看和编辑表中的数据。它不支持索引，因此每行搜索都是全表扫描。</li><li><strong>ARCHIVE 引擎：</strong> 如果您需要存储大量未索引的数据，例如日志，这是您所需要的引擎。它使用压缩来节省空间并以易于备份和传输的方式存储数据。虽然 ARCHIVE 引擎允许简单的 SELECT 和 INSERT 语句，但它不支持事务或能够删除或更新记录。</li><li><strong>BLACKHOLE 引擎：</strong> Blackhole 引擎接受数据，但丢弃它并不存储它。您可能会问，为什么它有用？Blackhole 引擎用于复制到多个从服务器，并且还用于数据库服务器的审计日志。</li><li><strong>FEDERATED 引擎：</strong> Federated 存储引擎允许您访问位于其他数据库上的表。它提供了能够创建一个逻辑数据库的能力，其中包含多个物理服务器。</li></ul><p>每个这些引擎都有独特的功能和适用于不同场景的最佳使用案例。这就是 MySQL 的可插拔存储引擎架构的美妙之处——您可以选择最适合您需求的一个。</p><h1 id="主题：1-5-存储引擎比较"><a href="#主题：1-5-存储引擎比较" class="headerlink" title="主题：1.5 存储引擎比较"></a><strong>主题：1.5 存储引擎比较</strong></h1><p>MySQL 的多种存储引擎，每个存储引擎具有独特的特性集，使其成为适应各种工作负载的灵活选择。现在，我们将比较这些存储引擎，探讨其强项和弱项，并建议适合的场景。</p><ol><li><strong>InnoDB vs. MyISAM</strong>：在写操作密集或要求事务的工作负载中，InnoDB优于 MyISAM，因为它提供 ACID 事务特性、行级锁定和崩溃恢复。然而，如果工作负载是读密集，并且事务的持久性或原子性不是关键问题，MyISAM可能是有意义的选择。</li><li><strong>InnoDB/MyISAM vs. MEMORY</strong>：MEMORY 存储引擎通过在内存中存储所有数据来提供 lightning-fast 数据访问，适合存储临时或会话数据。然而，与 InnoDB 和 MyISAM 不同，所有数据在服务器关闭或崩溃时都会丢失。</li><li><strong>InnoDB/MyISAM/MEMORY vs. CSV</strong>：CSV 存储引擎使数据处理变得更加简单和灵活，因为它允许在任何文本编辑器中编辑数据。然而，由于缺少索引，因此对每行搜索可能会进行全表扫描，并且可能不是对大型工作负载的有效解决方案。</li><li><strong>InnoDB/MyISAM/MEMORY/CSV vs. ARCHIVE</strong>：当处理大量 seldom-referenced 数据时，例如日志或历史事务，ARCHIVE 存储引擎具有优势，因为它通过压缩数据来节省存储空间。</li><li><strong>InnoDB/MyISAM/MEMORY/CSV/ARCHIVE vs. BLACKHOLE 和 FEDERATED</strong>：这两个存储引擎相对较特殊，与其他存储引擎相比较：BLACKHOLE 可能有助于审计日志或多主复制，而 FEDERATED 可能有助于创建逻辑上的单个数据库来自多个物理服务器。</li></ol><p>记住，选择正确的存储引擎主要取决于您的特定工作负载和应用要求。</p><h1 id="主题：1-6-选择正确的存储引擎"><a href="#主题：1-6-选择正确的存储引擎" class="headerlink" title="主题：1.6 选择正确的存储引擎"></a><strong>主题：1.6 选择正确的存储引擎</strong></h1><p>选择正确的存储引擎对设置 MySQL 数据库至关重要，因为它可以大大影响应用的性能和可靠性。下面是要考虑的因素：</p><ul><li><strong>数据完整性</strong>：如果您的应用要求高数据完整性，并且事务需要原子性（所有或者没有），您应该考虑使用 InnoDB 存储引擎，它支持 ACID（原子性、一致性、隔离性、持久性）特性。</li><li><strong>全文搜索</strong>：如果您计划运行全文搜索查询，MyISAM 和 InnoDB 都支持这些，但具有不同的特性。您需要独立地探索这些特性，以确定它们是否适合您的使用情况。</li><li><strong>内存使用</strong>：如果您需要最大的读/写速度，并且数据是临时的（例如会话数据），MEMORY 存储引擎，它将所有数据存储在内存中，可能是最佳选择。</li><li><strong>大量数据</strong>：处理大量 seldom-referenced 或历史数据时，考虑 ARCHIVE 存储引擎，它通过压缩数据来有效地存储数据。</li><li><strong>读/写操作比率</strong>：评估应用的读/写操作比率。如果读操作明显多于写操作，您可能会从 MyISAM 中受益。然而，InnoDB 更适合写密集的应用。</li><li><strong>服务器故障</strong>：考虑发生故障时的情况是至关重要的。如果数据持久性是关键问题，InnoDB 应该是您的选择，因为它可以通过事务日志恢复从故障中。然而，MyISAM 不保证数据持久性在故障时。</li></ul><h1 id="主题：1-7-回顾和评估"><a href="#主题：1-7-回顾和评估" class="headerlink" title="主题：1.7 回顾和评估"></a><strong>主题：1.7 回顾和评估</strong></h1><p>在我们的上一课中，我们深入了解了 MySQL 的各种存储引擎，了解了它们的独特特性并比较了它们基于某些标准。我们已经：</p><ul><li>定义了存储引擎是什么并讨论了它们在 MySQL 中的角色。</li><li>了解了 InnoDB 和 MyISAM 存储引擎的特性和优势。</li><li>探索了其他 MySQL 存储引擎，例如 MEMORY、CSV 和 ARCHIVE 等。</li><li>比较了这些存储引擎，以了解它们的最佳使用场景。</li><li>讨论了在选择正确的存储引擎时要考虑的因素。</li></ul><p>让我们测试一下你的理解，在我们结束这个系列之前：</p><ol><li><strong>问题 1：</strong> InnoDB 与 MyISAM 有什么区别，并且在哪些情况下可能会更喜欢使用其中一个？</li><li><strong>问题 2：</strong> 描述一种情况，在哪里使用 MEMORY 存储引擎可能会有所帮助？</li><li><strong>问题 3：</strong> 如果您有存储大量日志数据的要求，您将选择哪个存储引擎，并且为什么？</li><li><strong>问题 4：</strong> 在选择数据库时要考虑的几个因素是什么？</li></ol><p>请按顺序回答这些问题。</p><hr><p><strong>答案 1：</strong> InnoDB 是一个存储引擎，它提供了 ACID（原子性、一致性、隔离性、持久性）完整性支持的事务功能，并且在写密集的应用或需要高数据完整性的场景中非常有用。然而，MyISAM 通常用于读密集的应用，因为它具有更快的读操作。然而，请记，MyISAM 不支持事务和崩溃安全性功能。</p><p><strong>答案 2：</strong> MEMORY 存储引擎可能会在处理临时数据时非常有用，例如会话数据。因为所有数据都存储在内存中，并且比磁盘存储更快，它提供了极快的访问时间。然而，请记，所有使用此存储引擎的数据在服务器终止或崩溃时都会丢失。</p><p><strong>答案 3：</strong> ARCHIVE 存储引擎可能会在处理大量偶尔引用数据或日志数据时非常有用。这个存储引擎支持压缩，可以节省大量的存储空间。</p><p><strong>答案 4：</strong> 在选择数据库时要考虑的因素可能包括：</p><ul><li>数据库主要处理的操作类型（读操作或写操作）。</li><li>事务支持和崩溃安全性机制是否是必需的。</li><li>数据量和接受的访问/读写速度。</li><li>特定功能，例如全文索引或 GIS 功能。</li></ul><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview18/">https://programmerscareer.com/mysql-interview18/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL面试问题:MySQL MVCC的实现原理</title>
      <link href="/zh-cn/mysql-interview17/"/>
      <url>/zh-cn/mysql-interview17/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>我们可以深入了解MySQL如何实现多版本并发控制(MVCC)的细节</p><p><img src="https://images.unsplash.com/photo-1464983953574-0892a716854b?crop=entropy&amp;cs=srgb&amp;fm=jpg&amp;ixid=M3wzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE3MTU1MDk5ODJ8&amp;ixlib=rb-4.0.3&amp;q=85&amp;w=500&amp;h=500" alt="photo by Dino Reichmuth on Unsplash"></p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：解析-MVCC"><a href="#主题：解析-MVCC" class="headerlink" title="主题：解析 MVCC"></a>主题：解析 MVCC</h1><p>多版本并发控制 (MVCC) 是数据库管理系统中使用的技术，用于处理多个用户同时访问同一数据而不发生冲突，从而提高处理效率。</p><p>简单来说，MVCC 允许多个事务同时访问同一数据而不发生冲突或需要读锁，这可能会严重影响性能。这是通过为事务创建数据的一个“快照”来实现的，其他并发事务不会影响这个快照。</p><p>现在，让我们分解一下术语 MVCC：</p><ul><li><strong>多版本</strong>：这意味着数据库保存多个版本的同一行。版本是数据在某个时间点的一个快照。</li><li><strong>并发控制</strong>：这表明技术用于处理同时进行的事务，不发生冲突，确保每个事务都保持数据库的假象，就好像它是唯一访问数据库的。</li></ul><p>MySQL 在其 InnoDB 存储引擎中实现了 MVCC。当事务更新 InnoDB 中的行时，原始行不会立即被覆盖或删除。相反，InnoDB 会存储更新前的旧版本，以便其他正在进行的事务可以看到原始版本。这就是数据行的多版本来源。</p><p>所以，为什么我们在 MySQL 中使用 MVCC？主要是性能原因。通过允许多个事务同时访问同一快照的数据，我们避免了读锁，这可能会严重影响性能，特别是在许多用户同时查询和更新同一数据库的情况下。</p><h1 id="主题：MySQL-中的-MVCC-是如何工作的"><a href="#主题：MySQL-中的-MVCC-是如何工作的" class="headerlink" title="主题：MySQL 中的 MVCC 是如何工作的"></a>主题：MySQL 中的 MVCC 是如何工作的</h1><p>让我们来详细地了解 MySQL 中的 MVCC 是如何工作的。</p><p>当事务在 MySQL (InnoDB) 中开始时，它会被分配一个唯一的事务 ID。这个 ID 用于创建事务的数据库视图。这个视图包含已提交数据的所有版本，直到事务开始时，并且包含事务自身所做的更改。事务不能看到其他并发事务所做的更改，这为其提供了一致的快照并确保隔离性。</p><p>当行被修改时，InnoDB 不会覆盖现有数据。相反，它会写入新行版本并保存旧版本的信息在一个名为撤销日志的区域中。这个日志包含需要反转更改的信息，如果事务被回滚，并且提供旧版本的行给其他事务，如果它们需要它们。</p><p>现在，让我们讨论一些相关的主题：读视图、撤销日志和清理。</p><p><strong>读视图</strong> 是 InnoDB 使用的机制，用于实现一致的读取，即读取数据库的快照，与事务开始时相对应。</p><p><strong>撤销日志</strong> 是 MVCC 的一个关键部分。当事务修改数据时，InnoDB 会写入新行并在撤销日志中存储需要反转更改的信息。如果其他事务需要看到旧版本的行，InnoDB 使用撤销日志中的信息来重构它们。</p><p><strong>清理</strong> 与 InnoDB 如何清理不再需要的旧版本的行有关。一旦所有可能需要访问旧版本的行的事务都完成了，InnoDB 就可以释放这些版本所占用的空间。这个过程被称为清理。</p><h1 id="主题：ACID-特性和-MVCC"><a href="#主题：ACID-特性和-MVCC" class="headerlink" title="主题：ACID 特性和 MVCC"></a>主题：ACID 特性和 MVCC</h1><p>在可靠的数据库管理系统中，维持 ACID 原则（Atomicity、Consistency、Isolation、Durability）是至关重要的方面之一。</p><ol><li><strong>原子性</strong>：如果事务包含多个操作，原子性意味着要么所有操作都成功执行，要么都不执行。事务不能部分完成。如果发生任何操作中的错误，整个事务将被回滚。</li><li><strong>一致性</strong>：一致性意味着事务应该将数据库从一个一致状态转换到另一个一致状态，根据已定义的规则。例如，如果帐户没有足够的余额进行提款，则事务应该被拒绝以维持一致性。</li><li><strong>隔离性</strong>：隔离性在多个事务同时执行时发挥作用。它意味着每个事务应该像是唯一一个事务一样执行。事务的中间状态不应该可见于其他事务。</li><li><strong>持久性</strong>：持久性确保事务一旦提交，就会永久保存。换句话说，事务的结果是永久的。</li></ol><p>MVCC (多版本并发控制) 与 ACID 特性相关，下面是详细的解释：</p><p>在 MySQL（特别是其 InnoDB 存储引擎）的上下文中，MVCC 提供了隔离和一致性。</p><p><strong>隔离性</strong> 由每个事务使用其自身的数据库快照来保证。即使多个事务同时试图读写同一数据，每个事务也会看到其自身的一致快照，就好像它是唯一一个事务一样。</p><p><strong>一致性</strong> 由 MVCC 中的回滚日志来维护。如果事务失败或回滚，则可以撤销该事务中的更改，以确保数据库处于一致状态。此外，通过为事务创建事务特定的数据视图，可以确保事务总是处理一致的数据集。</p><h1 id="主题：快照读和当前读"><a href="#主题：快照读和当前读" class="headerlink" title="主题：快照读和当前读"></a>主题：快照读和当前读</h1><p>在 MySQL 中，当 MVCC (多版本并发控制) 发挥作用时，有两种主要类型的读取操作：快照读和当前读。让我们详细了解这些概念。</p><p><strong>快照读</strong></p><p>快照读，就像名字所表明的，提供了数据库在事务开始时的一致快照。它不会看到其他并发执行的事务所做的更改。这种读取是默认模式下 <code>SELECT</code> 语句的。快照读是 MVCC 的核心，它为 MVCC 提供了“一致视图”的概念。</p><p><strong>当前读</strong></p><p>与快照读不同，当前读看到最新提交的数据，包括其他事务所做的更改。模式如 <code>SELECT…FOR UPDATE</code> 和 <code>SELECT…LOCK IN SHARE MODE</code> 使用当前读。它还用于当前事务所做的数据更改，例如 <code>UPDATE</code>、<code>INSERT</code> 和 <code>DELETE</code>。</p><p>这两种类型的读取提供了事务处理数据的灵活方法。事务是否要看到数据库在事务开始时的状态，或者要看到最新数据，包括其他事务所做的更改，取决于使用哪种类型的读取。</p><h1 id="主题：在-MySQL-中管理死锁"><a href="#主题：在-MySQL-中管理死锁" class="headerlink" title="主题：在 MySQL 中管理死锁"></a>主题：在 MySQL 中管理死锁</h1><p>现在，让我们探讨 MySQL 的 MVCC 中的另一个关键方面——处理死锁。</p><p>死锁发生在两个或多个事务同时持有和请求锁时，创造了一个循环依赖，无法解决。 无处理，这些事务可能会永久等待，显然不是理想的。</p><p>MySQL 处理死锁的方法是使用等待图。简单地说，当事务 A 等待事务 B 释放行锁时，就在 A 和 B 之间添加一条边。 如果添加这条边创建了一个循环，则检测到死锁。</p><p>在检测到死锁后，MySQL 需要解决它。它通过选择一个事务作为“受害者”并回滚它来完成。 在大多数情况下，它选择已经做了最少工作的事务，以便少量的工作被丢弃。 回滚受害者事务后，死锁就被解决了。</p><p>在 MySQL 中，您可以使用 <code>SHOW ENGINE INNODB STATUS;</code> 来获取有关最近死锁的信息，这可以帮助调试。</p><p>死锁管理，尽管大多数自动，要谨慎地处理事务的设计和执行。建议尽可能地缩短事务并尽可能地提交它们，以减少死锁的可能性。</p><h1 id="主题：MVCC-性能影响"><a href="#主题：MVCC-性能影响" class="headerlink" title="主题：MVCC 性能影响"></a>主题：MVCC 性能影响</h1><p>尽管 MySQL 的 MultiVersion Concurrency Control (MVCC) 在内部为并发访问提供了许多好处，但要识别 MVCC 不是无价的。 让我们来探讨一些这些：</p><ol><li><strong>磁盘空间</strong>: 其中一个主要开销是增加的磁盘空间。 由于 MVCC 保存不同版本的行以提供隔离、一致的视图给事务，需要更多的磁盘空间。 这可能会在重读写混合的工作负载中显著。</li><li><strong>CPU 和 I/O 资源</strong>: 生成多版本的数据、维护它们并清理不必要的版本 (垃圾回收) 可能会耗费 CPU 和 I/O 资源。</li><li><strong>锁定开销</strong>: 尽管 MVCC 减少了锁定，它并不完全消除了，特别是对写事务 (插入、更新、删除) 的锁定。 这些锁定增加了性能开销。</li><li><strong>增加复杂性</strong>: MVCC 增加了数据库引擎的复杂性。 它需要管理多版本的数据、处理回滚、解决冲突和清理旧版本。 这种复杂性增加了整体性能的开销。</li></ol><p>在哪些场景中可能考虑替代 MVCC？</p><p>虽然 MVCC 为多用户访问提供了出色的好处，但它可能不是每个场景的最佳选择。 例如，在大量写入一次并多次读取的应用程序中，可能更好地考虑 MyISAM 存储引擎，它不支持 MVCC。</p><p>此外，在要求绝对最新数据的应用程序中，也可能要考虑其他方法，因为 MVCC 提供了数据的“快照”，而不是最新版本。</p><p>要了解工作负载、性能期望和硬件资源可用性之前，就要考虑使用 MVCC 的决定。</p><h1 id="主题：回并评估"><a href="#主题：回并评估" class="headerlink" title="主题：回并评估"></a>主题：回并评估</h1><p>现在，让我们回和总结 MySQL 中 MultiVersion Concurrency Control (MVCC) 的不同方面：</p><ol><li><strong>MVCC 是数据库管理系统中用于处理并发事务的方法</strong>。</li><li><strong>MVCC 在 MySQL 中提供每个事务的“快照”，允许多个事务同时读取（并写入）同一数据项</strong>，大大提高了数据库的性能和可伸缩性。</li><li><strong>快照读和当前读是 MySQL 中 MVCC 的两个关键概念</strong>。快照读提供事务开始时数据的一致视图，并确保事务使用了一致的数据状态。当前读是指考虑其他事务已提交的最新数据的一种读取方式。</li><li><strong>MVCC 与数据库的 ACID 属性密切相关</strong>，确保事务的原子性、一致性、隔离性和持久性。</li><li><strong>MVCC 在 MySQL 中处理死锁</strong>，这是两个事务等待对方释放资源的情况。</li><li><strong>虽然 MVCC 提供了许多优势，但它也不是完全免费的</strong>，例如增加磁盘空间和 CPU 使用量。</li></ol><p>这些是我们在 MySQL 中讨论 MVCC 的多个方面。现在，就是时候评估你的理解了。考虑以下问题：</p><ul><li>MVCC 如何在 MySQL 中提高并发事务？</li><li>MySQL 中 MVCC 的快照读和当前读有什么区别？</li><li>MVCC 在 MySQL 中是如何处理死锁的？</li><li>MVCC 在使用时会带来哪些性能交换？</li></ul><p>思考这些问题。您可以在纸上写下回答或者简单地为自我评估思考。</p><hr><ol><li>MVCC 通过允许多个用户同时访问同一行的表来提高并发事务。每个事务都会获取数据的一致状态，在事务开始时。</li><li>在 MySQL 中，快照读和当前读是两种不同的读取隔离级别。快照读是指事务读取数据库状态的一致快照，确保事务内部的数据一致性。当前读是指考虑其他事务已提交的最新数据的一种读取方式。</li><li>MVCC 在 MySQL 中处理死锁通过 wait-for 图来处理。当一个事务等待另一个事务释放锁时，会在 wait-for 图中添加一条边。如果添加这条边创造了一个循环，则会检测到死锁。MySQL 会选择一个事务作为“受害者”并回滚它来解决死锁。</li><li>MVCC 与数据库的 ACID 属性密切相关，确保事务的原子性、一致性、隔离性和持久性。</li></ol><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview17/">https://programmerscareer.com/mysql-interview17/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL面试问题:什么时候分割数据库，什么时候分割表?</title>
      <link href="/zh-cn/mysql-interview16/"/>
      <url>/zh-cn/mysql-interview16/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>让我们概述一下在MySQL中拆分数据库和表的课程</p><p><img src="https://images.unsplash.com/photo-1488489153583-89ce18dd4968?crop=entropy&amp;cs=srgb&amp;fm=jpg&amp;ixid=M3wzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE3MTU1MDk3NTh8&amp;ixlib=rb-4.0.3&amp;q=85&amp;w=500&amp;h=500" alt="photo by Geranimo on Unsplash"></p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：了解数据分布"><a href="#主题：了解数据分布" class="headerlink" title="主题：了解数据分布"></a>主题：了解数据分布</h1><p>你好，我们将在本课程中开始了解数据分布。首先，让我们确定我们所说的“数据分布”是指什么。</p><p>数据分布是将数据、计算任务和应用程序分布在网络中的多个计算机上的方法。分布数据可以提高应用程序的性能、可靠性和可访问性。 😊</p><p>数据分布有多种原因。请允许我为您介绍其中的一些主要优势：</p><p><strong>提高性能</strong>：通过分布数据，可以提高应用程序访问数据的速度。如果有效地执行，数据分布可以确保资源位于需要它们的地方，从而降低访问延迟并提高速度。</p><p><strong>冗余和可靠性</strong>：通过数据分布，可以存储多个数据副本在不同位置。这提供了冗余并增加了数据的总体可靠性。如果一个服务器失败，应用程序可以从另一个服务器访问相同的数据。</p><p><strong>可伸缩性</strong>：通过数据分布，当业务或应用程序增长时，可以更轻松地扩展基础设施。新的服务器可以随时添加到网络中。</p><p><strong>负载平衡</strong>：通过有效地分布数据，可以确保服务器的负载均衡。这确保了无单点瓶，影响应用程序性能的情况不会发生。</p><p>数据分布可以采用多种方法，例如水平分区（也称为分片）、垂直分区和功能分区。每种方法都有其特点并适用于不同类型的应用程序。我们将在后续课程中详细探讨这些。</p><h1 id="主题：MySQL数据库分割（分片）"><a href="#主题：MySQL数据库分割（分片）" class="headerlink" title="主题：MySQL数据库分割（分片）"></a>主题：MySQL数据库分割（分片）</h1><p>我很高兴看到你想深入了解！现在，让我们深入探讨数据分割，也就是<strong>分片</strong>。</p><p>在 MySQL 中，分片是将一个较大的数据库分割成更小的、更易于管理的部分，称为分片。每个分片都是一个独立的数据库。</p><p>想象一下，类似于将一个大书分割成多个章节，其中每个章节可以独立存储独特的信息。类似地，当我们分片数据库时，它就像将一个大数据库分割成多个“章节”，其中每个章节存储独特的数据。</p><p>然而，为什么要这样做呢？ 🤔 分片通常用于以下几个原因：</p><p><strong>提高性能</strong>：分片可以大大提高读/写速度。当您发出查询时，不必浏览整个数据库，只需浏览特定的分片，显著提高速度。</p><p><strong>可伸缩性</strong>：分片使数据库水平可伸缩。如果您的应用程序增长并且数据库开始变得太大以适合单个服务器，您可以随时添加更多的分片。</p><p><strong>可靠性</strong>：如果一个分片出现故障，它不会导致整个应用程序崩溃。其他分片将继续运行无事故。</p><p>虽然分片有其多种好处，但它也有一些缺点：</p><p><strong>增加复杂性</strong>：整个数据库环境变得更复杂。</p><p><strong>数据分布</strong>：您必须决定如何分布数据，这可能会困难。</p><p><strong>跨分片加入数据</strong>：如果您想要加入来自不同分片的表，这可能会困难或慢。</p><p>在 MySQL 中，分片通常在应用程序层上进行，通过分片库或框架。其中一些流行的分片算法包括范围基础、列表基础、哈希基础和目录基础分片。</p><h1 id="主题：MySQL中的表分割（分区）"><a href="#主题：MySQL中的表分割（分区）" class="headerlink" title="主题：MySQL中的表分割（分区）"></a><strong>主题：MySQL中的表分割（分区）</strong></h1><p>如果记忆中，以前我们讨论了数据分布和为什么要将数据库分割成多个小部分，这个过程称为分片。</p><p>类似地，表分区是一种将大表分割成更可管理的小部分的方法，同时仍然能够访问和操作数据，就好像分区的表是一个单独的实体。换句话说，即使数据存储在分区中，从用户的角度来看，它仍然像是一个表。很酷，对吧？</p><p>现在，<strong>为什么会有用处？</strong> 😊</p><p>分区可能是解决方案，如果你有一个非常大的表，导致慢查询和更新，特别是如果该表预计会超过单个服务器的容量。</p><p>在本质上来说，分区是关于管理和优化数据以提高性能的。在不必要的复杂性出现的情况下使用分区可能会导致问题。</p><p>MySQL提供四种分区类型：</p><p><strong>1. RANGE分区：</strong> 这是分区的简单类型。它最适合处理在特定范围内的数据，例如日期或量。</p><p><strong>2. LIST分区：</strong> 它根据预定义的值列表进行分区。</p><p><strong>3. HASH分区：</strong> 在这种情况下，MySQL应用哈希函数在分区键上进行确定。它用于确保数据均匀地分布在指定数量的分区中。</p><p><strong>4. KEY分区：</strong> 它类似于哈希分区，但在这种情况下，MySQL服务器内部计算哈希值，用户不能控制。</p><p>所以，这是理论，在下一课中，我们将讨论如何在 MySQL 中实现这些原理，并提供一些实际示例来帮助说明这个概念。</p><h1 id="主题：数据库和表分割的实践例"><a href="#主题：数据库和表分割的实践例" class="headerlink" title="主题：数据库和表分割的实践例"></a><strong>主题：数据库和表分割的实践例</strong></h1><p>好的！现在让我们将数据库分片和表分区的理论应用到实际例子中。</p><p><strong>例 1：数据库分片</strong></p><p>假设我们有一个全球范围的电子商务网站，客户数据在迅速增长中。我们可以为每个地理区创建一个分片，例如北美、欧洲和亚洲等。每个区的数据库分片仅存储位于该区内的客户数据。这样，我们就可以通过局部化数据和查询来提高性能。</p><p><strong>例 2：表分区</strong></p><p>在我们的电子商务网站的情况下，考虑一种情况，其中我们有 millions 的订单，并且大多数查询都是对最近的订单进行的。我们可以决定按日期分区“Orders”表，并为每个月保存单独的分区。这样，对特定时期的查询只需要扫描更少的行并执行更快。</p><p>但是，这些是如何在实践中进行的？</p><p>对于 MySQL 中的数据库分片，有各种分片框架可用，例如 Vitess、phpMyAdmin 等。例如，在 Vitess 中，您将定义一个 VSchema，其中包含分片指令来自动分片所需的表。</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">{  </span><br><span class="line">  "sharded": true,  </span><br><span class="line">  "vindexes": {  </span><br><span class="line">    "hash": {  </span><br><span class="line">      "type": "hash"  </span><br><span class="line">    }  </span><br><span class="line">  },  </span><br><span class="line">  "tables": {  </span><br><span class="line">    "your_table": {  </span><br><span class="line">      "column_vindexes": [  </span><br><span class="line">        {  </span><br><span class="line">          "column": "your_shard_column",  </span><br><span class="line">          "name": "hash"  </span><br><span class="line">        }  </span><br><span class="line">      ]  </span><br><span class="line">    }  </span><br><span class="line">  }  </span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>对于 MySQL 中的表分区，可以使用 ALTER TABLE 命令进行分区。</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE orders  </span><br><span class="line">PARTITION BY RANGE( YEAR(order_date) )  </span><br><span class="line">(  </span><br><span class="line">  PARTITION p0 VALUES LESS THAN (1990),  </span><br><span class="line">  PARTITION p1 VALUES LESS THAN (2000),  </span><br><span class="line">  PARTITION p2 VALUES LESS THAN (2010),  </span><br><span class="line">  PARTITION p3 VALUES LESS THAN (2020),  </span><br><span class="line">  PARTITION p4 VALUES LESS THAN MAXVALUE  </span><br><span class="line">);</span><br></pre></td></tr></tbody></table></figure><p>在这个脚本中，我们根据“order_date”列对“orders”表进行分区。</p><p>请记，这些过程通常由应用程序或框架处理，因此对 SQL 有一些了解是必要的。同时，分片和分区都会带来复杂性，只有在其好处超过复杂性时才应该使用它们。</p><h1 id="主题：作出明智的决定"><a href="#主题：作出明智的决定" class="headerlink" title="主题：作出明智的决定"></a><strong>主题：作出明智的决定</strong></h1><p>我们已经讨论了很多内容，最后我们将讨论如何作出一个有理由的决定，重复了前面的课程中的一些关键点，并提供了一些额外的提示。</p><p>下面是要考虑的因素：</p><p><strong>数据库分片（分割）决策作出：</strong></p><ol><li><strong>数据大小</strong>：如果数据库变得太大而难以有效处理，可能需要分割。</li><li><strong>性能</strong>：如果数据库中的频繁查询因数据量而变慢，分割可以帮助提高处理速度，因为它可以减少每个查询处理的数据量。</li><li><strong>可伸缩性</strong>：如果您预计数据库将超过单个服务器的容量，在早期阶段实施分割可能是一个好的预防措施。</li><li><strong>数据类型</strong>：分割可能会受数据类型的影响。例如，多租户应用程序，其中来自多个客户的数据存储在同一数据库中是一个分割的好候选。</li></ol><p><strong>表分区决策作出：</strong></p><ol><li><strong>表大小</strong>：如果表在数据库中变得无限大，可能需要分区。</li><li><strong>查询性能</strong>：如果大多数查询只处理表的某个部分（例如，最近的条目），分区可以大大加快这些查询的速度。</li><li><strong>维护</strong>：分区也可以帮助维护表（例如，备份、更新和删除），因为这些操作可以在单个分区上执行，而不是对整个表进行线下维护。</li></ol><p>在决定是否要分割或分区时，应该根据需要提高性能和处理大量数据或两者都是的。然而，这是一个复杂性增加的决定，应该只有在必要时并且其他简单优化技术不足时才应用。</p><h1 id="主题：回顾和评估"><a href="#主题：回顾和评估" class="headerlink" title="主题：回顾和评估"></a><strong>主题：回顾和评估</strong></h1><p>我们已经完成了数据分布的旅程，特别是MySQL中的数据库分割（分片）和表分区（分区）。现在，让我们快速回顾一下主要点，然后转到评估来巩固您的学习。</p><h2 id="主要点"><a href="#主要点" class="headerlink" title="主要点"></a><strong>主要点</strong></h2><ol><li>了解数据分布：数据分布具有显著的性能优势，但也会增加复杂性。了解何时和怎样使用它是至关重要的。</li><li>MySQL数据库分割（分片）：MySQL数据库分割涉及将数据库分割为更小的部分，基于一个键。它可以显著提高查询响应时间，增加可靠性并支持水平缩放。</li><li>MySQL表分区（分区）：MySQL表分区涉及将表分割为更小的部分，而无需更改SQL查询。分区可以根据各种策略进行，例如范围、列值、哈希值等。</li><li>实际示例：我们讨论了如何为全球客户的电子商务网站实现数据库分割，并如何使用表分区来提高性能，以处理最近的数据。</li><li>作出明智的决定：决定是否要实现数据库分割或表分区，或者两者都要，并为什么要考虑数据大小、查询性能、可伸缩性和数据类型。</li></ol><p>现在，让我们来进行评估。您将被提供一些场景，并要求决定是否要使用分割、分区、两者都要，或者不要，并为什么。</p><h2 id="评估场景"><a href="#评估场景" class="headerlink" title="评估场景"></a><strong>评估场景</strong></h2><ol><li>场景 1：您正在为医院设计应用程序，其中包含一个名为 <code>patients</code> 的表，用于存储患者记录。医院每年处理数千名患者，并且大多数患者只会来一次每年。大多数查询涉及访问最近的患者记录。您应该使用分割、分区、两者都要，或者不要，并为什么？</li><li>场景 2：您正在为技术新闻网站开发应用程序，其中文章经常更新以进行修正，并且新信息和用户评论被不断地写入。评论被存储在一个名为 <code>comments</code> 的表中，每条评论与一个文章相关。您应该使用分割、分区、两者都要，或者不要，并为什么？</li><li>场景 3：您正在为全球范围内的电子商务网站开发应用程序，其中包含一个名为 <code>transactions</code> 的表，包含网站上的所有交易的详细信息。您应该使用分割、分区、两者都要，或者不要，并为什么？</li></ol><hr><p><strong>场景 1</strong>：根据场景，应该在 <code>patients</code> 表上实现 <strong>表分区</strong>。查询涉及访问最近的患者记录，并且分区可以为这些查询提供有效的查询性能。分割可能不是必要的，因为我们没有明确的分割键，并且管理分布式事务和维护一致性可能会增加不必要的复杂性。</p><p><strong>场景 2</strong>：在这种情况下，可能的解决方案是在 <code>comments</code> 表上实现分区。基于日期的分区系统可能会很好地工作，因为旧文章的评论可能会被频繁地读取，但不太可能会更新。分割可能会对这种情况造过多的复杂性。</p><p><strong>场景 3</strong>：在这种情况下，分割 <code>transactions</code> 表可能会有好处，特别是在交易的位置上。这可能会使来自同一地区的交易被分组在一起，从而可能会导致更有效的查询。此外，分割还可能会帮助平衡多个数据库的负载，并为其提供额外的规模和性能优势。此外，您可能还会考虑分区单个分片。</p><p>这些是根据提供的信息而作出的推荐解决方案。然而，每个应用程序可能有独特的要求和约束，并且在作出设计决定时要考虑所有因素。记住，先测量再优化！</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview16/">https://programmerscareer.com/mysql-interview16/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常见(20+)软件面试问题(+答案)关于MySQL/Redis/Kafka</title>
      <link href="/zh-cn/software-interview-set/"/>
      <url>/zh-cn/software-interview-set/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>收集了关于MySQL/Redis/Kafka的软件面试问题，这篇文章会持续更新</p><span id="more"></span><blockquote class="colorquote success"><p>**如果这真的对你有帮助，请我喝杯咖啡，感谢我的辛勤工作，这会激励我创造更多。: D * *<br><a href="https://ko-fi.com/programmerscareer">给我买杯咖啡</a>  </p></blockquote><p>MySQL 面试：为什么MySQL使用B+树进行索引? <a href="https://programmerscareer.com/zh-cn/mysql-interview4/">https://programmerscareer.com/zh-cn/mysql-interview4/</a></p><p>MySQL 面试：数据库的事务隔离级别有哪些？各有哪些优缺点 <a href="https://programmerscareer.com/zh-cn/mysql-interview15/">https://programmerscareer.com/zh-cn/mysql-interview15/</a></p><p>MySQL 面试：什么是数据库事务，MySQL 为什么会使用 InnoDB 作为默认选项？ <a href="https://programmerscareer.com/zh-cn/mysql-interview14/">https://programmerscareer.com/zh-cn/mysql-interview14/</a></p><p>MySQL 面试：简述乐观锁以及悲观锁的区别以及使用场景 <a href="https://programmerscareer.com/mysql-interview5/">https://programmerscareer.com/mysql-interview5/</a></p><p>MySQL 面试：产生死锁的必要条件有哪些？如何解决死锁？ <a href="https://programmerscareer.com/zh-cn/mysql-interview6/">https://programmerscareer.com/zh-cn/mysql-interview6/</a></p><p>Redis 面试：Redis 有几种数据结构？Zset 是如何实现的？ <a href="https://programmerscareer.com/zh-cn/redis-interview6/">https://programmerscareer.com/zh-cn/redis-interview6/</a></p><p>MySQL 面试：聚簇索引和非聚簇索引有什么区别？ <a href="https://programmerscareer.com/zh-cn/mysql-interview13/">https://programmerscareer.com/zh-cn/mysql-interview13/</a></p><p>MySQL 面试：简述脏读和幻读的发生场景，InnoDB 是如何解决幻读的？ <a href="https://programmerscareer.com/zh-cn/mysql-interview12/">https://programmerscareer.com/zh-cn/mysql-interview12/</a></p><p>MySQL 面试：唯一索引与普通索引的区别是什么？使用索引会有哪些优缺点？ <a href="https://programmerscareer.com/zh-cn/mysql-interview11/">https://programmerscareer.com/zh-cn/mysql-interview11/</a></p><p>Redis 面试：简述 Redis 持久化中 RDB 以及 AOF 方案的优缺点 <a href="https://programmerscareer.com/zh-cn/redis-interview5/">https://programmerscareer.com/zh-cn/redis-interview5/</a></p><p>MySQL 面试：简述 MySQL 的间隙锁 <a href="https://programmerscareer.com/zh-cn/mysql-interview10/">https://programmerscareer.com/zh-cn/mysql-interview10/</a></p><p>Redis 面试：如何用Redis实现分布式锁 <a href="https://programmerscareer.com/zh-cn/redis-interview2/">https://programmerscareer.com/zh-cn/redis-interview2/</a></p><p>Redis 面试：简述 Redis 中如何防止缓存雪崩和缓存击穿 <a href="https://programmerscareer.com/zh-cn/redis-interview4/">https://programmerscareer.com/zh-cn/redis-interview4/</a></p><p>MySQL 面试：MySQL 有什么调优的方式？ <a href="https://programmerscareer.com/zh-cn/mysql-interview9/">https://programmerscareer.com/zh-cn/mysql-interview9/</a></p><p>MySQL 面试：简述 MySQL 的主从同步机制，如果同步失败会怎么样？ <a href="https://programmerscareer.com/zh-cn/mysql-interview1/">https://programmerscareer.com/zh-cn/mysql-interview1/</a></p><p>MySQL 面试：MySQL 的索引什么情况下会失效？ <a href="https://programmerscareer.com/zh-cn/mysql-interview8/">https://programmerscareer.com/zh-cn/mysql-interview8/</a></p><p>MySQL 面试：什么是 SQL 注入攻击？如何防止这类攻击？ <a href="https://programmerscareer.com/zh-cn/mysql-interview7/">https://programmerscareer.com/zh-cn/mysql-interview7/</a></p><p>MySQL 面试：简述数据库中的 ACID 分别是什么？ <a href="https://programmerscareer.com/zh-cn/mysql-interview2/">https://programmerscareer.com/zh-cn/mysql-interview2/</a></p><p>Redis 面试：简述 Redis 中跳表的应用以及优缺点 <a href="https://programmerscareer.com/zh-cn/redis-interview1/">https://programmerscareer.com/zh-cn/redis-interview1/</a></p><p>Kafka 面试：Kafka 发送消息是如何保证可靠性的？ <a href="https://programmerscareer.com/zh-cn/kafka-interview1/">https://programmerscareer.com/zh-cn/kafka-interview1/</a></p><p>MySQL 面试：MySQL 如何设计索引，如何优化查询？ <a href="https://programmerscareer.com/zh-cn/mysql-interview3/">https://programmerscareer.com/zh-cn/mysql-interview3/</a></p><p>Redis 面试：假设 Redis 的 master 节点宕机了，你会怎么进行数据恢复？ <a href="https://programmerscareer.com/zh-cn/redis-interview3/">https://programmerscareer.com/zh-cn/redis-interview3/</a></p><p>MySQL 面试：假设建立联合索引 (a, b, c) 如果对字段 a 和 c 查询，会用到这个联合索引吗？ <a href="https://programmerscareer.com/zh-cn/redis-interview19/">https://programmerscareer.com/zh-cn/redis-interview19/</a></p><p>MySQL 面试：MySQL 有哪些常见的存储引擎？它们的区别是什么？ <a href="https://programmerscareer.com/zh-cn/redis-interview18/">https://programmerscareer.com/zh-cn/redis-interview18/</a></p><p>MySQL 面试：简述 MySQL MVCC 的实现原理 <a href="https://programmerscareer.com/zh-cn/redis-interview17/">https://programmerscareer.com/zh-cn/redis-interview17/</a></p><p>MySQL 面试：数据库中什么情况下进行分库，什么情况下进行分表？ <a href="https://programmerscareer.com/zh-cn/redis-interview16/">https://programmerscareer.com/zh-cn/redis-interview16/</a></p><blockquote class="colorquote success"><p>**如果这真的对你有帮助，请我喝杯咖啡，感谢我的辛勤工作，这会激励我创造更多。: D * *<br><a href="https://ko-fi.com/programmerscareer">给我买杯咖啡</a>  </p></blockquote><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> set </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL Interview Question: Suppose to create a composite index (a, b, c) If you query fields A and c, will this composite index be used?</title>
      <link href="/mysql-interview19/"/>
      <url>/mysql-interview19/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Let’s create a lesson plan focused on MySQL, specifically on understanding the application of composite index</p><p><img src="https://images.unsplash.com/photo-1470071459604-3b5ec3a7fe05?crop=entropy&amp;cs=srgb&amp;fm=jpg&amp;ixid=M3wzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE3MTU1MDg5Mzd8&amp;ixlib=rb-4.0.3&amp;q=85&amp;w=500&amp;h=500" alt="photo by v2osk on Unsplash"></p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-Introduction-to-Composite-Indexes-in-MySQL"><a href="#Topic-1-1-Introduction-to-Composite-Indexes-in-MySQL" class="headerlink" title="Topic: 1.1 Introduction to Composite Indexes in MySQL"></a><strong>Topic: 1.1 Introduction to Composite Indexes in MySQL</strong></h1><p>Composite indexes, also known as concatenated or multi-column indexes, are a form of database index that spans two or more columns in a database table. These columns are arranged in a specific order, and the composite index is directed by this column order.</p><p>In a simple analogy, consider a library. Single-field indexing is like sorting the books solely based on authors’ names. However, a composite index is more like sorting the books based on both authors’ names and book titles.</p><p>In MySQL, composite indexes play a fundamental role in increasing the efficiency of database operations. It’s important to understand that MySQL can use a composite index for queries that involve any of the columns in the index, but the index would be most efficient when you use the leftmost prefix of the index column list.</p><p>One key feature of MySQL composite indexes is “leftmost prefixing”. In a composite index, the column order matters. In a composite index (a, b, c), MySQL can use this index to speed up queries involving ‘a’ or ‘a and b’, but not ‘b and c’, because ‘b and c’ is not a leftmost prefix of the index column list.</p><p>So, composite indexes can improve query performance to a great extent, but their efficient use depends on how we are querying the data.</p><h1 id="Topic-1-2-Creating-a-Composite-Index"><a href="#Topic-1-2-Creating-a-Composite-Index" class="headerlink" title="Topic: 1.2 Creating a Composite Index"></a><strong>Topic: 1.2 Creating a Composite Index</strong></h1><p>Creating a composite index in MySQL is similar to creating a single-column index, with a slight change in syntax.</p><p>Here’s the basic syntax for creating a composite index:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX index_name  </span><br><span class="line">ON table_name(col1, col2, …);</span><br></pre></td></tr></tbody></table></figure><ul><li><code>index_name</code>&nbsp;is the name you want to give to the index.</li><li><code>table_name</code>&nbsp;is the name of the table you want to create the index on.</li><li><code>(col1, col2, …)</code>&nbsp;are the names of the columns you want to include in the index, in the order you want them to appear.</li></ul><p>Let’s consider a practical example. Suppose there’s a&nbsp;<code>sales</code>&nbsp;table with&nbsp;<code>ProductID</code>,&nbsp;<code>OrderDate</code>, and&nbsp;<code>Region</code>&nbsp;columns. If you often perform queries that filter or sort by&nbsp;<code>ProductID</code>&nbsp;and&nbsp;<code>OrderDate</code>, a composite index will be beneficial. Here’s how you’d create it:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX idx_sales  </span><br><span class="line">ON sales(ProductID, OrderDate);</span><br></pre></td></tr></tbody></table></figure><p>In the above example,&nbsp;<code>idx_sales</code>&nbsp;is a composite index on the&nbsp;<code>sales</code>&nbsp;table including&nbsp;<code>ProductID</code>&nbsp;and&nbsp;<code>OrderDate</code>. The order of columns matters because MySQL will use the index for queries that involve&nbsp;<code>ProductID</code>&nbsp;alone or both&nbsp;<code>ProductID</code>&nbsp;and&nbsp;<code>OrderDate</code>, but not&nbsp;<code>OrderDate</code>&nbsp;alone.</p><p>Remember that using composite indexes comes with trade-offs. While they can significantly speed up querying, they can also slow down write operations (like INSERT, UPDATE, DELETE), because MySQL must also update the indexes. It’s important to find the right balance to optimize your database performance.</p><h1 id="Topic-1-3-Querying-A-and-C-Fields"><a href="#Topic-1-3-Querying-A-and-C-Fields" class="headerlink" title="Topic: 1.3 Querying A and C Fields"></a><strong>Topic: 1.3 Querying A and C Fields</strong></h1><p>This topic tackles an important question: Will MySQL use a composite index&nbsp;<code>(a, b, c)</code>&nbsp;if you’re querying only fields A and C?</p><p>The answer largely depends on your SQL query and how you structured your index. If the columns being used in the WHERE clause are the first N consecutive columns of the index, then the index can be used. So if you’re querying on a composite&nbsp;<code>(a, b, c)</code>&nbsp;index with fields A and C but without field B, the index may not be as effective.</p><p>For example, consider this composite index:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX comp_index  </span><br><span class="line">ON table(a, b, c);</span><br></pre></td></tr></tbody></table></figure><p>And suppose we have this query:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT *  </span><br><span class="line">FROM table  </span><br><span class="line">WHERE a = 1 AND c = 3;</span><br></pre></td></tr></tbody></table></figure><p>In this case, MySQL would only use the index on field&nbsp;<code>a</code>&nbsp;and would ignore the index on&nbsp;<code>c</code>, because&nbsp;<code>c</code>&nbsp;is not contiguous with&nbsp;<code>a</code>&nbsp;in the index leftmost prefix.</p><p>Alternatively, to make sure the index on fields&nbsp;<code>a</code>&nbsp;and&nbsp;<code>c</code>&nbsp;gets used, you could restructure your composite index as&nbsp;<code>(a, c, b)</code>&nbsp;or&nbsp;<code>(c, a, b)</code>&nbsp;and adjust your queries accordingly. The point here is that the fields in&nbsp;<code>WHERE</code>&nbsp;clause should align with the leftmost prefix of the index columns.</p><p>Keep in mind that it’s always a good idea to regularly analyze the performance of your queries and adjust indexes as necessary. MySQL’s EXPLAIN statement is a useful tool to understand how your queries interact with indexes.</p><p>In the next section, we will learn how to optimize the use of composite indexes in MySQL for better results.</p><h1 id="Topic-1-4-Composite-Index-Optimization"><a href="#Topic-1-4-Composite-Index-Optimization" class="headerlink" title="Topic: 1.4 Composite Index Optimization"></a><strong>Topic: 1.4 Composite Index Optimization</strong></h1><p>Optimizing composite indexes in MySQL can significantly improve your database queries’ efficiency and speed. Remember, an efficiently implemented index saves time, resources, and improves overall application performance.</p><p>Here are several key points to remember for the effective use of composite indexes:</p><ol><li><strong>Order of Columns:</strong>&nbsp;The order of columns in the composite index can make a significant difference. MySQL can efficiently use the index if the columns in your query align with the leftmost prefix of the index. If your WHERE clause uses several columns, you might obtain multiple indexes or a composite index — the choice between these options would rely on specific application requirements.</li><li><strong>Index Cardinality:</strong>&nbsp;Index cardinality refers to the diversity of indexed values. Index columns with higher cardinality lead to fewer row scans and increased query performance. Hence, in a composite index, the column with the highest cardinality should ideally be placed first.</li><li><strong>Equality vs. Range Conditions:</strong>&nbsp;In a composite index, MySQL can perform equality checks for all columns and a range check for the last column. If there’s a range condition in the middle of your WHERE clause, MySQL can’t use the index parts to the right of that range.</li><li><strong>Over-Indexing:</strong>&nbsp;While indexes accelerate data retrieval, they slow down data modifications such as INSERT, UPDATE, and DELETE queries because each modification in indexed column data requires an update in the index structure. Ensure you’re not over-indexing your tables — every index should serve a purpose.</li><li><strong>Use EXPLAIN:</strong>&nbsp;The EXPLAIN keyword in MySQL shows how the optimizer chooses indexes to execute the query. Regularly check your queries using EXPLAIN to understand how the optimizer interacts with your indexes.</li></ol><h1 id="Topic-1-5-Review-and-Assessments"><a href="#Topic-1-5-Review-and-Assessments" class="headerlink" title="Topic: 1.5 Review and Assessments"></a><strong>Topic: 1.5 Review and Assessments</strong></h1><p>Over the course of our sessions, we’ve learned about Composite Indexes in MySQL, their structure, and their distinction from single field indexes. We studied the syntax and examples of creating a composite index. We then explored querying specific fields like A and C with a composite index. We then progressed to achieve a deeper understanding of optimizing our use of composite indexes in MySQL.</p><p>Key concepts we covered include:</p><ol><li><strong>Composite Indexes</strong>: They’re indexes that span multiple columns. This multi-column categorization can dramatically speed up query execution.</li><li><strong>Creating Composite Indexes</strong>: We studied the syntax and walked through an example of creating a composite index.</li><li><strong>Querying A and C Fields</strong>: We observed that MySQL can only utilize the portions of an index where the columns are referenced in the WHERE clause from left to right without skipping any columns.</li><li><strong>Composite Index Optimization</strong>: We went through some essential tips and tricks for optimizing the use of composite indexes, including the order of columns, index cardinality, distinguishing between equality and range conditions, avoiding over-indexing and making use of the EXPLAIN keyword in MySQL.</li></ol><p>It’s now time to assess your understanding of Composite Indexes.</p><p>Example Problem:</p><p>Let’s say you are running an online book store that has thousands of books. Your main&nbsp;<code>books</code>&nbsp;table in your MySQL database has the following columns:&nbsp;<code>id, title, author, genre, publication_year and price</code>. You realize that you frequently execute the following query:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT *  </span><br><span class="line">FROM books  </span><br><span class="line">WHERE genre = 'Science Fiction' AND publication_year = 2018;</span><br></pre></td></tr></tbody></table></figure><p>To optimize this query, you create the following composite index:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX genre_year_index  </span><br><span class="line">ON books (genre, publication_year);</span><br></pre></td></tr></tbody></table></figure><p>This composite index should make your common query faster.</p><p>Now, it’s your turn!</p><p>Question: It’s the holiday season and your store is offering discounts on many books. You plan to send an email to all users who bought ‘Science Fiction’ books published after 2010. Write a SQL query to extract a list of user_ids from an orders table, which has the columns:&nbsp;<code>order_id, user_id, book_id, order_date</code>. Assume there is also a junction table named ‘orders_books’ with&nbsp;<code>order_id, book_id</code>.</p><hr><p>to get the list of&nbsp;<code>user_id</code>&nbsp;from the orders table who bought ‘Science Fiction’ books published after 2010, we will use JOIN to combine information from the&nbsp;<code>orders</code>,&nbsp;<code>orders_books</code>&nbsp;and&nbsp;<code>books</code>&nbsp;tables.</p><p>Your SQL query would look something like this:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT DISTINCT o.user_id  </span><br><span class="line">FROM orders AS o  </span><br><span class="line">JOIN orders_books AS ob ON o.order_id = ob.order_id  </span><br><span class="line">JOIN books AS b ON ob.book_id = b.id  </span><br><span class="line">WHERE b.genre = 'Science Fiction' AND b.publication_year &gt; 2010;</span><br></pre></td></tr></tbody></table></figure><p>This query checks the&nbsp;<code>genre</code>&nbsp;and&nbsp;<code>publication_year</code>&nbsp;of the books in each order and returns the&nbsp;<code>user_id</code>&nbsp;for those matching the criteria. The&nbsp;<code>DISTINCT</code>&nbsp;keyword is used to eliminate any duplicate&nbsp;<code>user_id</code>&nbsp;from the result.</p><p>Remember, understanding the structure of your data and how it is related is crucial when working with SQL and databases. Also, always assure you have the right indexes set for your queries.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview19/">https://programmerscareer.com/zh-cn/mysql-interview19/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL Interview Question: What are the common storage engines for MySQL? What’s the difference?</title>
      <link href="/mysql-interview18/"/>
      <url>/mysql-interview18/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Here is a detailed curriculum of your learning plan for MySQL’s storage engines</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-Introduction-to-MySQL-Storage-Engines"><a href="#Topic-1-1-Introduction-to-MySQL-Storage-Engines" class="headerlink" title="Topic: 1.1 Introduction to MySQL Storage Engines"></a><strong>Topic: 1.1 Introduction to MySQL Storage Engines</strong></h1><p>In MySQL, a storage engine is the underlying software component that a database management system uses to create, read, update and delete (CRUD) the data. Simply put, it’s responsible for the management of information within a database. You can think of it being analogous to how a filesystem manages files on a disk.</p><p>Each table in a MySQL database is created with a particular storage engine. MySQL provides several storage engines such as InnoDB, MyISAM, MEMORY, and others as well that allow us to choose a one that is best fit for our requirements.</p><p>When interacting with a database, we largely don’t have to be concerned about storage engines — we can just focus on writing SQL queries. But the choice of a storage engine has an impact on various characteristics of how a database functions such as:</p><ul><li><strong>Transaction support:</strong>&nbsp;Transaction allows several modifications in a database to be processed as one unit of work, either all data modifications made within a transaction are committed to the database, or none of them are. InnoDB supports transaction, MyISAM does not.</li><li><strong>Locking levels:</strong>&nbsp;Locking prevents multiple processes from interfering with each other’s activities. Different storage engines employ different locking mechanisms ranging from row-level to table-level locking.</li><li><strong>Data durability and crash recovery:</strong>&nbsp;This is the ability of a database to recover from a crash or power loss. InnoDB has strong data durability and crash recovery capabilities.</li></ul><p>A question you might be asking:&nbsp;<em>Can I use multiple storage engines in a single database?</em>&nbsp;Yes! In fact, each table can use a different storage engine.</p><h1 id="Topic-1-2-Understanding-the-InnoDB-Engine"><a href="#Topic-1-2-Understanding-the-InnoDB-Engine" class="headerlink" title="Topic: 1.2 Understanding the InnoDB Engine"></a><strong>Topic: 1.2 Understanding the InnoDB Engine</strong></h1><p>InnoDB is the default storage engine for MySQL. It provides the standard ACID-compliant transaction features, along with row-level locking and foreign key relationships. These are a few of the reasons why it’s heavily favored in scenarios where data integrity and performance are crucial.</p><p>Now let’s break down and understand these features:</p><ul><li><strong>ACID Compliance:</strong>&nbsp;The ACID properties (Atomicity, Consistency, Isolation, Durability) are the key transaction processing concepts. They maintain data integrity over multiple transactions, thereby ensuring that your data remains consistent and reliable throughout and after all operations.</li><li><strong>Row-level locking:</strong>&nbsp;As opposed to table-level locking (as in MyISAM), InnoDB employs row-level locking where each row modified in the process of a transaction locks that specific row and allows other transactions to modify other rows.</li><li><strong>Foreign Key Relationships</strong>: Foreign keys enforce referential integrity among tables in a database. In other words, it helps prevent actions that would destroy links between tables.</li></ul><p>InnoDB also has crash recovery capabilities. This means that InnoDB can auto-correct any inconsistencies that occur as a result of premature shutdown or major failure by replaying its logs.</p><p>In terms of performance, InnoDB uses a method known as Multiversion Concurrency Control (MVCC) to get past the need for read locks when executing SELECT statements. This is a significant benefit if you have a busy site where SELECT statements are common and data integrity is crucial.</p><h1 id="Topic-1-3-Understanding-the-MyISAM-Engine"><a href="#Topic-1-3-Understanding-the-MyISAM-Engine" class="headerlink" title="Topic: 1.3 Understanding the MyISAM Engine"></a><strong>Topic: 1.3 Understanding the MyISAM Engine</strong></h1><p>The MyISAM engine is one of the earliest storage engines in MySQL, and before MySQL version 5.5, MyISAM was the default storage engine. There are some distinguishing features and uses of MyISAM that make it efficient in specific scenarios.</p><p>MyISAM does full table-level locking for INSERT, UPDATE, and DELETE operations. What does this really mean? Well, when a row is being written or updated, the entire table which the row is part of, is locked, and no other operations can write to the same table until the write or update process is completed.</p><p>One might see this as a disadvantage compared to the row-level locking that InnoDB offers; however, there are specific cases when table-level locking works perfectly. Those are the scenarios where read operations vastly outnumber the writes, such as in a blog or a website where most of the time you retrieve data to display and updates to data are infrequent.</p><p>Another key feature of MyISAM is that it supports Full-Text Search indexes, allowing for natural language searching within character fields. Although InnoDB also supports this feature now, MyISAM was the primary choice for Full-Text Search for a long time.</p><p>However, the MyISAM engine does not support transactions and foreign key constraints, which might be significant downsides for certain applications. Furthermore, it lacks crash recovery, so a crash can result in data loss or data corruption in a MyISAM table.</p><h1 id="Topic-1-4-Other-MySQL-Storage-Engines"><a href="#Topic-1-4-Other-MySQL-Storage-Engines" class="headerlink" title="Topic: 1.4 Other MySQL Storage Engines"></a><strong>Topic: 1.4 Other MySQL Storage Engines</strong></h1><p>In addition to InnoDB and MyISAM, MySQL provides other storage engines, each with their strengths and optimal use-cases. Let’s get to know them a bit better:</p><ul><li><strong>MEMORY Engine:</strong>&nbsp;As the name suggests, this engine keeps all data in memory, offering extremely fast data access times. But remember, data stored in a table using the MEMORY engine will be lost when the server shuts down or crashes. It’s excellent for storing session or temporary data.</li><li><strong>CSV Engine:</strong>&nbsp;This engine allows you to access the data in comma-separated values (CSV) format. You can even view and edit data in the table using any text editor. It doesn’t support indexes, so every row search is a full table scan.</li><li><strong>ARCHIVE Engine:</strong>&nbsp;If you need to store large amounts of unindexed data, like logs, this is the engine for you. It uses compression to save space and stores data in a way that is easy to back up and transport. While the ARCHIVE engine allows simple SELECT and INSERT statements, it does not support transactions or the ability to delete or update a record.</li><li><strong>BLACKHOLE Engine:</strong>&nbsp;The Blackhole engine accepts data but throws it away and does not store it. You might wonder why it’s useful? The Blackhole engine can be used for replicating to more than one slave, and is also used for audit logging on a database server.</li><li><strong>FEDERATED Engine:</strong>&nbsp;The Federated Storage Engine allows you to access tables located on other databases on other servers. It provides the ability to create one logical database from many physical servers.</li></ul><p>Each of these engines has unique capabilities and fits different scenarios depending on the requirements. That’s the beauty of MySQL’s pluggable storage engine architecture — you can choose the one that serves your needs the best.</p><h1 id="Topic-1-5-Comparison-of-Storage-Engines"><a href="#Topic-1-5-Comparison-of-Storage-Engines" class="headerlink" title="Topic: 1.5 Comparison of Storage Engines"></a><strong>Topic: 1.5 Comparison of Storage Engines</strong></h1><p>MySQL’s versatile set of storage engines, each with their unique feature set, make it an adaptable choice for a vast array of workloads. Now, we will contrast these storage engines, exploring their strengths and weaknesses, and suggesting best-fit contexts.</p><ol><li><strong>InnoDB vs. MyISAM</strong>: InnoDB outshines MyISAM when your workload relies heavily on writing operations or requires transactions, as it provides ACID-compliant transaction features, row-level locking and crash recovery. On the contrary, MyISAM could be a sensible choice when the workload is read-intensive, and the durability or atomicity of the transactions is not a deal-breaker.</li><li><strong>InnoDB/MYISAM vs. MEMORY</strong>: The MEMORY storage engine, delivering lightning-fast data access by holding all data in memory, is a good fit for storing temporary or session data. But unlike InnoDB and MyISAM, all data is lost when the server shuts down or crashes.</li><li><strong>InnoDB/MYISAM/MEMORY vs. CSV</strong>: The CSV engine makes data handling more manageable and flexible by allowing data edit in any text editor. However, it lacks indexing, resulting in full table scans for each row search, and thus might not be performant for large workloads.</li><li><strong>InnoDB/MYISAM/MEMORY/CSV vs. ARCHIVE</strong>: When it comes to storing large amounts of rarely-referenced data, like logs or historical transactions, the ARCHIVE engine excels by saving storage space through compression.</li><li><strong>InnoDB/MYISAM/MEMORY/CSV/ARCHIVE vs. BLACKHOLE and FEDERATED</strong>: These two engines are quite niched compared to the others: BLACKHOLE can be helpful for tasks like audit logging or multi-slave replication, while FEDERATED can help create a logically single database from various physical servers.</li></ol><p>Remember, choosing the right storage engine largely depends on your specific workload and application requirements.</p><h1 id="Topic-1-6-Choosing-the-Right-Storage-Engine"><a href="#Topic-1-6-Choosing-the-Right-Storage-Engine" class="headerlink" title="Topic: 1.6 Choosing the Right Storage Engine"></a><strong>Topic: 1.6 Choosing the Right Storage Engine</strong></h1><p>Selecting the right storage engine is a crucial decision when setting up your MySQL database because it can significantly impact your application’s performance and reliability. Here are some factors to consider when making your choice:</p><ul><li><strong>Data Integrity</strong>: If your application demands high data integrity where transactions need to be atomic (all-or-nothing), you should consider using the InnoDB storage engine which supports ACID (Atomicity, Consistency, Isolation, Durability) properties.</li><li><strong>Full-text Search</strong>: If you plan to run full-text search queries, both MyISAM and InnoDB support this but with varying features. You’ll have to individually explore these features to make sure they fit your use case.</li><li><strong>Memory Usage</strong>: If you need maximum read/write speed and the data you’re working with is temporary (like session data), the MEMORY storage engine, which stores all data in memory, could be the ideal fit for you.</li><li><strong>Large Amounts of Data</strong>: For handling large amounts of seldom-referenced or historical data, consider the ARCHIVE engine which compresses the data for efficient storage.</li><li><strong>Number of Reads/Writes</strong>: Evaluate your application’s read-to-write operation ratio. If the number of read operations significantly exceeds write operations, you may benefit from the MyISAM engine. Conversely, InnoDB is more suitable for write-heavy applications.</li><li><strong>Server Failures</strong>: Consideration for what happens during a crash is crucial. If durability is essential for your application, InnoDB should be your choice since it can recover from a crash using transaction logs. On the other hand, MyISAM doesn’t guarantee data durability in case of a crash.</li></ul><p>Remember, there is no one-size-fits-all engine, and you might end up using different storage engines for different tables within the same application according to your precise needs.</p><h1 id="Topic-1-7-Review-and-Assessments"><a href="#Topic-1-7-Review-and-Assessments" class="headerlink" title="Topic: 1.7 Review and Assessments"></a><strong>Topic: 1.7 Review and Assessments</strong></h1><p>Over our last few lessons, we’ve taken an in-depth tour of MySQL’s various storage engines, understanding their unique features, and compared them based on certain criteria. We have:</p><ul><li>Defined what&nbsp;<strong>storage engines</strong>&nbsp;are and their role in MySQL.</li><li>Grasped the features and advantages of the&nbsp;<strong>InnoDB</strong>&nbsp;and&nbsp;<strong>MyISAM</strong>&nbsp;engines.</li><li>Explored other MySQL storage engines like&nbsp;<strong>MEMORY</strong>,&nbsp;<strong>CSV</strong>,&nbsp;<strong>ARCHIVE</strong>, and more.</li><li>Made a comparison of these storage engines to understand their best use-cases.</li><li>Discussed the factors to consider when choosing the right storage engine for your database.</li></ul><p>Let’s test out your understanding before we conclude this series:</p><ol><li><strong>Question 1:</strong>&nbsp;What distinguishes InnoDB from MyISAM, and when might you prefer to use one over the other?</li><li><strong>Question 2:</strong>&nbsp;Describe a situation where you would benefit from using the MEMORY engine.</li><li><strong>Question 3:</strong>&nbsp;If you had a requirement for storing large amounts of log data, which storage engine would you choose, and why?</li><li><strong>Question 4:</strong>&nbsp;Name a few factors you’d consider when choosing a storage engine for your database.</li></ol><p>Please respond to these questions one by one.</p><hr><p><strong>Answer 1:</strong>&nbsp;InnoDB is a storage engine that offers features like ACID-compliant transaction support, row-level locking, and crash recovery. This makes it suitable for write-heavy applications or scenarios that require high data integrity. On the other hand, MyISAM is often used for read-heavy applications because it has faster read capabilities. However, it lacks transaction support and crash safety features.</p><p><strong>Answer 2:</strong>&nbsp;The MEMORY storage engine can be a valuable tool when you’re dealing with temporary data, such as session data. As all data is stored in memory and is faster than disk-based storage, it offers extremely quick access times. However, bear in mind that all data stored with this engine will be lost if the server terminates or crashes.</p><p><strong>Answer 3:</strong>&nbsp;The ARCHIVE storage engine can be a wise choice when dealing with logging data or any large amount of rarely-referenced data. This engine supports compression, which can save a significant amount of storage space.</p><p><strong>Answer 4:</strong>&nbsp;When choosing a storage engine for your database, you might consider factors such as:</p><ul><li>The type of operations your database will be mostly handling (READs or WRITEs).</li><li>Whether transaction support and crash safety mechanisms are required.</li><li>The volume of data and the acceptable access/read-write speed.</li><li>Specific features like full-text indexing or GIS capabilities.</li></ul><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview18/">https://programmerscareer.com/zh-cn/mysql-interview18/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.</p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>My SQL Interview Question: The implementation principle of MySQL MVCC</title>
      <link href="/mysql-interview17/"/>
      <url>/mysql-interview17/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>we can dive into the details of how MySQL implements Multi-Version Concurrency Control (MVCC)</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-Unpacking-MVCC"><a href="#Topic-Unpacking-MVCC" class="headerlink" title="Topic: Unpacking MVCC"></a>Topic: Unpacking MVCC</h1><p>MultiVersion Concurrency Control (MVCC) is a technique used in database management systems to avoid conflicts between users accessing the same data simultaneously, thereby increasing processing efficiency.</p><p>In essence, MVCC allows multiple transactions to access the same data without conflicts or the need for read locks, which can slow down performance significantly. This is achieved by creating a “snapshot” of the data at the point a transaction begins. Other transactions happening concurrently won’t affect this snapshot.</p><p>Now, let’s break down the term MVCC:</p><ul><li><strong>MultiVersion</strong>: This suggests that the database maintains several versions of the same record. The “version” is a snapshot of the data at a certain point in time.</li><li><strong>Concurrency Control</strong>: This implies that the technique is used to handle simultaneous transactions without conflict, ensuring that each transaction maintains the illusion that it’s the only one accessing the database.</li></ul><p>MySQL implements MVCC in its InnoDB storage engine. When a transaction updates a row in InnoDB, the original row is not immediately overwritten or deleted. Instead, InnoDB stores the old version of the row internally for any other active transactions that need to see the original version. This is how “versions” of data rows come into existence.</p><p>So, why do we use MVCC in a system like MySQL? Primarily, it’s for performance reasons. By allowing multiple transactions to access the same snapshot of data without conflict, we avoid the need for read locks that can bottleneck the system. In a system where many users might be querying and updating the same database, this can significantly speed up processing times.</p><h1 id="Topic-How-MVCC-works-in-MySQL"><a href="#Topic-How-MVCC-works-in-MySQL" class="headerlink" title="Topic: How MVCC works in MySQL"></a>Topic: How MVCC works in MySQL</h1><p>Let’s now zoom into the internals of how MVCC operates within MySQL.</p><p>When a transaction starts in MySQL (InnoDB), it gets assigned a unique transaction ID. This ID is used to create its view of the database. This view consists of all the committed data up until the time the transaction started, and any changes made by the transaction itself. The transaction can’t see any data modified by other simultaneous transactions, providing a consistent snapshot and ensuring isolation.</p><p>When a row is modified within a transaction, InnoDB won’t overwrite the existing data. Instead, it writes the new row version and maintains the old version in an area called an undo log. This log contains information needed to revert changes if a transaction is rolled back, and it provides older versions of a row to other transactions that might need them.</p><p>Now let’s talk a bit about some related topics: Read Views, Undo Logs, and Purging.</p><p><strong>Read view</strong>&nbsp;is the mechanism InnoDB uses to implement consistent reads, i.e., reading the snapshot of the database corresponding to the point in time when the transaction started.</p><p><strong>Undo logs</strong>&nbsp;are a crucial part of MVCC. As mentioned earlier, when a transaction modifies data, InnoDB writes the new row to the database and stores information necessary to reconstruct the older version of the row in an undo log record. If another transaction needs to see the older version of the row, InnoDB uses the undo log record to reconstruct it.</p><p><strong>Purging</strong>&nbsp;relates to how InnoDB cleans up old versions of a row that are no longer needed by any ongoing transactions. Once all transactions that might need to access an older row version have completed, InnoDB can free space held by this version. This process is referred to as purging.</p><h1 id="Topic-ACID-Properties-and-MVCC"><a href="#Topic-ACID-Properties-and-MVCC" class="headerlink" title="Topic: ACID Properties and MVCC"></a>Topic: ACID Properties and MVCC</h1><p>One of the crucial aspects of any reliable database management system is ensuring that it maintains certain properties defined by the ACID principle, which stands for Atomicity, Consistency, Isolation, and Durability.</p><ol><li><strong>Atomicity</strong>: If a transaction involves multiple operations, atomicity means that either all the operations are executed successfully, or none of them are. There’s no in-between — a transaction can’t be partially complete. If an error happens during any operation in a transaction, the whole transaction is rolled back.</li><li><strong>Consistency</strong>: Consistency means that a transaction should bring the database from one consistent state to another, according to predefined rules. For example, if an account doesn’t have sufficient balance for a withdrawal, the transaction should be rejected to maintain consistency.</li><li><strong>Isolation</strong>: Isolation comes into play when multiple transactions are being executed simultaneously. It means each transaction should behave as if it’s the only one being executed. The intermediate state of a transaction should not be visible to other transactions.</li><li><strong>Durability</strong>: Durability ensures that once a transaction has been committed, it will remain, even in the event of power loss, crashes, or other system errors. In other words, the results of a transaction are permanent.</li></ol><p>Now, how does MVCC (MultiVersion Concurrency Control) relate to the ACID properties? Here’s the connection:</p><p>In the context of MySQL (and more specifically its InnoDB storage engine), MVCC provides isolation and consistency.</p><p><strong>Isolation</strong>&nbsp;is ensured as each transaction works with its snapshot of the data, isolated from the changes made by others. Even if multiple transactions are trying to read and write the same data simultaneously, each will see its consistent snapshot, as if it’s the only transaction happening.</p><p><strong>Consistency</strong>&nbsp;is maintained thanks to the use of undo logs in MVCC. If a transaction fails or is rolled back, the changes made within that transaction can be undone to ensure the database remains in a consistent state. Furthermore, by creating a transaction-specific view of the data, MVCC ensures that the transaction always works with a consistent set of data.</p><h1 id="Topic-Snapshot-Read-and-Current-Read"><a href="#Topic-Snapshot-Read-and-Current-Read" class="headerlink" title="Topic: Snapshot Read and Current Read"></a>Topic: Snapshot Read and Current Read</h1><p>In MySQL, there are two main types of reads that are utilized when MVCC (MultiVersion Concurrency Control) comes into play: snapshot read and current read. Let’s dive into these concepts.</p><p><strong>Snapshot Read</strong></p><p>A snapshot read, as the name suggests, provides a consistent snapshot of the data as it was when the transaction started. It doesn’t see changes made by other concurrently executing transactions. This read is the default mode for&nbsp;<code>SELECT</code>&nbsp;statements when&nbsp;<em>not</em>&nbsp;in&nbsp;<code>LOCK IN SHARE MODE</code>&nbsp;or&nbsp;<code>FOR UPDATE</code>&nbsp;modes. Snapshot read is crucial in providing the “consistent view” of data which is integral to the concept of MVCC.</p><p><strong>Current Read</strong></p><p>Unlike a snapshot read, a current read sees the latest committed data, including changes made by other transactions. Modes like&nbsp;<code>SELECT…FOR UPDATE</code>&nbsp;and&nbsp;<code>SELECT…LOCK IN SHARE MODE</code>&nbsp;use current reads. It’s also used when a query modifies data (like&nbsp;<code>UPDATE</code>,&nbsp;<code>INSERT</code>,&nbsp;<code>DELETE</code>).</p><p>These two types of reads offer flexible ways of handling data in transactions. The use of snapshot read or current read depends on whether you want a transaction to see only the data as it was when the transaction began, or if it needs to see the latest data, including modifications made by other transactions.</p><h1 id="Topic-Managing-Deadlocks-with-MVCC"><a href="#Topic-Managing-Deadlocks-with-MVCC" class="headerlink" title="Topic: Managing Deadlocks with MVCC"></a>Topic: Managing Deadlocks with MVCC</h1><p>Now that we’ve explored the snapshot and current reads in MySQL’s MVCC, let’s understand another critical aspect of transaction handling — dealing with deadlocks.</p><p>A deadlock happens when two or more transactions mutually hold and request for locks, creating a cyclic dependency that can’t be resolved. Without intervention, these transactions could wait indefinitely, which is obviously not ideal.</p><p>MySQL handles deadlocks in MVCC by utilizing a wait-for graph. In layman’s terms, whenever transaction A waits for transaction B to release a row lock, an edge is added from A to B in the wait-for graph. If adding this edge creates a cycle, a deadlock is detected.</p><p>Upon detecting a deadlock, MySQL needs to resolve it. It does so by choosing a transaction as the ‘victim’ and rolling it back. In most cases, it chooses the one that has done the least amount of work, so less work is lost. After rolling back the victim transaction, the deadlock is resolved.</p><p>In MySQL, you can use&nbsp;<code>SHOW ENGINE INNODB STATUS;</code>&nbsp;to get information about the most recent deadlock, which can aid in debugging.</p><p>Deadlock management, while mostly automatic, demands caution on the design and execution of transactions. It’s advisable to keep transactions as short as possible and commit them as soon as possible to minimize the chances of deadlocks.</p><h1 id="Topic-Performance-Implications-of-MVCC"><a href="#Topic-Performance-Implications-of-MVCC" class="headerlink" title="Topic: Performance Implications of MVCC"></a>Topic: Performance Implications of MVCC</h1><p>Despite all the benefits that MultiVersion Concurrency Control underpins in MySQL, it’s important to recognize that MVCC isn’t without its performance trade-offs. Let’s delve into some of these:</p><ol><li><strong>Disk Space</strong>: One of the main overheads of MVCC is increased disk space. Because MVCC keeps different versions of a row to provide isolated, consistent views to transactions, more disk space is required. This could be significant in heavy read-write mixed workloads.</li><li><strong>CPU and I/O Resources</strong>: The process of producing multiple versions of data, maintaining them, and removing unnecessary versions (purging) can put a burden on CPU and I/O resources.</li><li><strong>Locking Overhead</strong>: While MVCC reduces the need for locking, it does not eliminate it entirely, especially for write transactions (Inserts, Updates, Deletes). These locks add to the performance overhead.</li><li><strong>Increased Complexity</strong>: MVCC adds complexity to the database engine. It needs to manage multiple versions of data, handle undos, resolve conflicts, and clean up old versions. This complexity adds overhead to the overall performance.</li></ol><p>When might you consider alternative methods to MVCC?</p><p>While MVCC offers excellent benefits regarding multi-user access, it might not be the perfect choice in specific scenarios. For instance, in cases where data is largely written once and read many times, like a logging application, it might be better to consider a storage engine like MyISAM which does not support MVCC.</p><p>Additionally, in applications where you want the absolute latest data, you can also look into other approaches since MVCC provides a “snapshot” of the data, not the latest version.</p><p>It’s necessary to understand the workload, performance expectations, and hardware resources available before making a decision regarding the use of MVCC.</p><h1 id="Topic-Review-and-Assessments"><a href="#Topic-Review-and-Assessments" class="headerlink" title="Topic: Review and Assessments"></a>Topic: Review and Assessments</h1><p>Now that we’ve explored different aspects of MultiVersion Concurrency Control (MVCC) in MySQL, it’s time to recap some of the key takeaways:</p><ol><li><strong>MVCC is a method used in database management systems to handle concurrent transactions.</strong></li><li><strong>MVCC provides each transaction a ‘snapshot’ of the database, allowing multiple transactions to read (and write to) a single data item simultaneously</strong>, which dramatically improves the database’s performance and scalability.</li><li><strong>Snapshot and current read are two critical concepts in MySQL’s MVCC</strong>. Snapshot read gives a consistent view of the data as of the transaction start, and current read considers the latest committed data.</li><li><strong>The ACID properties in databases are closely related to MVCC</strong>, ensuring Atomicity, Consistency, Isolation, and Durability of transactions.</li><li><strong>MVCC helps in managing deadlocks in MySQL</strong>, which are situations where two transactions wait for each other to release resources.</li><li><strong>While MVCC offers several advantages, it’s not without some performance trade-offs, such as increased disk space and CPU usage.</strong></li></ol><p>These are some of the many aspects we’ve covered about MVCC in MySQL. With that, it’s now time to assess your understanding of the topic. Consider the following questions:</p><ul><li>How does MVCC improve concurrent transactions in MySQL?</li><li>What’s the difference between snapshot read and current read in MySQL’s MVCC?</li><li>How does MVCC in MySQL manage deadlocks?</li><li>Can you explain the performance implications that come with using MVCC?</li></ul><p>Reflect on these questions. You can write down your responses or simply think through them for self-evaluation.</p><hr><ol><li>MVCC improves concurrent transactions by allowing multiple users to access the same row of a table at the same time, instead of locking the data entirely. Each transaction gets a “snapshot” of the data at the point the transaction began, ensuring a consistent state of the data is used throughout the transaction.</li><li>Snapshot read and current read in MySQL’s MVCC are two different isolation levels for reading data. A snapshot read refers to the consistent read of the database state at the time the transaction starts, ensuring data consistency for that transaction. A current read, on the other hand, is a type of read where the most recent committed data (including those made by other transactions) is considered.</li><li>MVCC manages deadlocks through a wait-for graph. When a transaction is waiting for a resource locked by another transaction, an edge is added to the wait-for graph. If adding this edge creates a cycle, a deadlock is detected. MySQL then chooses a transaction to be the ‘victim’ and rolls it back to resolve the deadlock.</li><li>MVCC is associated with some performance trade-offs. It requires additional disk space to keep multiple versions of each row in a table. Additional CPU and I/O resources are used for managing these versions, handling undo operations, and cleaning up old row versions. The complexity of MVCC handling can also add to the overhead in the overall performance.</li></ol><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview17/">https://programmerscareer.com/zh-cn/mysql-interview17/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.</p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL Interview Question: When to split databases and when to split tables?</title>
      <link href="/mysql-interview16/"/>
      <url>/mysql-interview16/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Let’s outline a curriculum for splitting databases and tables in MySQL</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-Understanding-Data-Distribution"><a href="#Topic-Understanding-Data-Distribution" class="headerlink" title="Topic: Understanding Data Distribution"></a>Topic: Understanding Data Distribution</h1><p>Hi, we’ll be starting our understanding of data distribution in this lesson. First and foremost, let’s get clarified about what we mean by ‘data distribution’.</p><p>Data distribution is the method of allocating data, computational tasks, and applications across multiple computers in a network. Distributing the data across multiple servers can improve the performance, reliability, and accessibility of applications. 😊</p><p>There are various reasons behind data distribution. Let me take you through some of the key advantages of it:</p><p><strong>Improved Performance:</strong>&nbsp;By distributing your data, you can improve the speed at which your application accesses this data. If done efficiently, data distribution can ensure that the resources are located close to where they are needed most, thereby reducing access latency and improving speed.</p><p><strong>Redundancy and Reliability:</strong>&nbsp;Through data distribution, multiple copies of the same data can be stored in different locations. This provides redundancy and increases the overall reliability of your data. If one server fails, your application can access the same data from a different server.</p><p><strong>Scalability:</strong>&nbsp;As your business or application grows, data distribution can make it easier to scale up your infrastructure. New servers can be added to the network as and when required.</p><p><strong>Load Balancing:</strong>&nbsp;Properly distributing data can help maintain a balanced load across servers. This ensures no single server becomes a bottleneck, affecting the performance of your applications.</p><p>There are many ways to distribute data, such as horizontal partitioning (also known as sharding), vertical partitioning, and functional partitioning. Each method has its own pros and cons and is suitable for different types of applications. We will be exploring these in depth in the upcoming lessons.</p><h1 id="Topic-Database-Splitting-Sharding-in-MySQL"><a href="#Topic-Database-Splitting-Sharding-in-MySQL" class="headerlink" title="Topic: Database Splitting (Sharding) in MySQL"></a>Topic: Database Splitting (Sharding) in MySQL</h1><p>I’m glad to see you’re eager to learn more! Now that we’ve explored the concept of data distribution, let’s delve into the fascinating process of database splitting, more commonly known as&nbsp;<strong>Sharding</strong>.</p><p>Sharding in MySQL is a process in which we break down a larger database into smaller, more manageable parts, called shards. Each shard holds a portion of the total data and functions as a separate database.</p><p>To illustrate, visualize a big book split into separate chapters, where each chapter can stand on its own and store unique information. Similarly, when we shard a database, it’s like splitting a huge database into ‘chapters,’ with each one housing unique data.</p><p>Now, why would we do that? 🤔 Sharding is generally implemented for a few reasons:</p><p><strong>Improved Performance:</strong>&nbsp;Sharding can greatly enhance read/write speeds. When you fire off a query, instead of sifting through a massive database, it only has to search a specific shard, drastically improving speed.</p><p><strong>Scalability:</strong>&nbsp;Sharding makes your database horizontally scalable. If your app grows and the database starts getting too large for a single server, you can always add more shards.</p><p><strong>Reliability:</strong>&nbsp;If one shard goes down, it won’t bring your entire application down with it. The rest of the shards will continue to work without any hitches.</p><p>While sharding has its manifold benefits, it also comes with some cons:</p><p><strong>Increased Complexity:</strong>&nbsp;The overall architecture of your database environment becomes more complicated.</p><p><strong>Data Distribution:</strong>&nbsp;You have to decide how to distribute your data, which can be challenging.</p><p><strong>Joining Data across Shards:</strong>&nbsp;If you want to join tables that reside on different shards, it might be complicated or slow.</p><p>In MySQL, sharding is typically done at the application level using sharding libraries or frameworks. Some of the popular sharding algorithms used are Range-Based, List-Based, Hash-Based, and Directory-Based sharding.</p><h1 id="Topic-Table-Splitting-Partitioning-in-MySQL"><a href="#Topic-Table-Splitting-Partitioning-in-MySQL" class="headerlink" title="Topic: Table Splitting (Partitioning) in MySQL"></a><strong>Topic: Table Splitting (Partitioning) in MySQL</strong></h1><p>If you recall, earlier we discussed data distribution and why you might want to split database into multiple, smaller parts, a process known as sharding.</p><p>In a similar sentiment, table partitioning is a way to divide a large table into smaller, more manageable parts, while still being able to access and manipulate the data as if the partitioned table were a single entity. In other words, even though the data is stored in separate partitions, from a user perspective, it’s as if there’s only one table. Neat, right?</p><p>Now,&nbsp;<strong>when would this come handy?</strong>&nbsp;😊</p><p>Partitioning can be the way to go if you have a massive table that results in slow queries and updates, especially if that table is expected to grow beyond the capacity of a single server.</p><p>In its essence, partitioning is about managing and optimizing data for improved performance. Employing partitioning when it’s uncalled for may lead unwanted complexity.</p><p>MySQL provides four different types of partitioning:</p><p><strong>1. RANGE Partitioning:</strong>&nbsp;This is the simplest type of partitioning. It works best when dealing with data that falls into certain ranges — like dates or quantities.</p><p><strong>2. LIST Partitioning:</strong>&nbsp;It partitions table based on the predefined list of values.</p><p><strong>3. HASH Partitioning:</strong>&nbsp;Here, MySQL applies a hash function on the partitioning key to ascertain the partition to be used. It’s used when you want to ensure data is spread evenly across a specified number of partitions.</p><p><strong>4. KEY Partitioning:</strong>&nbsp;It’s similar to hash partitioning, but in this case, MySQL server takes care of calculating the hash value in an internal way, which user can’t control.</p><p>So, that’s the theory, in the next lessons we’ll talk about how you can implement these principles in MySQL and I’ll provide some real-life examples to help illustrate this concept.</p><h1 id="Topic-Practical-Examples-in-Database-and-Table-Splitting"><a href="#Topic-Practical-Examples-in-Database-and-Table-Splitting" class="headerlink" title="Topic: Practical Examples in Database and Table Splitting"></a><strong>Topic: Practical Examples in Database and Table Splitting</strong></h1><p>Great! Now that we’ve discussed the theory of database sharding and table partitioning, let’s put it into practice with some hands-on examples.</p><p><strong>Example 1: Database Sharding</strong><br>Suppose we have an e-commerce website with a global user base and the customer data is expanding rapidly. We can create a shard for each geographical region: North America, Europe, Asia, etc. Each region’s database shard would store only the data associated with the customers located in that region. This way, we’re improving performance by localizing data and queries.</p><p><strong>Example 2: Table Partitioning</strong><br>In the case of our e-commerce site, consider a situation where we have millions of orders, and most queries are for recent orders. We can choose to partition the Orders table by date, keeping data for each month in a separate partition. With this, queries for specific periods would only need to scan fewer rows and perform much faster.</p><p>But how these are implemented practically?</p><p>For database sharding in MySQL, there are various sharding frameworks available like Vitess, phpMyAdmin, etc. For instance, in Vitess, you would define a VSchema which includes sharding instructions to auto-shard the desired table.</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">{  </span><br><span class="line">  "sharded": true,  </span><br><span class="line">  "vindexes": {  </span><br><span class="line">    "hash": {  </span><br><span class="line">      "type": "hash"  </span><br><span class="line">    }  </span><br><span class="line">  },  </span><br><span class="line">  "tables": {  </span><br><span class="line">    "your_table": {  </span><br><span class="line">      "column_vindexes": [  </span><br><span class="line">        {  </span><br><span class="line">          "column": "your_shard_column",  </span><br><span class="line">          "name": "hash"  </span><br><span class="line">        }  </span><br><span class="line">      ]  </span><br><span class="line">    }  </span><br><span class="line">  }  </span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>As for partitioning a table in MySQL, it can be done by ALTER TABLE command.</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE orders  </span><br><span class="line">PARTITION BY RANGE( YEAR(order_date) )  </span><br><span class="line">(  </span><br><span class="line">  PARTITION p0 VALUES LESS THAN (1990),  </span><br><span class="line">  PARTITION p1 VALUES LESS THAN (2000),  </span><br><span class="line">  PARTITION p2 VALUES LESS THAN (2010),  </span><br><span class="line">  PARTITION p3 VALUES LESS THAN (2020),  </span><br><span class="line">  PARTITION p4 VALUES LESS THAN MAXVALUE  </span><br><span class="line">);</span><br></pre></td></tr></tbody></table></figure><p>In this script, we partition the ‘orders’ table based on the ‘order_date’ column.</p><p>Remember, these processes are normally handled by your application or a framework, thus some knowledge of SQL is required. Also, both sharding and partitioning come with their complexities and should only be used when the benefits outweigh these complexities.</p><h1 id="Topic-Making-an-Informed-Decision"><a href="#Topic-Making-an-Informed-Decision" class="headerlink" title="Topic: Making an Informed Decision"></a><strong>Topic: Making an Informed Decision</strong></h1><p>We’ve covered a lot of ground at this point, and last but not least, we’ll discuss how you can make an educated decision on when to split databases or tables, reiterating some key points from previous lessons as well as a few additional tips.</p><p>Here are some factors to consider:</p><p><strong>Database Sharding (Splitting) Decision Making:</strong></p><ol><li><strong>Data Size</strong>: If your database is becoming too large to handle efficiently, it might be time to consider sharding.</li><li><strong>Performance</strong>: If frequent queries are significantly slowing down due to the large size of the database, sharding can help improve the processing speed by reducing the amount of data each query needs to process.</li><li><strong>Scalability</strong>: If you foresee your database growing beyond the capacity of a single server, implementing sharding from an early phase can be a good preventative measure.</li><li><strong>Type of Data</strong>: Sharding can also be driven by the nature of data. For example, multi-tenant applications where data from many customers is stored in the same database is a perfect candidate for sharding.</li></ol><p><strong>Table Partitioning Decision Making:</strong></p><ol><li><strong>Table Size</strong>: Just like with database sharding, if a table in your database is growing endlessly, you might want to consider partitioning it.</li><li><strong>Query Performance</strong>: If the majority of the queries against a table only deal with a segment of the data (e.g., the most recent entries), partitioning can speed up these queries significantly.</li><li><strong>Maintenance</strong>: Partitioning also makes it easier to perform maintenance on a table (like backups, updates, and deletes) as these operations can be performed on individual partitions instead of the tabling the entire table offline.</li></ol><p>In essence, the decision to partition or shard should be made based on the need to improve performance, handle large amounts of data, or both. That said, it’s not a decision to be taken lightly as it adds complexity to your database structure and application logic. It should only be implemented when necessary and other simpler optimization techniques are no longer sufficient.</p><h1 id="Topic-Review-and-Assessments"><a href="#Topic-Review-and-Assessments" class="headerlink" title="Topic: Review and Assessments"></a><strong>Topic: Review and Assessments</strong></h1><p>At this point, we have completed our journey through data distribution, specifically focusing on Database Splitting (Sharding) and Table Splitting (Partitioning) in MySQL. Now, let’s take a quick look back at the key points and then move on to an assessment to consolidate your learning.</p><p><strong>Key Points</strong></p><ol><li>Understanding Data Distribution: Data distribution has significant performance benefits but can also increase complexity. Knowing when and how to use it is crucial.</li><li>Database Splitting (Sharding) in MySQL: Sharding in MySQL involves splitting a database into smaller parts based on a key. It can significantly improve query response time, increase reliability, and facilitate horizontal scalability.</li><li>Table Splitting (Partitioning) in MySQL: Partitioning in MySQL involves breaking a table into smaller pieces without having to change SQL queries. The partitioning can be done based on various strategies like ranges, list values, hash values, etc.</li><li>Practical Examples: We discussed how database sharding might be implemented for an e-commerce site with a global customer base, and how table partitioning can be used to improve performance for frequently accessed recent data.</li><li>Making an Informed Decision: Deciding when to implement database sharding or table partitioning should consider data size, query performance, scalability, and type of data.</li></ol><p>Let’s now move to the assessment. You’ll be presented with a couple of scenarios, and your task is to decide whether to use sharding, partitioning, both, or none, and why.</p><p><strong>Assessment Scenarios</strong></p><ol><li>Scenario 1: You’re designing an application for a hospital, where you have a&nbsp;<code>patients</code>&nbsp;table storing patient records. The hospital sees thousands of patients each year, and on average, a patient visits once a year. Most queries involve accessing only recent patient records. Would you implement sharding, partitioning, both or none, and why?</li><li>Scenario 2: You’re developing an application for a tech news website where articles are often updated for corrections, and new information and user comments are constantly being written. The comments are stored in a&nbsp;<code>comments</code>&nbsp;table, and each comment is associated with an article. Would you implement sharding, partitioning, both or none, and why?</li><li>Scenario 3: You’re working on an e-commerce site that handles transactions from all over the world. The database includes a&nbsp;<code>transactions</code>&nbsp;table, holding details of every transaction ever made on the site. Should you implement sharding, partitioning, both, or none, and why?</li></ol><hr><ol><li><strong>Scenario 1</strong>: Given the scenario, it makes sense to implement&nbsp;<strong>table partitioning</strong>&nbsp;on the&nbsp;<code>patients</code>&nbsp;table. The queries involve accessing only recent patient records, and partitioning would allow for efficient query performance. Sharding might not be necessary as we do not have a clear shard key, and managing distributed transactions and maintaining consistency among shards might add unnecessary complexity.</li><li><strong>Scenario 2</strong>: In this scenario, a proper solution may be to partition the&nbsp;<code>comments</code>&nbsp;table. A date-based partitioning system might work well here, as comments related to older articles are probably read frequently, but not updated that much. Sharding might be overkill for this situation as it could add unnecessary complexity.</li><li><strong>Scenario 3</strong>: Sharding the&nbsp;<code>transactions</code>&nbsp;table would be beneficial here, especially on something like the location of the transaction. This would enable transactions from the same region to be grouped together, which could lead to more efficient querying. Furthermore, sharding can also help balance the load across multiple databases which provides additional benefits in terms of scalability and performance. In addition to sharding, you might also consider partitioning of individual shards.</li></ol><p>These are the preferred solutions based on the information provided. However, every application can have unique requirements and constraints, and it’s crucial to consider all factors when making design decisions. Remember, measure before you optimize!</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview16/">https://programmerscareer.com/zh-cn/mysql-interview16/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.</p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Common(20+) Software Interview Questions(+ Answers) about MySQL/Redis/Kafka</title>
      <link href="/software-interview-set/"/>
      <url>/software-interview-set/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>a collection of software interview questions&nbsp;about MySQL/Redis/Kafka, and this article updated on an ongoing basis</p><span id="more"></span><blockquote class="colorquote success"><p><strong>If it really helps you, Buy me a coffee for my HARD work, that will motivate me to create more. :D</strong><br><a href="https://ko-fi.com/programmerscareer">Buy Me a Coffee</a>  </p></blockquote><p>MySQL Interviews: Why does MySQL use B+ trees for&nbsp;indexing？ <a href="https://programmerscareer.com/mysql-interview4/">https://programmerscareer.com/mysql-interview4/</a></p><p>MySQL Interviews: MySQL interviews: What are the transaction isolation levels? What are the tradeoffs? <a href="https://programmerscareer.com/mysql-interview15/">https://programmerscareer.com/mysql-interview15/</a></p><p>MySQL Interviews: What are database transactions and why does MySQL use InnoDB as the default option <a href="https://programmerscareer.com/mysql-interview14/">https://programmerscareer.com/mysql-interview14/</a></p><p>MySQL Interviews: Briefly describe the difference between optimistic locks and pessimistic locks and the usage scenarios <a href="https://programmerscareer.com/mysql-interview5/">https://programmerscareer.com/mysql-interview5/</a></p><p>MySQL Interviews: What are the necessary conditions for a deadlock to occur? How do I resolve deadlocks? <a href="https://programmerscareer.com/mysql-interview6/">https://programmerscareer.com/mysql-interview6/</a></p><p>Redis Interviews: How many data structures does Redis have? How is Zset implemented? <a href="https://programmerscareer.com/redis-interview6/">https://programmerscareer.com/redis-interview6/</a></p><p>MySQL Interviews: What is the difference between a clustered index and a non-clustered index? <a href="https://programmerscareer.com/mysql-interview13/">https://programmerscareer.com/mysql-interview13/</a></p><p>MySQL Interviews: Briefly describe the occurrence scenarios of dirty reading and phantom reading. How does InnoDB solve phantom reading? <a href="https://programmerscareer.com/mysql-interview12/">https://programmerscareer.com/mysql-interview12/</a></p><p>MySQL Interviews: What is the difference between a unique index and a normal index? What are the advantages and disadvantages of using indexes? <a href="https://programmerscareer.com/mysql-interview11/">https://programmerscareer.com/mysql-interview11/</a></p><p>Redis Interviews: Briefly describe the advantages and disadvantages of RDB and AOF schemes in Redis persistence <a href="https://programmerscareer.com/redis-interview5/">https://programmerscareer.com/redis-interview5/</a></p><p>MySQL Interviews: Briefly describe gap locks in MySQL <a href="https://programmerscareer.com/mysql-interview10/">https://programmerscareer.com/mysql-interview10/</a></p><p>Redis Interviews: How to implement Distributed Locks with Redis <a href="https://programmerscareer.com/redis-interview2/">https://programmerscareer.com/redis-interview2/</a></p><p>Redis Interviews: How to prevent cache avalanche and cache penetration with Redis <a href="https://programmerscareer.com/redis-interview4/">https://programmerscareer.com/redis-interview4/</a></p><p>MySQL Interviews: How to tune MySQL performance <a href="https://programmerscareer.com/mysql-interview9/">https://programmerscareer.com/mysql-interview9/</a></p><p>MySQL Interviews: Briefly describe the primary/secondary synchronization mechanism of MySQL. What happens if the synchronization fails? <a href="https://programmerscareer.com/mysql-interview1/">https://programmerscareer.com/mysql-interview1/</a></p><p>MySQL Interviews: When doesn’t MySQL use the index? <a href="https://programmerscareer.com/mysql-interview8/">https://programmerscareer.com/mysql-interview8/</a></p><p>MySQL Interviews: What is an SQL injection attack? How can such attacks be prevented? <a href="https://programmerscareer.com/mysql-interview7/">https://programmerscareer.com/mysql-interview7/</a></p><p>MySQL Interviews: What are ACID in a database? <a href="https://programmerscareer.com/mysql-interview2/">https://programmerscareer.com/mysql-interview2/</a></p><p>Redis Interviews: The application and advantages and disadvantages of jump table in Redis <a href="https://programmerscareer.com/redis-interview1/">https://programmerscareer.com/redis-interview1/</a></p><p>Kafka Interviews: How does Kafka send messages reliably? <a href="https://programmerscareer.com/kafka-interview1">https://programmerscareer.com/kafka-interview1</a> /</p><p>MySQL Interviews: How does MySQL design indexes and optimize queries? <a href="https://programmerscareer.com/mysql-interview3/">https://programmerscareer.com/mysql-interview3/</a></p><p>Redis Interviews: If the Redis master node is down, how do you recover the data? <a href="https://programmerscareer.com/redis-interview3/">https://programmerscareer.com/redis-interview3/</a></p><p>MySQL Interviews: Suppose to create a composite index (a, b, c) If you query fields A and c, will this composite index be used? <a href="https://programmerscareer.com/redis-interview19/">https://programmerscareer.com/redis-interview19/</a></p><p>MySQL Interviews: What are the common storage engines for MySQL? What’s the difference? <a href="https://programmerscareer.com/redis-interview18/">https://programmerscareer.com/redis-interview18/</a></p><p>MySQL Interviews: The implementation principle of MySQL MVCC <a href="https://programmerscareer.com/redis-interview17/">https://programmerscareer.com/redis-interview17/</a></p><p>MySQL Interviews: When to split databases and when to split tables? <a href="https://programmerscareer.com/redis-interview16/">https://programmerscareer.com/redis-interview16/</a></p><blockquote class="colorquote success"><p><strong>If it really helps you, Buy me a coffee for my HARD work, that will motivate me to create more. :D</strong><br><a href="https://ko-fi.com/programmerscareer">Buy Me a Coffee</a>  </p></blockquote><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote><!--/plan learn Redis about below in topics, Please add a topic named "Review and Assessments" and put it at the end:  If the Redis master node is down, how do you recover the data?--></body></html>]]></content>
      
      
      <categories>
          
          <category> set </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Syntactic Sugars that You Should Know in Golang</title>
      <link href="/golang-syntactic-sugar/"/>
      <url>/golang-syntactic-sugar/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Exploring Syntactic Sugars in Go: A Comprehensive Guide</p><span id="more"></span><blockquote class="colorquote success"><p>Walking with a friend in the dark is better than walking alone in the light.<br> — Helen Keller  </p></blockquote>  <blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/golang-syntactic-sugar/">https://programmerscareer.com/zh-cn/golang-syntactic-sugar/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote><!-- --><h2 id="Introduction-to-Syntax-Sugars-in-Go"><a href="#Introduction-to-Syntax-Sugars-in-Go" class="headerlink" title="Introduction to Syntax Sugars in Go"></a>Introduction to Syntax Sugars in Go</h2><p>Before I get into the specifics of syntactic sugar, let me explain to you what syntactic sugar is.</p><p>In computer science, “syntactic sugar” refers to a programming syntax that is internally transformed into a base syntax in order to make a program easier to read or express. In other words, this syntax does not introduce new features, but rather provides a more convenient way of programming.</p><p><strong>Golang</strong>, being a modern language, contains a lot of syntactic sugar to ease the programmer’s burden and make the code more readable.</p><p>For example, many high-level programming languages have the <code>++</code> operator, which is syntactic sugar used to increment the value of a variable by 1. Thus, instead of <code>i = i + 1</code>, we can type <code>i++</code>, which is shorter and faster to type, and which expresses the same incremental operation.</p><p>Next we’ll go through the common syntactic sugars in Golang, detailing each one. This will help you understand and use Golang better and write more compact and readable code.</p><p>Of course, the goal is not only to learn these features, but also to understand when and why to use them. A responsible Go developer knows not only how to utilize these syntactic sugars, but also when it is appropriate to use them.</p><h2 id="Variadic-Parameters"><a href="#Variadic-Parameters" class="headerlink" title="Variadic Parameters"></a>Variadic Parameters</h2><h3 id="Basic-Introduction"><a href="#Basic-Introduction" class="headerlink" title="Basic Introduction"></a>Basic Introduction</h3><p>Go allows a function to take any number of values as arguments, and Go provides the … operator to be used only at the end of a function’s parameter list. When using this operator, you should be aware of the following points:</p><ul><li>A function can have at most one variadic parameter;</li><li>The type of a variadic parameter is always a slice type;</li><li>The last parameter of a function can be a variadic parameter.</li></ul><h3 id="Declaration-and-Calling"><a href="#Declaration-and-Calling" class="headerlink" title="Declaration and Calling"></a>Declaration and Calling</h3><p>The declaration of a variadic function is similar to that of a regular function, except that the last parameter must be a variadic parameter. <strong>In the function body, a variadic parameter is treated as a slice.</strong></p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">SumData</span><span class="hljs-params">(values …<span class="hljs-type">int64</span>)</span></span> (sum <span class="hljs-type">int64</span>) {</span><br><span class="line"><span class="hljs-comment">// Type of values is []int64.</span></span><br><span class="line">sum = <span class="hljs-number">0</span></span><br><span class="line"><span class="hljs-keyword">for</span> _, v := <span class="hljs-keyword">range</span> values {</span><br><span class="line">sum += v</span><br><span class="line">}</span><br><span class="line"><span class="hljs-keyword">return</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>When calling a variadic function, you can use two styles to pass arguments to a variadic parameter of type <code>[]T</code>:</p><blockquote><p><strong>1. Pass a slice as an argument</strong>. This slice must be assignable to a value of type <code>[]T</code> (or can be implicitly converted to type <code>[]T</code>). <strong>Following this argument, there must be three dots ‘…’</strong>.<br><strong>2. Pass zero or more arguments that can be implicitly converted to type T</strong> (or can be assigned to a value of type T). <strong>These arguments will be added to an anonymous slice of type <code>[]T</code> that is created at runtime, and then this slice will be passed as an argument to the function call</strong>.</p></blockquote><p>Note that you cannot mix these two styles of argument passing in the same variadic function call.</p><p>Note that you cannot mix these two styles of argument passing in the same variadic function call.</p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> {</span><br><span class="line">a0 := SumData()</span><br><span class="line">a1 := SumData(<span class="hljs-number">3</span>)</span><br><span class="line">a3 := SumData(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">8</span>)</span><br><span class="line"><span class="hljs-comment">// The top three lines are equivalent to the bottom three lines.</span></span><br><span class="line">b0 := SumData([]<span class="hljs-type">int64</span>{})…</span><br><span class="line">b1 := SumData([]<span class="hljs-type">int64</span>{<span class="hljs-number">2</span>})…</span><br><span class="line">b3 := SumData([]<span class="hljs-type">int64</span>{<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>})…</span><br><span class="line">fmt.Println(a0, a1, a3)</span><br><span class="line">fmt.Println(b0, b1, b3)</span><br><span class="line">}</span><br><span class="line"><span class="hljs-comment">// print</span></span><br><span class="line"><span class="hljs-comment">// 0 3 15</span></span><br><span class="line"><span class="hljs-comment">// 0 3 15</span></span><br></pre></td></tr></tbody></table></figure><p>The <code>Print</code>、<code>Println</code> and <code>Printf</code> functions in the <code>fmt</code> standard library package are all variadic functions. Their declarations are roughly as follows:</p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Print</span><span class="hljs-params">(a …<span class="hljs-keyword">interface</span>{})</span></span> (n <span class="hljs-type">int</span>, err <span class="hljs-type">error</span>)  </span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Printf</span><span class="hljs-params">(format <span class="hljs-type">string</span>, a …<span class="hljs-keyword">interface</span>{})</span></span> (n <span class="hljs-type">int</span>, err <span class="hljs-type">error</span>)  </span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Println</span><span class="hljs-params">(a …<span class="hljs-keyword">interface</span>{})</span></span> (n <span class="hljs-type">int</span>, err <span class="hljs-type">error</span>)</span><br></pre></td></tr></tbody></table></figure><h2 id="Ignoring-Unnecessary-Information"><a href="#Ignoring-Unnecessary-Information" class="headerlink" title="Ignoring Unnecessary Information"></a>Ignoring Unnecessary Information</h2><p>We want to initialize the <code>init</code> function in a package but do not want to use any of the methods in the package. In this case, we can use the <code>_</code> operator to rename the import of an unused package:</p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> _ <span class="hljs-string">"github.com/tfrain"</span></span><br></pre></td></tr></tbody></table></figure><p>Sometimes we don’t necessarily use the return values of a function, and we have to come up with a creative name for it. Is there a way to handle unnecessary return values? Of course, we can use the <code>_</code> operator to assign the unwanted values to a blank identifier, which allows us to ignore them:</p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_, ok := test(a, b <span class="hljs-type">int</span>)</span><br></pre></td></tr></tbody></table></figure><ol><li>Sometimes we want to exclude certain fields from serialization in JSON. The <code>-</code> operator can help us with this. Go structures provide a labeling feature, and in the structure tag, we can use the <code>-</code> operator to perform special handling on fields that we don’t want to serialize:</li></ol><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">type</span> Person <span class="hljs-keyword">struct</span> {</span><br><span class="line">Name <span class="hljs-type">string</span> <span class="hljs-string">`json:"-"`</span></span><br><span class="line">Age <span class="hljs-type">string</span> <span class="hljs-string">`json:"age"`</span></span><br><span class="line">Email <span class="hljs-type">string</span> <span class="hljs-string">`json:"email,omitempty"`</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><ol start="2"><li>When we use <code>json.Marshal</code> to serialize a structure, it does not ignore empty values by default. Instead, it outputs the zero value of the field’s type (the zero value of a <code>string</code> type is “”, and the zero value of an object type is <code>nil</code>). If we want to ignore empty fields during serialization, we can add the <code>omitempty</code> attribute to the structure tag:</li></ol><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">type</span> Person <span class="hljs-keyword">struct</span> {</span><br><span class="line">Name <span class="hljs-type">string</span> <span class="hljs-string">`json:"name"`</span></span><br><span class="line">Age <span class="hljs-type">string</span> <span class="hljs-string">`json:"age"`</span></span><br><span class="line">Email <span class="hljs-type">string</span> <span class="hljs-string">`json:"email,omitempty"`</span></span><br><span class="line">Active <span class="hljs-type">bool</span> <span class="hljs-string">`json:"active,omitempty"`</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2 id="Declaration-Statements"><a href="#Declaration-Statements" class="headerlink" title="Declaration Statements"></a>Declaration Statements</h2><h3 id="Short-Variable-Declaration"><a href="#Short-Variable-Declaration" class="headerlink" title="Short Variable Declaration"></a>Short Variable Declaration</h3><p>In some other programming languages, it’s not common to declare variables every time they’re used. In Go, you can declare and initialize local variables using the syntax <code>name := expression</code> instead of using the <code>var</code> statement for declaration. This can reduce the number of steps required for declaration:</p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">var</span> a <span class="hljs-type">int</span> = <span class="hljs-number">10</span></span><br><span class="line">same as</span><br><span class="line">a := <span class="hljs-number">10</span></span><br></pre></td></tr></tbody></table></figure><p>When using short variable declaration, there are two things to note:</p><ul><li>Short variable declaration can only be used inside functions, not for initializing global variables.</li><li>Short variable declaration introduces a new variable, so you can’t declare the same variable again in the same scope.</li><li>When declaring multiple variables using short variable declaration, if one variable is new, you can use short variable declaration, but if all variables are already declared, you can’t declare them again.</li></ul><h3 id="Declaring-Variables-with-Unspecified-Length"><a href="#Declaring-Variables-with-Unspecified-Length" class="headerlink" title="Declaring Variables with Unspecified Length"></a>Declaring Variables with Unspecified Length</h3><p>In Go, arrays usually have a fixed length, and you have to specify the length when declaring the array. However, you can also omit the length and use the <code>…</code> operator to declare arrays. In this case, you just need to fill in the element values, and the compiler will handle the length:</p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a := […]<span class="hljs-type">int</span>{<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>} <span class="hljs-comment">// same as a := [3]int{1, 3, 5}</span></span><br></pre></td></tr></tbody></table></figure><p>When declaring a large array, you can use the <code>…</code> operator to set specific values for some indices:</p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a := […]<span class="hljs-type">int</span>{<span class="hljs-number">1</span>: <span class="hljs-number">20</span>, <span class="hljs-number">999</span>: <span class="hljs-number">10</span>} <span class="hljs-comment">// array length is 1000, index 1 has value 20, index 999 has value 10, other indices have value 0</span></span><br></pre></td></tr></tbody></table></figure><h2 id="Checking-logic"><a href="#Checking-logic" class="headerlink" title="Checking logic"></a>Checking logic</h2><h3 id="Checking-if-a-Key-Exists-in-a-Map-in-Go"><a href="#Checking-if-a-Key-Exists-in-a-Map-in-Go" class="headerlink" title="Checking if a Key Exists in a Map in Go"></a>Checking if a Key Exists in a Map in Go</h3><p>Go provides the syntax <code>value, ok := m[key]</code> to check if a key exists in a map. This syntax is commonly used to only check the <code>ok</code> value. If the key exists, it returns the value associated with the key; otherwise, it returns an empty value:</p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> <span class="hljs-string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> {</span><br><span class="line">dict := <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">int</span>{<span class="hljs-string">"tfrain"</span>: <span class="hljs-number">1</span>}</span><br><span class="line"><span class="hljs-keyword">if</span> value, ok := dict[<span class="hljs-string">"tfrain"</span>]; ok {</span><br><span class="line">fmt.Println(value)</span><br><span class="line">} <span class="hljs-keyword">else</span> {</span><br><span class="line">fmt.Println(<span class="hljs-string">"Key:tfrain not exist"</span>)</span><br><span class="line">}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h3 id="Type-Assertions"><a href="#Type-Assertions" class="headerlink" title="Type Assertions"></a>Type Assertions</h3><p>We often use <code>interface</code> in Go, where there are two types: interfaces with methods and empty interfaces. Since Go 1.18 does not have generics, we can use empty interfaces as a pseudo-generic type. When we use empty interfaces as input parameters or output values, we need to use type assertions to obtain the type we need. In Go, the syntax for type assertions is as follows:</p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">value, ok := x.(T)</span><br></pre></td></tr></tbody></table></figure><p>Here, <code>x</code> is an <code>interface</code> type, and <code>T</code> is a specific type. This syntax requires distinguishing the type of <code>x</code>. If <code>x</code> is an empty interface type:</p><p><strong>The type assertion for empty interface types is essentially a comparison of <code>_type</code> and the type to be matched in <code>eface</code>. If the comparison is successful, the value is assembled in memory and returned. If the comparison fails, the register is cleared, and the default value is returned.</strong></p><p>If <code>x</code> is a non-empty interface type:</p><p><strong>The type assertion for non-empty interface types is essentially a comparison of <code>*itab</code> in <code>iface</code>. If the comparison is successful, the value is assembled in memory and returned. If the comparison fails, the register is cleared, and the default value is returned.</strong></p></body></html>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> code </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>你应该了解的 Golang 的语法糖</title>
      <link href="/zh-cn/golang-syntactic-sugar/"/>
      <url>/zh-cn/golang-syntactic-sugar/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>探索 Go 中的语法糖：综合指南<br><img src="https://images.unsplash.com/photo-1508923567004-3a6b8004f3d7?crop=entropy&amp;cs=srgb&amp;fm=jpg&amp;ixid=M3wzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE3MTUxODY1NzR8&amp;ixlib=rb-4.0.3&amp;q=85&amp;w=500&amp;h=500" alt="photo by Matteo Catanese on Unsplash"></p><span id="more"></span><blockquote class="colorquote success"><p>The free man is he who does not fear to go to the end of his thought.<br> — Léon Blum  </p></blockquote>  <h2 id="Golang-语法糖简介："><a href="#Golang-语法糖简介：" class="headerlink" title="Golang 语法糖简介："></a>Golang 语法糖简介：</h2><pre><code>解释什么是语法糖以及它们在 Golang 中的重要性。</code></pre><p>在计算机科学中，”语法糖”是指一种编程语法，它是为了使程序更易于读或表达，而在内部转化为基础语法。换句话说，这种语法并没有引入新的功能，而是提供了一种更加方便的编程方式。</p><p><strong>Golang</strong>，作为一个现代语言，包含了大量的语法糖来减轻程序员的负担并使代码更可读。</p><p>例如，许多高级编程语言中的 <code>++</code> 操作符，它是语法糖，用于增加变量的值 1。因此，我们可以输入 <code>i++</code> 而不是 <code>i = i + 1</code>，它更短和更快速地输入，并且它表达相同的增量操作。</p><p>接下来我们将会遍历Golang中的常见语法糖，分别详细介绍。这将会帮助你更好的理解和使用Golang，写出更紧凑、可读性更高的代码。</p><p>当然，学习的目标不仅是学习这些特性，更重要的是了解何时和为什么要使用它们。一个负责的 Go 开发人员不仅知道如何利用这些语法糖，还需要知道何时合适地使用它们。</p><h2 id="可变长参数"><a href="#可变长参数" class="headerlink" title="可变长参数"></a>可变长参数</h2><h3 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h3><p><code>Go</code>语言允许一个函数把任意数量的值作为参数，<code>Go</code>语言内置了…操作符，在函数的最后一个形参才能使用，使用它必须注意如下事项：</p><ul><li>一个函数的最后一个参数可以是一个变长参数；</li><li>一个函数可以最多有一个变长参数；</li><li>一个变长参数的类型总为一个切片类型。</li></ul><h3 id="声明和调用"><a href="#声明和调用" class="headerlink" title="声明和调用"></a>声明和调用</h3><p>变长函数声明和普通函数声明类似，只不过最后一个参数必须为变长参数。&nbsp;<strong>一个变长参数在函数体内将被视为一个切片。</strong></p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">SumData</span><span class="hljs-params">(values ...<span class="hljs-type">int64</span>)</span></span> (sum <span class="hljs-type">int64</span>) {</span><br><span class="line"><span class="hljs-comment">// type of values is []int64。</span></span><br><span class="line">sum = <span class="hljs-number">0</span></span><br><span class="line"><span class="hljs-keyword">for</span> _, v := <span class="hljs-keyword">range</span> values {</span><br><span class="line">sum += v</span><br><span class="line">}</span><br><span class="line"><span class="hljs-keyword">return</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>在变长参数函数调用中，可以使用两种风格的方式将实参传递给类型为<code>[]T</code>的变长形参：</p><blockquote><p><strong>1.传递一个切片做为实参</strong>。此切片必须可以被赋值给类型为<code>[]T</code>的值（或者说此切片可以被隐式转换为类型<code>[]T</code>）。&nbsp;**此实参切片后必须跟随三个点<code>…</code>**。<br><strong>2.传递零个或者多个可以被隐式转换为<code>T</code>的实参</strong>（或者说这些实参可以赋值给类型为<code>T</code>的值）。&nbsp;<strong>这些实参将被添加入一个匿名的在运行时刻创建的类型为<code>[]T</code>的切片中</strong>，然后此切片将被传递给此函数调用。</p></blockquote><p>注意，这两种风格的方式不可在同一个变长参数函数调用中混用。</p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> {</span><br><span class="line">a0 := SumData()</span><br><span class="line">a1 := SumData(<span class="hljs-number">3</span>)</span><br><span class="line">a3 := SumData(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">8</span>)</span><br><span class="line"><span class="hljs-comment">// The top three lines are equivalent to the bottom three lines.</span></span><br><span class="line">b0 := SumData([]<span class="hljs-type">int64</span>{}...)</span><br><span class="line">b1 := SumData([]<span class="hljs-type">int64</span>{<span class="hljs-number">2</span>}...)</span><br><span class="line">b3 := SumData([]<span class="hljs-type">int64</span>{<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>}...)</span><br><span class="line">fmt.Println(a0, a1, a3) </span><br><span class="line">fmt.Println(b0, b1, b3) </span><br><span class="line">}</span><br><span class="line"><span class="hljs-comment">// print </span></span><br><span class="line"><span class="hljs-comment">// 0 3 15</span></span><br><span class="line"><span class="hljs-comment">// 0 3 15</span></span><br></pre></td></tr></tbody></table></figure><p><code>fmt</code>标准库包中的<code>Print</code>、<code>Println</code>和<code>Printf</code>函数均为变长参数函数。 它们的声明大致如下：</p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Print</span><span class="hljs-params">(a ...<span class="hljs-keyword">interface</span>{})</span></span> (n <span class="hljs-type">int</span>, err <span class="hljs-type">error</span>)  </span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Printf</span><span class="hljs-params">(format <span class="hljs-type">string</span>, a ...<span class="hljs-keyword">interface</span>{})</span></span> (n <span class="hljs-type">int</span>, err <span class="hljs-type">error</span>)  </span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Println</span><span class="hljs-params">(a ...<span class="hljs-keyword">interface</span>{})</span></span> (n <span class="hljs-type">int</span>, err <span class="hljs-type">error</span>)</span><br></pre></td></tr></tbody></table></figure><h2 id="忽略相关信息"><a href="#忽略相关信息" class="headerlink" title="忽略相关信息"></a>忽略相关信息</h2><p>我们只想初始化包里的<code>init</code>函数，但是不会使用包内的任何方法，这时就可以使用&nbsp;_&nbsp;操作符号重命名导入一个不使用的包：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import&nbsp;_&nbsp;"github.com/tfrain"</span><br></pre></td></tr></tbody></table></figure><p>方法的返回值我们并不一定都使用，还要绞尽脑汁的给他想一个命名，有没有办法可以不处理不要的返回值呢？当然有，还是&nbsp;_&nbsp;操作符，将不需要的值赋给空标识符，就可以忽略：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_,&nbsp;ok&nbsp;:=&nbsp;test(a,&nbsp;b&nbsp;int)</span><br></pre></td></tr></tbody></table></figure><ol><li>有些时候我们想要<code>json</code>里面的某些字段不参加序列化，- 操作符可以帮我们处理，<code>Go</code>语言的结构体提供标签功能，在结构体标签中使用&nbsp;<strong>-</strong>&nbsp; 操作符就可以对不需要序列化的字段做特殊处理:</li><li>我们使用<code>json.Marshal</code>进行序列化时不会忽略<code>struct</code>中的空值，默认输出字段的类型零值（<code>string</code>类型零值是””，对象类型的零值是<code>nil</code>），如果我们想在序列化时忽略掉这些没有值的字段时，可以在结构体标签中中添加<code>omitempty</code>&nbsp;：</li></ol><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">type&nbsp;Person&nbsp;struct{  </span><br><span class="line">&nbsp;&nbsp;Name&nbsp;string&nbsp;   `json:"-"`  </span><br><span class="line">&nbsp;&nbsp;Age&nbsp;string&nbsp;    `json:"age"`  </span><br><span class="line">&nbsp;&nbsp;Email&nbsp;string&nbsp;&nbsp;&nbsp;`json:"email,omitempty"`</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h2 id="声明相关"><a href="#声明相关" class="headerlink" title="声明相关"></a>声明相关</h2><h3 id="短变量声明"><a href="#短变量声明" class="headerlink" title="短变量声明"></a>短变量声明</h3><p>每次使用变量时都要先进行函数声明，对于些其他语言的人来说，并不习惯，那么在<code>Go</code>语言是不是也可以不进行变量声明直接使用呢？我们可以使用&nbsp;<strong>name := expression</strong>&nbsp;的语法形式来声明和初始化局部变量，相比于使用<code>var</code>声明的方式可以减少声明的步骤：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var&nbsp;a&nbsp;int&nbsp;=&nbsp;10  </span><br><span class="line">same as</span><br><span class="line">a&nbsp;:=&nbsp;10</span><br></pre></td></tr></tbody></table></figure><p>使用短变量声明时有两个注释事项：</p><ul><li>短变量声明只能在函数内使用，不能用于初始化全局变量</li><li>短变量声明代表引入一个新的变量，不能在同一作用域重复声明变量</li><li>多变量声明中如果其中一个变量是新变量，那么可以使用短变量声明，否则不可重复声明变量；</li></ul><h3 id="声明不定长数组"><a href="#声明不定长数组" class="headerlink" title="声明不定长数组"></a>声明不定长数组</h3><p>数组一般是有固定长度的，所以我们在声明数组时一般要声明长度，因为数组在编译时就要确认，但也可以不写数组长度，使用…操作符声明数组时，你只管填充元素值，其他的交给编译器自己去搞就好了；</p><p><code>a&nbsp;:=&nbsp;[…]int{1,&nbsp;3,&nbsp;5}&nbsp;//&nbsp;same as&nbsp;a&nbsp;:=&nbsp;[3]{1,&nbsp;3,&nbsp;5}   </code></p><p>有时我们想声明一个大数组，但是某些<code>index</code>想设置特别的值也可以使用…操作符搞定：</p><p><code>a&nbsp;:=&nbsp;[…]int{1:&nbsp;20,&nbsp;999:&nbsp;10}   //&nbsp;数组长度是100,&nbsp;下标1的元素值是20，下标999的元素值是10，其他元素值都是0   </code></p><h2 id="判断相关"><a href="#判断相关" class="headerlink" title="判断相关"></a>判断相关</h2><h3 id="判断map的key是否存在"><a href="#判断map的key是否存在" class="headerlink" title="判断map的key是否存在"></a>判断map的key是否存在</h3><p>Go语言提供语法&nbsp;<code>value, ok := m[key]</code>来判断<code>map</code>中的<code>key</code>是否存在，一般都是只利用ok来进行判断。value如果存在就会返回key所对应的值，不存在就会返回空值：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import&nbsp;"fmt"  </span><br><span class="line">  </span><br><span class="line">func&nbsp;main()&nbsp;{  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;dict&nbsp;:=&nbsp;map[string]int{"tfrain":&nbsp;1}  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;value,&nbsp;ok&nbsp;:=&nbsp;dict["tfrain"];&nbsp;ok&nbsp;{  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fmt.Printf(value)  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fmt.Println("key:tfrain not exist")  </span><br><span class="line">&nbsp;&nbsp;&nbsp;&nbsp;}  </span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h3 id="类型断言"><a href="#类型断言" class="headerlink" title="类型断言"></a>类型断言</h3><p>我们通常都会使用<code>interface</code>，一种是带方法的<code>interface</code>，一种是空的<code>interface</code>，<code>Go1.18</code>之前是没有泛型的，所以我们可以用空的<code>interface{}</code>来作为一种伪泛型使用，当我们使用到空的<code>interface{}</code>作为入参或返回值时，就会使用到类型断言，来获取我们所需要的类型，在Go语言中类型断言的语法格式如下：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">value,&nbsp;ok&nbsp;:=&nbsp;x.(T)</span><br></pre></td></tr></tbody></table></figure><p>x是<code>interface</code>类型，T是具体的类型。这里类型断言需要区分<code>x</code>的类型，<br>如果<code>x</code>是空接口类型：</p><p><strong>空接口类型断言实质是将eface中_type与要匹配的类型进行对比，匹配成功在内存中组装返回值，匹配失败直接清空寄存器，返回默认值。</strong></p><p>如果<code>x</code>是非空接口类型：</p><p>*<em>非空接口类型断言的实质是 iface 中 <em>itab 的对比。</em>itab 匹配成功会在内存中组装返回值。匹配失败直接清空寄存器，返回默认值。</em>*</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/golang-syntactic-sugar/">https://programmerscareer.com/golang-syntactic-sugar/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。</p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> code </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>use-channel</title>
      <link href="/zh-cn/use-channel/"/>
      <url>/zh-cn/use-channel/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><h2 id="单并发控制"><a href="#单并发控制" class="headerlink" title="单并发控制"></a>单并发控制</h2><p>在Go语言中，判断<code>channel</code>是否关闭并不能直接保证<code>channel</code>中的数据已经全部消费完毕。当你从一个<code>channel</code>接收数据时，你会得到两个值：接收到的数据和一个布尔值。布尔值为<code>false</code>时表示<code>channel</code>已经被关闭且没有更多的数据可接收。但是，仅凭这个机制并不能保证在<code>channel</code>关闭时已经消费了所有发送到<code>channel</code>的数据。</p><p>为了确保在关闭<code>channel</code>之前所有的数据都被消费完毕，你需要更细致的控制发送和接收的过程。以下是一个推荐的做法：</p><span id="more"></span><h3 id="使用-for-range-循环和同步原语"><a href="#使用-for-range-循环和同步原语" class="headerlink" title="使用 for range 循环和同步原语"></a>使用 <code>for range</code> 循环和同步原语</h3><ol><li><p><strong>发送端</strong>：发送数据到<code>channel</code>。</p></li><li><p><strong>接收端</strong>：使用<code>for range</code>循环来接收<code>channel</code>上的数据。这个循环会持续接收数据直到<code>channel</code>被关闭。</p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">for</span> msg := <span class="hljs-keyword">range</span> ch {</span><br><span class="line">    <span class="hljs-comment">// 处理msg</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure></li><li><p><strong>同步原语</strong>：使用<code>sync.WaitGroup</code>来确保所有的数据都被发送并且在关闭<code>channel</code>之前都被接收处理。</p><figure class="highlight go hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">var</span> wg sync.WaitGroup</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment">// 发送数据</span></span><br><span class="line"><span class="hljs-keyword">for</span> _, msg := <span class="hljs-keyword">range</span> messages {</span><br><span class="line">    wg.Add(<span class="hljs-number">1</span>)</span><br><span class="line">    <span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(m <span class="hljs-type">string</span>)</span></span> {</span><br><span class="line">        <span class="hljs-keyword">defer</span> wg.Done()</span><br><span class="line">        <span class="hljs-comment">// 发送消息</span></span><br><span class="line">        ch &lt;- m</span><br><span class="line">    }(msg)</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="hljs-comment">// 等待所有消息发送完毕</span></span><br><span class="line">wg.Wait()</span><br><span class="line"><span class="hljs-built_in">close</span>(ch)</span><br></pre></td></tr></tbody></table></figure></li><li><p>**关闭<code>channel</code>**：当所有的数据都被发送并且<code>WaitGroup</code>的计数器归零后，关闭<code>channel</code>。此时，<code>for range</code>循环将退出。</p></li></ol><p>这种方法利用<code>for range</code>循环的特性，在<code>channel</code>关闭后自动结束循环，这确保了在<code>channel</code>关闭之前所有的数据都已经被接收并处理。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul><li>确保在所有数据发送完成后关闭<code>channel</code>。否则，发送到已关闭的<code>channel</code>将会导致panic。</li><li>在多个发送者的情况下，需要小心协调以避免在数据发送完毕之前关闭<code>channel</code>。</li><li>使用<code>sync.WaitGroup</code>时，确保正确地使用<code>Add</code>、<code>Done</code>和<code>Wait</code>方法来避免死锁。</li></ul><p>通过上述方法，你可以确保<code>channel</code>在所有数据都被正确消费后才关闭，这是在并发编程中确保数据完整性的一种有效方式。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> code </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka 面试：Kafka 发送消息是如何保证可靠性的？</title>
      <link href="/zh-cn/kafka-interview1/"/>
      <url>/zh-cn/kafka-interview1/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>你曾被提过类似的问题在面试中问过吗？或者将来会遇到，让我们一起探索和掌握它！</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a>  </p></blockquote><h1 id="主题-1-1-如何理解-Kafka-工作原理？"><a href="#主题-1-1-如何理解-Kafka-工作原理？" class="headerlink" title="主题: 1.1 如何理解 Kafka 工作原理？"></a><strong>主题</strong>: 1.1 如何理解 Kafka 工作原理？</h1><p>Apache Kafka 是 LinkedIn 开源并后来捐赠给 Apache Software Foundation 的实时数据处理软件平台。其目标是为处理实时数据流提供一个统一、高吞吐量、低延迟的平台。它使用 Scala 和 Java 编写。</p><p>Kafka 生态系统包括生产者、消费者、主题、Brokers 和 ZooKeeper：</p><p><strong>生产者</strong>：生产者是将原始消息推送到 Kafka Brokers 的组件。生产者可以将消息发送到特定主题或者让 Kafka 进行路由和负载平衡。</p><p><strong>Brokers</strong>：Kafka Brokers 是系统的核心部分；它们接收生产者发来的消息，分配偏移量并提交消息到磁盘上的存储。</p><p><strong>消费者</strong>：消费者从Brokers读取。然而，与传统的消息系统不同，消费者从Brokers拉取消息。</p><p><strong>主题和分区</strong>：主题是特定类别的消息流。Kafka 主题分割成多个分区，其中包含记录的顺序不可更改的列表。分区允许并行化主题，并将数据分割到多个节点上。</p><p><strong>ZooKeeper</strong>：ZooKeeper 管理和协调 Kafka 集群。ZooKeeper 服务用于维护名称和配置数据，并提供灵活和可靠的同步功能。</p><p>Kafka 的工作原理类似于传递系统。例如，想象一下邮递员（生产者）向特定邮件盒（主题）投递信件（消息）。邮件局（Kafka）排序和维护这些信件，最后，居民（消费者）从邮件盒中提取他们的邮件。</p><h1 id="主题：-1-2-Kafka-生产者"><a href="#主题：-1-2-Kafka-生产者" class="headerlink" title="主题： 1.2 Kafka 生产者"></a><strong>主题</strong>： 1.2 Kafka 生产者</h1><p>Kafka 生产者是负责向 Kafka 主题发布数据（称为记录）的组件。生产者是为了向 Kafka Brokers提供数据的关键组件。</p><p>下面是 Kafka 生产者的工作原理：</p><p><strong>创建生产者</strong>：生产者使用特定的属性创建，例如Brokers的地址、键序列化器和值序列化器。Brokers使用这些属性来识别正确的主题并了解如何解析消息。</p><p><strong>写数据</strong>：创建生产者后，它可以开始发送记录到指定主题。Kafka 记录包含一个键和一个值。这些是字节数组。键是可选的，用于确定特定分区的主题，其中消息将被写入。如果键不存在，Kafka 使用轮询方法写入分区。</p><p><strong>分区</strong>：生产者发布数据到不同的分区，可以采用轮询方法或者语义上的有意义方法。当键为 null 时，数据将按轮询方式写入分区。如果键存在，所有具有该键的消息都将写入同一分区（如果分区数量不变）。</p><p><strong>序列化</strong>：Kafka 消息是字节数组。因此，无论数据格式如何，您必须将其转换为字节，以发送到 Kafka。我们称这个过程为序列化。因此，每次发送记录时，生产者必须将对象转换为字节。</p><p><strong>确认和重试</strong>：在分布式系统中，机器会失败。Kafka 提供了确认和重试的机制。Kafka 可以设置为在写入领导者（ack=1）、所有追随者（ack=all）或者不确认（ack=0）时进行确认。</p><p>从生产者配置中可以看出，我们可以通过调整可靠性和持久性保证来利用有效地事件驱动的系统的深入理解。</p><h1 id="主题-1-3-可靠消息传递-—-基本原理"><a href="#主题-1-3-可靠消息传递-—-基本原理" class="headerlink" title="主题: 1.3 可靠消息传递 — 基本原理"></a><strong>主题</strong>: 1.3 可靠消息传递 — 基本原理</h1><p>可靠消息传递是任何消息中间件的关键部分。 Kafka 提供了强大的持久性保证和容错性来确保可靠消息传递。</p><p>可靠消息传递的基本原理在 Kafka 中主要围绕以下主要概念：</p><p><strong>生产者和消息确认</strong>：我们已经了解过，生产者向 Kafka Brokers发送消息。这些消息可以以不同的方式进行确认，控制生产者的 acks 属性。该确认级别影响消息的持久性。一个 ack 的值为 ‘1’ 表示已成功写入主题的领导者日志。一个 ack 的值为 ‘all’ 表示已成功写入所有同步复制的日志。</p><p><strong>复制和同步复制</strong>：复制是确保消息持久性的关键特性。每个 Kafka 分区都有多个复制，其中一个被选为领导者。所有的写入和读取都通过领导者进行。其他是追随者，其主要任务是复制领导者。只有在所有的同步复制中写入消息时，消息才被认为已提交并成功写入。</p><p><strong>消费者偏移量和传递语义</strong>：消费者从 Kafka 主题中读取消息并在其偏移量上进行跟踪，以存储消息的偏移量。Kafka 提供三种传递语义：至多一次、至少一次和精确一次。通过正确地存储和管理偏移量，Kafka 确保消息至少被传递一次。</p><p><strong>提交和未提交的消息</strong>：在 Kafka 中，消息被认为已提交，当它们成功地写入所有同步复制的日志时。消息可以写入日志，但是消费者不能消费它们，直到它们被提交，保护数据一致性和部分数据在故障发生时。</p><p>中文翻译:</p><h1 id="主题-1-4-Kafka-Brokers和主题复制"><a href="#主题-1-4-Kafka-Brokers和主题复制" class="headerlink" title="主题: 1.4 Kafka Brokers和主题复制"></a><strong>主题:</strong> 1.4 Kafka Brokers和主题复制</h1><p>Kafka Brokers是系统的核心部分，处理生产者发送的消息，分配偏移量并将消息持久化到磁盘上。现在，让我们深入了解。</p><p>Kafka 集群由多个Brokers组成。每个Brokers可以处理来自多个客户端的数据和请求，因为主题分区并分布在多个Brokers实例上。</p><p><strong>主题复制:</strong> Kafka 的复制是可靠性和容错性的关键特性。每个主题可以有多个复制，允许在多个Brokers上存储。这意味着即使Brokers出现故障，主题数据仍然可以从其他Brokers处获取。</p><p>复制的主题分区被分布到集群中的多个Brokers上。具有复制的主题提供了 Kafka 的容错性。</p><p><strong>Leader 和 Follower:</strong> 对于分区，一个复制会成为 Leader，其他的会成为 Follower。领导者处理分区的读取和写入请求，而追随者以被动的方式复制领导者。如果领导者出现故障，其中一个追随者将自动成为新的领导者。</p><p><strong>同步复制(ISR):</strong> 如果追随者超出领导者的范围（配置可变），领导者将从 ISR（同步复制）列表中删除追随者。只有 ISR 列表中的成员才能被选为领导者。</p><p><strong>复制和可靠性:</strong> Brokers在主题复制的角色和功能是关键的，为 Kafka 提供的数据传递语义。读取和写入Brokers确保记录的持久性，并且Brokers的故障不会影响数据的完整性。</p><h1 id="主题-1-5-Kafka-消费者的进入和出口"><a href="#主题-1-5-Kafka-消费者的进入和出口" class="headerlink" title="主题: 1.5 Kafka 消费者的进入和出口"></a><strong>主题:</strong> 1.5 Kafka 消费者的进入和出口</h1><p>Kafka 消费者是读取和处理数据的应用程序。消费者的角色和功能是关键的，为 Kafka 提供了可靠性和容错性。</p><p>下面是 Kafka 消费者的一些关键方面：</p><p><strong>消费者组:</strong> 多个消费者可以组成一个“消费者组”。作为组的一部分，他们共享消费负载，每个消费者读取主题的分区。这为 Kafka 提供了负载平衡和容错性的特性。</p><p><strong>消费消息:</strong> 消费者读取主题并处理它们。他们维护下一条消息的偏移量。</p><p><strong>偏移量和消费者位置:</strong> 每个消费者组维护其偏移量或位置——记录哪些消息已被消费。如果消费者成功处理了一条消息，则偏移量将进一步。因此，即使消费者崩溃，它也可以从其离开的地方继续，增加了系统的容错性和坚持性。</p><p><strong>重平衡:</strong> 当消费者停止或新消费者加入 Kafka 消费者组时，重平衡协议被初始化。该协议确保消费者优雅地离开，而新消费者加入平滑地，不会影响消费者组内的消息消费过程。</p><p><strong>传递语义:</strong> 根据消费者如何管理偏移量和提交，Kafka 提供三种传递语义——至多一次、至少一次和精确一次。正确地设计消费者应用程序是关键的，以确保它们能够正确地处理这些语义。</p><p>在 Kafka 数据流中，消费者起着重要的角色，驱动实时处理系统。深入了解 Kafka 消费者是关键的，以利用 Kafka 的全部潜力来构建健壮和可扩展的数据处理系统。</p><h1 id="主题-1-6-Kafka-如何可靠传递消息"><a href="#主题-1-6-Kafka-如何可靠传递消息" class="headerlink" title="主题: 1.6 Kafka 如何可靠传递消息"></a><strong>主题:</strong> 1.6 Kafka 如何可靠传递消息</h1><p>Kafka 的主要责任是可靠地传递生产者（写数据）发送的记录到消费者（读数据）。下面是 Kafka 如何确保可靠消息传递的细节：</p><p><strong>复制和冗余性:</strong> Kafka 通过主题复制功能确保消息持久性。Kafka 主题被分割成分区，并且每个分区可以在多个节点上复制，称为伺服器。这意味着同一条消息可以存在多个地方，提供了高级冗余性。</p><p><strong>Leader 和 Follower:</strong> 对于每个 Kafka 分区，伺服器可以在两种角色中选择：领导者和追随者。所有的读取和写入都由领导者处理，而追随者以被动的方式复制领导者。如果领导者出现故障，则追随者可以替代并为消费者提供业务持续性。</p><p><strong>确认(ACKs):</strong> ACKs 起着重要的作用。当生产者发送消息时，它可以选择在写入领导者的日志中收到确认（acks=1），或者在写入所有同步复制中收到确认（acks=all）。这种选择会贡献到性能和坚持性的权衡。</p><p><strong>同步复制(ISRs):</strong> Kafka 强制要求只有处于同步状态的复制才能被选为领导者。ISR 是一个复制，它已经完全抓住了分区领导者，并且没有超过指定时间内领导者日志的延迟。确保领导者总是来自 ISR 给 Kafka 提供了强一致性，因为它保证了写入到领导者并确认的消息不会丢失，只要故障数量在复制因子内。</p><p><strong>消费者偏移量:</strong> Kafka 消费者维护其偏移量（读取位置）。即使消费者出现故障，它也可以从它保存的偏移量中恢复读取消息，从而最小化数据丢失。</p><p>总结一下，Kafka 确保可靠地传递消息通过分割数据并复制到多个节点以提供冗余性，确认，维护 ISR 列表以提供一致性，并利用偏移量进行有效的消费。</p><h1 id="主题：1-7-Kafka-可靠性最佳实践"><a href="#主题：1-7-Kafka-可靠性最佳实践" class="headerlink" title="主题：1.7 Kafka 可靠性最佳实践"></a><strong>主题</strong>：1.7 Kafka 可靠性最佳实践</h1><p>Kafka 集群的可靠性主要取决于管理和相关的传递实践。下面是 Kafka 的可靠性最佳实践：</p><p><strong>监控你的集群</strong>：保持关注你的 Kafka 集群。这包括追踪各种指标，例如未提交的消息数量、进入和从每个节点传出的数据率、主题和分区数量，以及未复制的分区数量。监控可帮助您识别潜在的问题并在严重程度上进行预防。</p><p><strong>合理的保留期</strong>：请记，增加保留期会增加存储和堆使用量。根据需要进行平衡，以避免资源限制。</p><p><strong>合理的分区数量</strong>：在选择分区数量时，请谨慎考虑。虽然更多的分区允许更好的并行性，但它也意味着更多的打开的服务器连接和更高的 ZooKeeper 负载。</p><p><strong>合理的复制因子</strong>：高复制因子提高了冗余性和可靠性，但它也会增加存储要求。根据所需的冗余程度进行配置。</p><p><strong>合理的确认策略</strong>：根据应用程序要求使用正确的确认策略（‘acks’）。对于关键数据，请考虑使用 ‘acks=all’，以确保数据在所有同步复制中都被确认。</p><p>**有效的 In-Sync Replicas (ISRs)**：配置 ISR 设置以确保您有正确的平衡，以便保持适当的延迟和持久性保证。请确保 min.insync.replicas 根据需要进行设置，以避免在故障期间丢失数据。</p><p><strong>消费者偏移管理</strong>：请确保消费者定期提交其偏移量。这可帮助避免在故障期间重新广播大量数据。但请勿提交过于频繁，因为每次提交都是对 ZooKeeper 的调用。</p><p>总之，在 Kafka 中实现可靠的传递需要一个平衡，其中包括操作要求、资源使用和应用程序特定要求。</p><h1 id="主题：1-8-Kafka-的消息传递语义"><a href="#主题：1-8-Kafka-的消息传递语义" class="headerlink" title="主题：1.8 Kafka 的消息传递语义"></a><strong>主题</strong>：1.8 Kafka 的消息传递语义</h1><p>在 Kafka 中，消息传递语义决定了生产者如何将消息传递给消费者。Kafka 提供三种消息传递语义：</p><p><strong>1. At Most Once</strong>：在这种情况下，消息被传递至多一次给消费者。这意味着消息可能会丢失，但它们不会被重新传递或重复。这是最快的，因为它涉及最少的生产者和 Kafka 之间的协调。然而，它不是最可靠的方法，因为任何在 Kafka 发送消息和消费者读取它之间的故障都会导致消息的丢失。</p><p><strong>2. At Least Once</strong>：消息被传递至少一次给消费者。但是，在某些情况下，消息可能会重复，这可能会导致问题。这种方法更可靠，因为它确保消息不会丢失。然而，它有重复消息的风险，因为可能会重新传递。对于幂等处理，这可能是完全可以的。</p><p><strong>3. Exactly Once</strong>：这确保每个消息被传递恰好一次——无损失，无重复。然而，它是最慢和最资源密集的选择，因为需要事务来跟踪进度。这通常用于关键系统，其中消息的丢失或重复可能会导致重大问题。</p><p>这些传递语义决定了你的 Kafka 基于应用程序的系统的坚持和可靠性。选择速度、一致性和可靠性取决于应用程序的使用情况。</p><h1 id="主题：1-9-回顾和评估"><a href="#主题：1-9-回顾和评估" class="headerlink" title="主题：1.9 回顾和评估"></a><strong>主题</strong>：1.9 回顾和评估</h1><p>我们已经详细介绍了 Kafka 课程的许多方面，让我们来做一个简短的回顾：</p><ol><li><strong>Kafka 是如何工作的</strong>：我们学习了各种 Kafka 组件如何相互作用以提供一个可靠、可伸缩和容错的消息系统。</li><li><strong>Kafka 生产者</strong>：我们深入探讨了 Kafka 生产者如何发送消息并了解了其关键配置。</li><li><strong>可靠消息传递的基本概念</strong>：我们了解了确保消息持久性和可靠性在 Kafka 中的基本概念。</li><li><strong>Kafka 节点和主题复制</strong>：我们深入探讨了 Kafka 节点的工作原理并了解了主题复制如何增加可靠性。</li><li><strong>Kafka 消费者</strong>：我们探索了 Kafka 消费者和消费者组的复杂性并确定了其角色在保持可靠性方面的重要性。</li><li><strong>Kafka 如何可靠地发送消息</strong>：我们剖析了 Kafka 内部机制，用于确保可靠的消息传递。</li><li><strong>Kafka 的可靠消息传递最佳实践</strong>：我们讨论了优化 Kafka 的消息传递以增加可靠性的具体方法。</li><li><strong>Kafka 的消息传递语义</strong>：最后，我们看了三种类型的传递语义，它们的重要性和使用场景。</li></ol><p>现在，是时候评估你的了解和应用了。我们可以进行一些练习问题和分析真实世界中广泛使用的 Kafka 场景，以帮助固定你所学的知识并帮助你更好地将 Kafka 集成到你的系统中。</p><p>例题：列出并解释 Kafka 中的三种不同的传递语义？</p><p><strong>解决方案</strong>：</p><ol><li><strong>At Most Once</strong>：在这种情况下，消息被传递至多一次，这意味着消息可能会丢失，但它们不会被重新传递或重复。这是最快的，但是，它不是最可靠的方法，因为任何在 Kafka 发送消息和消费者读取它之间的故障都会导致消息的丢失。</li><li><strong>At Least Once</strong>：消息被传递至少一次，这意味着消息是确保传递的，但是，在某些情况下，消息可能会重复，这可能会导致问题。这种方法更可靠，但是，重复可能会成为问题。</li><li><strong>Exactly Once</strong>：在这种情况下，消息被传递恰好一次——无损失，无重复。然而，它是最慢和最资源密集的选择，因为需要事务来跟踪进度。这通常用于关键系统，其中消息的丢失或重复可能会导致重大问题。</li></ol><h2 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h2><p>Kafka 集群中 Kafka 生产者的角色是什么？</p><h2 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h2><p>请解释 Kafka 中主题复制的概念。为什么它是重要的？</p><h2 id="问题3"><a href="#问题3" class="headerlink" title="问题3"></a>问题3</h2><p>请介绍 Kafka 中的 In-Sync Replicas (ISRs)。</p><h2 id="问题4"><a href="#问题4" class="headerlink" title="问题4"></a>问题4</h2><p>请提供可靠消息传递在 Kafka 中的一些最佳实践。</p><h2 id="问题5"><a href="#问题5" class="headerlink" title="问题5"></a>问题5</h2><p>请说明 Kafka 是如何保证可靠消息传递的？</p><h2 id="答案1"><a href="#答案1" class="headerlink" title="答案1"></a>答案1</h2><p>Kafka 集群中的 Kafka 生产者的角色是发布数据或消息到一个或多个 Kafka 主题。生产者发送的消息会被追加到提交日志的末尾并分配一个唯一的偏移号码。</p><h2 id="答案2"><a href="#答案2" class="headerlink" title="答案2"></a>答案2</h2><p>Kafka 主题复制是 Kafka 中的一个特性，用于确保集群中的消息在某些 Kafka 节点（由于故或维护而不可用）不可用时仍然可用。每个主题可以在配置的节点数量上复制。这有助于确保没有消息丢失并提供高数据可用性。</p><h2 id="答案3"><a href="#答案3" class="headerlink" title="答案3"></a>答案3</h2><p>In-Sync Replicas (ISRs) 是与领导者同步的复制集。任何超过某个配置时间未向领导者发送获取请求的复制集成 ISR 集合。如果复制集未能从领导者获取，它将从 ISR 集合中删除并不会被认为是为客户端生产数据的候选者。</p><h2 id="答案-4"><a href="#答案-4" class="headerlink" title="答案 4"></a>答案 4</h2><p>在 Kafka 中可靠消息传递的一些最佳实践包括根据使用场景选择正确的消息传递语义，遵循最小权限原则进行权限管理，为长期主题使用压缩，监控并设置警报关键指标，保持 Kafka 集群和客户端库的更新，等等。</p><h2 id="答案-5"><a href="#答案-5" class="headerlink" title="答案 5"></a>答案 5</h2><p>Kafka 保证可靠消息传递通过多种机制来实现，例如复制、In-Sync Replicas (ISRs)、确认和配置可靠性语义。生产者会等待来自全部 In-Sync Replicas 的确认，直到消息被写入。如果消息写入失败，生产者会自动重试。消费者会维护一个偏移量来跟进每个主题的进度。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/kafka-interview1/">https://programmerscareer.com/kafka-interview1/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL面试:简要介绍MySQL的主从同步机制</title>
      <link href="/zh-cn/mysql-interview1/"/>
      <url>/zh-cn/mysql-interview1/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>让我们构建MySQL的主/从同步机制课程，并了解如果同步失败会发生什么</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题-1-1-数据库同步简介"><a href="#主题-1-1-数据库同步简介" class="headerlink" title="主题:1.1 数据库同步简介"></a>主题:1.1 数据库同步简介</h1><hr><p>数据库同步是数据库世界中的一个关键概念。跨多个平台、数据库或系统维护准确、一致的数据的复杂性一直是一个挑战。这就是数据库同步的亮点所在。</p><p>当我们谈论数据库同步时，我们指的是确保两个或多个数据库中的数据是一致的过程。这通常意味着所有数据库中的数据应该是相同的，以反映任何数据库中的所有更新。例如，在银行系统中，客户的账户余额应该是相同的，无论是在网上、在自动取款机上还是在分行检查。如果客户在分行取款，这应该立即反映在网上和自动取款机上看到的余额上。这种实时准确性是通过所涉及的各种数据库的同步来实现的。</p><p>同步的一些主要好处包括:</p><ul><li><strong>数据一致性</strong>:数据库同步确保数据在所有平台上保持一致。这在金融和医疗保健等许多行业至关重要，因为这些行业的数据准确性至关重要。</li></ul><ul><li><strong>效率</strong>:通过确保一个数据库中的变化反映在所有其他数据库中，同步有助于使系统更高效，数据更可靠。冗余减少了，用户总是可以访问最新的数据，无论他们从哪里访问数据。</li><li><strong>可扩展性</strong>:随着系统规模的增长，其数据也在增长。数据库同步允许随着数据输入的增加而轻松扩展数据库。可以同步多个服务器来处理更多数据，从而提高系统的整体性能。  </li><li><strong>备份</strong>:同步可以作为数据备份的一种形式。如果一台服务器宕机，数据不会丢失，因为它镜像在另一台服务器上。这提高了数据可靠性和系统耐久性。<br>在课程的下一部分中，我们将仔细研究数据库系统中的主要和次要体系结构模型，包括MySQL。请继续关注!</li></ul><hr><h1 id="主题-1-2理解主-次体系结构"><a href="#主题-1-2理解主-次体系结构" class="headerlink" title="主题:1.2理解主/次体系结构"></a>主题:1.2理解主/次体系结构</h1><hr><p>在许多数据库系统中，特别是在MySQL中，一种流行的结构是主/从体系结构，也称为主/从体系结构。</p><p>在深入研究体系结构细节之前，让我们简要讨论一下每个组件代表什么。</p><ul><li><strong>Primary Database (Master Database)</strong>:原始数据库或主数据库。此处所做的任何更改或更新也会反映在辅助数据库中。主数据库通常处于读写模式，并且通常是大多数应用程序操作发生的地方。</li><li><strong>Secondary Database (Slave Database)</strong>:这些是主数据库的副本。辅助数据库的存在通常是为了增强可靠性、数据恢复和负载平衡。它们复制主数据库中的数据，虽然有些应用程序允许双向同步(其中一个数据库上的更新反映在另一个数据库上)，但许多辅助数据库是只读的。</li></ul><p>在MySQL环境中，主数据库以二进制日志(binlog)记录对其执行的更新。该日志作为所有更改的书面历史记录，可用于将这些更改复制到辅助数据库。很酷，对吧?</p><p>在主服务器上执行事件或事务时，辅助服务器上不会立即发生任何事情。相反，事件首先被写入主服务器上的二进制日志。</p><p>辅助服务器有一个名为I/O Thread的组件，它连接到主服务器，并几乎立即将二进制日志事件复制到中继日志中。</p><p>另一个名为SQL线程的组件从中继日志中读取事件，并将其应用到辅助服务器。这样，在辅助服务器上以相同的顺序执行相同的事件，因此，两个服务器上的数据是一致的。</p><p>该模型提供了备份供应、分析性能、读取可伸缩性和高可用性等优点。但是，它需要仔细管理以确保数据一致性并避免冲突。</p><p>在接下来的课程模块中，我们将深入研究此同步机制的其他细节以及如何有效地处理潜在问题。</p><h1 id="主题-1-3-MySQL的同步机制"><a href="#主题-1-3-MySQL的同步机制" class="headerlink" title="主题: 1.3 MySQL的同步机制"></a>主题: 1.3 MySQL的同步机制</h1><hr><p>MySQL有一套丰富的机制来确保数据在不同数据库之间保持一致。以下是MySQL同步的关键要素:</p><ul><li><strong>1.二进制日志</strong>:二进制日志记录对MySQL数据的所有更改。这包括数据更改，如表创建操作或对表数据的更改，以及导致更改的每个语句所花费的时间。这在同步数据方面起着关键作用。</li><li><strong>2.复制</strong>:复制是MySQL中最流行的功能之一。它允许从一个MySQL数据库服务器(主服务器)复制数据到一个或多个MySQL数据库服务器(辅助服务器)。默认情况下，复制是异步的，这带来了很大的灵活性。但是您也可以选择设置半同步复制。</li><li><strong>3.全局事务标识符(gtid):</strong> gtid使跟踪事务更容易。当事务发生时，将为其提供一个GTID，该GTID在所有服务器上都是唯一的。gtid的主要好处是支持更简单的自动故障转移和更高的可靠性。</li><li><strong>4.组复制</strong>:组复制增强MySQL的复制。它提供了对崩溃或无法访问的服务器的内置检测，并可以重新配置组、主要选举和从其他组成员自动分布式恢复，因此业务操作不必停止。</li><li><strong>5.InnoDB ReplicaSet</strong>:对于不需要高可用性系统的小规模设置，可以部署一种称为InnoDB ReplicaSet的轻量级故障转移管理方法。它提供了易于使用的命令行工具来设置和管理较小规模的复制集。</li><li><strong>6.半同步复制</strong>:半同步复制提供了一个选项，只有当要复制的数据被发送到另一个副本时，提交才能成功返回到客户端。半同步复制可用于阻止事务，直到副本确认已将事件写入其副本日志，从而防止由于主节点丢失或崩溃而导致的数据丢失。因此，我们可以说半同步复制是同步复制的高持久性和异步复制的低延迟之间的折衷。</li></ul><p>MySQL通过这些同步机制实现数据一致性。这些机制确保副本接收主数据库上的更新，从而实现跨预期数据处理管道的数据协调。</p><p>接下来，我们将深入研究同步失败的后果以及如何检测和减轻这些事件。</p><hr><h1 id="主题-1-4-同步失败的后果"><a href="#主题-1-4-同步失败的后果" class="headerlink" title="主题: 1.4 同步失败的后果"></a>主题: 1.4 同步失败的后果</h1><hr><p>在任何同步至关重要的系统中，例如MySQL中的主/从设置，同步失败可能导致各种问题。以下是同步失败的一些潜在后果:</p><ul><li><strong>1.数据不一致</strong>:这是同步失败最直接和最明显的影响之一。例如，在银行应用程序中，您可能在不同的数据库中得到不同的帐户余额值，这可能导致重大的财务影响。</li><li><strong>2. 服务中断</strong>:如果服务器没有正确同步，依赖于数据库的服务可能面临性能问题甚至完全失败。这可能会破坏应用程序的可用性，并导致糟糕的用户体验。</li><li><strong>3. 数据损坏</strong>:在最坏的情况下，同步失败甚至可能导致数据损坏。例如，如果两个用户同时修改相同的数据，但这些修改没有正确同步，就会发生这种情况。</li></ul><p>了解同步失败的症状与了解同步失败的后果同样重要。症状可能包括日志中的错误或异常数量增加、性能突然下降，或者在比较主数据库和辅助数据库时数据不一致。</p><p>缓解策略通常首先通过定期检查数据库运行状况或配置与复制失败相关的特定错误代码警报来检测故障。一旦检测到，需要快速响应以诊断问题的原因并采取纠正措施。</p><p>这些纠正操作的性质将取决于特定的问题和数据库的配置，可以是简单的数据库重启，也可以是更剧烈的完全数据重新同步，甚至可以是故障转移到不同的服务器。</p><p>现在，我们知道预防问题比解决问题更好。这就引出了我们的下一个主题，即首先防止同步故障发生的最佳实践。</p><h1 id="主题-1-5-防止同步失败"><a href="#主题-1-5-防止同步失败" class="headerlink" title="主题:1.5 防止同步失败"></a><strong>主题</strong>:1.5 防止同步失败</h1><hr><p>防止MySQL数据库同步失败需要仔细规划、监控和应用最佳实践，以确保数据的一致性。以下是实现这一目标的一些重要步骤:</p><ul><li><strong>1.定期监视</strong>:定期监视数据库的运行状况和性能。这包括监视复制的状态、检查状态和错误日志，以及为各种复制事件设置警报。</li><li><strong>2.使用可靠的网络</strong>:网络故障可能导致重大的同步问题。因此，请确保主服务器和辅助服务器通过可靠的网络连接。考虑使用冗余网络路径来提高可用性。</li><li><strong>3.应用程序中彻底的错误处理</strong>:您的应用程序还应该配备良好的设备来处理错误，包括来自数据库的错误。彻底的错误处理可以防止由于应用程序错误而导致同步失败的实例。</li><li><strong>4.使用gtid</strong>:正如我们前面所讨论的，全局事务标识符(Global Transaction Identifiers, gtid)在防止同步失败方面非常方便，因为它们提供了一种一致的方式来跟踪所有服务器上的每个复制事件。</li><li><strong>5.定期备份</strong>:定期备份您的数据库。备份是在发生灾难性故障时的最后一道防线。此外，通过在单独的环境中恢复备份来验证备份，以确保它们是好的。</li><li><strong>6.测试故障转移场景</strong>:在受控条件下定期测试故障转移场景，以了解在实际故障转移场景中可能出现的潜在问题。这有助于在实际中断发生时最小化RTO(恢复时间目标)。</li><li><strong>7.使用半同步复制</strong>:正如我们在前几课中所讨论的，半同步复制还可以帮助防止“提交成功不一致”。在这种方法中，主服务器等待，直到至少一个辅助服务器接收到更改并将其记录到其中继日志中。</li><li><strong>8.保留Binlogs直到所有副本都处理完它们</strong>:这可以防止主系统崩溃，然后在复制流的较早点提升备份主系统的问题。</li></ul><p>通过应用这些策略，您可以大大减少在MySQL环境中遇到同步失败的机会。</p><p>在我们的下一个主题中，我们将继续讨论现实世界的场景，以弥合理论与实践之间的差距。</p><h1 id="主题-1-6-同步失败案例分析"><a href="#主题-1-6-同步失败案例分析" class="headerlink" title="主题:1.6 同步失败案例分析"></a>主题:1.6 同步失败案例分析</h1><hr><p>为了更好地理解同步失败在现实场景中是如何发生的，让我们使用一个反映实践中可能面临的问题的假设案例:</p><p>假设我们有一家科技初创公司，它的移动应用拥有快速增长的用户基础。该公司使用主-从MySQL设置来管理其用户数据。有一天，他们发布了一个新特性，由于用户操作的增加，导致数据库写入量激增。</p><p>尽管考虑到应用的成功，这是一个令人高兴的问题，但它导致了一个意想不到的问题:辅助服务器开始落后于主服务器。随着用户操作的增加，辅助服务器处理来自主服务器的二进制日志的延迟导致了这种延迟。这被称为复制延迟。</p><p>这是同步MySQL设置中的一个常见问题。在这种情况下，故障不是突然崩溃，而是不断增长的延迟，这通常很难立即检测到。用户开始注意到应用程序体验中的不一致。例如，用户可能删除了一个帖子，但仍然在他们的提要中看到它，因为指向延迟的辅助服务器的读取操作仍然在那里找到了该帖子。</p><p>该公司最终通过监控系统发现了这个问题，注意到复制延迟不断增加，并立即采取了行动。他们的答复包括:</p><ul><li><strong>扩展他们的数据库设置</strong>:他们增加了更多的辅助服务器，并优化了这些服务器之间的读操作分布，以更好地处理负载。</li><li><strong>缓冲写</strong>:他们为非关键的写操作实现了队列系统，从而减少了数据库的即时负载。</li><li><strong>优化他们的应用程序操作</strong>:他们发现许多并发读写操作是不必要的，并重新设计了他们的应用程序逻辑来减少这些。</li></ul><p>通过这种情况，该公司认识到积极监控数据库设置的健康状况、预测扩展需求和优化应用程序操作以减少不必要的数据库负载的重要性。</p><p>在此场景中面临的问题以及为纠正这些问题所采取的步骤是许多实际应用程序的典型问题。从这个案例研究中，我们看到了我们在前几课中谈到的预防和缓解措施的重要性。</p><p>在下一节课中，我们将重温和复习我们在课堂上学到的关键概念，通过一些实际作业来加强它们，并通过一些评估来评估你的理解。</p><h1 id="主题-1-7-审查和评估"><a href="#主题-1-7-审查和评估" class="headerlink" title="主题:1.7 审查和评估"></a><strong>主题</strong>:1.7 审查和评估</h1><hr><h2 id="审查"><a href="#审查" class="headerlink" title="审查"></a>审查</h2><p>让我们回顾一下我们在整个课程中涵盖的关键概念:</p><ol><li>数据库同步:我们首先了解数据库同步的需求、它的好处和潜在的挑战。这个概念对于维护跨多个数据库实例的数据一致性至关重要。</li><li>主/辅助架构:我们探讨了MySQL中常用的主/辅助架构。此设置允许将数据从主服务器复制到一个或多个辅助服务器。</li><li>MySQL中的同步机制:我们深入研究了MySQL用于实现同步的机制，包括二进制日志记录和复制。</li><li>同步失败的后果:我们讨论了同步失败的潜在影响，从数据不一致到服务中断，甚至数据损坏。</li><li>防止同步故障:我们了解了防止这些故障的各种策略和最佳实践，例如定期监视、gtid和可靠的网络连接。</li><li>同步故障案例研究:我们研究了一个真实的场景，以了解此类故障是如何发生的，以及处理它们的步骤。</li></ol><h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><p>现在，让我们用一些问题来测试你的理解:</p><ol><li>为什么在数据库系统中需要同步?具体来说，在小学/中学的设置中?</li><li>MySQL实现同步的关键机制是什么?</li><li>同步失败的潜在后果是什么?</li><li>描述一些防止MySQL数据库同步失败的策略。</li><li>在我们讨论的案例研究中，公司是如何发现这个问题的?他们是如何应对这种情况的?</li></ol><p>请慢慢回答这些问题。你对这些概念的理解比速度更重要。</p><h2 id="答案"><a href="#答案" class="headerlink" title="答案"></a>答案</h2><ul><li>**1. 为什么在数据库系统中需要同步?具体来说，在主/备的设置中?**。</li></ul><p>在数据库系统中，同步对于确保跨多个数据库实例的数据一致性至关重要。在主/辅助设置中，它允许将数据从主服务器复制到一个或多个辅助服务器，以提高性能并提供可靠的冗余数据存储。</p><ul><li>**2. MySQL实现同步的关键机制是什么?**。</li></ul><p>MySQL通过二进制日志记录和相关的复制技术实现同步。主服务器生成所有数据更改的二进制日志。辅助服务器获取此日志并应用更改，从而实现与主服务器的同步。</p><ul><li>**3. 同步失败的潜在后果是什么?**。</li></ul><p>其后果可能包括跨服务器的数据不一致、服务中断，在严重的情况下还可能导致数据损坏。这可能导致系统不可靠，并对用户体验产生负面影响。</p><ul><li>**4. 描述一些防止MySQL数据库同步失败的策略</li></ul><p>预防性策略包括定期监视数据库运行状况和性能、使用可靠的网络连接、在应用程序中进行彻底的错误处理、使用全局事务标识符(Global Transaction Identifiers, gtid)、执行定期备份、测试故障转移场景、半同步复制，以及确保保留二进制日志，直到所有副本都处理完它们。</p><ul><li><strong>5. 在我们讨论的案例研究中，公司是如何发现这个问题的?他们是如何应对这种情况的?</strong></li></ul><p>该公司通过监控系统发现了这个问题，注意到复制延迟的增加。他们的回应包括通过增加更多的辅助服务器来扩展数据库设置，实现一个队列系统来缓冲写并减少数据库上的即时负载，以及优化他们的应用程序操作以减少不必要的数据库负载。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview1/">https://programmerscareer.com/mysql-interview1/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 面试：简述 MySQL 的间隙锁</title>
      <link href="/zh-cn/mysql-interview10/"/>
      <url>/zh-cn/mysql-interview10/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>你曾在面试中被要求类似的问题吗？或者将来会遇到，让我们一起探索和掌握它。</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：深入探讨-MySQL"><a href="#主题：深入探讨-MySQL" class="headerlink" title="主题：深入探讨 MySQL"></a><strong>主题</strong>：深入探讨 MySQL</h1><p>MySQL 是一个广泛使用的、开源的关系数据库管理系统 (RDBMS)。它使用关系数据库和结构化查询语言 (SQL) 来管理其数据。“My” 在 MySQL 中是 Michael Widenius 的女儿 My 的名字的缩写。</p><p>MySQL 数据库是一个稳定、可靠和强大的解决方案，具有高级特性，例如：</p><ul><li>坚实事务支持</li><li>复制和故障转移集群支持</li><li>工作流控制和计划任务</li><li>查询缓存</li><li>高级复制技术</li></ul><p>这使 MySQL 成为应用要求完整数据保护和实时分析的优秀选择，例如财务、银行、电子商务、CRM、ERP 应用等等。</p><p>接下来，让我们开始从理论上了解数据库。为了简单起见，让我们想象数据库是一个大的数字文件柜，满载的文件夹。文件夹代表表。在每个表中，包含真实数据，表示记录。每条记录包含有关单个实体的信息。</p><p>例如，如果你是一个商业主人，你可能有一个数据库，其中包含一个客户表和一个订单表等等。每行在客户表中代表一个单独的客户，每行在订单表中代表一个单独的订单。</p><h1 id="主题：探讨-MySQL-事务"><a href="#主题：探讨-MySQL-事务" class="headerlink" title="主题：探讨 MySQL 事务"></a><strong>主题</strong>：探讨 MySQL 事务</h1><p>事务是数据库系统的基本概念。在 MySQL 中，事务是一组 SQL 语句的执行单元。事务遵循 ACID 模型，即原子性、一致性、隔离性和持久性。这个模型确保了数据库事务的可靠性。</p><p>例如，如果你在转账时从一个银行账户转移资金，这需要多个操作，例如从一个账户扣除资金并将其转移到另一个账户。在这种情况下，事务确保这些操作（信用和贷方）全部发生或不发生，确保数据一致性。</p><p>我们的下一步是学习 MySQL 中的锁定机制，这与事务密切相关。在数据库的上下文中，锁是与记录相关的标志。这个标志可以控制记录是否可以被读取或写入。</p><p>它是锁定使多名用户同时访问数据库时不发生冲突的关键。当记录或表被锁定时，这意味着某个事务正在访问数据，并且不应中断。</p><p>中文翻译:</p><h1 id="主题：MySQL中锁定的介绍"><a href="#主题：MySQL中锁定的介绍" class="headerlink" title="主题：MySQL中锁定的介绍"></a><strong>主题</strong>：MySQL中锁定的介绍</h1><p>在数据库领域，“锁定”是一个重要的特性，它确保并发数据访问的一致性和顺序。在 MySQL 中，InnoDB 存储引擎支持多种类型的锁定在不同的级别上，以确保事务不会相互干扰。</p><p>锁定特别重要在多个事务试图访问和操作同一块数据时。当一个事务锁定某块数据时，它阻止其他事务进行冲突的更改，直到锁定被释放。</p><p>MySQL 中有两种主要类型的锁定：</p><ol><li>**共享锁 (S)**：这是一个只读锁定。多个共享锁可以同时保持对同一块数据，只要没有排他锁。</li><li>**排他锁 (X)**：排他锁是一个写锁定。当一个事务持有排他锁时，其他事务不能读取或写入该数据，直到锁定被释放。</li></ol><p>在 MySQL 中，锁定可以发生在三个级别上：</p><ul><li><strong>行级锁定</strong>：这些锁定被放在数据行上。这是锁定的最细粒度，并允许最高的并发性。</li><li><strong>页级锁定</strong>：这些锁定被放在数据页上。页级锁定比行级锁定更粗糙，并提供中等的并发性。</li><li><strong>表级锁定</strong>：这些锁定被放在整个表上。这是锁定的最粗糙的，并提供最低的并发性。通常，在高并发环境中，我们希望避免表级锁定，因为它们可能会成为瓶。</li></ul><p>了解这些基本锁定的概念后，我们可以深入研究 MySQL 中的更复杂的锁定类型，例如间隙锁。</p><h1 id="主题：行锁和表锁在-MySQL-中"><a href="#主题：行锁和表锁在-MySQL-中" class="headerlink" title="主题：行锁和表锁在 MySQL 中"></a><strong>主题</strong>：行锁和表锁在 MySQL 中</h1><p>为了保证数据一致性并允许最高的并发性，MySQL 使用两种类型的锁定：行级锁定和表级锁定。每种类型都有自己的地方和目的。</p><p><strong>行级锁定</strong></p><p>行级锁定更细粒度，在更新特定行的表时使用。这意味着只锁定涉及操作的行，并不锁定整个表。这允许更高的并发性，其中多个事务可以同时访问不同行的同一表。</p><p>InnoDB 支持行级锁定。它会自动设置锁定在读和写操作时，但它不会锁定整个表。</p><p><strong>例子</strong>：如果您正在更新特定记录的员工表，例如，如果使用这种锁定机制，则只会阻止试图修改该特定员工记录的事务。其他员工记录的任务可以继续进行。</p><p><strong>表级锁定</strong></p><p>表级锁定更粗糙。它锁定整个表在特定数据库操作时。通常，MySQL 在写操作时应用这种锁定。</p><p>虽然这种锁定允许简单的管理和更少的内存使用，但在高并发使用情况下，其并发性较低，因为多个事务需要同时访问同一表。</p><p>通过了解这两种类型的锁定，您已经一步 closer 了解了数据库操作的内部工作原理，并且在深入研究更复杂的锁定类型，例如间隙锁，时间戳锁定等方面有所帮助。</p><p>中文翻译:</p><h1 id="主题：讨论-MySQL-中的间隙锁"><a href="#主题：讨论-MySQL-中的间隙锁" class="headerlink" title="主题：讨论 MySQL 中的间隙锁"></a><strong>主题</strong>：讨论 MySQL 中的间隙锁</h1><p>间隙锁是 MySQL 中一个重要的机制，用于防止幻行。幻行是一种行，它满足 WHERE 子句的条件，但是在事务中未被初始查看或更新。</p><p>让我们考虑一种情况，其中我们有一个事务，它选择了特定范围内的行，并且后面要更新这些行。在这个操作期间，另一个事务插入了新行到该范围，创造了我们所称为的“幻行”。如果没有间隙锁，第一个事务不会意识到新行被第二个事务添加，并可能导致数据不一致。</p><p>这就是间隙锁的作用！</p><p>间隙锁是锁定索引记录之间的间隙。更具体地说，它是锁定索引记录的范围。在 MySQL 中，间隙锁防止其他事务在间隙被锁定的事务提供可重复读时插入新行。</p><p>例如，假设您有一个索引列，并且运行了以下语句在 REPEATABLE READ 隔离级别下：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM table_name WHERE index_column &gt; 100 FOR UPDATE;</span><br></pre></td></tr></tbody></table></figure><p>MySQL 会为所有索引记录上锁，其中 <code>index_column</code> 的值大于 100，并为其后的间隙上锁。</p><p>请记，然而，间隙锁是双刃剑！虽然它可以确保一致性，但它也可能会引入锁等待或甚至死锁，如果不正确地管理。</p><h1 id="主题：间隙锁的例子场景"><a href="#主题：间隙锁的例子场景" class="headerlink" title="主题：间隙锁的例子场景"></a><strong>主题</strong>：间隙锁的例子场景</h1><p>要更好地理解间隙锁，让我们考虑一个例子场景。假设我们有一个表 <code>orders</code>，它有许多行。</p><p>场景 1:<br>例如，考虑以下 SQL 语句，</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM orders WHERE id &gt; 3 FOR UPDATE;</span><br></pre></td></tr></tbody></table></figure><p>在这个查询中的事务中，MySQL 会为所有记录上锁，其中 <code>id</code> 的值大于 3。这意味着另一事务不能在 <code>orders</code> 表中插入任何新记录，其中 <code>id</code> 的值大于 3，直到第一事务完成。</p><p>场景 2:<br>现在考虑另一个 SQL 语句，</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO orders (id, item) VALUES (102, 'New_Item');</span><br></pre></td></tr></tbody></table></figure><p>如果我们试图在先前事务（带有 SELECT … FOR UPDATE 语句）仍然处于活动状态时执行此语句，它将被阻止，直到第一事务完成。这是由第一事务所应用的间隙锁所导致的，它不允许任何新记录的插入，其中 <code>id</code> 的值大于 3。</p><p>这些例子场景说明了间隙锁如何控制并发事务，确保数据状态的一致性并消除幻读在某些事务隔离级别，例如 REPEATABLE READ 或 SERIALIZABLE 中。</p><p>现在，我们可以深入研究 MySQL 中锁定的更复杂的细节。</p><h1 id="主题：通过锁的迷宫"><a href="#主题：通过锁的迷宫" class="headerlink" title="主题：通过锁的迷宫"></a><strong>主题</strong>：通过锁的迷宫</h1><p>在 MySQL 中，锁形成了一个复杂的迷宫，每个锁都有重要的作用，但如果不处理正确，可能会导致延迟或死锁。</p><p>下面是锁之间的简单交互方式：</p><ol><li><strong>共享锁和排他锁</strong>：</li></ol><ul><li>共享锁允许其他事务读取（共享锁）锁定的对象，但不允许写入（排他锁）。</li><li>排他锁阻止其他事务读取/写入锁定的对象。</li><li>可以应用额外的共享锁到已锁定的对象上，但请求排他锁将等待。</li></ul><ol><li><strong>表锁和行锁</strong>：</li></ol><ul><li>表锁简单明了，但提供了更低的并发性，可能会导致事务延迟。</li><li>行锁提供更高的并发性，因为它们只锁定特定行在表中。</li></ul><ol><li><strong>Gap 锁和 Next-Key 锁</strong>：</li></ol><ul><li>Gap 锁阻止插入到特定范围内的索引记录。它们与行锁（或 Next-Key 锁）配合起来防止 REPEATABLE READ 或 SERIALIZABLE 隔离级别中的幻读。</li></ul><ol><li><strong>意向锁</strong>：</li></ol><ul><li>意向锁表明事务计划要获取的锁（共享或排他）之前就已经获取了它。它们是通知机制，不是控制机制。</li></ul><ol><li><strong>自增锁</strong>：</li></ol><ul><li>自增锁用于维护自增值的序列。它们避免了多个事务同时尝试插入到自增列中的冲突。</li></ul><p>成功地通过这个迷宫需要对每种锁类型和事务之间的影响有清晰的理解。</p><h1 id="主题：复习和评估"><a href="#主题：复习和评估" class="headerlink" title="主题：复习和评估"></a><strong>主题</strong>：复习和评估</h1><p>在过去的课程中，我们深入探讨了 MySQL 和其锁机制。让我们回顾一下这些主题，以确保良好的理解：</p><ol><li><strong>深入了解 MySQL</strong>：我们开始时，了解了 MySQL 的界面、命令和与其他 SQL 实现的差异，为学习过程奠定了坚实的基础。</li><li><strong>探索 MySQL 事务</strong>：我们深入探讨了 MySQL 事务的核心概念，讨论了其一致性和隔离级别，确保数据的准确性和并发性。</li><li><strong>了解 MySQL 锁</strong>：我们介绍了 MySQL 锁的概念，这是维护数据完整性和并发控制的关键。</li><li><strong>行锁和表锁</strong>：我们探讨了行级锁和表级锁，并讨论了它们在 MySQL 中的重要性。</li><li><strong>讨论 MySQL 的Gap 锁</strong>：我们深入探讨了 gap 锁，包括它是什么、它是如何工作的和它在 REPEATABLE READ 或 SERIALIZABLE 隔离级别中的重要性。</li><li><strong>Gap 锁的示例场景</strong>：我们步行了常见的场景，以了解 gap 锁的实际应用。</li><li><strong>通过锁的迷宫</strong>：我们讨论了 MySQL 中锁之间的交互和影响，这是一个复杂但有趣的主题。</li></ol><h2 id="例子问题："><a href="#例子问题：" class="headerlink" title="例子问题："></a>例子问题：</h2><p>考虑一种高流量数据库，您经常遇到死锁。您的任务是识别一个可能的解决方案来最小化这些发生的可能性。</p><p><strong>解决方案</strong>：可能的解决方案包括缩短事务时间、确保事务访问表的相同顺序或者增加 innodb_lock_wait_timeout 值。还可以确保使用最具体的锁来帮助减少死锁的可能性。</p><p>中文翻译：</p><h2 id="简单问题："><a href="#简单问题：" class="headerlink" title="简单问题："></a>简单问题：</h2><p>考虑一个事务，它读取和写入表中的多条记录。要确保高流量数据库中的最小阻塞，应该使用哪种锁（行级锁、表级锁或Gap锁），并且避免幻读？</p><h2 id="进阶问题："><a href="#进阶问题：" class="headerlink" title="进阶问题："></a>进阶问题：</h2><p>在票务预订系统中，可能会有多个并发事务试图同时预订同一座位。如何使用 MySQL 的锁机制来确保公平的系统？</p><h2 id="专家问题："><a href="#专家问题：" class="headerlink" title="专家问题："></a>专家问题：</h2><p>在 MySQL 的上下文中，如何处理银行应用中的死锁场景，其中两个事务同时尝试转移两个账户之间的资金？</p><h2 id="简单问题解决方案："><a href="#简单问题解决方案：" class="headerlink" title="简单问题解决方案："></a>简单问题解决方案：</h2><p>对于这种场景，使用行级锁机制将是最有效的。它会提供所需的锁定来确保数据完整性，同时避免高流量情况下不相关行的不必要阻塞。此外，包含“FOR UPDATE”子句在 SELECT 语句中可能会避免幻读。</p><h2 id="进阶问题解决方案："><a href="#进阶问题解决方案：" class="headerlink" title="进阶问题解决方案："></a>进阶问题解决方案：</h2><p>在票务预订系统中，要确保公平的系统，我们可以使用 SELECT FOR UPDATE 命令。这会为所遇到的所有索引记录放置排他的 Next-Key 锁，从而防止其他事务在覆盖的记录锁下插入新行。它还会选择座位的当前状态，并如果它可用，则更新其为已预订，确保座位不会被双预订。</p><h2 id="专家问题解决方案："><a href="#专家问题解决方案：" class="headerlink" title="专家问题解决方案："></a>专家问题解决方案：</h2><p>在银行应用中，如果两个事务同时尝试转移两个账户之间的资金，我们可能会遇到死锁场景。要处理这种情况，我们可以使用访问帐户的固定顺序。例如，事务可能会先访问具有较低 ID 的帐户。这将防止死锁，因为两个事务不会无限期地等待对方，消除了死锁的循环等待条件。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview10/">https://programmerscareer.com/mysql-interview10/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 面试：唯一索引与普通索引的区别是什么？使用索引会有哪些优缺点？</title>
      <link href="/zh-cn/mysql-interview11/"/>
      <url>/zh-cn/mysql-interview11/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>让我们深入探讨 MySQL 中的“唯一索引”和 “普通索引”的评论和评估。</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：了解-MySQL-中的索引"><a href="#主题：了解-MySQL-中的索引" class="headerlink" title="主题：了解 MySQL 中的索引"></a><strong>主题</strong>：了解 MySQL 中的索引</h1><p>在任何关系数据库管理系统中，如 MySQL，数据的高效访问是关键方面之一，特别是在处理大量数据时。我们所关心的效率是系统如何快速地定位并检索所需的数据。这就是 <strong>索引</strong> 发挥作用的地方。</p><p>你可以将索引比作书的索引。假设你想找到某个特定主题。你有两种选择：</p><ol><li>你可以逐页扫描，直到找到主题。</li><li>你可以去索引，找到主题的页码，然后直接翻到那一页。</li></ol><p>后者更快，是不是？在数据库世界中，逐页扫描被称为 <strong>全表扫描</strong>。如果你有 millions 行，这可能会花费很长时间。但是如果你有一个索引，MySQL 可以使用它来更快地定位数据——就像你使用书的索引来找到主题一样。</p><p>索引创建一个条目，并因此可以更快地检索数据。请记，然而，虽然索引加快了查询，但它们可能会慢下来写操作（INSERT、UPDATE、DELETE）的速度，因为每次写操作都要更新索引。因此，我们需要维持平衡并只在经常搜索的列上使用索引。</p><h1 id="主题：MySQL-中的普通索引"><a href="#主题：MySQL-中的普通索引" class="headerlink" title="主题：MySQL 中的普通索引"></a><strong>主题</strong>：MySQL 中的普通索引</h1><p>现在我们对索引有了良好的理解并了解了它在 MySQL 中的角色，让我们来深入探讨一种特定的索引类型，即 <strong>普通索引</strong>（也称为 <strong>非唯一索引</strong>）。</p><p>普通索引（Non-unique Index）允许你通过数据库表的一个或多个列来加速查询过程。与唯一索引不同，普通索引不会对值的唯一性进行约束。换句话说，普通索引允许在索引列上重复的值。</p><p>例如，假设我们有一个 <code>Students</code> 表，其中包含列 <code>ID</code>、<code>Name</code>、<code>Age</code> 和 <code>Address</code>。当我们正在查询数据时，我们通常使用 <code>WHERE</code> 子句来过滤数据。例如：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`SELECT * FROM Students WHERE Age = 20`</span><br></pre></td></tr></tbody></table></figure><p>在没有索引的情况下，MySQL 将需要浏览 <code>Students</code> 表的每一行，以找到 <code>Age</code> 等于 20 的行。这可能会耗时且不高效。如果我们为 <code>Age</code> 列创建一个普通索引，MySQL 可以使用这个索引来快速定位相关的行。</p><p>在 MySQL 中创建一个普通索引非常简单，你可以使用 <code>CREATE INDEX</code> 命令，然后提供索引的名称、表和列。</p><p>下面是如何在 <code>Students</code> 表上为 <code>Age</code> 列创建一个普通索引的例子：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX age_index ON Students (Age);</span><br></pre></td></tr></tbody></table></figure><p>请记，虽然普通索引可能会加快读操作，但它们也会占用存储空间并可能会慢下来写操作（INSERT、UPDATE、DELETE），因为它们需要更新每次写操作时。因此，它们应该被谨慎和策略地使用。</p><h1 id="主题：MySQL中的唯一索引"><a href="#主题：MySQL中的唯一索引" class="headerlink" title="主题：MySQL中的唯一索引"></a><strong>主题</strong>：MySQL中的唯一索引</h1><p>我们已经有了关于正常索引的深入了解，现在是时候讨论MySQL中的<strong>唯一索引</strong>了。</p><p>唯一索引是一种索引，它强制约束，要求所有值在索引中都不相同。这意味着，唯一索引不允许在索引所在的列（或列组合）上出现重复值，使它们非常有用，当你想要防止某些字段的重复时。</p><p>例如，考虑一个名为Users 的表，其中每个用户都有一个唯一的电子邮件地址。在这种情况下，在电子邮件列上创建一个唯一索引将确保两个用户不能具有相同的电子邮件地址。</p><p>创建唯一索引的语法与创建正常索引的语法略有差异：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE UNIQUE INDEX index_name ON table_name (column_name);</span><br></pre></td></tr></tbody></table></figure><p>请替换 <code>index_name</code> 为您希望为索引命名的名称，<code>table_name</code> 为要在其上创建索引的表的名称，并将 <code>column_name</code> 替换为要在其上创建索引的列的名称。</p><p>例如，要在 Users 表上创建一个唯一索引，您可以使用以下语法：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE UNIQUE INDEX email_index ON Users (Email);</span><br></pre></td></tr></tbody></table></figure><p>每次在 Users 表中插入或更新一个电子邮件时，MySQL都会检查唯一索引，并如果发现另一行具有相同的电子邮件值，就不会允许更改。</p><p>请记住，唯一索引不仅可以帮助保持数据完整性，还可以帮助提高数据检索操作的性能。</p><h1 id="主题：正常索引与唯一索引的差异"><a href="#主题：正常索引与唯一索引的差异" class="headerlink" title="主题：正常索引与唯一索引的差异"></a><strong>主题</strong>：正常索引与唯一索引的差异</h1><p>我们已经详细讨论了数据库中的索引，并讨论了两种特定类型的索引：<strong>正常索引</strong>（或非唯一索引）和<strong>唯一索引</strong>。 两者都有不同的角色，了解差异是至关重要的。</p><ol><li><strong>唯一性</strong>：根据名称本身就可以看出差异——正常索引在列或列组合上允许重复值。 相反，唯一索引不允许插入具有重复索引列值的新行。</li><li><strong>用途</strong>：正常索引主要用于提高MySQL的操作效率。 唯一索引，然而，具有双重目的。 它们可以同时提高操作效率并维护数据一致性，因为它们会拒绝具有重复值的新行。</li><li><strong>约束</strong>：当您在具有唯一索引的表中插入一行时，MySQL先检查是否会违反唯一性约束。 如果是这样，MySQL就会拒绝更改并发出错误。 与正常索引相比，MySQL不会执行这些检查。</li></ol><p>了解何时使用哪种类型的索引是至关重要的。 当您想要加速大型数据集上的查询时，正常索引就足够了。 但是，如果您需要确保列中的每个值都是唯一的，则应使用唯一索引，尽管它会消耗更多的资源来强制唯一性约束。</p><h1 id="主题：优化-SQL-查询使用索引"><a href="#主题：优化-SQL-查询使用索引" class="headerlink" title="主题：优化 SQL 查询使用索引"></a><strong>主题</strong>：优化 SQL 查询使用索引</h1><p>使用索引来提高数据库的性能并组织数据是使用 MySQL 索引的主要目标之一。 当正确使用时，索引可以显著加快数据检索操作的速度。 下面是一些提示，可帮助您优化 SQL 查询使用索引：</p><ol><li><strong>索引搜索字段</strong>：这似乎很简单，但值得重复。 如果您经常在表中搜索特定字段，请考虑索引该字段。 这可能会大大提高数据库的性能。</li><li><strong>考虑索引大小</strong>：索引的数据量越小，速度越快。 因此，具有较小数据类型的索引列通常会更快。 例如，INT 比 VARCHAR 更快，VARCHAR 比 TEXT 更快。</li><li><strong>限制写操作上的索引</strong>：索引可能会慢下写操作（例如 INSERT、UPDATE 和 DELETE 语句），因为每次修改数据时，索引也需要更新。 如果表经常更新，请考虑减少索引的数量。</li><li><strong>复合索引</strong>：它们由多个列组成，并可以加速在 WHERE 子句中过滤多列时的数据检索。 注意，它们按左侧前缀的顺序工作。 这意味着索引列的顺序很重要。</li><li><strong>使用 EXPLAIN 计划</strong>：MySQL 的 EXPLAIN 语句可以显示 MySQL 优化器如何执行您的查询，帮助您了解数据库是否能使用索引，并允许您进一步优化您的查询。</li></ol><p>这就完成了关于如何优化 SQL 查询使用索引的课程。</p><h1 id="主题：索引的常见陷阱"><a href="#主题：索引的常见陷阱" class="headerlink" title="主题：索引的常见陷阱"></a><strong>主题</strong>：索引的常见陷阱</h1><p>MySQL 中的索引是强大的工具，可以显著加快查询的速度。 然而，您应该注意以下几点，在使用它们时要小心。</p><ol><li><strong>过多的索引</strong>：有过多的索引可能会反效果。 每个索引都会增加 MySQL 更新和管理这些索引所花费的时间。 这可能会慢下写操作。 因此，要确保只有必要的索引。</li><li><strong>不了解卡尔数</strong>：卡尔数是索引中的唯一值数量。 如果卡尔数低（意味着有许多重复值），索引可能不会非常有效。 您应该关注索引的卡尔数并考虑是否应该使用另一列作为索引。</li><li><strong>索引错误的列</strong>：索引应该基于经常搜索或排序的列。 索引错误的列可能会导致不高效的查询。</li><li><strong>忽略查询执行计划</strong>：MySQL 的 EXPLAIN 语句可以提供有价值的信息，帮助您了解如何执行您的查询并识别使用的索引。 忽略这些信息可能会导致不高效的索引或优化的机会被错过。</li><li><strong>使用大 VARCHAR 或 TEXT 索引</strong>：大 VARCHAR 或 TEXT 列的索引可能会消耗大量内存并慢下查询。 在这种情况下，索引前缀（<code>INDEX(column(10))</code>)可能会有用。</li></ol><p>记住，有效的索引的秘诀在于了解数据并了解应用如何查询它。 有适当数量的良好选择的索引可以使数据库的性能显著提高。</p><h1 id="主题：回顾和评估"><a href="#主题：回顾和评估" class="headerlink" title="主题：回顾和评估"></a><strong>主题</strong>：回顾和评估</h1><p>我们已经学习了 MySQL 索引的许多内容，包括它们是什么、它们的类型（普通和唯一索引）、它们是如何用于查询优化的、以及一些常见的误解和陷阱。</p><p>现在是时候进行快速评估了。这将帮助强化你的学习并帮助突出任何我们可能需要重新访问的地方。</p><p><strong>例题</strong>：</p><p>为了测试你的理解，让我们通过一个例题来进行。</p><p>我们有一个名为 students 的 MySQL 数据库表，其结构如下：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| id (INT) | name (VARCHAR) | class (VARCHAR) | age (INT) |</span><br></pre></td></tr></tbody></table></figure><p>你经常需要查找来自特定 class 的学生。如何优化这个查询？</p><p><strong>解决方案</strong>：</p><p>为了优化这个查询，我们可以为 class 列添加一个索引。由于我们经常搜索这个字段，为其添加索引可以显著增加查询的性能。</p><p>下面是创建索引的 SQL 语句：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX idx_students_class ON students (class);</span><br></pre></td></tr></tbody></table></figure><p>现在，让我们测试你的理解：</p><ol><li><strong>简单问题</strong>（难度：3/10）：要为 age 列添加索引，你将使用哪个 SQL 语句？</li></ol><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX idx_students_age ON students(age);</span><br></pre></td></tr></tbody></table></figure><ol><li><strong>复杂熟问题</strong>（难度：6/10）：在添加索引之前，你应该考虑哪些因素？</li></ol><ul><li>列的卡尔伴：高卡尔伴列（具有许多独特值的列）最适合索引化。</li><li>应用程序的读写比率：如果应用程序执行更多的读操作，索引化是有益的。但是，如果应用程序执行更多的写操作（插入、更新、删除），索引的维护成本可能会超过好处。</li><li>列的数据类型：索引小数据类型列的速度更快。</li></ul><ol><li><strong>复杂未知问题</strong>（难度：9/10）：数据库表 students 还有一个名为 registration_date 的列（日期类型），并且你正在运行查询来找到注册于特定年份的学生。你可以使用哪种索引来优化这个查询，并且怎样创建它？</li></ol><p>在这种情况下，你可以创建一个函数或表达式的索引，在 MySQL 8.0 或更高版本中称为函数索引。</p><p>要在 MySQL 8.0 或更高版本中创建函数索引，可以使用以下语句：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX idx_students_registration_year ON students((YEAR(registration_date));</span><br></pre></td></tr></tbody></table></figure><p>这样，MySQL 就可以直接将年份映射到索引中的行，从而加快查询的速度。</p><p>请注意，在 MySQL 8.0 或更高版本中创建函数或表达式索引是受支持的。如果你使用的是早期版本的 MySQL，你将需要添加一个单独的列来存储年份，然后索引该列。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview11/">https://programmerscareer.com/mysql-interview11/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 面试：简述脏读和幻读的发生场景，InnoDB 是如何解决幻读的？</title>
      <link href="/zh-cn/mysql-interview12/"/>
      <url>/zh-cn/mysql-interview12/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>你曾被要求类似问题在面试中吗？或者将来会遇到，让我们一起探索和掌握它。</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：1-1-数据库事务中的问题介绍"><a href="#主题：1-1-数据库事务中的问题介绍" class="headerlink" title="主题：1.1 数据库事务中的问题介绍"></a><strong>主题</strong>：1.1 数据库事务中的问题介绍</h1><p>在深入数据库事务的复杂性时，需要承认这些操作不总是简单的。它们的主要目的是执行一系列操作，使数据库从一个一致的状态变化到另一个一致的状态。然而，同时进行事务时，我们遇到了许多问题，需要解决以维持一致性和完整性。</p><p>其中一个挑战是并发事务的问题。为了维持事务的 <strong>ACID</strong> 属性（原子性、一致性、隔离性和持久性），数据库系统必须正确地处理并发事务的执行。如果未能确保正确管理，可能会导致以下问题：</p><ol><li><strong>脏读</strong>：这种问题发生在一个事务读取另一个事务还未提交的变更时。如果后者事务被回滚，则前者事务读取了一个无效的值。</li><li><strong>不可重复的读取</strong>：这是当一个事务多次读取同一行时，每次读取都会得到不同的数据，因为其他事务正在更新该行同时进行。</li><li><strong>幻读</strong>：这是当一个事务执行两次相同的查询时，第二次结果集包含未在第一次结果集中的行，由另一个事务添加。</li></ol><p>这些事务控制问题会破坏数据库事务的顺畅功能并影响数据完整性。在以下课程中，我们将深入探讨脏读和幻读的场景，并了解解决方案，包括 MySQL InnoDB 引擎提供的解决方案。</p><h1 id="主题：1-2-理解脏读"><a href="#主题：1-2-理解脏读" class="headerlink" title="主题：1.2 理解脏读"></a><strong>主题</strong>：1.2 理解脏读</h1><p>在数据库的上下文中，“脏读”是指一个事务读取另一个事务还未提交的脏数据。例如，事务 1 修改了某行，但尚未提交。现在，在事务 1 提交之前，事务 2 读取了未提交的变更。这就是脏读。</p><p>为什么这是一个问题？ 假设事务 1 最终回滚。在这种情况下，变更被撤销，但事务 2 已经读取了脏数据，导致不一致性并可能导致无效的结果在数据库中。</p><p>下面是一个简单的例子：</p><p><strong>步骤 1：</strong></p><ul><li>事务 1 在 <code>orders</code> 表中修改了 <code>order_status</code> 字段，将其从 ‘Pending’ 更新为 ‘Shipped’。</li></ul><p><strong>步骤 2：</strong></p><ul><li>在事务 1 提交之前，事务 2 读取了 <code>order_status</code> 并发现它是 ‘Shipped’。</li></ul><p><strong>步骤 3：</strong></p><ul><li>事务 1 遇到错误并执行 ROLLBACK 操作，将 <code>order_status</code> 更改回 ‘Pending’。</li></ul><p><strong>步骤 4：</strong></p><ul><li>然而，事务 2 继续进行，并读取 ‘Shipped’ 状态，尽管这从未存在过。</li></ul><p>脏读可能会导致严重的错误，特别是在数据分析或报告过程中，准确性是至关重要的。</p><p>中文翻译:</p><h1 id="主题：1-3-理解幻读"><a href="#主题：1-3-理解幻读" class="headerlink" title="主题：1.3 理解幻读"></a><strong>主题</strong>：1.3 理解幻读</h1><p>像脏读一样，幻读也是数据库事务中的并发问题。幻读通常发生在事务重新查询它已经查询过的数据，但发现新行，这些行在初始读取之后被其他事务插入或更新。</p><p>这些“幻”行是由另一个事务在我们的初始事务开始之后并在其结束之前插入或更新所导致的。</p><p>为了更清楚地理解这一点，让我们考虑一个简单的例子：</p><p><strong>步骤 1：</strong></p><ul><li>事务 1 从 <code>orders</code> 表中检索所有 <code>order_status</code> 为 ‘Pending’ 的行。</li></ul><p><strong>步骤 2：</strong></p><ul><li>在这之间，事务 2 在 <code>orders</code> 表中插入了一个新行，其 <code>order_status</code> 为 ‘Pending’，并提交。</li></ul><p><strong>步骤 3：</strong></p><ul><li>现在，事务 1 再次运行相同的检索查询。这次，它发现事务 2 插入的行——这是一个幻行。</li></ul><p>幻读问题主要发生在较低的隔离级别中，例如“读已提交”，但不是较高的隔离级别，例如“序列化”。这是由于使用排他范围锁来阻止在读范围内插入新行所导致的。</p><p>然而，这些较高的隔离级别也会遇到问题，例如较低的并发和较高的争用。因此，事务隔离级别的选择通常需要权衡性能和一致性之间的交换。但是，不要担心，InnoDB 提供了处理这些情况的方法。</p><h1 id="主题：1-4-InnoDB-在处理幻读方面的作用"><a href="#主题：1-4-InnoDB-在处理幻读方面的作用" class="headerlink" title="主题：1.4 InnoDB 在处理幻读方面的作用"></a><strong>主题</strong>：1.4 InnoDB 在处理幻读方面的作用</h1><p>InnoDB 存储引擎在 MySQL 中起着关键的作用，处理数据库事务问题，包括幻读。它通过使用 <strong>多版本并发控制 (MVCC)</strong> 来允许多个事务同时访问同一行，而不会影响彼此的工作。</p><p>每个事务看到数据库在其工作开始时的一个快照，使并发事务相互隔离。这对 MySQL InnoDB 中的 “I” (一致性) 部分起着重要作用。</p><p>此外，您还可以在 MySQL 中设置不同的隔离级别来自定衡读一致性、并发和性能之间的平衡。这些隔离级别包括 READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ 和 SERIALIZABLE。</p><p>重复读级别是 InnoDB 的默认级别，它保证了所有在同一事务中的读取都会看到数据库在事务开始时的一个快照。这个特性有效地防止了幻读。</p><p>然而，在某些业务场景中，序列化级别可能是必需的，提供最高的数据一致性，但是以代价较低的并发和性能。</p><p>在本课程的后期，我们将详细讨论 InnoDB 如何实现 ACID 属性并自定化这些事务属性，根据用户需求进行调整。</p><h1 id="主题：1-5事务隔离级别"><a href="#主题：1-5事务隔离级别" class="headerlink" title="主题：1.5事务隔离级别"></a><strong>主题</strong>：1.5事务隔离级别</h1><p>事务隔离级别在数据库管理系统中如何管理并保护事务免受潜在问题（脏读、不可重复读和幻读）的中心角色。</p><p>在 MySQL 中，有四种预设的隔离级别，每种级别具有性能和保护之间的不同权衡：</p><ol><li><strong>读未提交</strong>：这是隔离级别的最低水平，它允许事务看到其他事务未提交的更改。这意味着事务可能会看到“脏”数据，其他事务可能会后悔。</li><li><strong>读已提交</strong>：这个级别保证了任何读取的数据都已提交。因此，它防止脏读。然而，如果事务多次读取同一行，它可能会看到不同的值，如果另一事务修改了该行之间，这可能会导致不可重复读。</li><li><strong>可重复读</strong>：这是 InnoDB 的默认隔离级别。它防止脏读和不可重复读，并确保所有读取的相同行在同一事务内返回相同的结果，除非该行自身被该事务修改。</li><li><strong>序列化</strong>：这是隔离级别的最高水平。它锁定读取的行，防止其他事务（读或写）访问它们，直到第一事务完成。虽然这种级别可以防止脏读、不可重复读和幻读，但它显著降低了并发性。</li></ol><p>了解这些隔离级别是管理并发事务有效的关键。在下一主题中，我们将讨论一些实现并发控制的技术和实践。</p><h1 id="主题：1-6并发控制的策略"><a href="#主题：1-6并发控制的策略" class="headerlink" title="主题：1.6并发控制的策略"></a><strong>主题</strong>：1.6并发控制的策略</h1><p>数据库中的并发控制的目的是允许多个事务同时访问数据库，而不会发生冲突或错误。为了有效地实现并发控制，我们可以利用以下策略：</p><ol><li><strong>锁定基于的协议</strong>：这是一种常见的方法，其中给定事务在需要时为数据项锁定访问。有两种锁：排他锁和共享锁。前者不允许其他事务访问数据项，后者允许，但仅限于读取目的。</li><li><strong>时间戳基于的协议</strong>：这种方法涉及为每个事务分配一个时间戳，确保早期事务具有优先权，特别是在冲突时。</li><li><strong>有效性基于的协议</strong>：也称为乐观并发控制，这种方法允许事务执行无限制并在提交时进行有效性检查。</li><li>**多版本并发控制 (MVCC)**：主要用于 InnoDB，MVCC允许每个与数据库连接的用户从事务开始时看到一致的快照集。</li><li><strong>数据项的粒度</strong>：这决定了锁定的数据项的大小——从单行到整个数据库。</li></ol><p>每种策略都有其优势和劣势。例如，锁定基于的协议可能会创造性能问题由于锁争，而 MVCC可能会为 InnoDB 提供高并发和减少了锁定的需求，但可能会增加存储的成本。</p><p>要选择一种策略，应考虑应用程序的需要和考虑，例如性能、一致性和复杂性。</p><h1 id="主题：1-7-回和评估"><a href="#主题：1-7-回和评估" class="headerlink" title="主题：1.7 回和评估"></a><strong>主题</strong>：1.7 回和评估</h1><p>你已经做得非常好地探索了数据库事务的关键方面，了解了并发控制的概念，它所倾向的问题，并使用各种策略来处理这些问题。</p><p>到目前为止，我们已经了解了并发控制的必要性，即处理同时发生的事务。我们已经识别了潜在的挑战，例如脏读、不可重复读和幻读，这些基本上涉及事务如何处理来自其他事务的数据更改。</p><p>我们深入探讨了脏读是什么，它是如何发生的，以及对数据库事务的影响。同样，我们对幻读发生的情况进行了详细讨论，并讨论了它可能会导致的问题。</p><p>我们研究了 MySQL 中 InnoDB 存储引擎的角色，特别是它是如何实现“一致读取”来处理幻读。</p><p>我们进一步深入探讨了事务隔离级别的概念，了解配置不同的事务隔离级别可以影响脏和幻读的发生。</p><p>我们还讨论了处理并发问题的各种策略，例如事务调度和使用各种类型的锁定基于的协议。</p><p>现在，让我们回一下这些关键概念，通过评估来评估你对脏读、幻读和 InnoDB 解决这些问题的方法的理解。</p><p>好的，让我们来解决三个评估问题。试着解决每一个，然后我会提供答案。</p><h2 id="简单问题（难度：3-10）"><a href="#简单问题（难度：3-10）" class="headerlink" title="简单问题（难度：3/10）"></a>简单问题（难度：3/10）</h2><p>假设同时发生两个事务，事务 1 读取了数据对象，事务 2 后来更新了它。识别这种读取问题可能会发生的。</p><h2 id="复杂熟问题（难度：6-10）"><a href="#复杂熟问题（难度：6-10）" class="headerlink" title="复杂熟问题（难度：6/10）"></a>复杂熟问题（难度：6/10）</h2><p>在数据库事务的上下文中，MySQL 中的 InnoDB 存储引擎是如何处理幻读的？描述一下 ‘一致读取’ 是如何帮助管理这些幻读。</p><h2 id="复杂未熟问题（难度：9-10）"><a href="#复杂未熟问题（难度：9-10）" class="headerlink" title="复杂未熟问题（难度：9/10）"></a>复杂未熟问题（难度：9/10）</h2><p>你是银行系统的数据库管理员。同时发生两个事务，其中一个是客户 ‘A’ 向客户 ‘B’ 转账，另一个是银行计算客户 ‘A’ 的总余额。由于这些事务的并发性，银行余额计算发生在转账事务未完成之前。解释可能会发生的问题。</p><h2 id="简单问题（难度：3-10）-1"><a href="#简单问题（难度：3-10）-1" class="headerlink" title="简单问题（难度：3/10）"></a>简单问题（难度：3/10）</h2><p>这是一个“脏读”的问题。在数据库管理中，脏读是指事务 1（Transaction 1）可以读取数据库中的行，该行已经由另一事务（Transaction 2）修改，但尚未提交。因此，如果 Transaction 2 回滚更改，Transaction 1 将读取被视为不存在的数据。</p><h2 id="复杂熟问题（难度：6-10）-1"><a href="#复杂熟问题（难度：6-10）-1" class="headerlink" title="复杂熟问题（难度：6/10）"></a>复杂熟问题（难度：6/10）</h2><p>InnoDB 存储引擎在 MySQL 中使用了“一致读取”来处理幻读。一致读取是 InnoDB 选择操作使用的非锁定读取，它为提供数据库的一致性快照提供了支持。它通过应用多版本并发控制（MVCC）来实现，其中存储多个版本的记录。这样，用户就可以无锁定延迟浏览数据库。</p><h2 id="复杂未熟问题（难度：9-10）-1"><a href="#复杂未熟问题（难度：9-10）-1" class="headerlink" title="复杂未熟问题（难度：9/10）"></a>复杂未熟问题（难度：9/10）</h2><p>在给定的场景中，可能会发生不可重复读的问题。不可重复读是指事务读取了同一行两次并获取了不同的数据。在这种情况下，银行余额计算事务可能先计算了余额，然后再次读取数据后客户 ‘A’ 转账了金额。因此，第一次和第二次读取会导致不同的客户 ‘A’ 的余额。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview12/">https://programmerscareer.com/mysql-interview12/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 面试：聚簇索引和非聚簇索引有什么区别？</title>
      <link href="/zh-cn/mysql-interview13/"/>
      <url>/zh-cn/mysql-interview13/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>你曾被提过类似问题在面试中问过吗？或者将来会遇到，让我们一起探索和掌握它！</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：1-1-聚集索引和非聚集索引的介绍"><a href="#主题：1-1-聚集索引和非聚集索引的介绍" class="headerlink" title="主题：1.1 聚集索引和非聚集索引的介绍"></a><strong>主题</strong>：1.1 聚集索引和非聚集索引的介绍</h1><p>了解数据存储和检索的方式对数据库的性能有着重要的影响。特别是了解 MySQL 是如何使用索引的非常重要。这就是聚集索引和非聚集索引的概念发挥作用的地方。</p><p>索引是数据库的一个重要组成部分。它们是查找表，数据库引擎使用它们来加速数据检索，就像书的索引一样，它可以帮助你快速定位信息，而不必阅读每一页。</p><p>现在，让我们详细地讨论聚集和非聚集索引：</p><p><strong>聚集索引</strong>：</p><p>就像名字所表明的那样，聚集索引决定了表中数据的物理排列顺序。为了更好地理解这一点，请考虑聚集索引是字典。在字典中，单词不是随机排列的，而是按字母顺序排列，这样你就可以快速跳到特定的字母部分并找到单词。在数据库的上下文中，这个“单词”是数据行。MySQL 就是按聚集索引的顺序组织数据行，以加快检索。请注意，表中只能有一个聚集索引。</p><p><strong>非聚集索引</strong>：</p><p>非聚集索引不决定表中数据的物理排列顺序。然而，它们保存了数据的“指针”。为了更好地理解，如果聚集索引是字典，那么非聚集索引就是书的索引。书的索引指向包含信息的页面，但它们本身不包含信息。这意味着数据库引擎必须执行额外的工作，以“去”数据行，与聚集索引相比，非聚集索引的数据检索可能会慢一些。然而，你可以有多个非聚集索引，这可能对数据检索的多种场景有所帮助。</p><h1 id="主题：1-2-聚集索引详解"><a href="#主题：1-2-聚集索引详解" class="headerlink" title="主题：1.2 聚集索引详解"></a><strong>主题</strong>：1.2 聚集索引详解</h1><p>聚集索引与数据的物理存储有关。当你为表创建一个聚集索引时，表中的行按索引键的顺序存储在磁盘上。表中只能有一个聚集索引，并且如果你没有显式定义一个聚集索引，SQL Server 将自动为你创建一个。这被称为堆。</p><p>聚集索引的结构也被称为 B+ 树结构。堆栈树的根节点位于树的顶部，然后分支出多个叶节点位于底部。这些叶节点包含数据行在索引的顺序中。</p><p>主键约束自动创建一个聚集索引，但在某些情况下，你可能希望手动创建一个聚集索引，这取决于你的要求。例如，如果你有一个员工数据表并经常按员工聘用日期进行查询，则可能会为聘用日期列创建一个聚集索引，以加快这些查询。</p><p>此外，在表中具有聚集索引的记录更新时，数据库可能会更慢，这是因为当记录更新在表中具有聚集索引时，数据库可能需要物理移动整行，以维护排序顺序。</p><h1 id="主题：1-3-非聚集索引的介绍"><a href="#主题：1-3-非聚集索引的介绍" class="headerlink" title="主题：1.3 非聚集索引的介绍"></a><strong>主题</strong>：1.3 非聚集索引的介绍</h1><p>现在我们已经对聚集索引有了深入的理解，了解它是如何排列和存储数据的。但是，并不总是想要根据单个聚集索引来检索数据。这就是非聚集索引的作用所在。</p><p>非聚集索引与聚集索引有着明显的区别。首先，创建非聚集索引不会重新排列表中数据的物理顺序。相反，它会创建一个独立的数据库对象，其中包含一个排序的列表，指向表中的数据。</p><p>为了说明这一点，请考虑一本书——相对于浏览整本书以找到特定主题，你通常会转到书的索引，是不是？它会直接将你导向包含指定主题的页面。这种快速导航就是非聚集索引所执行的功能！</p><p>非聚集索引的架构与聚集索引相似——B-树数据结构中的根节点、中间级节点和叶节点。然而，非聚集索引的叶节点仅包含索引列和指向数据表中相应行的指针。你可以为单个表创建多个非聚集索引，每个索引都为特定查询提供了加速。</p><p>在 MySQL 中，非聚集索引就是所有的辅助索引，其中每个索引都包含主键列的副本，用于指向搜索键匹配的行。</p><h1 id="主题：1-4-聚集和非聚集索引的差异"><a href="#主题：1-4-聚集和非聚集索引的差异" class="headerlink" title="主题：1.4 聚集和非聚集索引的差异"></a><strong>主题</strong>：1.4 聚集和非聚集索引的差异</h1><p>现在我们已经对聚集和非聚集索引有了深入的理解，让我们来明确它们之间的主要差异：</p><ol><li><strong>数据的排列顺序</strong>：聚集索引决定了表中数据的物理排列顺序。另一方面，非聚集索引不会改变数据记录的存储方式，但会创建一个数据库对象，该对象指向原始记录。</li><li><strong>索引数量</strong>：表中只能有一个聚集索引，但是可以有多个非聚集索引。请记，越多的索引，就需要越多的磁盘空间。</li><li><strong>数据检索速度</strong>：聚集索引可能会比非聚集索引更快地检索数据，但这并不总是如此。如果非聚集索引覆盖了查询（即，查询的数据可以从索引的叶节点中服务），它可能会更快地检索数据，尽管它需要一些额外的跳转。</li><li><strong>更新性能</strong>：聚集索引可能会降低更新的性能，而非聚集索引通常不会影响性能。</li><li><strong>存储空间</strong>：由于非聚集索引是与表数据分开存储的，因此它需要额外的存储空间。每个非聚集索引是一个独立的磁盘结构，其中包含一个排序的列表，其中包含列值，而聚集索引是表数据本身并形成了索引的最低级别。</li></ol><p>在数据库的大图景中——数据检索速度、存储效率、更新速度等等——所有这些因素都依赖于良好的索引。清楚地了解何时和为什么使用聚集和非聚集索引可以帮助您优化数据库性能。</p><h1 id="主题：1-5-选择正确的索引"><a href="#主题：1-5-选择正确的索引" class="headerlink" title="主题：1.5 选择正确的索引"></a><strong>主题</strong>：1.5 选择正确的索引</h1><p>恭喜！现在我们知道什么是聚集索引和非聚集索引，并了解了它们之间的主要差异，让我们深入探讨选择正确的索引进行性能优化。</p><p>在 MySQL 中选择正确的索引来进行性能优化，主要取决于了解将要执行的查询。它不仅仅是选择聚集或非聚集索引，还包括了列和其卡inality 的理解。</p><p>下面是一些关键点来帮助你决定：</p><ol><li><strong>使用聚集索引来处理宽列查询</strong>：由于聚集索引本身就是表数据，因此对宽列查询来说非常有用，因为它可以减少读取的数量。</li><li><strong>使用非聚集索引来处理特定列查询</strong>：非聚集索引在需要检索较小的列集时非常有用。在这种情况下，为这些列创建非聚集索引可能会有好处。</li><li><strong>高卡inality列</strong>：当列具有高卡inality（每行都是唯一的）时，使用它作为聚集索引可能会导致更快的查找。</li><li><strong>低卡inality列</strong>：对于具有低卡inality（许多行共享相同值）的列，使用非聚集索引通常更有效。</li><li><strong>数据修改操作</strong>：如果应用程序包含频繁的插入、更新和删除操作，非聚集索引可能是更好的选择，因为它们不会影响磁盘上的数据排序。</li><li><strong>空间考虑</strong>：由于非聚集索引是独立的磁盘结构，它们会消耗额外的存储空间。如果存储空间是一个限制，聚集索引可能是更好的选择，虽然在某些情况下，它可能会影响速度。</li></ol><p>记住，最佳策略总是取决于特定的工作负载。它是必要的进行持续的监控和分析，并根据性能进行索引策略的调整。</p><h1 id="主题：1-6-示例和用例"><a href="#主题：1-6-示例和用例" class="headerlink" title="主题：1.6 示例和用例"></a><strong>主题</strong>：1.6 示例和用例</h1><p>好的！你已经做得很好了。为了巩固理解，让我们来看看一些实际的例子和用例。</p><p>开始时，让我们考虑一个基本的例子，假设你直接管理一个在线书店。你有一个名为 <code>Books</code> 的表，其中包含以下列：<code>BookID</code>、<code>Title</code>、<code>Author</code>、<code>Genre</code>、<code>Price</code> 和 <code>PublicationDate</code>。</p><ol><li><strong>使用聚集索引</strong>：假设客户经常根据 <code>BookID</code> 在您的商店中搜索书籍。为了提高这些常见的拉取请求的速度，您可以使用 <code>BookID</code> 列上的聚集索引。由于聚集索引确定数据在表中的物理排序，行查找可能会显著加快。</li><li><strong>使用非聚集索引</strong>：如果客户经常根据 <code>Genre</code> 或 <code>Author</code> 搜索书籍，则可能有利于创建非聚集索引在这些列上。正如我们所了解的，非聚集索引特别有用当你需要检索较小的列集时。</li></ol><p><strong>用例</strong>：假设您的数据库具有名为 <code>Customers</code> 的表，其中包含数百万条记录，并经常需要检索客户信息根据 <code>CustomerID</code>。在这种情况下，使用 <code>CustomerID</code> 列上的聚集索引可以显著加快这些查找。然而，如果业务需求要求您根据 <code>LastName</code> 和 <code>ZipCode</code> 检索记录，则非聚集索引在 <code>LastName</code> 和 <code>ZipCode</code> 列上可能更有效。</p><p>请记住，这些只是例子，并且实际的实现可能会大大地变化，取决于因素如数据大小、查询复杂性和硬件能力。了解何时使用聚集和非聚集索引——基于智能数据库设计——是管理 SQL 数据库的重要方面。</p><h1 id="主题：1-7-回顾和评估"><a href="#主题：1-7-回顾和评估" class="headerlink" title="主题：1.7 回顾和评估"></a><strong>主题</strong>：1.7 回顾和评估</h1><p>恭喜！让我们回顾主要的概念并进行评估。</p><ol><li><strong>聚集索引</strong>：这种类型的索引确定了表数据的物理排序。表只能有一个聚集索引。</li><li><strong>非聚集索引</strong>：这种类型的索引是独立的磁盘结构，引用表数据，帮助加速不在聚集索引范围内的查询。表可以有多个非聚集索引。</li><li><strong>高 vs. 低卡inality</strong>：高卡inality指的是具有独特值的列，在大多数，如果不是所有，行上。对高卡inality列使用聚集索引可能会导致更快的查找。低卡inality指的是具有多个行共享相同值的列。对于这些列，非聚集索引通常更有效。</li><li><strong>选择正确的索引</strong>：这取决于各种因素，包括查询类型、卡inality、数据修改需求和空间约束。</li></ol><p>现在，让我们通过几个问题来评估我们的理解：</p><ol><li><strong>聚集索引和非聚集索引之间的主要区别是什么？</strong></li><li><strong>在哪种情况下，非聚集索引比聚集索引更适合？</strong></li><li><strong>高卡inality和低卡inality是什么意思，并且如何影响索引类型的选择？</strong></li></ol><p><strong>问题</strong>：聚集索引和非聚集索引之间的主要区别是什么？<br><strong>答案</strong>：聚集索引和非聚集索引之间的主要区别在于存储和引用数据的方式。聚集索引确定了表数据的物理排序，本身就是表数据，而非聚集索引是独立的结构，指向数据位于数据库的其他地方。</p><p><strong>问题</strong>：在哪种情况下，非聚集索引比聚集索引更适合？<br><strong>答案</strong>：非聚集索引更适合在数据库需要支持大量搜索查询的列上，这些列不在聚集索引范围内。此外，非聚集索引还更适合在表经常更新时，因为更新不会导致整个表需要重新组织，与聚集索引相比。</p><p><strong>问题</strong>：高卡inality和低卡inality是什么意思，并且如何影响索引类型的选择？<br><strong>答案</strong>：卡inality是数据值在列中的独特性。高卡inality意味着列中具有大量独特值，低卡inality意味着列中具有多个重复值。对高卡inality列使用聚集索引可能会导致更快的查找，而对低卡inality列使用非聚集索引通常更有效，因为在这些列上，值是非常重复的。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview13/">https://programmerscareer.com/mysql-interview13/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 面试：什么是数据库事务，MySQL 为什么会使用 InnoDB 作为默认选项？</title>
      <link href="/zh-cn/mysql-interview14/"/>
      <url>/zh-cn/mysql-interview14/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>你曾被提过类似问题在面试中问过吗？或者将来会遇到，让我们一起探索和掌握它！</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题-1-1-—-深入探讨事务"><a href="#主题-1-1-—-深入探讨事务" class="headerlink" title="主题 1.1 — 深入探讨事务"></a>主题 1.1 — 深入探讨事务</h1><p>简单地说，事务是在数据库管理系统（或类似系统）中对数据库进行的单元工作，并以可靠的方式独立处理。</p><p>事务通常表示数据库中的任何更改。更具体地说，事务是一系列数据库操作的逻辑单位。</p><p>考虑转移银行帐户中的资金的例子。这项操作需要两个步骤：</p><ol><li>在一个帐户中取款。</li><li>在另一个帐户中存款。</li></ol><p>两个步骤都必须完成，以便事务被认为已完成。如果在这两个操作之间发生了什么，例如服务器故障，事务将被认为是不完整的，并且数据库必须回滚到其前一致状态。</p><p>这样，事务帮助数据库保持<strong>完整性</strong>，确保相关操作的集合要么全部发生，要么全部不发生。事务的概念与 ACID（原子性、一致性、隔离性、持久性）密切相关，为数据的可靠处理提供了框架。</p><h1 id="主题-1-2-—-MySQL-和事务"><a href="#主题-1-2-—-MySQL-和事务" class="headerlink" title="主题 1.2 — MySQL 和事务"></a>主题 1.2 — MySQL 和事务</h1><p>MySQL 是一个数据库管理系统，提供了处理事务的支持。这意味着 MySQL 允许您将某些操作组合在一起，以便要么所有操作都执行，要么不执行。这在数据库中的中间步骤失败可能导致数据库不一致的场景中尤其重要。</p><p>再次考虑转移银行帐户中的资金的例子。现在，让我们说我们正在使用 MySQL 数据库来管理这些事务。让我们按步进：</p><ol><li>用户 A 启动了一项事务，请求转移 $100 给用户 B。</li><li>MySQL 开始了事务。</li><li>MySQL 从用户 A 的帐户平衡中扣除 $100。</li><li>MySQL 尝试为用户 B 的帐户添加 $100。</li><li>我们考虑两种情况：</li></ol><ul><li>如果操作成功，MySQL 提交了事务，数据库显示了两个用户的更新帐户平衡。</li><li>如果出现故障（可能是由于服务器崩溃或未预期的问题），MySQL 回滚了事务。结果是数据库保持了其初始状态，没有对用户 A 或用户 B 的帐户平衡进行更改。数据库保持一致性。</li></ul><p>这样，MySQL 在保持 ACID 原则的情况下，为数据库处理提供了关键角色。</p><p>请记，MySQL 的事务处理功能不是每个设置都提供，而是需要特定类型的存储引擎。我们将在以后的主题中进一步探讨这一点。</p><h1 id="主题-1-3-—-了解-InnoDB"><a href="#主题-1-3-—-了解-InnoDB" class="headerlink" title="主题 1.3 — 了解 InnoDB"></a>主题 1.3 — 了解 InnoDB</h1><p>现在，我们已经了解了事务在维护数据库完整性的重要性并了解了 MySQL 是如何处理事务的，是时候探讨 InnoDB 了。</p><p>InnoDB 是 MySQL 的存储引擎。初始版本的 MySQL 用户需要选择两种主要类型的存储引擎——MyISAM 和 InnoDB。每个引擎都有自己的优势和劣势。然而，MyISAM，一个更早的引擎，不支持事务。InnoDB，另一方面，提供了完整的事务支持，涉及多条语句的提交和回滚。InnoDB 还提供行级锁定，增加了多用户并发和性能，并具有我们已经讨论过的一些特性。</p><p>自 MySQL 5.5 版本的发布以来，InnoDB 已经成为默认的 MySQL 存储引擎，除非另外指定。这种决定主要基于 InnoDB 的稳定性和全功能性。</p><p>因此，InnoDB 的强事务支持，以及其他特性，使它成为广泛和复杂的数据库系统的强大选择。</p><h1 id="主题-1-4-—-InnoDB-的优势"><a href="#主题-1-4-—-InnoDB-的优势" class="headerlink" title="主题 1.4 — InnoDB 的优势"></a>主题 <strong>1.4 — InnoDB 的优势</strong></h1><p>InnoDB 的主要优势在于其强大的事务处理和行级锁定功能。这使它成为广泛和复杂的数据库系统的强大选择，特别是在具有高数量并发用户的情况下。</p><p>让我们来详细分析一些这些优势：</p><ol><li><strong>可靠性和持久性——ACID 遵从性：</strong> 就像我之前提到的一样，InnoDB 的事务遵从 ACID 模型，由其提交、回滚和崩溃恢复功能支持。它确保您的事务是可靠的，并且数据是持久的。</li><li><strong>行级锁定：</strong> InnoDB 使用行级锁定，而 MyISAM 使用表级锁定。行级锁定更有效，因为它允许更高的并发性和在多用户环境中的更好的性能。</li><li><strong>InnoDB 缓冲池：</strong> InnoDB 使用缓冲池来缓存其表的数据和索引。这个特性减少了 I/O 操作，使系统更快和更具有性能。</li><li><strong>外键约束：</strong> InnoDB 支持使用外键约束来维护参考完整性。当数据在一个表中依赖数据在另一个表中时，您可以通过外键约束来防止错误地删除关键数据。</li><li><strong>自动崩溃恢复：</strong> InnoDB 具有自动崩溃恢复的功能。在崩溃期间更新的关键数据不会丢失，因为引擎自动重放其日志。</li></ol><p>这些只是 InnoDB 为 MySQL 数据库带来的许多优势的一些。根据您的特定需求，可能还有更多与您的使用场景相关的好处。</p><h1 id="主题1-5-—-InnoDB-与-MyISAM"><a href="#主题1-5-—-InnoDB-与-MyISAM" class="headerlink" title="主题1.5 — InnoDB 与 MyISAM"></a>主题1.5 — InnoDB 与 MyISAM</h1><p>InnoDB 和 MyISAM 都是 MySQL 的存储引擎，但它们有显著的差异。了解这些差异对决定适合特定用例的存储引擎至关重要。</p><p>让我们根据以下几个关键参数进行比较：</p><ol><li><strong>事务：</strong> 我们以前已经讨论过，InnoDB 支持事务，而 MyISAM 不支持。如果您需要事务性整性，则应选择 InnoDB。</li><li><strong>锁定：</strong> InnoDB 实现了行级锁定，而 MyISAM 实现了表级锁定。行级锁定允许更高的并发性并提供更好的性能，特别是对频繁、小数据修改的操作。</li><li><strong>外键约束：</strong> InnoDB 支持外键约束，而 MyISAM 不支持。</li><li><strong>全文搜索：</strong> MyISAM 具有内置的全文搜索支持，这使它成为主要要求的好选项。</li><li><strong>数据安全性：</strong> InnoDB 使用事务日志来确保数据安全性（ACID 兼容性），而 MyISAM 不使用。</li><li><strong>压缩：</strong> InnoDB 支持表压缩，允许表数据和相关索引进行压缩，以节省磁盘空间并提高 I/O 效率和性能。</li></ol><p>最重要的是要记住，没有一个通用的“正确”选择之间的 InnoDB 和 MyISAM。适合的引擎取决于您的特定情况和要求。</p><h1 id="主题1-6-—-案例研究：真实世界的例子和场景，数据完整性和事务的重要性"><a href="#主题1-6-—-案例研究：真实世界的例子和场景，数据完整性和事务的重要性" class="headerlink" title="主题1.6 — 案例研究：真实世界的例子和场景，数据完整性和事务的重要性"></a>主题1.6 — 案例研究：真实世界的例子和场景，数据完整性和事务的重要性</h1><p>数据完整性和事务是许多真实世界的应用程序中的关键要素。为了说明其重要性在实际场景中，让我们考虑几个案例研究。</p><p><strong>在线银行和金融服务：</strong></p><ol><li>在在线银行系统中，假设一个客户从储蓄账户转移了资金到支票账户。这个过程包括两个单独的任务：减少储蓄账户的余额和增加支票账户的余额。两个任务都需要发生。如果系统在储蓄账户被扣除后但是在支票账户被加载之前出现故障，客户就会损失资金。事务的 ACID 特性确保数据的一致性。</li></ol><p><strong>电子商务平台：</strong></p><ol><li>考虑一个客户在电子商务网站上下单。这个过程包括检查库存、确认付款、更新库存和确认订单。任何错误或故障在一个阶段应该阻止整个过程。事务为这些操作提供了安全的通路，确保数据的一致性。</li></ol><p><strong>航空航班预订系统：</strong></p><ol><li>当一个座位在航班上预订时，系统先检查座位的可用性，然后预订座位，然后接受付款。如果航空预订系统崩溃在座位被预订但是在付款确认之前，航空公司就会损失。通过事务，在后期的故障中，前期的阶段自动回滚，释放座位以供其他客户使用。</li></ol><p>这些是几个场景，其中数据一致性是至关重要的。在关键系统中，InnoDB 的强大功能为数据的一致性提供了非常有用的支持。</p><h1 id="主题1-7-—-MySQL-面试题：数据库事务为什么重要，为什么-InnoDB-是-MySQL-的默认选项？"><a href="#主题1-7-—-MySQL-面试题：数据库事务为什么重要，为什么-InnoDB-是-MySQL-的默认选项？" class="headerlink" title="主题1.7 — MySQL 面试题：数据库事务为什么重要，为什么 InnoDB 是 MySQL 的默认选项？"></a>主题1.7 — MySQL 面试题：数据库事务为什么重要，为什么 InnoDB 是 MySQL 的默认选项？</h1><p>事务是数据库系统的一个重要概念。它们用于保护组织的信息，在系统故障（例如电力中断、软件崩溃或更危险的内容攻击）发生时进行保护。</p><p>事务是一系列的单个逻辑单元的操作序列。操作可以包括读取数据库记录、修改这些记录或者在特定参数内进行数据操作。</p><p>在数据库系统中，事务被管理使用 ACID 的缩写，它代表原子性、一致性、隔离性和持久性。</p><ul><li><strong>原子性：</strong>保证事务中所做的所有更改都被提交到数据库中，或者如果发生错误，则不会提交任何更改。</li><li><strong>一致性：</strong>确保事务不会在运行后将数据库置于不一致的状态。</li><li><strong>隔离性：</strong>确保一个事务不会干另一个事务。</li><li><strong>持久性：</strong>确保已提交的更新持久化，即使发生电力中断或系统崩溃。</li></ul><p>现在，为什么 InnoDB 是 MySQL 的默认选项？</p><p>InnoDB 存储引擎提供了一种强大和可靠的方式来处理事务。它具有许多特性，例如 ACID 兼容事务支持、行级锁定和实际实现，例如外键，使其成为 MySQL 的默认引擎。</p><p>此外，InnoDB 提供了崩溃恢复功能并提供硬件加速，例如固态硬盘 (SSD) 或硬盘。</p><p>简而言，InnoDB 的优势在于其广泛适用的特性集，包括事务、可靠性和性能优化，适合大多数工作负载。</p><h1 id="主题1-8-—-复习和评估"><a href="#主题1-8-—-复习和评估" class="headerlink" title="主题1.8 — 复习和评估"></a>主题1.8 — 复习和评估</h1><p>在本课程中，我们已经讨论了：</p><ul><li><strong>事务</strong> 的重要性在维护数据完整性，</li><li>MySQL 如何支持事务并为其提供好处，</li><li>InnoDB 的介绍、其优势和为什么它是 MySQL 的默认存储引擎，</li><li>InnoDB 和 MyISAM 之间的差异，</li><li>在实际场景中，数据完整性和事务的重要性，</li><li>并提供了一些常见的 MySQL 面试问题和答案。</li></ul><p>为了复习，我将提供一组问题和问题，它们将从简单到复杂，所以请思考深入地。</p><p><strong>问题 1 (3/10 难度)：</strong></p><p>ACID 是事务的四个属性的缩写，它们是什么？</p><p><strong>问题 2 (6/10 难度)：</strong></p><p>为什么事务在数据库中的数据完整性方面重要？</p><p><strong>问题 3 (9/10 难度)：</strong></p><p>为什么 InnoDB 是 MySQL 的默认选项，并在哪些方面优于 MyISAM？在回答中包含 InnoDB 的好处。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview14/">https://programmerscareer.com/mysql-interview14/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 面试：数据库的事务隔离级别有哪些？各有哪些优缺点</title>
      <link href="/zh-cn/mysql-interview15/"/>
      <url>/zh-cn/mysql-interview15/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>你曾被提过类似问题在面试中问过吗？或者将来会遇到，让我们一起探索和掌握它！</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题-1-1：事务隔离级别简介"><a href="#主题-1-1：事务隔离级别简介" class="headerlink" title="主题 1.1：事务隔离级别简介"></a><strong>主题 1.1：事务隔离级别简介</strong></h1><p>让我们开始了解 MySQL 中的事务隔离级别！</p><p>先来看基本知识。</p><p>在允许并发事务的数据库系统中，事务隔离级别决定了一个事务与另一个事务之间的隔离程度。它们是必要的，因为它们帮助管理并发事务，防止数据不一致，并确保任何事务系统中的数据的完整性。</p><p>ANSI/ISO SQL 标准定义了四个事务隔离级别，具有相应的现象防止：</p><ol><li><strong>读未提交</strong>：这是事务隔离级别的最低级别，在这种情况下，一个事务可能会看到另一个事务尚未提交的更改。</li><li><strong>读已提交</strong>：它保证了任何数据的读取是在读取时提交的。它不能防止其他事务修改数据。</li><li><strong>可重复读</strong>：这个级别确保了如果一个事务读取了数据，然后其他事务修改了该数据，则第一个事务将获取相同的数据，不管后续的读取是否发生。</li><li><strong>序列化</strong> - 这个级别提供了最高的数据保护，它通过执行事务来实现，或者是一个接一个的事务。但是，这可能会导致性能问题。</li></ol><p>还要知道，MySQL，具有 InnoDB 存储引擎，只支持 Repeatable Read（默认隔离级别）、Read Committed 和 Serializable。</p><p>每个隔离级别都有其优点和缺点，解决了某些问题，同时可能会引入其他问题。这是管理并发事务的必要权衡，以平衡性能和准确性。</p><h1 id="主题-1-2：读未提交级别"><a href="#主题-1-2：读未提交级别" class="headerlink" title="主题 1.2：读未提交级别"></a><strong>主题 1.2：读未提交级别</strong></h1><p>在“读未提交”中，事务可能会读取尚未提交的数据，这是因为它读取的数据尚未提交到数据库中。</p><p>考虑下面的场景：一个事务正在修改表的一些行：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">UPDATE Inventory   </span><br><span class="line">SET Quantity = Quantity - 10   </span><br><span class="line">WHERE ItemName = 'Apples';</span><br></pre></td></tr></tbody></table></figure><p>当这个事务仍然在进行时，另一个事务读取了同一表的数据。根据读未提交级别，它会看到尚未提交的更改，包含正在处理的数据，导致所谓的“脏读”。</p><p>可能会出现一个事务失败（并发行回），使这些更改无效。但是，第二个事务已经读取了未提交数据，继续使用错误、不准确的数据。这可能会导致数据不一致。</p><p>在性能方面，然而，“读未提交”通常更快，因为它不需要为读数据锁定，以防止其他事务修改或读取。</p><p>然而，“读未提交”的缺点现在显现出来。它无法保证数据的准确性和一致性，因为，就像我们所说的，它允许“脏读”。</p><p>在实际应用中，这个隔离级别通常被避免，除非性能是最重要的因素，数据准确性不是主要考虑因素。</p><h1 id="主题-1-3：读已提交级别"><a href="#主题-1-3：读已提交级别" class="headerlink" title="主题 1.3：读已提交级别"></a><strong>主题 1.3：读已提交级别</strong></h1><p>根据名字所表明，“读已提交”级别允许事务只看其他事务在开始读取之前已经提交的更改。因此，它解决了我们在“读未提交”隔离级别中讨论的“脏读”问题。</p><p>让我们通过一个简单的例子来说明：</p><p>考虑两个账户，‘A’ 和 ‘B’，其当前余额分别为 $500 和 $200。假设一笔交易被初始化，从账户 ‘A’ 中转出 $100，并转入账户 ‘B’。在此过程中，账户 ‘A’ 的余额减少到 $400，尽管交易尚未完成。</p><p>在“读未提交”隔离级别中，如果另一项目试图同时计算两个账户的总余额，它可能会将账户 ‘A’ 的中间状态（即 $400）和账户 ‘B’ 的原始状态（即 $200）相加，导致错误的总余额 $600。</p><p>然而，在“读已提交”隔离级别中，第二项目等待第一项目完全完成。因此，它正确地计算总余额为 $700（$400 在账户 ‘A’ 中 + $300 在账户 ‘B’ 中）。</p><p>因此，在“读已提交”隔离级别中，一个事务不会看到其他事务未提交的更改，这是维护数据一致性的一个大步。</p><p>然而，现在我们面临另一个问题，称为“非重复读”。这发生在单个事务的生命周期内，试图两次读取同一行，但每次读取时获取不同的数据。这种情况是可能的，如果，在第一次和第二次读取之间，另一项目修改了该行并提交了更改。</p><h1 id="主题1-4：可重复读级别"><a href="#主题1-4：可重复读级别" class="headerlink" title="主题1.4：可重复读级别"></a><strong>主题1.4：可重复读级别</strong></h1><p>在“可重复读”隔离级别下，不仅其他事务的变更在提交之前是不可见的（就像“读提交”一样），但是事务第一次读取某些数据后，该数据在该事务的生命周期内不能变化。</p><p>换句话说，在同一事务中多次运行相同的 SELECT 查询将返回相同的结果，不管其他并发事务是否发生变化。这种约束解决了“非重复读”问题。</p><p>让我们来看一个例子：</p><p>考虑一种情况，其中事务读取了某些行，然后另一个独立事务修改了其中的某些行并提交了变更。如果第一个事务再次尝试读取相同的行，根据“读提交”隔离级别，它会注意到这些变化。</p><p>但是，在“可重复读”隔离级别下，第一个事务不会因为其他事务在其生命周期内提交的变更而察觉到任何变化。因此，读取相同的行会产生相同的结果。</p><p>虽然它解决了“脏读”和“非重复读”问题，但它也会遇到另一个问题：“幻读”问题，我们将在我们的下一节中讨论。</p><h1 id="主题1-5：序列化级别"><a href="#主题1-5：序列化级别" class="headerlink" title="主题1.5：序列化级别"></a><strong>主题1.5：序列化级别</strong></h1><p>“序列化”级别是所有级别中最严格的，提供了最高的数据一致性。它不仅处理“脏读”和“非重复读”问题，还解决了“幻读”问题。</p><p>首先，让我们了解一下“幻读”是什么。它是在事务的中间运行时新行被添加或现有行被删除的事务中发生的。它被命名为“幻”，因为这些记录似乎是“幻”的。</p><p>例如，考虑一个事务读取了某些行。另一个独立事务在此期间添加了某些新行并提交了变更。如果第一个事务再次读取该表，它会看到新行，这些行似乎是“幻”的。</p><p>在“序列化”隔离级别下，这种情况是不可能的。当事务在这个级别下运行时，它似乎就像其他事务不存在一样，消除了并发性相关的问题。</p><p>然而，这种精确性有代价。“序列化”隔离级别严重降低了性能，特别是对大型数据库。</p><p>简而言，“序列化”隔离级别确保绝对数据完整性，但是以性能为代价。</p><p>在讨论了每个特定的隔离级别之后，必须注意，您选择的级别最终取决于应用程序的性质。它总是关于性能和数据完整性之间的平衡。</p><h1 id="主题1-6：MySQL事务隔离级别解释"><a href="#主题1-6：MySQL事务隔离级别解释" class="headerlink" title="主题1.6：MySQL事务隔离级别解释"></a><strong>主题1.6：MySQL事务隔离级别解释</strong></h1><p>我们先讨论过，MySQL 中可用的四种事务隔离级别分别是读未提交（Read Uncommitted）、读已提交（Read Committed）、可重复读（Repeatable Read）和序列化（Serializable）。每种级别都为数据一致性、并发性和性能之间提供了不同的平衡。</p><p>然而，问题仍然存在：MySQL 是如何内部实现这些级别的？</p><p>MySQL 主要使用锁定来确保并发事务之间的数据一致性和隔离。它使用不同类型的锁，例如共享锁和排他锁，根据事务的要求和设置的隔离级别。</p><p>我们不会深入讨论细节，但是让我们了解这些锁是什么：</p><ol><li><strong>共享锁（S 锁）</strong>：当事务只是读取记录并未修改它时，会保持共享锁。多个事务可以同时保持共享锁的同一记录。</li><li><strong>排他锁（X 锁）</strong>：当事务修改记录时，会保持排他锁。在给定时间内，只有一个事务可以保持排他锁的记录。</li></ol><p>这些锁用于维护数据一致性并防止数据不一致。例如：</p><ul><li>在 <strong>Read Uncommitted</strong> 级别下，不会使用任何锁来防止其他事务写入记录。</li><li>在 <strong>Read Committed</strong> 级别下，会使用共享锁，但是在读取行后立即释放锁。</li><li>在 <strong>Repeatable Read</strong> 级别下，会使用共享锁并保持其直到事务完成。</li><li>在 <strong>Serializable</strong> 级别下，会使用共享锁，并且直到事务完成之前，其他事务不能修改或插入新记录。</li></ul><p>因此，根据使用的隔离级别，MySQL 引擎会以不同的方式获取和释放这些锁来实现所需的数据一致性，并在并发性和反之之间进行权衡。</p><p>然而，这种机制只是冰山一角。实际实现要复杂得多，并涉及许多其他因素，例如锁升级、死锁检测、日志缓冲和更多。</p><h1 id="主题1-7：实践案例"><a href="#主题1-7：实践案例" class="headerlink" title="主题1.7：实践案例"></a><strong>主题1.7：实践案例</strong></h1><p>在本节中，我们将通过实际场景来了解不同的事务隔离级别的实际应用，并将所有的学习联系起来。</p><p>最合适的隔离级别主要取决于特定的读/写工作负载和每个应用的业务要求。在实际场景中，我们需要找到并发性和隔离之间的平衡。</p><p>让我们来看几个场景：</p><p><strong>场景 1：银行系统</strong></p><p>对于处理事务性数据的银行系统，例如银行转账，脏读和非重复读是绝对不可接受的。例如，如果你从一个自动Tellermachine（ATM）取出了钱，但由于并发事务，系统未能立即注册扣除，这可能会导致你提取了超过你的余额。这是对我们来说的一个美妙的场景，但对银行来说是一个灾难性的情况！</p><p>因此，对于这样的系统，通常使用较高的隔离级别，例如<code>SERIALIZABLE</code>或<code>REPEATABLE READ</code>，尽管这可能会影响性能。</p><p><strong>场景 2：电子商务应用</strong></p><p>对于电子商务应用，允许脏读可能会导致卖出更多的商品，而如果我们非常严格地处理隔离级别，它可能会降低应用的性能并影响用户体验。通常使用<code>READ COMMITTED</code>的隔离级别在这里进行了交换，在交换中，我们在严格的隔离和增加并发性之间进行了权衡。</p><p><strong>场景 3：数据分析和报告</strong></p><p>在数据分析或报告场景中，我们正在读取大量数据但不会修改它，通常可以使用较低的隔离级别，例如<code>READ UNCOMMITTED</code>。这可以减少锁的开销并提高吞吐量。</p><p>请记，没有一个解决方案适用于所有的系统，它总是取决于特定的要求和情况。</p><h1 id="主题1-8：就绪面试"><a href="#主题1-8：就绪面试" class="headerlink" title="主题1.8：就绪面试"></a>主题1.8：就绪面试</h1><p><strong>问题：</strong> 解释事务隔离级别。</p><p><strong>答案：</strong> 事务隔离级别控制在从数据库中选择数据时所发生的锁定的程度。数据项上的锁定对数据库的并发性和一致性至关重要，特别是事务处理中。根据 SQL 标准定义的四种标准事务隔离级别：未提交读取、已提交读取、可重复读取和序列化。</p><p><strong>问题：</strong> 每种事务隔离级别的优势和劣势是什么？</p><p><strong>答案：</strong></p><ul><li><strong>未提交读取：</strong> 事务可能会读取其他事务尚未提交的更改，导致脏读和其他不一致性。优势是需要锁定的少量，因此性能更好。</li><li><strong>已提交读取：</strong> 允许事务只读已提交的更改，避免脏读，但仍可能导致非重复读取或幻读。通常提供了一致性和性能的良好平衡。</li><li><strong>可重复读取：</strong> 确保任何读取的数据不会更改，避免脏读和非重复读取，但仍可能导致幻读。</li><li><strong>序列化：</strong> 最高级别的隔离。确保事务以完全隔离的方式进行，避免脏读、非重复读取和幻读，但可能会导致性能下降，因为需要广泛的锁定。</li></ul><p><strong>问题：</strong> 何时可能使用每种隔离级别？</p><p><strong>答案：</strong></p><ul><li><strong>未提交读取：</strong> 数据分析任务，在看到未提交更改是可取的情况下，性能是关键的。</li><li><strong>已提交读取：</strong> 应用程序，在维持高度并发性更重要的情况下，可能会出现偶尔不一致性，例如某些低影响的电子商务应用程序。</li><li><strong>可重复读取：</strong> 在维持数据的一致性是至关重要的情况下，例如某些金融应用程序。</li><li><strong>序列化：</strong> 仅在严格需要时使用，因为性能方面的影响，例如管理高度敏感数据的应用程序。</li></ul><p>这些只是一些可能的面试问题的例子。记住，深入理解这些概念将允许您适应面试者可能会问的任何特定问题。</p><h1 id="主题1-9：回顾和评估"><a href="#主题1-9：回顾和评估" class="headerlink" title="主题1.9：回顾和评估"></a>主题1.9：回顾和评估</h1><p>了解数据库事务的事务隔离级别是处理数据库事务时的基本知识。到目前为止，我们已经探讨了不同的事务隔离级别、其使用、优势和可能的弱点。</p><p>为了巩固理解，让我们来快速回顾并提出一些问题：</p><p><strong>1. 根据 SQL 标准，描述四种事务隔离级别。</strong></p><p>_你的答案： ______</p><p><strong>2. 描述一种场景，在哪里你会使用 REPEATABLE READ 隔离级别。</strong></p><p>_你的答案： ______</p><p><strong>3. ‘脏读是指事务读取其他事务尚未提交的数据’ 是否为真？</strong></p><p>_你的答案： ______</p><p><strong>4. 哪种事务隔离级别具有最严格的锁定，导致事务性能上的最大影响？为什么？</strong></p><p>_你的答案： ______</p><p><strong>5.</strong>&nbsp;<strong>‘在 Read Committed 级别下可能会发生幻读’ 是否为真？</strong></p><p>_你的答案： ______</p><p>花时间来回答这些问题，反思你的回答，并与我们所学的内容进行比较。当你准备好时，我们可以一起讨论答案。如果你有任何不确定或需要更深入的解释，请勿犹豫。让我们确保你完全理解了这个概念！</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview15/">https://programmerscareer.com/mysql-interview15/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL面试: 简述数据库中的 ACID 分别是什么？</title>
      <link href="/zh-cn/mysql-interview2/"/>
      <url>/zh-cn/mysql-interview2/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p> 我将为学习MySQL准备一个主题概述，特别关注数据库中的ACID属性。</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：1-1-ACID-理论"><a href="#主题：1-1-ACID-理论" class="headerlink" title="主题：1.1 ACID 理论"></a>主题：1.1 ACID 理论</h1><p>ACID（原子性、一致性、隔离性和持久性）是一个缩写词，用于定义一组属性，确保数据库操作的可靠处理，尤其是在事务模型中。</p><p>ACID的元素代表：</p><ul><li><strong>原子性</strong>：这意味着事务必须被视为一个单位，它要么完全成功，要么完全失败。如果事务中的任何部分失败，则整个事务失败，并且在事务期间所做的更改被回滚（返回到其前一个状态）。</li><li><strong>一致性</strong>：一致性确保事务将数据库从一个有效状态带到另一个有效状态。它不允许事务将数据库留在一个不一致的状态。</li><li><strong>隔离性</strong>：隔离性确保事务安全地和独立地在同一时间内处理，而不会相互影响。</li><li><strong>持久性</strong>：名字所暗示的，持久性确保提交事务的结果或效果在未来的系统故障后仍然有效。</li></ul><p>这些基本属性使数据库在所有事务中维持数据完整性和一致性。</p><h1 id="主题：1-2-ACID-实践"><a href="#主题：1-2-ACID-实践" class="headerlink" title="主题：1.2 ACID 实践"></a>主题：1.2 ACID 实践</h1><p>ACID属性在MySQL数据库中极其重要，确保数据的可靠性和完整性。现在，让我们看看它们在实践中是如何工作的。</p><ul><li><strong>原子性</strong>：MySQL 通过事务来确保原子性。在MySQL数据库中，事务是一组SQL语句，以单一的单位执行。这意味着事务中的所有SQL语句都要么全部执行，要么全部不执行。如果在事务过程中发生任何故障，则在事务期间所做的更改被回滚，并将数据库返回到其前一个状态。</li><li><strong>一致性</strong>：MySQL中的一致性属性确保只有遵循所有规则和约束的有效数据被写入数据库。如果事务导致无效数据，则整个事务被回滚，数据库保持不变。这确保了数据库从一个有效状态到另一个有效状态的过渡。</li><li><strong>隔离</strong>：在MySQL中，并发事务与其他事务隔离。这意味着事务的执行不会影响其他事务的执行。MySQL使用锁和不同的隔离级别来实现隔离。这防止了脏读、不可重复读和幻影读等问题。</li><li><strong>持久性</strong>：MySQL通过在事务成功之前将更改永久写入磁盘存储来确保持久性。这意味着一旦用户收到事务成功的通知，他们就可以确信事务已经永久记录并且在任何后续服务器故障或重启之后都会存在。</li></ul><p>了解这些时，重要的是要注意MySQL允许您根据应用程序的需求定义事务边界，提供不同的配置选项。</p><h1 id="主题：1-3-MySQL中的原子性"><a href="#主题：1-3-MySQL中的原子性" class="headerlink" title="主题：1.3 MySQL中的原子性"></a>主题：1.3 MySQL中的原子性</h1><p>原子性是ACID数据库系统中的关键属性。它确保事务被视为一个单位的工作单元，要么完全成功，要么完全失败。没有一个事务被留在部分完成的状态。</p><p>在MySQL中，事务通常包含多个SQL命令。原子性保证，如果发生电源故障、系统崩溃或网络问题，那么事务执行后的命令被撤销。这就好像事务从未发生过一样。另一方面，如果所有事务中的命令都成功执行，则认为事务成功提交到数据库。</p><p>以下是MySQL事务中原子性的示例：</p><p>假设我们运营一家书店，我们正在更新库存和销售记录中的书籍数量。事务可能类似于以下内容：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">START TRANSACTION;  </span><br><span class="line">UPDATE Inventory SET Quantity = Quantity - 1 WHERE BookID = 100;  </span><br><span class="line">UPDATE Sales SET TotalSold = TotalSold + 1 WHERE BookID = 100;  </span><br><span class="line">COMMIT</span><br></pre></td></tr></tbody></table></figure><p>在这个事务中，我们有两个UPDATE语句。这两个语句都要成功，以便事务成功提交。如果例如由于系统崩溃或网络错误，则整个事务由于原子性原则被回滚，确保我们的库存和销售记录保持一致。</p><p>原子性是一个强大的属性，确保我们的数据库操作是安全可靠的。</p><h1 id="主题：1-4-数据库中的一致性"><a href="#主题：1-4-数据库中的一致性" class="headerlink" title="主题：1.4 数据库中的一致性"></a>主题：1.4 数据库中的一致性</h1><p>数据库系统中的一致性确保数据库事务将系统从一个一致状态带到另一个一致状态。这意味着如果执行一个违反数据库一致性规则的事务，整个事务将被回滚，并且数据库将保持不变。</p><p>在MySQL中，一致性由约束系统保留。约束是对表中列的规则，防止无效数据被输入到它们。有几种约束类型，包括：</p><ul><li><strong>唯一约束</strong>：这确保所有列中的值都是唯一的。</li><li><strong>主键约束</strong>：这唯一地标识表中的每一条记录。</li><li><strong>外键约束</strong>：这维护引用完整性，确保两个表之间的链接是有效的。</li><li><strong>不为空约束</strong>：这确保列不能有NULL值。</li><li><strong>检查约束</strong>：这确保所有列中的值满足特定条件。</li></ul><p>以下是一个示例，展示了唯一约束如何确保一致性：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE Employees (  </span><br><span class="line">    ID int NOT NULL,  </span><br><span class="line">    Name varchar(255) NOT NULL,  </span><br><span class="line">    Age int,  </span><br><span class="line">    PRIMARY KEY (ID),  </span><br><span class="line">    UNIQUE (Name)  </span><br><span class="line">);</span><br></pre></td></tr></tbody></table></figure><p>在上述示例中，<code>UNIQUE (Name)</code>约束确保了两个员工不能有相同的名字，从而促进了一致性。如果我们尝试插入两个具有相同名字的员工，MySQL将不允许这样做，并且数据库的一致性将得到保留。</p><h1 id="主题：1-5-数据库中的隔离"><a href="#主题：1-5-数据库中的隔离" class="headerlink" title="主题：1.5 数据库中的隔离"></a>主题：1.5 数据库中的隔离</h1><p>隔离是ACID中的“I”，意味着每个事务都应该以与其他事务相隔离的方式进行。这意味着一个事务的执行不会影响其他事务的执行。在数据库中，隔离对于防止在事务同时执行时可能出现的一些问题非常重要。</p><p>在MySQL中，并发事务由一个特定的机制称为锁定管理。MySQL提供了多种锁类型，包括共享锁（读锁）和独占锁（写锁）。锁的类型取决于事务是读还是写。</p><p>MySQL还支持多个隔离级别，包括：</p><ul><li><strong>未提交读</strong>：最低级别的隔离。事务可以看到其他事务中未提交的更改，通常导致问题如脏读。</li><li><strong>已提交读</strong>：与其他事务相比，隔离级别较高。事务只能看到其他事务已提交的更改。</li><li><strong>可重复读</strong>：MySQL中的默认隔离级别。保证单个事务内的所有读取都会返回相同的数据，即使在事务期间发生更改。</li><li><strong>可序列化</strong>：最高级别的隔离。事务以串行方式执行，即一次只执行一个事务。</li></ul><p>以下是隔离在MySQL中的一个示例：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 开始一个事务  </span><br><span class="line">START TRANSACTION;  </span><br><span class="line">-- 读取数据  </span><br><span class="line">SELECT * FROM table_name WHERE condition;  </span><br><span class="line">-- 尝试再次读取相同数据将返回相同的结果，  </span><br><span class="line">-- 无论其他事务是否对数据进行更改  </span><br><span class="line">SELECT * FROM table_name WHERE condition;  </span><br><span class="line">-- 提交事务  </span><br><span class="line">COMMIT;</span><br></pre></td></tr></tbody></table></figure><p>在上述示例中，在可重复读隔离级别下，两个SELECT语句将返回相同的结果，即使其他事务对数据进行更改，因为其他事务对数据的更改在事务提交之前不会对这个事务可见。</p><h1 id="主题：1-6-数据库中的持久性"><a href="#主题：1-6-数据库中的持久性" class="headerlink" title="主题：1.6 数据库中的持久性"></a>主题：1.6 数据库中的持久性</h1><p>在数据库系统中，“持久性”（ACID中的“D”）关注一次事务成功提交后数据的持久性。如果事务已成功提交，持久性保证该事务所做的更改将在任何后续故障（如电源失败、系统崩溃或其他未预期的关机）后仍然存在。</p><p>MySQL 确保持久性，在事务更改被实际更改之前，先将所有事务更改写入二进制日志中。这个二进制日志作为历史记录，可以用来从任何时间点重建数据状态。</p><p>每次提交事务时，MySQL首先将该事务所做的更改写入二进制日志，然后MySQL开始实际执行更改。如果系统故障发生，MySQL可以回放二进制日志，直到上一个已提交事务，确保所有已提交事务的持久性。</p><p>让我们考虑一个更新表中的记录的例子：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">START TRANSACTION;  </span><br><span class="line">UPDATE Employees SET Salary = Salary + 5000 WHERE ID = 100;  </span><br><span class="line">COMMIT;</span><br></pre></td></tr></tbody></table></figure><p>在上述事务中，员工薪资被更新。一旦<code>COMMIT</code>语句执行，更新将在二进制日志中立即写入，在实际更改之前。这确保了，即使在更新后的系统崩溃，该事务也不会丢失。  </p><h1 id="主题：1-7-在MySQL中的事务控制"><a href="#主题：1-7-在MySQL中的事务控制" class="headerlink" title="主题：1.7 在MySQL中的事务控制"></a><strong>主题：</strong>1.7 在MySQL中的事务控制</h1><p>事务控制是管理ACID属性的方法，并引用用于控制事务的操作和命令。在MySQL中，事务控制命令包括START TRANSACTION，COMMIT和ROLLBACK。</p><ul><li><code>START TRANSACTION</code>：标记事务的开始。</li><li><code>COMMIT</code>：标记事务的结束，并永久保存自上次COMMIT或START TRANSACTION以来所做的任何更改。</li><li><code>ROLLBACK</code>：撤销自上次COMMIT或START TRANSACTION以来所做的任何更改。</li></ul><p>以下是在MySQL中的事务控制实际操作的示例：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">-- 开始一个事务  </span><br><span class="line">START TRANSACTION;  </span><br><span class="line">-- 将数据插入表中  </span><br><span class="line">INSERT INTO Customers (Name, Email) VALUES ('John Doe', 'johndoe@example.com');  </span><br><span class="line">-- 如果上述语句出现问题，我们可以撤销（反转）事务  </span><br><span class="line">ROLLBACK;  </span><br><span class="line">-- 现在让我们再试一次，这次没有错误  </span><br><span class="line">START TRANSACTION;  </span><br><span class="line">INSERT INTO Customers (Name, Email) VALUES ('John Doe', 'johndoe@example.com');  </span><br><span class="line">-- 由于一切顺利，我们现在可以提交事务（完成并保存我们的更改）  </span><br><span class="line">COMMIT;</span><br></pre></td></tr></tbody></table></figure><p>在这个示例中，<code>ROLLBACK</code>语句用于反转一个包含错误的事务。一旦问题得到解决，事务再次尝试，并在成功时，<code>COMMIT</code>语句用于完成并保存更改。</p><p>事务控制帮助维护ACID属性，因为它为将一个或多个语句组合成一个事务提供了能力，从而提供了更大的控制权，确保数据完整性。</p><h1 id="主题：1-8-在MySQL中的高级主题"><a href="#主题：1-8-在MySQL中的高级主题" class="headerlink" title="主题：1.8 在MySQL中的高级主题"></a><strong>主题：</strong>1.8 在MySQL中的高级主题</h1><p>了解ACID原则及其如何在MySQL中实现后，您可能还想探索更多高级主题，以提高您的MySQL专业知识。一些值得注意的领域包括但不限于：</p><ul><li><strong>索引</strong>：MySQL中的索引用于加速从数据库中检索数据的速度。数据库中的索引与书中末尾的索引类似，它们帮助您更快地找到信息。</li><li><strong>存储过程</strong>：这些是预先编写的SQL语句，以名称存储并以单元形式执行。它们有助于避免重复编写经常需要的SQL代码。</li><li><strong>数据类型</strong>：MySQL具有多种数据类型，以适应各种数据。从字母数字字符串、日期和时间、数值到更复杂的数据类型，如JSON和空间数据类型都有在MySQL中的可用性。</li><li><strong>处理NULL值</strong>：MySQL数据库中的NULL值可能很困难。它们表示缺失或未知的数据。MySQL提供了多种函数，如IS NULL、IS NOT NULL、IFNULL()和COALESCE()，以处理NULL值。</li><li><strong>连接和联合</strong>：连接用于将两个或多个表的行组合在一起，基于相关列。它们在数据库中经常使用，因为很少有一个表中包含所有需要的数据。联合用于将两个或多个SELECT语句的结果集组合在一起。</li><li><strong>安全</strong>：处理用户权限和安全连接到MySQL数据库是任何数据库管理的重要部分。</li></ul><h1 id="主题-1-9-回顾和评估"><a href="#主题-1-9-回顾和评估" class="headerlink" title="**主题:**1.9 回顾和评估"></a>**主题:**1.9 回顾和评估</h1><p>这是我们在这些课程中学到的概述:</p><ol><li><strong>理论中的ACID:</strong> 我们学习了ACID属性(原子性、一致性、隔离性、持久性)及其在数据库系统中的重要性。</li><li><strong>实践中的ACID:</strong> 我们超出了理论,了解如何在MySQL中实现这些属性,以及它们如何确保数据完整性和一致性。</li><li><strong>MySQL中的原子性:</strong> 我们探索了原子性,并通过实际示例了解了它如何确保数据库操作要么完全完成,要么不发生。</li><li><strong>MySQL中的一致性:</strong> 我们学习了MySQL如何确保数据在任何SQL操作之前和之后保持一致。</li><li><strong>MySQL中的隔离:</strong> 我们讨论了隔离的概念及其在并发数据库处理中的重要性。</li><li><strong>MySQL中的持久性:</strong> 我们学习了持久性在MySQL数据库中的含义,并观察了MySQL如何确保数据更改在任何后续故障后仍然存在。</li><li><strong>MySQL中的事务控制:</strong> 我们了解了如何使用事务控制在MySQL中管理ACID属性。我们主要了解了START TRANSACTION、COMMIT和ROLLBACK命令的使用。</li><li><strong>MySQL的高级主题:</strong> 我们深入了解更高级的主题,如索引、存储过程、数据类型等,以扩展我们对MySQL的理解。</li></ol><p>我建议重新查看这些主题,并确保对它们有坚定的理解。</p><p>以下是测试您关于ACID属性和MySQL事务控制理解的一些评估问题:</p><p><strong>问题1:</strong> 在MySQL中,什么是原子性?它在实践中如何实现?</p><p><strong>问题2:</strong> 在MySQL中,一致性的含义是什么,以及MySQL如何确保数据在任何SQL操作之前和之后保持一致?</p><p><strong>问题3:</strong> 如何在MySQL中,特别是在并发数据库处理期间,实现隔离?</p><p><strong>问题4:</strong> 在MySQL中,持久性属性的含义是什么?</p><p><strong>问题5:</strong> 在MySQL中,关于事务控制,讨论START TRANSACTION、COMMIT和ROLLBACK命令的重要性。</p><h2 id="答案1"><a href="#答案1" class="headerlink" title="答案1:"></a>答案1:</h2><p>在MySQL中,原子性表示一个事务必须被视为一个不可分割的单位,这意味着要么它完全完成,要么不执行。在实践中,MySQL通过START TRANSACTION、COMMIT和ROLLBACK命令实现原子性。如果事务被提交,则所做的更改都是永久的。如果事务被回滚,则没有任何更改。</p><h2 id="答案2"><a href="#答案2" class="headerlink" title="答案2:"></a>答案2:</h2><p>在MySQL中,一致性确保所有数据更改都将将数据库从一个有效状态带到另一个,维持数据库规则和完整性。MySQL使用多种机制来确保一致性。这些包括定义的表架构,预定义规则,触发器和约束,如主键,外键,唯一,不为空和检查约束。</p><h2 id="答案3"><a href="#答案3" class="headerlink" title="答案3:"></a>答案3:</h2><p>在MySQL中,隔离确保并发执行事务的结果使系统状态变为如果事务以顺序执行,即一次执行一个。MySQL通过多种隔离级别和锁定机制实现隔离。</p><h2 id="答案4"><a href="#答案4" class="headerlink" title="答案4:"></a>答案4:</h2><p> 在MySQL中,持久性属性的含义是一旦事务被提交,它将保持不变,即使在系统故障,电源损失,崩溃或错误等情况下。这通常通过使用数据库备份和事务日志来实现,这些日志可以用于恢复数据库在故障发生前的状态。</p><h2 id="答案5"><a href="#答案5" class="headerlink" title="答案5:"></a><strong>答案5:</strong></h2><p>在MySQL中,START TRANSACTION表示操作的开始点。COMMIT表示当前事务中所做的更改被永久化。ROLLBACK表示如果在处理任何SQL命令时发生错误,则已执行的SQL命令将被撤销以维护数据库完整性。这些命令共同帮助在MySQL设置中管理ACID属性期间的事务。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview2/">https://programmerscareer.com/mysql-interview2/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 面试：MySQL 如何设计索引，如何优化查询？</title>
      <link href="/zh-cn/mysql-interview3/"/>
      <url>/zh-cn/mysql-interview3/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>让我们详细设计一门深入理解 MySQL 的课程，特别是索引设计和查询优化方面的课程。</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h3 id="主题：MySQL-概述"><a href="#主题：MySQL-概述" class="headerlink" title="主题：MySQL 概述"></a><strong>主题</strong>：MySQL 概述</h3><hr><p>数字世界的一个重要部分是数据库，MySQL 是其中的一位明星。那么，MySQL 到底是什么呢？</p><p>MySQL 是一个关系数据库管理系统。但是，MySQL 与其他数据库管理系统有什么区别呢？它是开源的，这意味着任何人都可以使用和修改它。这导致了全球范围内开发人员和组织的广泛采用。</p><p>你经常会看到 MySQL 支持网站和应用程序的数据需求，甚至在科学研究中起到了帮助作用。它的灵活性在支持各种数据类型和提供了大量用于数据操作和提取的函数方面显著。它的强大安全系统也巩固了其在数据库领域的重要性。</p><p>MySQL 的可靠性和速度在数据检索和管理方面是众多数据库管理系统中的一个明星。</p><p>MySQL 的核心是结构化查询语言（SQL），它为用户提供了操作数据库的能力。我们可以创建、检索、更新和删除数据，并执行其他复杂分析通过 SQL 命令。</p><p>在我们的课程中，我们将帮助您熟悉 SQL，包括基本和更复杂的命令，并进行进一步的学习。</p><p>了解 MySQL 是了解以后主题，例如数据库架构、数据库设计的原则和特定主题，例如索引设计和查询优化，的先决条件。</p><h3 id="主题：SQL-in-MySQL-Basics"><a href="#主题：SQL-in-MySQL-Basics" class="headerlink" title="主题：SQL in MySQL&nbsp;(Basics)"></a><strong>主题</strong>：SQL in MySQL&nbsp;(Basics)</h3><hr><p>SQL，或结构化查询语言，是所有关系数据库管理系统的基石，包括 MySQL。它是我们与数据库交互和通信的语言。让我们来看看您需要了解的一些基本 SQL 命令，以便与 MySQL 数据库交互。</p><ul><li><strong>SELECT</strong>: 这是我们最常使用的命令——它允许我们选择数据库中的数据。例如，<code>SELECT * FROM people;</code> 将选择并显示所有数据从 “people” 表中。或者，您可能希望选择特定列，例如，先名和姓氏：<code>SELECT firstname, lastname FROM people;</code>。</li><li><strong>INSERT INTO</strong>: 这个命令允许我们插入新数据到数据库中。例如，<code>INSERT INTO people (firstname, lastname) VALUES('John', 'Doe');</code> 将插入一个新人，其名字为 John，姓氏为 Doe。</li><li><strong>UPDATE</strong>: 就名称所言，使用这个命令可以更新现有数据。例如，<code>UPDATE people SET age=30 WHERE firstname='John' AND lastname='Doe';</code> 将更新所有名为 John Doe 的人的年龄为 30。</li><li><strong>DELETE</strong>: 请谨慎使用此命令，因为它会删除数据！例如，<code>DELETE FROM people WHERE firstname='John' AND lastname='Doe';</code> 将删除所有名为 John Doe 的记录。</li><li><strong>CREATE</strong>, <strong>ALTER</strong>, <strong>DROP</strong>: 这些命令用于操作数据库的架构或结构本身，并不是存储的数据。CREATE 允许我们创建新表，ALTER 允许更改表的结构，DROP 删除表。</li></ul><p>熟悉这些命令将为您提供一个良好的基础，以深入探讨更复杂的 SQL 命令在 MySQL 中的使用。</p><p>请记在运行这些命令并了解其结果时练习。</p><h1 id="主题：MySQL中的高级-SQL"><a href="#主题：MySQL中的高级-SQL" class="headerlink" title="主题：MySQL中的高级 SQL"></a><strong>主题</strong>：MySQL中的高级 SQL</h1><hr><p>虽然基本的 SQL 命令提供了一个坚实的基础，但是真正理解和利用 MySQL 的更高级工具来处理数据库是如此重要。下面是一些高级 MySQL 命令，可以帮助您更有效地操作数据库：</p><ul><li><strong>JOIN</strong>：SQL 的 JOIN 子句允许您根据公共字段组合来合并表的行。JOIN 命令有多种类型，例如 INNER JOIN、LEFT JOIN、RIGHT JOIN 和 FULL OUTER JOIN 等。例如：<code>SELECT Orders.OrderID, Customers.CustomerName FROM Orders INNER JOIN Customers ON Orders.CustomerID = Customers.CustomerID;</code> 这条命令将显示订单 ID 和客户名称从 Orders 和 Customers 表中，其中客户 ID 匹配。</li><li><strong>GROUP BY</strong>：这个命令与聚合函数 COUNT、MAX、MIN、SUM 和 AVG 一起使用，用于根据一个或多列来分组结果集。例如：<code>SELECT COUNT(animal_type), animal_type FROM animal GROUP BY animal_type;</code> 这条命令将显示每种动物类型在 ‘animal’ 表中的数量。</li><li><strong>HAVING</strong>：这个命令类似 WHERE 子句，但是适用于聚合函数。例如：<code>SELECT COUNT(product_id), product_name FROM products GROUP BY product_name HAVING COUNT(product_id) &gt; 5;</code> 这条命令将显示来自 ‘products’ 表的产品名称和数量，但只显示数量大于 5 的产品名称。</li><li><strong>UNION</strong>：UNION 操作用于合并两个或多个 SELECT 语句的结果集。每个 SELECT 语句内部必须有相同数量的列，并且列必须具有相似的数据类型。例如：<code>SELECT column_name(s) FROM table1 UNION SELECT column_name(s) FROM table2;</code></li><li><strong>CASE</strong>：这个命令允许 SQL 中的条件语句。例如：<code>SELECT CASE WHEN age &lt; 18 THEN 'Children' WHEN age BETWEEN 18 AND 65 THEN 'Adults' ELSE 'Seniors' END AS age_group FROM people;</code> 这条命令根据人们的年龄来分类人们在 ‘people’ 表中。</li></ul><p>学习这些命令会为您打开 MySQL 的全部力量。</p><p>记住，要真正理解这些，实践是关键。</p><h1 id="主题：MySQL-中的数据库架构"><a href="#主题：MySQL-中的数据库架构" class="headerlink" title="主题：MySQL 中的数据库架构"></a><strong>主题</strong>：MySQL 中的数据库架构</h1><hr><p>在高效的数据库中，架构是至关重要的抽象蓝图，它展示了数据库结构的组织和访问方式。因此，让我们来讨论一下！</p><p>当您想象数据库时，想象一整个文件柜。在 MySQL 术语中，数据库中的表就成为了数据库架构的一部分。它们包含了我们通过 SQL 命令交互的数据。</p><p>每个文件柜（或者数据库）中的分区（或者列）被称为列或字段。每个列代表数据库中的一种数据类型。例如，在存储员工信息的表（或者文件柜）中，不同类别的信息，例如员工 ID、姓名、职位等，成为了不同的列。</p><p>设计数据库架构可能看起来很简单——为每种数据类型创建一个表，对吧？但是，不！有效地设计架构可以避免冗余，防止数据异常，并优化资源使用。</p><p>MySQL 强烈地遵循关系数据库的原则，将数据组织在相互链接的表中。这给我们带来了主键和外键这些概念，帮助建立表之间的连接（我们将在数据库设计课程中进一步讨论）。</p><h1 id="主题：数据库设计的原则"><a href="#主题：数据库设计的原则" class="headerlink" title="主题：数据库设计的原则"></a><strong>主题</strong>：数据库设计的原则</h1><hr><p>设计数据库不仅仅是决定表、列和使用 SQL 命令。一个良好的数据库保证了有效和可靠的数据存储和检索。让我们来讨论一下数据库设计的基本原则：</p><ul><li><strong>实体-关系 (ER) 模型</strong>：想象一下实体是“事物”或“对象”，与数据库相关（例如公司数据库中的员工）。关系定义了这些实体之间的交互。以图形方式表示这些实体和其关系给我们提供了 ER 模型，这是数据库设计的基本步骤。</li><li><strong>规范化</strong>：这是组织数据的过程，以消除冗余并提高数据完整性。有多种规范形式（第一、第二、第三、BCNF），每个形式都有其前提条件。</li><li><strong>主键</strong>：每张表都必须有一个列（或一组列），称为主键，可以唯一地识别表中的每一行。</li><li><strong>外键</strong>：这是另一张表的主键的字段（或集合）。外键用于防止破坏表之间的链接。</li><li><strong>原子性</strong>：这是操作完全成功或失败的想法。您不想数据库更新部分完成——它完全成功或不成功。</li><li><strong>安全性</strong>：数据库通常包含敏感数据。良好设计的数据库具有多层安全性，包括授权、访问控制和加密。</li><li><strong>备份和恢复</strong>：数据是有价值的。良好设计的数据库包括定期备份策略和有效的恢复，以处理数据丢失。</li><li><strong>可伸缩性和性能</strong>：良好的数据库设计还考虑了可伸缩性（数据量增长时数据库能否处理？）和性能（系统能够响应查询多快？）。</li></ul><p>了解这些原则会为您提供一个能够设计一个健壮、可靠和高效的数据库的能力。</p><h1 id="主题：MySQL-索引"><a href="#主题：MySQL-索引" class="headerlink" title="主题：MySQL 索引"></a><strong>主题</strong>：MySQL 索引</h1><hr><p>MySQL 索引是数据库设计的关键部分，可以大大提高数据库表上的数据检索操作的速度。类似于书的索引，MySQL 索引允许数据库系统找到数据，而无需扫描整张数据库表中的每一行。</p><p>下面是关于 MySQL 索引的一些要点：</p><ul><li>索引用于更快地找到具有特定列值的行。在没有索引的情况下，MySQL 必须从第一行开始，然后逐行读取整张数据库表，以找到相关的行。</li><li>索引还用于强制 UNIQUE 约束，并帮助有效的排序和分组。</li><li>索引可以根据其结构分类：B-Tree、哈希、RTree 和 Full-text。</li><li>B-Tree（平衡树）是最常用的索引结构，它按顺序排列数据，以便快速检索。 B-Tree 确保树保持平衡，以优化搜索时间。</li><li>索引会增加数据库操作的成本。虽然数据检索操作变得更快，但数据修改操作（例如 INSERT、UPDATE 和 DELETE）会变得更慢，因为需要额外的操作来维护索引。</li><li>不是所有的字段都需要索引。只有在 WHERE、ORDER BY、GROUP BY 或 JOIN 子句中使用的字段才会受益于索引。</li></ul><p>了解和正确实现索引可以大大提高数据库操作的性能。</p><h1 id="主题：在-MySQL-中设计索引"><a href="#主题：在-MySQL-中设计索引" class="headerlink" title="主题：在 MySQL 中设计索引"></a><strong>主题：</strong>在 MySQL 中设计索引</h1><hr><p>在高效的数据库管理中，设计索引是一个重要的部分。今天我们将讨论 MySQL 是如何设计索引的，以及它如何提高整体性能。</p><p>创建正确的索引是更多的艺术而不是科学，通常需要查询速度和写入速度之间的权衡。</p><p>在设计索引时要考虑的步骤：</p><p><strong>选择正确的列：</strong> 索引可以包含多列，但是需要考虑列的顺序。MySQL 只能使用索引中的左侧列。</p><p><strong>考虑数据类型：</strong> 数据类型越小，存储量越小，因此索引也越小，并且查询速度越快。</p><p><strong>考虑卡尔性：</strong> 具有多个唯一值的列（高卡尔性）通常具有更有效的索引。</p><p><strong>了解您的工作负载：</strong> 如果您的应用程序执行大量 SELECT 查询，则更多的索引可能有帮助。另一方面，如果您的应用程序执行大量 INSERT、UPDATE 和 DELETE 操作，则更多的索引可能会降低性能。</p><p><strong>分析您的查询：</strong> 使用 MySQL 的 EXPLAIN 语句来了解如何使用您的索引，并识别可以进行改进的地方。</p><p>记住，索引是数据库设计的重要部分。它们可以显著提高数据库的性能，因此在处理大量数据时，总是值得考虑。</p><h1 id="主题：-MySQL-查询优化"><a href="#主题：-MySQL-查询优化" class="headerlink" title="主题： MySQL 查询优化"></a><strong>主题：</strong> MySQL 查询优化</h1><hr><p>管理数据库的一个重要方面是确保它们运行有效地。当处理大量数据时，查询可能会变得耗时。因此，在 MySQL 中优化这些查询是至关重要的，以提高数据库系统的整体性能。</p><p>在 MySQL 中进行查询优化包括多个步骤：</p><ol><li><strong>解析：</strong> MySQL 开始解析 SQL 查询，以确保其语法正确，并确定数据库对象的存在。</li><li><strong>预处理：</strong> MySQL 决定表的读取顺序，尤其是多表查询。它还确定要使用的索引。</li><li><strong>优化：</strong> MySQL 应用多种优化策略，以使查询更有效。最著名的是使用索引，但 MySQL 还利用其他技术，例如合并多个相似的查询，减少临时表，并选择有效的表连接路径。</li><li><strong>执行：</strong> 最后，MySQL 执行查询并返回结果。实际执行是一个平衡，在从存储引擎获取数据和处理 SQL 命令之间进行。</li></ol><p>了解 MySQL 如何优化查询有助于编写更有效的 SQL 代码并设计更好的数据库架构。它可以显著减少查询执行时间，特别是对复杂查询和大数据库的处理。</p><p>记住使用 <strong>EXPLAIN</strong> 语句，它可以提供有关如何优化您的查询的见解。它显示 MySQL 如何计划执行查询，并可能帮助识别瓶颈或改进的地方。</p><h1 id="主题：复习和评估"><a href="#主题：复习和评估" class="headerlink" title="主题：复习和评估"></a><strong>主题：</strong>复习和评估</h1><p>经历了 MySQL 的复杂地图后，现在是时候进行详细回并通过评估测试你的实践知识了。</p><p>回：</p><ol><li>我们开始了 MySQL 的角色，了解 MySQL 作为一个强大的数据库管理系统。</li><li>然后我们进入了 MySQL 的本质，了解 <strong>1.2 SQL 在 MySQL（基本）</strong> 和 <strong>1.3 SQL 在 MySQL（高级）</strong>，掌握了 MySQL 中使用的基本和更复杂的 SQL 命令。</li><li>我们学习了数据库的结构，通过 <strong>1.4 数据库架构在 MySQL</strong> 的概念。</li><li>了解 <strong>1.5 MySQL 数据库设计原则</strong> 帮助我们理解确保数据库有效运行的结构。</li><li>我们了解了 <strong>1.6 MySQL 索引</strong> 的重要性，帮助加快数据检索的速度。</li><li>然后我们学习了如何通过 <strong>1.7 在 MySQL 中设计索引</strong> 来提高性能。</li><li>最后，我们探讨了 MySQL 如何通过 <strong>1.8 MySQL 查询优化</strong> 来提高数据库性能。</li></ol><p>如果你想测试你的理解，你可以说 <strong>“/test”</strong> 来进行评估。请记，这项评估是为了帮助固定你的知识并识别可能需要更多关注的地方。不要太担心它——它是学习的工具，不是最后考试。</p><p>让我们开始评估。</p><h4 id="问题-1："><a href="#问题-1：" class="headerlink" title="问题 1："></a>问题 1：</h4><p>说出 MySQL 中 <code>CHAR</code>、<code>VARCHAR</code> 和 <code>TEXT</code> 数据类型之间的区别。</p><h4 id="问题-2："><a href="#问题-2：" class="headerlink" title="问题 2："></a>问题 2：</h4><p>解释 MySQL 中的 <code>JOIN</code> 操作是什么，并列出其不同类型。</p><h4 id="问题-3："><a href="#问题-3：" class="headerlink" title="问题 3："></a>问题 3：</h4><p>在 MySQL 数据库表中，说明 <code>NULL</code> 值是什么，并说明如何检查数据库表中的这些值。</p><h4 id="答案-1："><a href="#答案-1：" class="headerlink" title="答案 1："></a>答案 1：</h4><p><code>CHAR</code> 和 <code>VARCHAR</code> 在 MySQL 中用于存储字符串值，主要区别如下：</p><ul><li><code>CHAR</code> 是一个固定长度数据类型，意味着它保留指定的空间，不管数据的实际大小。它在读操作时更快，因为 MySQL 知道 <code>CHAR</code> 列中的值的位置。</li><li><code>VARCHAR</code> 是一个变长数据类型。它根据存储的数据的大小来消耗空间。如果你处理变长的字符串，它可以节省存储空间。</li><li><code>TEXT</code> 也是用于存储字符串的数据类型，但它是为了存储大量文本而设计的。字符串的长度不是固定的，类似于 <code>VARCHAR</code>。</li></ul><h4 id="答案-2："><a href="#答案-2：" class="headerlink" title="答案 2："></a>答案 2：</h4><p>MySQL 中的 <code>JOIN</code> 操作是将两个或多个表的行组合在一起，根据它们之间的相关列。 <code>JOIN</code> 的类型包括：</p><ul><li><code>INNER JOIN</code>：返回具有匹配值的记录，来自被加入的两个表。</li><li><code>LEFT JOIN</code> (或 <code>LEFT OUTER JOIN</code>)：返回左表的所有记录和右表的匹配记录。如果找不到匹配，右侧的结果为 <code>NULL</code>。</li><li><code>RIGHT JOIN</code> (或 <code>RIGHT OUTER JOIN</code>)：返回右表的所有记录和左表的匹配记录。如果找不到匹配，左侧的结果为 <code>NULL</code>。</li><li><code>FULL JOIN</code> (或 <code>FULL OUTER JOIN</code>)：返回左表或右表的记录，当存在匹配时。</li></ul><h4 id="答案-3："><a href="#答案-3：" class="headerlink" title="答案 3："></a>答案 3：</h4><p>在 MySQL 数据库表中，<code>NULL</code> 值表示缺少或未知的数据。你可以使用 SQL 语句中的 <code>IS NULL</code> 或 <code>IS NOT NULL</code> 子句来检查数据库表中的 <code>NULL</code> 值。</p><p>记住，当处理 <code>NULL</code> 时，它不是值，它是一个状态，表明值是未知或缺少的，因此 <code>NULL</code> 不等于 <code>NULL</code>。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview3/">https://programmerscareer.com/mysql-interview3/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么MySQL使用B+树进行索引?</title>
      <link href="/zh-cn/mysql-interview4/"/>
      <url>/zh-cn/mysql-interview4/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>讨论数据库中索引的重要性，特别是如何提高查询性能。</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="1-1-为什么索引？"><a href="#1-1-为什么索引？" class="headerlink" title="1.1 **为什么索引？"></a>1.1 **为什么索引？</h1><p>类似书的索引一样，数据库中的索引帮助我们快速找到数据，无需阅读整本书。索引在数据库表被访问时大大加快数据检索的速度，从而提高应用性能。索引对大表的优化非常重要，尤其是对“SELECT”查询和 WHERE 子句的优化。虽然索引提高了读性能，但它们也会慢下写性能（插入、更新和删除）。这是因为每次数据变化时，索引都需要更新。因此，有过多的索引可能会影响数据库性能。总之，一个好的索引是创造一个平衡。我们想要保持查询快速和有效，但不要过载系统并使其性能受到损害的索引维护。</p><h1 id="1-2-MySQL-中的索引类型："><a href="#1-2-MySQL-中的索引类型：" class="headerlink" title="1.2 MySQL 中的索引类型："></a>1.2 <strong>MySQL 中的索引类型</strong>：</h1><p>MySQL 使用各种索引类型来提高查询性能。下面是常见的类型：</p><ul><li><strong>主键索引（Primary Index）</strong>：这种索引要求列只能包含唯一、非空值。每张表只能有一个主键索引。</li><li><strong>唯一索引（Unique Index）</strong>：如果列不包含 NULL 值，这种索引防止字段具有重复值。除了允许 NULL 值外，唯一索引与主键索引几乎相同。</li><li><strong>索引（或普通索引）</strong>：它允许重复和 NULL 值在列中。它是 MySQL 中的基本索引类型。</li><li><strong>全文索引（Full-text Index）</strong>：如果你处理文本数据并经常使用全文搜索，这种索引非常有用。</li><li><strong>复合索引（或多列索引）</strong>：如果在 WHERE 子句中使用多列，创建复合索引可以加快查询性能。</li></ul><p>这些索引类型为我们创建或管理的数据库提供了不同的优势，并帮助我们确保数据库性能尽可能优化。</p><h1 id="1-3-B-树解析"><a href="#1-3-B-树解析" class="headerlink" title="1.3 B+ 树解析"></a>1.3 <strong>B+ 树解析</strong></h1><p>B+ 树是一种自平衡搜索树，它维护有序数据并允许高效的插入、删除和搜索操作。与二叉搜索树（BST）不同，B+ 树是多层次的树，每个节点可以有多个子节（通常大于两个）。B+ 树的重要特性包括：</p><ol><li>所有数据都存储在叶节点中。</li><li>所有叶节点处于同一深度，确保平衡。</li><li>所有叶节点都相连，允许有效的范围查询。</li><li>非叶节点存储复制的键来指导搜索。</li></ol><p>B+ 树的组合特性使它们特别适合处理大量数据和大量读操作的系统，例如数据库或文件系统。</p><p>每个节点在 B+ 树中包含一些键和指针。键用作分隔值，分割其子树。例如，如果节点包含值 [10, 20, 30]，它有四个子节（子树）。</p><p>B+ 树中的一个基本属性是，如果节点包含 n 个键，它将有 n+1 个指针（子节）。另一个属性是，所有的 B+ 树键是排序的。</p><p>由于 B+ 树的高效性在访问、存储和检索数据方面受到广泛的欢迎，它们与数据库世界，包括 MySQL 密切相关。</p><h1 id="主题-1-4-B-树的优势"><a href="#主题-1-4-B-树的优势" class="headerlink" title="主题 1.4: B+ 树的优势"></a><strong>主题 1.4: B+ 树的优势</strong></h1><p>让我们深入探讨 B+ 树为数据库带来的优势，特别是 MySQL：</p><ol><li><strong>有效的磁盘读写操作:</strong> 每个 B+ 树节点包含多个键和指针在同一磁盘块上，这大大减少了读取或写入大范围的数据所需的 I/O 操作。因此，您可以扫描大量数据使用最少的磁盘读取。</li><li><strong>更快的搜索时间:</strong> 由于 B+ 树是平衡的，所以相等数量的比较都会导致所有叶节点，使数据检索变得更快。搜索操作的时间复杂度为对数级别。</li><li><strong>有效的插入和删除:</strong> B+ 树的数据结构使其在插入和删除操作时保持平衡和有序。这导致最小的磁盘空间浪费并最大化了性能效率。</li><li><strong>升序或降序排序顺序检索:</strong> B+ 树的叶节点相互链接，这使得快速的顺序读取变得更加容易，特别是在数据库中。</li><li><strong>适用于等式和范围检索:</strong> 由于自平衡性和每个页面的最小和最大键，B+ 树非常适合等式和范围查询。</li><li><strong>多级索引:</strong> B+ 树可以适应多级索引，进一步提高搜索性能并减少磁盘 I/O 操作。</li></ol><h1 id="主题-1-5-MySQL-中的-B-树索引"><a href="#主题-1-5-MySQL-中的-B-树索引" class="headerlink" title="主题 1.5: MySQL 中的 B+ 树索引"></a><strong>主题 1.5: MySQL 中的 B+ 树索引</strong></h1><p>让我们详细了解 MySQL 中为什么和如何使用 B+ 树进行索引。</p><p>在 MySQL 中，特别是使用 InnoDB 存储引擎时，B+ 树用作主索引和辅助索引来提高数据库的性能，主要是通过显著地减少数据访问时间。</p><p>这是怎样工作的：</p><ol><li><strong>主索引:</strong> MySQL 使用 B+ 树作为主索引来唯一地识别每行，其中按主键顺序排列。叶节点存储实际数据，主键值作为指针来访问数据。因此，当直接搜索主键时，MySQL 快速地通过 B+ 树来找到并检索数据。</li><li><strong>辅助索引:</strong> MySQL 表中的辅助索引也是一个 B+ 树。唯一的差异是叶节点不存储实际数据，而是存储主键的指针。因此，当使用辅助索引进行搜索时，MySQL 使用辅助索引的 B+ 树来找到主键，然后使用主键来导航主 B+ 树来获取实际数据。虽然这需要导航两个 B+ 树，但它仍然非常快和有效。</li></ol><p>B+ 树在 MySQL 索引中的优势是它大大减少了需要进行磁盘访问的项目数量，这大大提高了性能，因为磁盘访问比内存操作慢得多。</p><h1 id="主题-1-6-MySQL-索引最佳实践"><a href="#主题-1-6-MySQL-索引最佳实践" class="headerlink" title="主题 1.6: MySQL 索引最佳实践:"></a><strong>主题 1.6: MySQL 索引最佳实践:</strong></h1><p>基于我们对 B+ 树的了解，让我们来讨论 MySQL 索引的最佳实。有效的索引是绝对必要的，以确保数据库查询运行顺畅和迅速。</p><ol><li><strong>了解数据:</strong> 在开始索引之前，先深入了解你所处理的数据。哪些列通常一起被查询？哪些列在 WHERE 子句中出现得比较常？这些了解可帮助指导索引策略。</li><li><strong>使用 EXPLAIN 关键字:</strong> 当优化索引时，使用 SQL 中的 EXPLAIN 关键字来了解数据库是如何解释查询的。这可以为你提供有关 SQL 优化器如何使用索引以及在哪里可以进行改进的见解。</li><li><strong>谨慎使用索引的开销:</strong> 虽然索引加速了搜索查询，但它们也涉及成本。它们占用空间，并且每次修改表中的数据（INSERT、UPDATE、DELETE）时，索引也需要更新。这可能会慢下来这些操作。</li><li><strong>索引 WHERE 子句中使用的列:</strong> 经常在 WHERE 子句中使用的列通常是索引的好候选。</li><li><strong>有效地使用多列索引:</strong> MySQL 允许您在多个列上创建索引。当您创建这样的索引时，MySQL 可以使用它来处理第一列，或者第一和第二列，或者所有列在索引中。</li><li><strong>为不同的存储引擎使用适当的索引:</strong> 如果您使用 InnoDB，请注意，它根据主键在磁盘上存储其行。因此，主键的选择对 InnoDB 表的性能有很大影响。</li></ol><p>请记，这些只是指导，最佳实可能会因使用情况的差异而变化。</p><h1 id="主题-1-7-实际案例研究"><a href="#主题-1-7-实际案例研究" class="headerlink" title="主题 1.7: 实际案例研究"></a><strong>主题 1.7: 实际案例研究</strong></h1><p>好！我们已经顺利地完成了结构化课程的学习。总是有帮助的是通过实际例子来增强我们的学习。因此，让我们来研究一些 MySQL 索引和 B+ 树的实际案例研究。</p><ol><li><strong>电子商务系统:</strong> 考虑亚马顿这样的在线商店系统。这些平台处理了巨大的数据量，包括商品、用户详细信息、交易详细信息等等。给定巨大数量的产品和交易频率，数据检索的速度至关重要。在这里，MySQL 索引发挥了重要作用。有效使用主键、唯一和全文索引显著加速了查询处理过程，为用户提供了有效、流畅的体验。B+ 树用于索引允许系统处理数百万个项目，而性能下降不会太大。</li><li><strong>社交媒体平台:</strong> 社交媒体平台如脸书或推特也广泛使用索引。每次我们打开我们的时线，系统就会查询一个非常大的数据库，以获取相关的帖子。想象一下在海量数据中找到一个 needle 在 haystack 中——这就是在没有索引的情况下找到我们的个人化时线所需要的时间。有效的索引允许这些服务快速地为我们提供每次登录或刷新时线所需要的数据。</li><li><strong>搜索引擎:</strong> Google、Yahoo、Bing 等搜索引擎也广泛使用索引来提供快速和准确的搜索结果。在没有有效的索引策略的情况下，无法在互联网的庞大世界中立即获取搜索结果。</li></ol><p>这些只是展示了实际应用中 B+ 树和索引的一些快照。无 matter 您是开发网站、应用程序或任何处理大量数据的平台，了解并有效地使用这些结构可以为性能和效率带来显著的差异。</p><h1 id="主题1-8：可能的面试问题和答案"><a href="#主题1-8：可能的面试问题和答案" class="headerlink" title="主题1.8：可能的面试问题和答案"></a><strong>主题1.8：可能的面试问题和答案</strong></h1><p>好的，让我们前进。让我们为 MySQL 索引和 B+ 树准备好一些可能的面试问题。掌握这些概念可以帮助你在工作申请中表现良好，总是更好的准备好！</p><p>下面是一些问题和答案</p><ol><li><strong>为什么数据库中的索引重要？</strong><br>索引在数据库中增加了数据检索的效率。索引与书籍中的索引类似，可以更快地访问数据。在 absence 的情况下，要找到数据，数据库需要浏览整个表的每一行——称为全表扫描——这可能会耗费时间和资源。</li><li><strong>什么是 B+ 树？</strong><br>B+ 树是数据库中用于有效和有序地存储数据的数据结构。它是一个平衡树结构，其中所有叶节点位于同一级别，使搜索、插入和删除操作都非常有效，即使处理大量数据也是如此。</li><li><strong>MySQL 是如何使用 B+ 树进行索引？</strong><br>MySQL 在 InnoDB 存储引擎中使用 B+ 树作为默认索引方案。主索引和辅助索引的 B+ 树都存储在 InnoDB 中。主索引的 B+ 树的叶节点包含表的行数据，辅助索引的 B+ 树的叶节点包含主键值。</li><li><strong>MySQL 索引的最佳实践？</strong><br>重要的最佳实践包括了解数据之前进行索引，使用 EXPLAIN 关键字来了解查询执行，索引列用于 WHERE 子句，有效地使用多列索引，考虑索引开销，并使用适当的索引取决于存储引擎。</li><li><strong>在哪里索引可以显著提高性能？</strong><br>电子商务平台可以作为一个好的例子。它们需要处理大量数据——用户详细信息、产品详细信息、交易历史等。索引可帮助排序和检索这些数据，提高搜索和交易效率并增加用户体验。</li></ol><h1 id="主题1-9：回和自我评估"><a href="#主题1-9：回和自我评估" class="headerlink" title="主题1.9：回和自我评估"></a><strong>主题1.9：回和自我评估</strong></h1><p>到了课程的最后一部分，我们将回主要内容并进行自我评估。</p><p>让我们回一下我们学习的内容：</p><ul><li><strong>为什么索引</strong>：我们已经了解了数据库中索引的重要性，并提高了数据检索的效率。</li><li><strong>MySQL 中的索引类型</strong>：我们已经探讨了 MySQL 中的各种索引类型，包括主索引、唯一索引、全文索引、简单索引和复合索引，并了解了它们的应用场景。</li><li><strong>B+ 树</strong>：我们已经深入了解了 B+ 树的结构，以及它们是如何工作的。</li><li><strong>B+ 树在 MySQL 索引中的应用</strong>：我们已经看到了 MySQL 如何使用 B+ 树作为索引结构，特别是 InnoDB 存储引擎。</li><li><strong>MySQL 索引的最佳实践</strong>：我们已经探讨了如何有效地使用索引，并提供了三个最佳实践。</li><li><strong>实际应用</strong>：我们已经看到了如何在社交媒体平台、搜索引擎和电子商务系统中应用索引和 B+ 树。</li></ul><p>现在，为了自我评估，请参考以下问题和小项目：</p><p>问题：</p><ol><li>数据库中的索引有哪些作用？</li><li>简要描述 B+ 树的结构和工作原理。</li><li>主索引和辅助索引在 MySQL 中有什么区别？</li><li>在 MySQL 中使用索引时，可以提供三个最佳实践。</li></ol><p>小项目：</p><ol><li>创建或下载一个小数据集，并在 MySQL 中实现索引，然后观察检索数据时的性能差异。</li><li>考虑一个电子商务数据库，其中包含用户信息、产品详细信息和交易历史表。为其设计一个基本架构并说明各种 MySQL 索引的应用。</li></ol><p>开心学习！</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview4/">https://programmerscareer.com/mysql-interview4/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 面试：简述乐观锁以及悲观锁的区别以及使用场景</title>
      <link href="/zh-cn/mysql-interview5/"/>
      <url>/zh-cn/mysql-interview5/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>你曾被提过类似问题在面试中问过吗？或者将来会遇到，让我们一起探索和掌握它！</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题-1-1：MySQL-和锁定机制简介"><a href="#主题-1-1：MySQL-和锁定机制简介" class="headerlink" title="主题 1.1：MySQL 和锁定机制简介"></a>主题 1.1：MySQL 和锁定机制简介</h1><p>让我们开始学习 MySQL 和锁定机制！</p><p>MySQL 是世界上最著名的开源关系数据库管理系统（RDBMS）之一。它非常受欢迎，特别是用于网站和在线出版的网络应用程序，并是 LAMP 开源网站应用程序软件堆栈的核心组件。</p><p>现在让我们谈谈为什么我们需要锁定机制在数据库中。 想象一场场景，两名人同时试图从同一银行账户中提款。 如果没有机制来防止它，他们可能会同时检查帐户余额，看到足够的资金，并继续提取超过帐户中实际存在的资金。 这是一种竞争条件，并可能导致严重的数据完整性问题。 这就是锁定机制发挥作用的地方！</p><h1 id="主题-1-2：锁定机制概述"><a href="#主题-1-2：锁定机制概述" class="headerlink" title="主题 1.2：锁定机制概述"></a>主题 1.2：锁定机制概述</h1><p>所以，让我们深入探讨 MySQL 中的锁定机制。 就像我们所说的，锁定在数据库中非常重要，特别是在多用户数据库环境中。</p><p>在 MySQL 中，锁定主要用于控制如何访问事务，以便每个事务可以看到数据的一致快照。 MySQL 中使用的主要类型的锁定有：</p><ol><li><strong>共享锁（读锁）</strong>：共享锁用于执行读操作（选择）时。 它允许并发事务读取（选择）资源，并保证无事务可以写入（更新/删除）该资源。</li><li><strong>排他锁（写锁）</strong>：排他锁用于执行数据修改操作时。 它确保持有锁的事务是唯一的事务，可以读取或写入资源。</li></ol><p>在下一章中，我们将深入探讨两种流行的锁定机制—— 乐观锁定和悲观锁定。 选择使用哪种锁定机制通常取决于系统的特定要求，例如并发事务可能会发生冲突的概率。</p><h1 id="主题-1-3：了解乐观锁定"><a href="#主题-1-3：了解乐观锁定" class="headerlink" title="主题 1.3：了解乐观锁定"></a>主题 1.3：了解乐观锁定</h1><p>让我们来详细了解<strong>乐观锁定</strong>！ 这是在多用户数据库中处理并发更新的策略。</p><p>乐观锁定基于多个事务可以完成而不会影响彼此的假设，因此允许多个事务访问同一条记录进行编辑。 这种方法在数据的争用较低的系统中很有用。</p><p>下面是乐观锁定的简单方法：</p><ol><li>从数据库中获取记录以进行更新。</li><li>更新之前，应用程序会检查另一用户是否已更新该记录以来。</li><li>如果记录未被其他用户更新，应用程序可以执行更新并一切顺利进行。</li><li>如果记录已被其他用户更新，应用程序通常会通知用户并中止事务或自动重试事务。</li></ol><p>乐观锁定的主要优点是其高效性。 它避免了获取和释放锁的开销并避免了事务等待锁。</p><p>但请记住，没有免费的午餐！ 在数据争用较高并且数据更新频繁的环境中，可能会出现许多事务冲突，这可能会导致性能问题。</p><h1 id="主题-1-4：了解悲观锁定"><a href="#主题-1-4：了解悲观锁定" class="headerlink" title="主题 1.4：了解悲观锁定"></a>主题 1.4：了解悲观锁定</h1><p>让我们来深入了解<strong>悲观锁定</strong>！ 这是 MySQL 中基于完全不同的假设的机制。 它假设冲突很可能会发生并强制执行严格的控制来防止这种情况。</p><p>下面是悲观锁定的工作方式：</p><ol><li>当获取记录以进行更新时，立即获取排他锁。</li><li>直到释放锁，其他事务不能更新此记录。</li><li>释放锁时，其他事务可以获取锁并更新此记录。</li></ol><p>悲观锁定是防止冲突的绝佳方法，因为它不允许另一事务进行，如果它可能会导致冲突。 它适用于数据争用较高并且记录频繁更新的环境。</p><p>但请记住，每个硬币都有两面！ 这种方法可能会导致降低并发性并影响系统性能，因为事务可能会被长时间保持等待锁。</p><h1 id="主题1-5：比较乐观锁和悲观锁。"><a href="#主题1-5：比较乐观锁和悲观锁。" class="headerlink" title="主题1.5：比较乐观锁和悲观锁。"></a><strong>主题1.5：比较乐观锁和悲观锁。</strong></h1><p>现在你已经熟悉了乐观锁和悲观锁，了解在哪些场景下使用哪一种可以显著影响应用的性能和可靠性。</p><p><strong>乐观锁</strong> 假设冲突较少并大多数避免了锁的获取和释放。它可能在低争用场景下导致更高的性能，因为它会导致更少的阻塞。然而，对于经常发生冲突的系统，锁的成本和频率的回滚可能会降低性能。</p><p>另一方面，<strong>悲观锁</strong> 假设冲突会经常发生并使用锁来防止它们。这种策略可能在高争用场景下有好处，因为它避免了冲突解决相关的回滚。然而，获取锁所需的等待时间可能会降低性能。</p><p>因此， golden rule 是：</p><blockquote><p><em>在冲突较少的情况下，选择乐观锁。在冲突经常发生的情况下，选择悲观锁。</em></p></blockquote><p>这就是 MySQL 中乐观锁和悲观锁的简要比较。</p><h1 id="主题1-6：锁定机制的使用场景"><a href="#主题1-6：锁定机制的使用场景" class="headerlink" title="主题1.6：锁定机制的使用场景"></a><strong>主题1.6：锁定机制的使用场景</strong></h1><p>厉害！现在我们已经了解了主要的锁定机制，让我们来看看这些机制在真实的场景中可能会有好处。</p><ol><li><p><strong>银行系统</strong>：<br>考虑一种银行应用程序，其中经常发生交易。这些交易需要一致和安全。在这种情况下，悲观锁是有利的，因为它确保一旦用户开始交易，就不会有其他用户修改数据，保证数据一致性。</p></li><li><p><strong>票务预订应用程序</strong>：<br>考虑一个在线票务预订系统，其中多个用户试图预订有限数量的票。在这种情况下，乐观锁可能是有利的，因为它允许多个用户同时访问票务预订功能。</p></li><li><p><strong>内容管理系统</strong>：<br>如果你在一个内容管理系统上工作，其中用户正在更新他们的博文或文章，乐观锁可能是有利的。由于两个用户试图编辑同一文章的可能性相对较低，系统可以处理这些偶尔的冲突。</p></li><li><p><strong>股票交易应用程序</strong>：<br>在一个股票交易应用程序上，悲观锁可能是有利的，因为它立即阻止其他交易，直到完成。在这种情况下，由于一次性的延迟可能会导致重大财务损失，悲观锁可能会有好处。</p></li></ol><p>记住，决定使用乐观锁或悲观锁主要取决于应用的性质，冲突的可能性，并发性的要求，以及延迟的容忍度。</p><h1 id="主题1-7-回顾和评估"><a href="#主题1-7-回顾和评估" class="headerlink" title="主题1.7 回顾和评估"></a>主题1.7 回顾和评估</h1><ol><li><strong>MySQL 和锁定机制的介绍</strong>：我们讨论了 MySQL 的功能，锁定机制的重要性和并发数据库访问的帮助。</li><li><strong>锁定机制的概述</strong>：我们浏览了各种锁定机制，它们的重要性在维护数据一致性和处理并发访问中，并分析了它们的优缺点。</li><li><strong>了解乐观锁定</strong>：我们深入探讨了乐观锁定的概念，它的优缺点和在 MySQL 中的实现。</li><li><strong>了解悲观锁定</strong>：我们探讨了悲观锁定，包括其强项和在 MySQL 中的实现。</li><li><strong>比较乐观和悲观锁定</strong>：我们比较了这两种锁定机制并结论了选择高度取决于特定的使用案例和系统要求。</li><li><strong>锁定机制的使用场景</strong>：我们浏览了可能的真实应用场景，其中这些锁定机制可以提供好处。</li></ol><h2 id="例子问题："><a href="#例子问题：" class="headerlink" title="例子问题："></a>例子问题：</h2><p>让我们来看一个例子：你有一个 MySQL 数据库，其中一个名为“Account”的表存储了用户的账户余额。两个不同的金融事务试图从同一帐户中扣除资金同时进行。如何使用 MySQL 中的乐观和悲观锁定机制来处理这种情况？</p><p><strong>答案</strong>：</p><p>对于 <strong>乐观锁定</strong>，您可以通过在 Account 表中使用版本列来处理这种情况。这是怎样做的：</p><ul><li>事务先读取帐户余额并记下版本。在更新帐户之前，它们检查版本是否仍然相同。如果版本已更改，这意味着另一事务在此期间更新了帐户余额，因此当前事务被回滚。这样就避免了不一致的扣除。</li></ul><p>对于 <strong>悲观锁定</strong>，您将锁定帐户对于每个金融事务。这是怎样做的：</p><ul><li>事务立即锁定帐户，在读取帐户余额时。只有一个事务可以持有锁，并持有它直到更新帐户余额。所有试图读取帐户余额的其他事务，当锁被持有时，将被阻止，直到锁被释放。</li></ul><p>现在，测试你的知识。</p><p>**问题 1 (简单)**：</p><p>在哪种情况下会选择乐观锁定而不是悲观锁定？</p><p>**问题 2 (中等)**：</p><p>悲观锁定在高吞吐量系统中可能会有哪些缺点，并说明如何减轻这些缺点？</p><p>**问题 3 (困难)**：</p><p>描述一种场景，其中既不适合乐观锁定也不适合悲观锁定，并说明所需的锁定或并发控制机制。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview5/">https://programmerscareer.com/mysql-interview5/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 面试：产生死锁的必要条件有哪些？如何解决死锁？</title>
      <link href="/zh-cn/mysql-interview6/"/>
      <url>/zh-cn/mysql-interview6/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>我们先来了解死锁是什么，并了解它们在事务中是如何发生的。</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题1-1：死锁的介绍"><a href="#主题1-1：死锁的介绍" class="headerlink" title="主题1.1：死锁的介绍"></a><strong>主题1.1：死锁的介绍</strong></h1><p>在多线程环境中，当两个或多个线程因为彼此持有并请求资源而无法进行时，就会出现死锁。在 MySQL 数据库的上下文中，死锁发生在两个或多个事务中，它们相互持有并请求锁，形成了资源的循环依赖。</p><p>在事务中，线程可能需要锁定多张表或行，这可能会导致线程需要一个已经被另一个线程锁定的资源的情况。同时，该线程可能正在等待另一个线程锁定的资源。这就是所谓的死锁。</p><p>让我们用一个简单的故事来说明：</p><p>想象两名漫画爱好者，Alice 和 Bob。Alice 现在持有最新的《超人》漫画，Bob 也想要它。同时，Bob 持有最新的《巧女》漫画，Alice 也想要它。现在，Alice 不想放弃她的《超人》漫画，直到她得到了《巧女》漫画。同时，Bob 也不想放弃他的《巧女》漫画，直到他得到了《超人》漫画。因此，两人都在等待对方释放他们的漫画，这就是死锁。</p><p>在数据库事务中，Alice 和 Bob 可能是事务，并且漫画可能是被锁定的资源。</p><h1 id="主题1-2：了解必要条件以创造死锁"><a href="#主题1-2：了解必要条件以创造死锁" class="headerlink" title="主题1.2：了解必要条件以创造死锁"></a><strong>主题1.2：了解必要条件以创造死锁</strong></h1><p>要了解死锁是如何发生的，我们需要熟悉 Coffman 条件，这是一组四个条件，它们必须全部满足才能发生死锁。这些条件被 Edward G. Coffman， Jr. 提出并命名。条件是：</p><ol><li><strong>互斥</strong>：至少一个资源必须以非共享模式持有。这意味着只有一个进程（或线程）可以使用资源在任何给定时间内。如果另一个进程请求资源，请求进程必须被延迟，直到资源被释放。</li><li><strong>持有和等待（资源持有）</strong>：一个进程至少持有一个资源并等待其他资源，这些资源目前被其他进程持有。</li><li><strong>不可抢占</strong>：资源不能被强行从持有它们的进程处除，直到资源被使用完成。资源只能在持有它们的进程释放它们时释放。</li><li><strong>环形等待</strong>：存在一个环形链条中的进程，其中每个进程持有一个资源并请求另一个资源，被另一个进程在链条中持有。基本上，存在一个进程 P1，它在等待一个由进程 P2 持有的资源，并且 P2 在等待由 P1 持有的资源。这就形成了一个环形链条中的等待进程。</li></ol><p>这四个条件 inherently 提供了一个逻辑结构来了解和结构防止策略。通过确保至少一个上述条件不会发生，我们可以防止死锁的形成。</p><h1 id="主题1-3：在-MySQL-中检测死锁"><a href="#主题1-3：在-MySQL-中检测死锁" class="headerlink" title="主题1.3：在 MySQL 中检测死锁"></a><strong>主题1.3：在 MySQL 中检测死锁</strong></h1><p>在 MySQL 中，InnoDB 存储引擎自动检测并解决死锁，通过回滚与其中一笔交易。因此，您的应用应该总是准备好重新发出交易，因为它被回滚了，因为发生了死锁。</p><p>当在 MySQL 中发生死锁时，它会立即被检测和解决。这是通过维护哪些事务正在等待哪些其他事务持有的锁的 <em>wait-for 图</em> 来实现的。通过这种方法，MySQL 可以检查等待图中是否存在循环。如果它检测到循环，这意味着死锁，并且它会回滚一笔交易来解决死锁。</p><p>为了提供更多的见解，MySQL 还提供了诊断信息，当它检测和解决死锁时。这些信息可以从 <code>SHOW ENGINE INNODB STATUS</code> 命令获取，它会显示最新的死锁错误。</p><p>但是，需要注意的是，死锁并不总是表明设计错误或错误。在高并发系统中，死锁可能会偶然发生，并且可以被视为做生意的成本。然而，如果您经常遇到它们，可能值得进一步调查，以看看是否可以进行交易处理的改进。</p><h1 id="主题1-4：避免死锁"><a href="#主题1-4：避免死锁" class="headerlink" title="主题1.4：避免死锁"></a><strong>主题1.4：避免死锁</strong></h1><p>下面是避免死锁的几个策略：</p><ol><li><strong>锁定表的顺序保持一致</strong>：总是锁定表以相同的顺序。例如，如果所有的事务都先锁定“orders”表，就不会有一个事务锁定“orders”表，另一个事务锁定“products”表并等待“orders”表。</li><li><strong>快速和短的事务</strong>：短的事务更少可能会锁定需要的行，因为它们更少可能会锁定需要的行。</li><li><strong>错误处理</strong>：由于 InnoDB 自动检测死锁并回滚一笔交易，因此您需要准备好在代码中捕捉该错误并重新发出交易。</li><li><strong>使用较低的隔离级别</strong>：如果可能，请使用读提交隔离级别而不是重复读来减少死锁的可能性。</li><li><strong>避免热点</strong>：如果可能，请避免频繁更新的行，以减少死锁的可能性。例如，如果可能，请考虑使用不同的策略来计数操作，而不是使用计数表，每次操作时更新。</li></ol><h1 id="主题1-5：解决死锁"><a href="#主题1-5：解决死锁" class="headerlink" title="主题1.5：解决死锁"></a><strong>主题1.5：解决死锁</strong></h1><p>在解决死锁方面，理想情况是MySQL的InnoDB存储引擎自动检测和处理死锁。 InnoDB 使用一种称为 <em>wait-for graph</em> 的机制来检测死锁。当发生死锁时，InnoDB 选择一个事务并杀死它，从而解决死锁。</p><p>虽然这样解决了死锁，但对应用程序开发者来说，应该在应用程序中处理这些场景。当 InnoDB 因为死锁而杀死事务时，它会引发一个错误，需要在应用程序中捕捉。通常情况下，被终止的事务应该重试。</p><p>InnoDB 的自动死锁检测可以解决死锁，但在某些情况下，检测和杀死事务可能会花费较长的时间，影响应用程序的性能。因此，还要为避免死锁而设计应用程序。</p><p>虽然完全避免死锁在高并发系统中困难，但尽量避免它们会使数据库系统的操作更加稳定和高效。良好的编码习惯、有效地设计表格、正确地应用事务和锁控制可帮助避免大多数死锁。</p><h1 id="主题1-6：诊断死锁"><a href="#主题1-6：诊断死锁" class="headerlink" title="主题1.6：诊断死锁"></a><strong>主题1.6：诊断死锁</strong></h1><p>调查和诊断死锁可以提供有价值的见解，帮助防止它们或提高响应时间。MySQL 包含多种工具可帮助这个过程。</p><ol><li><strong>SHOW ENGINE INNODB STATUS</strong>：这条命令输出了一段文本报告，包含最近的死锁的信息，如果发生了死锁。它是在死锁发生后立即运行的，因为其信息会在下一个死锁中丢失。</li><li><strong>InnoDB 监视器</strong>：这些是更详细和更广泛的报告，包含 InnoDB 内部的详细信息，包括死锁。它们分为标准、锁和互斥监视器。</li><li><strong>性能架构</strong>：MySQL 的性能架构可以配置为捕获详细数据事件，包括事务事件。这些数据存储在表中并可以像其他 MySQL 数据一样查询。</li><li><strong>二进制日志</strong>：MySQL 的二进制日志可帮助确定导致死锁的查询序列。这需要启用二进制日志并以行格式进行日志。</li><li><strong>错误日志</strong>：死锁会在这里记录下来，如果启用了 innodb_print_all_deadlocks 配置选项。</li></ol><p>通过分析这些来源，可以确定参与死锁的事务并了解它们试图访问的资源。在许多情况下，详细分析可能会指出更好的锁序或更好的事务大小来避免预见的死锁。</p><h1 id="主题1-7：-复习和评估"><a href="#主题1-7：-复习和评估" class="headerlink" title="主题1.7： 复习和评估"></a>主题1.7： <strong>复习和评估</strong></h1><p><strong>示例问题：</strong> 假设您在 MySQL 数据库中遇到了死锁。您决定运行命令 <code>SHOW ENGINE INNODB STATUS</code> 获取更多信息。</p><p><code>LATEST DETECTED DEADLOCK</code> 部分给出了以下输出：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">LATEST DETECTED DEADLOCK  </span><br><span class="line">------------------------  </span><br><span class="line"></span><br><span class="line">2022-08-24 23:08:02 7f3e6e2fd700  </span><br><span class="line">*** (1) TRANSACTION:  </span><br><span class="line">TRANSACTION 118945420, ACTIVE 22 sec inserting  </span><br><span class="line">mysql tables in use 1, locked 1  </span><br><span class="line">1700 lock struct(s), heap size 187648, 1249789 row lock(s), undo log entries 1  </span><br><span class="line">MySQL thread id 155, OS thread handle 0x7f3e6e3e7700, query id 25749768 localhost user  </span><br><span class="line">INSERT INTO customer (id, name, address) VALUES (3, 'John Doe', '123 Main St')  </span><br><span class="line">*** (1) WAITING FOR THIS LOCK TO BE GRANTED:  </span><br><span class="line">RECORD LOCKS space id 66873 page no 70541 n bits 600 index `id` of table `test`.`customer` trx id 118945420 lock mode S waiting up to 3 years total: 47.56T, and currently at 47.68T to rise above: 47.68T  </span><br><span class="line">*** (2) TRANSACTION:  </span><br><span class="line">TRANSACTION 118945416, ACTIVE (PREPARED) 13 sec committing, thread declared inside InnoDB 476  </span><br><span class="line">mysql tables in use 1, locked 1  </span><br><span class="line">1 lock struct(s), heap size 368, 0 row lock(s)  </span><br><span class="line">MySQL thread id 117, OS thread handle 0x7f3e6e2fd700, query id 25749765 localhost user  </span><br><span class="line">COMMIT  </span><br><span class="line">*** (2) HOLDS THE LOCK(S):  </span><br><span class="line">RECORD LOCKS space id 66873 page no 70541 n bits 600 index `id` of table `test`.`customer` trx id 118945416 lock mode S  </span><br><span class="line">*** (2) WAITING FOR THIS LOCK TO BE GRANTED:  </span><br><span class="line">RECORD LOCKS space id 66873 page no 70541 n bits 600 index `id` of table `test`.`customer` trx id 118945416 lock_mode X waiting up to 3 years total: 47.68T to rise above: 47.56T  </span><br><span class="line">*** WE ROLL BACK TRANSACTION (1)</span><br></pre></td></tr></tbody></table></figure><p>根据此信息，什么是导致死锁的原因，并可能解决它？</p><p><strong>问题 1 — 简单熟练问题（难度 3/10）：</strong></p><p>Coffman 条件中的四个条件是什么？请提供每个条件的简要说明。</p><p><strong>问题 2 — 复杂熟练问题（难度 6/10）：</strong></p><p>为了预防或最小化死锁发生，您将执行哪些步骤？</p><p><strong>问题 3 — 复杂问题（难度 9/10）：</strong></p><p>MySQL InnoDB 引擎为什么会自动解决死锁？什么是其优势和潜在的缺点？</p><p><strong>请先自己试图找到答案，再问助。</strong>  </p><p><strong>解决示例问题的方法：</strong> 两个事务同时等待资源，其中事务（1）正在等待 <code>id</code> 索引的 <code>S</code> 模式（读）锁，该锁被事务（2）所持有。同时，事务（2）正在等待同一资源的 <code>X</code> 模式（写）锁，并持有 <code>S</code> 模式（读）锁。</p><p>这种情况意味着两个事务都无法进行，导致死锁。解决方法是确保事务请求锁的顺序，这是避免死锁的一种常见技术。</p><p><strong>回答问题 1 的方法：</strong> Coffman 条件如下：</p><ol><li><strong>互斥：</strong> 资源只能由一个进程所持有。</li><li><strong>保持和等待：</strong> 已经持有资源的进程可以请求新资源。</li><li><strong>不可抢：</strong> 只有持有资源的进程才能释放它。</li><li><strong>环形等待：</strong> 存在一个环形链条，其中每个进程持有下一个进程所需的资源。</li></ol><p><strong>回答问题 2 的方法：</strong> 多种方法可以防止或最小化死锁：</p><ol><li><strong>锁超时设置：</strong> 限制事务等待获取锁的时间，可以减少等待时间并可能解决死锁。</li><li><strong>锁顺序：</strong> 按特定顺序请求锁可以避免环形等待条件。</li><li><strong>频繁提交：</strong> 较小的事务更可能与其他事务不发生冲突。</li><li><strong>死锁检测工具：</strong> 使用内置或第三方工具确定死锁发生的时间和原因，以便编程解决方案可以应用。</li></ol><p><strong>回答问题 3 的方法：</strong> 当 MySQL 发生死锁时，InnoDB 引擎会自动选择具有最少行锁的事务并回滚它来解决死锁。</p><p><strong>优势：</strong></p><ol><li>这种自动解决可以帮助保持数据库运行良好，无需手动干预。</li></ol><p><strong>潜在的缺点：</strong></p><ol><li>如果事务较大或重要，则回滚可能会导致数据不被更新或保存正确。</li><li>持续回滚可能会影响性能。</li><li>不是所有的业务逻辑场景适合自动回滚。</li></ol><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview6/">https://programmerscareer.com/mysql-interview6/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 面试：什么是 SQL 注入攻击？如何防止这类攻击？</title>
      <link href="/zh-cn/mysql-interview7/"/>
      <url>/zh-cn/mysql-interview7/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>下面是学习 MySQL 中的 SQL 注入攻击的提议课程：</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：SQL-注入攻击简介"><a href="#主题：SQL-注入攻击简介" class="headerlink" title="主题：SQL 注入攻击简介"></a>主题：SQL 注入攻击简介</h1><p>SQL 注入（SQLi）是网站应用安全性漏洞中最著名的类别之一。它发生在攻击者可以在输入字段中插入恶意 SQL 语句以执行或修改时。简单来说，SQLi 攻击利用网站的弱输入验证，其中 SQL 命令被解析。</p><p>这种攻击可能导致未经授权的用户列表查看、整个表的删除以及在某些情况下，攻击者可能会获得管理员权限，全部通过在数据库上运行恶意 SQL 语句来完成。SQLi 相对容易防止，但仍然发生非常频繁，并且具有令人惊讶的后果。</p><p>攻击者可以通过在被包含在 SQL 语句中的字段中插入自己的命令来操纵您的 SQL 查询。这些攻击成功时，网站应用程序未能正确验证输入之前将其包含在 SQL 查询中。</p><p>例如，想象一下一个简单的登录功能，其中用户必须输入用户名和密码。与此功能相关的 SQL 查询可能会像这样看起来：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM users WHERE username = '[username]' AND password = '[password]';</span><br></pre></td></tr></tbody></table></figure><p>在这种情况下，攻击者可能会提交“<code>admin'; --</code>”作为他们的用户名。您的查询将然后看起来像这样：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM users WHERE username = 'admin'; --' AND password = '[password]';</span><br></pre></td></tr></tbody></table></figure><p>在 SQL 中，从&nbsp;<code>--</code>&nbsp;开始的任何内容都被视为注释并被忽略。因此，攻击者已经成功地绕过了密码检查并可以以&nbsp;<code>admin</code>&nbsp;身份登录。</p><p>请记，这是 SQLi 的最简单形式——存在更复杂的 SQLi 方法，它们可能会有更为严重的后果。</p><h1 id="主题：SQL注入攻击的示例"><a href="#主题：SQL注入攻击的示例" class="headerlink" title="主题：SQL注入攻击的示例"></a>主题：SQL注入攻击的示例</h1><p>SQL注入攻击的形态很多种。下面是一些常见的例子：</p><p><strong>1. 显示隐藏数据：</strong><br>假设我们有一个显示过滤后的产品的页面：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://example.com/products?category=Books</span><br></pre></td></tr></tbody></table></figure><p>它可能使用以下 SQL 查询：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM products WHERE category = 'Books'</span><br></pre></td></tr></tbody></table></figure><p>攻击者可以更改 URL 到：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://example.com/products?category=Books' OR '1'='1</span><br></pre></td></tr></tbody></table></figure><p>这可能会修改 SQL 查询为：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM products WHERE category = 'Books' OR '1'='1'</span><br></pre></td></tr></tbody></table></figure><p>由于 ‘1’=’1’ 总是真的，它会显示所有的产品，不仅仅是书籍。</p><p><strong>2. 绕过应用程序逻辑：</strong></p><p>考虑另一种情况，其中应用程序检查用户的登录凭证使用以下代码：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM users WHERE username = '$username' AND password = '$password'</span><br></pre></td></tr></tbody></table></figure><p>攻击者可以使用 SQLi 绕过密码检查使用以下输入：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">' OR '1'='1' -- 对于用户名</span><br><span class="line">randompassword 对于密码</span><br></pre></td></tr></tbody></table></figure><p>这将看起来像：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM users WHERE username = '' OR '1'='1' --' AND password = 'randompassword'</span><br></pre></td></tr></tbody></table></figure><p>注释掉密码检查的 SQL 查询的部分，导致非授权的登录。</p><p><strong>3. UNION 攻击：</strong></p><p>UNION 操作可以用于从数据库的其他表中检索数据。例如，URL：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://example.com/products?category=Books</span><br></pre></td></tr></tbody></table></figure><p>如果查询是：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT price, name, description FROM products WHERE category = 'Books'</span><br></pre></td></tr></tbody></table></figure><p>攻击者可能会试：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://example.com/products?category=Books' UNION SELECT username, password FROM users --</span><br></pre></td></tr></tbody></table></figure><p>这可能会导致泄露用户凭证。</p><p>请记住，这些攻击大量依赖于后端查询结构和保护机制的存在。不是所有的网站或数据库都会受到这些精确的攻击。然而，这些示例应该能够给你一个想法，说明 SQLi 利用了不正确处理用户提供的数据来操纵 SQL 查询。</p><h1 id="主题：了解-SQL-注入的影响"><a href="#主题：了解-SQL-注入的影响" class="headerlink" title="主题：了解 SQL 注入的影响"></a>主题：了解 SQL 注入的影响</h1><p>SQL 注入可能导致各种危险后果，其严重程度大量取决于攻击者侵害的用户帐户的权限和数据库的用途。下面是 SQL 注入攻击的可能影响：</p><p><strong>1. 数据泄露：</strong></p><p>SQL 注入攻击的最直接和危险的后果是数据泄露。如果攻击者成功利用了 SQL 注入漏洞，他们可能会获取存储在数据库中的敏感数据。这可能包括个人身份信息（PII）、财务数据、商业秘密、密码或更多内容。</p><p><strong>2. 数据修改：</strong></p><p>SQL 注入不仅仅是关于查看数据的事情。攻击者可能会使用它来修改或删除数据库中的数据——这可能范围从更改价格或平衡到删除整个表。</p><p><strong>3. 丢失的可追溯性和非否认性：</strong></p><p>SQL 注入可能会导致丢失的可追溯性和非否认性。攻击者可能会在数据库上执行操作，并以其他用户（或者管理员）的身份进行。这可能会使追踪操作的过程变得困难，创造了非否认性问题。</p><p><strong>4. 损害商业的声誉：</strong></p><p>成功的 SQL 注入攻击可能会严重损害业务的声誉。客户信任商业处理其数据，并且一旦发生数据泄露，可能会损失这种信任。</p><p><strong>5. 法律后果：</strong></p><p>根据侵害的数据和司法管辖区，SQL 注入攻击可能会导致法律后果，例如罚金、诉讼或两项都有。</p><p>这些后果显示了 SQL 注入攻击的重要性，并且在接下来的课程中，我们将深入探讨如何防止它们。</p><h1 id="主题：防止-SQL-注入攻击"><a href="#主题：防止-SQL-注入攻击" class="headerlink" title="主题：防止 SQL 注入攻击"></a>主题：防止 SQL 注入攻击</h1><p>防止 SQL 注入攻击的关键是确保应用程序和数据库之间的数据流是安全和有保证的。下面是可以用来帮助防止 SQL 注入攻击的技术：</p><p><strong>1. 使用准备好的语句（参数化查询）：</strong></p><p>最有效的方法是使用准备好的语句。定义了参数的准备好的语句确保参数被绑定到查询中，并且不是查询的一部分，这意味着攻击者不能影响查询结构。这有效地消除了所有的 SQL 注入攻击。大多数网络语言现在都支持准备好的语句。</p><p><strong>2. 使用存储过程：</strong></p><p>与准备好的语句类似，存储过程也分离了数据和命令和查询。然而，存储过程还具有额外的好处，例如提高性能和可重用的代码。</p><p><strong>3. 输入验证：</strong></p><p>虽然这种方法自身不足以防止 SQL 注入攻击，但它仍然是必要的步骤。通过验证用户输入，我们确保它符合长度、类型、语法和业务规则的特性。</p><p><strong>4. 最小权限原则：</strong></p><p>不要为用户帐户提供更多的权限，它们所需要的。例如，如果帐户仅用于在应用程序中执行选择语句，就不要为其提供删除表的能力。如果攻击者侵害了有限的帐户，则可能会限制其造成的损害。</p><p><strong>5. 定期更新和补丁：</strong></p><p>保持数据库管理系统（DBMS）和所有软件的更新和补丁，并使用最新的安全修复。</p><p>这些是可以用来确保数据库的安全性并防止 SQL 注入攻击的几个防护技术。</p><p>中文翻译:</p><h1 id="主题：防止-SQL-注入的最佳实践"><a href="#主题：防止-SQL-注入的最佳实践" class="headerlink" title="主题：防止 SQL 注入的最佳实践"></a>主题：防止 SQL 注入的最佳实践</h1><p>除了上述防止措施外，下面是更多的最佳实践，可帮助避免 SQL 注入漏洞：</p><p><strong>1. 数据转义：</strong></p><p>数据转义是指将数据处理为原始数据，而不是作为 SQL 查询的一部分。这可以通过使用特定的函数来转义特殊字符，例如引号，或者通过使用预编译语句来隐式处理。</p><p><strong>2. 详细错误处理：</strong></p><p>黑客经常依赖数据库的错误消息来获取数据库的结构信息。最佳实践是避免直接向终端用户暴露这些错误，相反，使用通用错误消息并将详细错误信息记录到一个安全的文件中，开发人员可以参考这些详细信息。</p><p><strong>3. 使用 Web 应用程序防火墙 (WAF)：</strong></p><p>Web 应用程序防火墙可以检查进入数据的数据并识别恶意 SQL 代码。它们不能替代良好的编码实践，但它们可以作为额外的防线。</p><p><strong>4. 定期代码审查：</strong></p><p>定期进行代码审查，其中安全是其中一个主题。这可以帮助确保安全编码实践被遵循并捕获潜在的问题。</p><p><strong>5. 进行测试并使用安全工具：</strong></p><p>定期测试应用、数据库和基础设施的安全性。有许多自动化工具可用，可以扫描 SQL 注入和其他漏洞。</p><p>记住，安全是一个过程，不是一个状态。定期更新技能和知识，了解新的漏洞和攻击技术，并定期审核和改进应用是维护强大安全性的一部分。</p><h1 id="主题：测试-SQL-注入漏洞"><a href="#主题：测试-SQL-注入漏洞" class="headerlink" title="主题：测试 SQL 注入漏洞"></a>主题：测试 SQL 注入漏洞</h1><p>测试 SQL 注入漏洞是确保应用和数据库的安全性的关键部分。它可以手动进行或者使用自动化工具进行。下面是详细说明：</p><p><strong>1. 手动测试：</strong></p><p>手动测试涉及使用技术来注入特殊字符到应用的输入中并观察应用的反应。例如，输入单引号 <code>'</code> 到文本字段中。如果应用抛出 SQL 错误，这可能表明应用受 SQL 注入攻击的影响。另一方面，如果应用运行良好并显示输入的字符，这可能表明应用正确处理输入。</p><p>记住，SQL 注入可能会以多种形式出现，并且详尽的手动测试可能涉及试验许多输入。</p><p><strong>2. 自动测试与安全工具：</strong></p><p>还有许多自动化工具可用，用于帮助检测 SQL 注入漏洞。这些工具可以爬行应用并测试各种输入，节省时间并提供详细的评估。它们可以测试已知的 SQL 注入技术并生成报告，显示可能的漏洞。</p><p>例如，SQLMap、Havij 和 Netsparker。</p><p>虽然测试和自动化工具可能非常有用，但它们并不完全可靠。即使工具未发现任何漏洞，这并不意味着应用是安全的。建议结合这些方法与上述防止技术和最佳实践。</p><h1 id="主题：SQL-注入的审查和评估"><a href="#主题：SQL-注入的审查和评估" class="headerlink" title="主题：SQL 注入的审查和评估"></a>主题：SQL 注入的审查和评估</h1><h2 id="审查："><a href="#审查：" class="headerlink" title="审查："></a>审查：</h2><ol><li><strong>SQL 注入攻击：</strong> 这是一种攻击方法，攻击者通过注入恶意 SQL 代码来操纵 SQL 查询，通过用户输入进行。</li><li><strong>防范措施：</strong> 主要手段包括预编译语句、存储过程、输入验证和强制最小特权，并定期更新系统。</li><li><strong>最佳实践：</strong> 这包括数据转义、详细错误处理、使用 Web 应用程序防火墙 (WAF)、定期代码审查和使用安全工具。</li><li><strong>检测漏洞：</strong> 手动测试可能会涉及试验许多输入。自动化工具如 SQLMap 也可以帮助检测可能的漏洞。</li></ol><p>现在，让我们进行评估。</p><h2 id="评估："><a href="#评估：" class="headerlink" title="评估："></a>评估：</h2><p>下面是一些简短的问题。这些问题是为了测试我们讨论的概念的理解和应用。</p><ol><li><strong>系统可能会显示 SQL 注入攻击的特征是哪些？</strong></li><li><strong>如何使用预编译语句来防范 SQL 注入攻击？</strong></li><li><strong>为什么详细错误处理和不向终端用户暴露数据库错误是重要的？</strong></li><li><strong>描述至少两种应该遵循的最佳实践来保护自身免受 SQL 注入攻击的。</strong></li></ol><hr><ol><li><strong>系统可能会显示 SQL 注入攻击的特征是哪些？</strong><br>答：系统可能会对 SQL 注入攻击感兴趣，如果它们直接使用未经过清理或验证的用户输入来构建 SQL 查询，或者如果它们向终端用户暴露数据库错误，或者如果它们不使用参数化查询或预编译语句。可能的征兆包括用户输入中的单引号导致错误，或者特定的输入提供了访问或数据检索，该访问或数据检索不应该可能。</li><li><strong>如何使用预编译语句来防范 SQL 注入攻击？</strong><br>答：预编译语句分离 SQL 查询结构和用户提供的数据。这阻止攻击者通过更改查询结构来操纵查询，因为用户输入不被视为 SQL 命令的一部分，使 SQL 注入攻击无效。</li><li><strong>为什么详细错误处理和不向终端用户暴露数据库错误是重要的？</strong><br>答：向终端用户暴露数据库错误可以为攻击者提供有用的信息关于数据库结构或应用设计，这可以用于攻击。另外，详细错误处理是防范 SQL 注入攻击的重要部分，因为它们允许系统友好地处理问题并可能提供日志或其他机制来警告可能的攻击。</li><li><strong>描述至少两种应该遵循的最佳实践来保护自身免受 SQL 注入攻击的。</strong><br>答：其中包括：</li></ol><ul><li>使用预编译语句或参数化查询：这确保用户提供的输入不会更改 SQL 查询的结构不利地。</li><li>输入验证：输入应该被验证为具有正确的形式之前使用。例如，如果系统期望整数，它应该确认输入确实是整数。</li><li>其他最佳实践包括详细错误处理、定期系统更新、强制最小特权原则和更多。</li></ul><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview7/">https://programmerscareer.com/mysql-interview7/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 面试：MySQL 的索引什么情况下会失效？</title>
      <link href="/zh-cn/mysql-interview8/"/>
      <url>/zh-cn/mysql-interview8/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>详细分析MySQL中的索引。了解内部工作原理、好处和如何通过索引提高查询性能。</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：MySQL索引深入分析"><a href="#主题：MySQL索引深入分析" class="headerlink" title="主题：MySQL索引深入分析"></a>主题：MySQL索引深入分析</h1><p>MySQL索引发挥着优化数据库搜索性能的重要作用。为了深入了解索引，让我们更详细地分析它们。</p><p>MySQL中的索引是什么？</p><p>简单来说，索引就像书的索引一样。当你需要找到信息时，你会参考索引，它会快速指导你到包含所需信息的页面。</p><p>在MySQL中，索引是数据结构（通常是B-Tree），它提高了数据库表的访问性能。索引用于快速定位数据，而不是每次访问数据库表时搜索整个数据库表。</p><p>它们可以使用数据库表的一个或多个列创建，为随机访问和记录的有序访问提供基础。</p><p>MySQL索引的优势：</p><ol><li><strong>更快的数据检索：</strong> 索引的主要优势是加快数据检索的速度。索引使数据检索变得更快。</li><li><strong>ORDER BY 优化：</strong> 索引可以优化 ORDER BY 子句，以更快地对数据进行排序。</li><li><strong>更好的性能：</strong> 它们显著提高了 SELECT 查询和 WHERE 子句的性能。</li></ol><p>请记，虽然索引加快了数据检索，但它会慢下数据修改操作，例如 INSERT、DELETE 和 UPDATE。这是因为每次修改数据时，索引也需要更新。</p><h1 id="主题：MySQL-中的索引类型"><a href="#主题：MySQL-中的索引类型" class="headerlink" title="主题：MySQL 中的索引类型"></a>主题：MySQL 中的索引类型</h1><p>了解 MySQL 中不同类型的索引，例如 PRIMARY、UNIQUE、INDEX、FULLTEXT 以及它们的使用。</p><p>MySQL 中有多种索引类型。每种类型在特定场景下使用，并提供其特殊的优势。让我们来详细了解这些不同类型：</p><ol><li><strong>PRIMARY 索引：</strong> 这是表的主要索引。每张表都应该有一个主要索引。值在这个索引中是唯一的并不为空。在大多数情况下，这是表的主键。</li><li><strong>UNIQUE 索引：</strong> 这个索引防止两条记录具有相同的值在特定列中。这帮助维护数据的完整性。它允许 NULL 值，但唯一性仍然被强制。</li><li><strong>INDEX (或 KEY)：</strong> 这是最简单的索引类型。它允许重复和 NULL 值。它通常用于提高特定搜索的性能，并不需要强制唯一性或非 NULL 性。</li><li><strong>FULLTEXT 索引：</strong> 这是用于全文搜索的索引。它是一个非常强大的索引类型，用于搜索文本值。然而，它是一个专门的索引类型，只适用于文本（不适用于数字或日期）。</li></ol><p>每种索引类型都为特定目的服务。优化数据库的最佳使用是至关重要的。</p><p>了解何时和何处使用适当的索引是至关重要的。它取决于存储的数据、数据的完整性要求、执行的查询以及许多其他因素。</p><h1 id="主题：MySQL索引管理"><a href="#主题：MySQL索引管理" class="headerlink" title="主题：MySQL索引管理"></a>主题：MySQL索引管理</h1><p>了解如何在 MySQL 中管理索引是优化数据库性能的关键技能。</p><p>当处理索引时，您可以执行以下主要操作：</p><h2 id="创建索引："><a href="#创建索引：" class="headerlink" title="创建索引："></a>创建索引：</h2><p>要在 MySQL 中创建索引，您可以使用 <code>CREATE INDEX</code> 语句：</p><p>CREATE INDEX index_name<br>ON table_name (column1, column2, …);</p><p>例如，如果我们有一个名为 <code>Students</code> 的表，并且我们想创建一个索引在 <code>LastName</code> 和 <code>FirstName</code> 列上，我们将写：</p><p>CREATE INDEX idx_students_name<br>ON Students (LastName, FirstName);</p><h2 id="删除索引："><a href="#删除索引：" class="headerlink" title="删除索引："></a>删除索引：</h2><p>要在 MySQL 中删除索引，您可以使用 <code>DROP INDEX</code> 语句：</p><p>DROP INDEX index_name ON table_name;</p><h2 id="禁用索引："><a href="#禁用索引：" class="headerlink" title="禁用索引："></a>禁用索引：</h2><p>在某些情况下，您可能希望暂时禁用索引。MySQL 允许您使用 <code>ALTER TABLE</code> 语句禁用索引：</p><p>ALTER TABLE table_name DISABLE KEYS;</p><p>要再次启用它，您将使用 <code>ENABLE KEYS</code>：</p><p>ALTER TABLE table_name ENABLE KEYS;</p><h2 id="重命名索引："><a href="#重命名索引：" class="headerlink" title="重命名索引："></a>重命名索引：</h2><p>MySQL 不支持直接重命名索引。要重命名索引，您需要先删除（删除）索引，然后再创建它们使用新名称。</p><p>请记，虽然索引有利并可能会加快数据检索，但它们也会带来其他成本。索引占用存储空间并会慢下数据更新操作（因为当数据更新时，索引也需要更新）。</p><h1 id="主题：优化-MySQL-与索引"><a href="#主题：优化-MySQL-与索引" class="headerlink" title="主题：优化 MySQL 与索引"></a>主题：优化 MySQL 与索引</h1><p>了解如何优化 MySQL 性能使用索引是管理数据库的关键部分。</p><p>一个关键因素，影响数据检索操作的效率是索引的正确使用。但是，怎样知道索引是有效的呢？ 请参考 <code>EXPLAIN</code> 命令。</p><p><code>EXPLAIN</code> 命令是 MySQL 中的一个强大工具，可帮助了解 MySQL 如何执行查询。通过使用 <code>EXPLAIN</code> 命令来查询之前，MySQL 将返回有关如何处理语句以及表的读取顺序的信息。</p><p>下面是一个例子：</p><p>EXPLAIN SELECT * FROM Students WHERE LastName = “Smith”;</p><p>输出可能会返回大量数据，但您需要关注主要三列：</p><ol><li><strong>select_type:</strong> 这告诉我们查询的类型。</li><li><strong>key:</strong> 这告诉我们 MySQL 使用哪个索引来运行查询。</li><li><strong>rows:</strong> 这告诉我们 MySQL 考虑了多少行来给出查询的结果。</li></ol><p>另外一个重要的事情是，不同的查询需要不同的优化。例如，一个 <code>SELECT</code> 查询，用于检索数据可能会被优化不同于一个 <code>UPDATE</code> 查询，用于更新数据。</p><p>作为一般规则，索引列在 <code>WHERE</code>、<code>JOIN</code>、<code>ORDER BY</code>、和 <code>GROUP BY</code> 子句中经常使用的列上的索引可以显著增加 <code>SELECT</code> 查询的速度。</p><p>然而，请记，索引会为数据库添加额外的负担，特别是对 <code>INSERT</code>、<code>UPDATE</code>、和 <code>DELETE</code> 语句的处理。因此，索引的数量应该尽可能地保持在最小的水平上，以减少负担。</p><h1 id="主题：何时MySQL不使用索引"><a href="#主题：何时MySQL不使用索引" class="headerlink" title="主题：何时MySQL不使用索引"></a>主题：何时MySQL不使用索引</h1><p>虽然索引是为了优化数据检索而设计的，但在某些场景下，MySQL可能会忽略已存在的索引。让我们深入探讨这些场景：</p><ol><li><strong>小表：</strong> 在具有较少行数的表中，MySQL优化器可能会忽略索引并执行全表扫描。这是因为在索引中先读取索引，然后再读取行可能会涉及更多的开销，而直接读取每一行可能更有效。</li><li><strong>低选择性：</strong> 具有多个重复值的索引具有低选择性。如果索引列不足以有效地缩小行数，MySQL可能会跳过使用索引并执行全表扫描。</li><li><strong>NULL值：</strong> 如果索引列包含 NULL 值并且 WHERE 子句是 IS NULL 或 IS NOT NULL，MySQL不能使用索引，因为比较操作不能与 NULL 值一起使用。</li><li><strong>不使用索引的左侧前缀：</strong> MySQL可以有效地使用索引，当 WHERE 子句使用左侧部分的多列索引时。然而，当查询不涉及左侧部分时，MySQL可能无法有效地使用索引。</li><li><strong>LIKE 操作符的通配符开头：</strong> 当使用 LIKE 操作符在 WHERE 子句中时，如果模式开头有通配符，MySQL不能利用索引。</li></ol><p>记住，索引是优化数据检索的有用工具，但它们不总是被使用。深入了解 MySQL 如何和何时使用索引可帮助您的数据库设计和查询构造。</p><h1 id="主题：回顾和评估"><a href="#主题：回顾和评估" class="headerlink" title="主题：回顾和评估"></a>主题：回顾和评估</h1><p>已经到了课程的尾端。在我们结束之前，让我们先做一个快速回：</p><ul><li>我们深入探讨了 MySQL 索引的概念。</li><li>我们学习了 MySQL 中的两种索引类型。</li><li>我们了解了如何管理 MySQL 中的索引。</li><li>我们看到了如何使用 <code>EXPLAIN</code> 命令来评估 MySQL 性能并优化数据检索。</li><li>我们探讨了 MySQL 可能不使用索引的场景。</li></ul><p>现在，来试试你的知识！下面是一些思考性的问题：</p><ol><li>MySQL 索引的主要目的是什么，并且如何提高数据库性能？</li><li>在 MySQL 中可以描述两种不同类型的索引，并且在哪些场景下使用它们？</li><li>如何禁用并重新启用 MySQL 中的索引？</li><li>MySQL 可能会在哪些场景下不使用索引，即使它可用？</li><li>如何使用 <code>EXPLAIN</code> 命令在 <code>employees</code> 表中基于 <code>employee_id</code> 进行数据检索？</li></ol><p>试着写下你的答案，然后与你的笔记或者你使用的其他资源进行比较。回和复习是强化学习的好方法。</p><p>记住，掌握任何主题都是时间、练习和持久努力的事情。保持坚持！</p><ol><li>MySQL 索引的主要目的是什么，并且如何提高数据库性能？ An index in MySQL 是一种数据结构，可以显著提高数据库表上的数据检索操作的速度。它类似于书的索引，可以使数据库在每次访问数据库表时找到数据，而不是扫描整个数据库中的每一行。索引可以极大地提高数据库性能。</li><li><strong>可以描述两种不同类型的索引在 MySQL 中，并在哪些场景下使用它们？</strong></li></ol><ul><li>PRIMARY index: 这是一种唯一索引，其中列必须包含唯一且不为 NULL 的值。这通常用于主键。</li><li>FULLTEXT index: 这是用于全文搜索的索引。它专门用于通过 SQL 查询中的字符串定位模式进行文本搜索。</li></ul><ol><li><strong>如何禁用并重新启用 MySQL 中的索引？</strong></li></ol><ul><li>禁用非唯一索引: <code>ALTER TABLE table_name DISABLE KEYS;</code></li><li>重新启用非唯一索引: <code>ALTER TABLE table_name ENABLE KEYS;</code></li></ul><ol><li><p><strong>在哪些场景下 MySQL 可能会不使用索引，即使它可用？</strong> MySQL 可能会在以下场景下不使用索引，即使它可用：如果 MySQL 估计使用索引会 slower 于全表扫描，例如，如果表很小或索引列具有很低的选择性（许多重复值）。</p></li><li><p><strong>可以使用 EXPLAIN 命令在 <code>employees</code> 表中基于 <code>employee_id</code> 进行数据检索吗？</strong> 下面是一个简单的例子：</p><p> EXPLAIN SELECT * FROM employees WHERE employee_id = 101</p><p> 记住，练习是学习这些概念的关键。不要害惕深入探讨并在真实的 MySQL 环境中试用这些命令来进一步探索！</p></li></ol><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview8/">https://programmerscareer.com/mysql-interview8/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 面试：MySQL 有什么调优的方式？</title>
      <link href="/zh-cn/mysql-interview9/"/>
      <url>/zh-cn/mysql-interview9/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>让我们深入探讨优化 MySQL性能</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：了解-MySQL-配置"><a href="#主题：了解-MySQL-配置" class="headerlink" title="主题：了解 MySQL 配置"></a><strong>主题：了解 MySQL 配置</strong></h1><p>优化 MySQL 性能的关键方面之一是了解并适当地调整其配置。但是，先来理解我们所说的“配置”在 MySQL 中是什么意思。</p><p><strong>MySQL 配置</strong> 指的是一组参数和设置，决定了 MySQL 如何运行。其中包括控制内存分配、表缓存大小和排序缓冲区大小的变量。</p><p>MySQL 配置文件通常被命名为 <code>my.cnf</code>，但是其位置可能因操作系统和 MySQL 版本而异。</p><p><code>my.cnf</code> 文件包含多个部分。<code>[mysqld]</code> 部分包含服务器特定的设置，而 <code>[client]</code> 部分包含客户端特定的选项。对这些设置进行修改将影响 MySQL 服务器的操作。</p><p>让我们考虑几个重要的设置：</p><ul><li><strong>innodb_buffer_pool_size:</strong> 如果您使用 InnoDB 存储引擎，则此是关键设置。缓冲池是数据和索引被缓存的地方，因此正确地设置它可以显著提高性能。</li><li><strong>max_connections:</strong> 这决定了 MySQL 可以处理多少并发连接。但是，请谨慎，因为高值可能会使 MySQL 快速消耗可用资源。</li><li><strong>query_cache_size:</strong> 查询缓存可以帮助加快响应时间，但它需要谨慎使用，因为它会为所有查询处理添加额外的开销。</li></ul><p>要进行更改，您可以在 <code>my.cnf</code> 文件中编辑这些参数，然后重新启动 MySQL，以使更改生效。</p><p>了解这些配置并根据您的特定使用场景进行细化可以大大提高 MySQL 服务器的性能。</p><h1 id="主题：调整服务器设置"><a href="#主题：调整服务器设置" class="headerlink" title="主题：调整服务器设置"></a><strong>主题：调整服务器设置</strong></h1><p>现在，让我们深入探讨一些关键的服务器设置，您可以调整以优化性能。</p><p>MySQL 有大量的服务器变量，您可以设置以影响其操作。它允许高度的自定化和调整，以适应特定的应用和硬件环境。以下是一些关键变量：</p><p><strong>1. key_buffer_size:</strong> 这变量决定了 MyISAM 表索引在内存中的缓存量。如果您使用 MyISAM 表，则大值可能会提高性能。</p><p><strong>2. innodb_buffer_pool_size:</strong> 我们已经提到过，这是对 InnoDB 存储引擎的关键设置。它指定 InnoDB 使用的内存缓冲区的大小，用于缓存其表的数据和索引。</p><p><strong>3. thread_cache_size:</strong> 这变量用于指定服务器应该缓存多少线程以供重用。当客户断开时，客户端的线程被放入缓存中，并且如果客户重新连接，他们可以重用缓存中的线程。</p><p><strong>4. table_open_cache:</strong> 这变量设置了所有线程可以打开的表数量。增加此值会增加 MySQL 所需的文件描述符数量。</p><p><strong>5. query_cache_size:</strong> 它设置查询缓存的大小。它用于缓存 SELECT 结果并在不再执行相同查询时返回它们。</p><p>请记住，配置和优化 MySQL 是更多的艺术而非科学，主要是通过增量更改和持续监控来进行的。使用工具如 MySQLTuner 或 MySQL Workbench 可以非常有用，以监控 MySQL 服务器的性能并进行必要的调整。</p><h1 id="主题：查询优化"><a href="#主题：查询优化" class="headerlink" title="主题：查询优化"></a><strong>主题：查询优化</strong></h1><p>优化 MySQL 查询是提高 MySQL 服务器性能的有效方法之一。下面是一些策略：</p><ol><li><strong>避免全表扫描</strong>：尽可能避免全表扫描，通过合理使用索引（后面会详细介绍）来找到相关行。当发生全表扫描时，MySQL 必须读取整个表才能找到相关行，这可能会在处理大表时严重影响性能。</li><li><strong>使用 EXPLAIN 分析查询性能</strong>：MySQL 提供了 EXPLAIN 语句，它可以提供有关 MySQL 如何执行查询的信息。这是一个有用的调试和优化工具。</li><li><strong>利用索引</strong>：索引用于快速找到具有特定列值的行。 absence 索引，MySQL 必须扫描整个表才能找到相关行。</li><li><strong>限制结果</strong>：如果您不需要完整的结果集来执行操作，请使用 LIMIT 可以显著降低查询的成本。</li><li><strong>规范化和去规范化——按需进行</strong>：虽然规范化通常是一个好的事情，因为它减少了数据冗余性，但去规范化可能会在某些情况下帮助。例如，如果存在大表并且主键到主键的连接很慢，去规范化可能会加快这些查询，因为它允许您跳过这些连接。</li></ol><h1 id="主题：优化数据库对象"><a href="#主题：优化数据库对象" class="headerlink" title="主题：优化数据库对象"></a><strong>主题：优化数据库对象</strong></h1><p>虽然服务器和查询优化是 MySQL 性能的关键因素，数据库对象的优化也是一个重要的因素，不要忽略它们。下面是要知道的内容：</p><ol><li><strong>存储引擎类型选择</strong>：MySQL 支持多种存储引擎，每种存储引擎都有其特点。最常用的是 MyISAM 和 InnoDB。MyISAM 更简单，通常在读多写少的负载下表现更好。 InnoDB 支持高级特性，例如事务和外键，并在写多读少的负载下表现更好。</li><li><strong>索引</strong>：索引用于快速定位数据，而不是每次访问数据库表时都搜索整个数据库表。它们可以加快数据检索，但每个索引都会增加插入、更新和删除记录的成本。</li><li><strong>规范化</strong>：规范化是有效地组织数据库的过程，其目的是消除冗余数据（例如，在多个表中存储相同的数据）并确保数据依赖性有意义。虽然规范化通常会提高性能，但在某些情况下，您可能需要考虑去规范化来优化性能。</li><li><strong>分区</strong>：分区是一个有力的工具，可以帮助提高数据库的性能，特别是对大表的处理。它是通过将大表分割成更小的、更可管理的部分来实现的，每个分区存储数据的特定子集，定义了分区函数。</li></ol><p>记住，数据库对象的优化应该与应用程序的特定需求和工作负载相匹配。请定期监控数据库的性能并根据应用程序的要求调整数据库的架构。</p><h1 id="主题：硬件考虑和调整"><a href="#主题：硬件考虑和调整" class="headerlink" title="主题：硬件考虑和调整"></a><strong>主题：硬件考虑和调整</strong></h1><p>MySQL 性能可能会受到硬件组件，例如 CPU、内存、存储和网络，的影响。让我们来详细了解：</p><p><strong>1. CPU：</strong> 服务器的 CPU 速度越快，MySQL 性能越好。一种技术是平衡 CPU 的负载，MySQL 支持这种功能。</p><p><strong>2. 内存：</strong> MySQL 服务器使用大量内存。越多的内存，就越多的数据可以被缓存，并且 MySQL 需要执行的磁盘 I/O 操作越少，性能就越好。考虑调整 innodb_buffer_pool_size，它是一个内存区域，用于存储被缓存的 InnoDB 数据，包括表和索引。</p><p><strong>3. 存储：</strong> 存储类型对 MySQL 性能有影响。固态硬盘（SSD）通常具有更快的数据访问时间，与传统的硬盘驱动（HDD）相比。请记住，写入磁盘要慢得多于从内存读取数据。因此，有足够的内存可以帮助减少磁盘写入操作的数量是至关重要的。</p><p><strong>4. 网络：</strong> 网络延迟可能会影响 MySQL 性能，特别是在分布式系统中，其中 MySQL 实例需要通过网络进行通信。升级到更快的网络技术可以降低这种延迟并提高整体性能。</p><p>优化硬件来满足 MySQL 数据库的需求可以显著提高其性能。请记住定期监控数据库，以评估硬件是否满足需求。在某些情况下，某些限制只能通过增加或添加更多的硬件资源来解决。</p><h1 id="主题：MySQL-复制和分区"><a href="#主题：MySQL-复制和分区" class="headerlink" title="主题：MySQL 复制和分区"></a><strong>主题：MySQL 复制和分区</strong></h1><p><strong>MySQL 复制</strong> 和 <strong>分区</strong> 是开发人员的两个强大工具，可以帮助增加数据库性能。让我们来详细了解：</p><p><strong>1. MySQL 复制：</strong></p><p>MySQL 复制是一个过程，可以帮助您维护多个 MySQL 数据库副本，通过自动地从主数据库复制数据。这可能会有帮助的多种方式，包括为数据备份创建副本、为故障转移环境创建副本或为数据分割简化常规任务。复制可以帮助提高高负载应用程序的性能，通过分担负载之间的多个从节点。</p><p><strong>2. MySQL 分区：</strong></p><p>分区是一个过程，通过将大表分割成更小的表来提高查询性能并简化管理任务。MySQL 可以将表分割成分区，并将其存储在分区中。分区可以通过以下方式进行：</p><ul><li><strong>范围分区：</strong> 表被分割为范围，其范围由分区函数确定。值在范围内被分配到分区中。例如，您可能会将销售数据分割为月度范围。</li><li><strong>列分区：</strong> 类似于范围分区，但分区是基于列匹配一组特定值列表的。</li><li><strong>哈希分区：</strong> 分区函数生成哈希值，该值确定分区。</li><li><strong>键分区：</strong> 类似于哈希分区，但只有整数、二进制或字符串类型的列可以被使用。</li><li><strong>复合分区：</strong> 是范围或列分区与哈希或键分区的组合。</li></ul><p>了解这些概念并实施它们可以显著提高数据库的性能，并且还允许更强的冗余性和可伸性在您的系统中。</p><h1 id="主题：回顾与评估"><a href="#主题：回顾与评估" class="headerlink" title="主题：回顾与评估"></a><strong>主题：回顾与评估</strong></h1><p>在这一阶段，重要的是回顾我们所发现的一切。</p><p><strong>1. MySQL配置：</strong></p><p>我们学习了MySQL配置的重要性，并学习了如何调整各种参数来提高性能。每个MySQL安装都是独特的，并且根据个人需求进行细调可以显著提高性能。</p><p><strong>2. 服务器设置的调整：</strong></p><p>我们深入研究了内存、缓存和各种其他服务器设置的调整，以获取最佳效率。</p><p><strong>3. 查询优化：</strong></p><p>我们了解了MySQL如何处理查询，并学习了如何更有效地编写查询来节省资源。</p><p><strong>4. 优化数据库对象：</strong></p><p>我们了解了优化MySQL数据库对象，例如表和索引，以获取更好的性能，并学习了相应的技术。</p><p><strong>5. 硬件考虑和优化：</strong></p><p>我们学习了硬件参数，例如CPU、内存、磁盘和网络，对MySQL性能的影响，并学习了如何优化硬件资源以获取更好的性能。</p><p>让我们开始评估。</p><p><strong>6. MySQL复制和分区：</strong></p><p>我们探讨了MySQL复制和分区的概念，了解了它们的有用性来增强数据库性能。</p><p><strong>评估 1：MySQL 配置</strong></p><p>MySQL 配置是指在 MySQL 数据库中定义和设置各种参数的过程，这些参数可以帮助提高数据库的性能和可靠性。这是数据库管理的重要部分，因为它可以帮助数据库处理更多的请求和提供更好的性能。</p><p><strong>评估 2：服务器设置的调整</strong></p><p>通过更改服务器设置，可以帮助优化 MySQL 数据库的性能。这可能包括内存、缓存和其他服务器设置的调整，以帮助数据库处理更多的请求并提供更好的性能。</p><p><strong>评估 3：查询优化</strong></p><p>要优化 SQL 查询，可以采取多种策略，例如使用索引、避免使用子查询、使用 JOIN 代替子查询等等。这可能会帮助数据库处理更多的请求并提供更好的性能。</p><p><strong>评估 4：模式对象</strong></p><p>讨论 MySQL 中优化模式对象的重要性。</p><p><strong>评估 5：硬件考虑</strong></p><p>硬件对 MySQL 性能有影响，哪些参数可以进行优化？</p><p><strong>评估 6：复制和分区</strong></p><p>解释 MySQL 复制和分区的概念。这些技术如何增强数据库性能？</p><p>请花些时间来回答这些问题。</p><p><strong>评估 1：MySQL 配置</strong></p><p>MySQL 配置是自定义设置，决定了 MySQL 如何运行。它的重要性在于，正确的配置可以确保有效地利用系统资源，提高查询执行速度，并提供更好的性能。</p><p><strong>评估 2：服务器设置</strong></p><p>更改服务器设置，例如增加缓冲区大小或限制最大连接数，可以大大提高 MySQL 性能。例如，增加缓冲区大小可以允许更多数据存储在内存中，减少磁盘 I/O。然而，所有更改都应考虑系统资源的负载。</p><p><strong>评估 3：查询优化</strong></p><p>要优化 SQL 查询，可以使用策略，例如选择所需字段、正确使用连接、创建索引以进行更快的搜索、使用 LIMIT 以及避免使用 ‘%’ 作为查询的开头。</p><p><strong>评估 4：模式对象</strong></p><p>优化模式对象可以显著提高查询速度。技术包括适当的索引、选择合适的数据类型和正常化数据库。</p><p><strong>评估 5：硬件考虑</strong></p><p>硬件直接影响 MySQL 性能。CPU 速度决定了查询处理的速度，并且更多的内存允许更大的缓冲和缓存区，从而减少磁盘 I/O。更快的磁盘也会降低 I/O 等待时间。要进行优化，可以增加内存、使用更快的磁盘或者分布数据库到多台机器上。</p><p><strong>评估 6：复制和分区</strong></p><p>MySQL 复制是一个过程，其中数据从一个 MySQL 数据库服务器（主服务器）复制到一个或多个 MySQL 数据库服务器（从服务器）。它增加了数据安全性、为高量网站提供了性能并是数据备份的一部分。</p><p>分区是数据库设计技术，用于提高性能、管理性、简化维护和降低存储大量数据的成本。它通过将单张表分割成更小的成员来工作，每个成员可以独立管理和访问。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/mysql-interview9/">https://programmerscareer.com/mysql-interview9/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 面试: 简述 Redis 中跳表的应用以及优缺点</title>
      <link href="/zh-cn/redis-interview1/"/>
      <url>/zh-cn/redis-interview1/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p> 解释跳跃表是什么以及它们通常在哪里被使用。</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：1-1-跳跃表简介"><a href="#主题：1-1-跳跃表简介" class="headerlink" title="主题：1.1 跳跃表简介"></a><strong>主题</strong>：1.1 跳跃表简介</h1><p>跳跃表是一种令人惊叹的数据结构。它们是为简单性和速度而设计的。</p><p>一个<strong>跳跃表</strong>是一种概率性数据结构，允许有效的搜索、插入和删除操作。它与有序链表非常相似，但跳跃表的魅力在于它们如何提高操作的速度。</p><p>跳跃表的主要思想是“跳过”大量元素，而不是遍历链表来找到一个元素。它使用连接以渐进方式的元素分数的链表层次结构。这个分数逐渐减少，这使得我们可以实现有效的搜索操作。</p><p>跳跃表在大数据场景中尤为出色。它的平均情况和最坏情况搜索和插入时间复杂度为O(log n)，这使它非常高效！</p><p>尽管它们可能没有与更常见的数据结构相同的受欢迎程度，但跳跃表具有重要的应用，其中一个应用是在Redis等数据库中使用。下一节课将帮助我们更深入地了解Redis如何利用跳跃表。</p><h1 id="主题：1-2-Redis中的跳跃表"><a href="#主题：1-2-Redis中的跳跃表" class="headerlink" title="主题：1.2 Redis中的跳跃表"></a><strong>主题</strong>：1.2 Redis中的跳跃表</h1><p>Redis，一款著名的开源内存数据结构项目，在其代码库中实现了跳跃表以解决某些用例。其中最令人印象深刻的是有序集合数据类型。</p><p>在Redis中，有序集合是一个元素与“分数”相关联的集合。尽管如何在传统哈希表中实现这一点，但有序集合的强大之处在于它们始终根据这个分数排序。这就是跳跃表发挥作用的地方。</p><p>Redis选择使用哈希表和跳跃表的组合来实现这个有序集合。哈希表允许Redis快速查找集合中的元素，而跳跃表维护元素根据它们的分数排序，从而实现快速检索元素范围、找到元素排名等操作。</p><p>有序集合之间的并集、交集和差集操作也使用跳跃表实现。此外，当Redis需要遍历大型有序集合时，它会使用跳跃表而不是哈希表进行遍历，因为这种方法更有效率。</p><p>跳跃表提供了有效的搜索和插入操作，对Redis的性能要求至关重要。</p><h1 id="主题：1-3-在Redis中跳跃表的应用"><a href="#主题：1-3-在Redis中跳跃表的应用" class="headerlink" title="主题：1.3 在Redis中跳跃表的应用"></a><strong>主题</strong>：1.3 在Redis中跳跃表的应用</h1><p>Redis广泛使用跳跃表，尤其是在有序集合方面。但为什么Redis会选择使用跳跃表，而不是选择其他可以使用的数据结构，例如二叉搜索树或AVL树？有几个原因。</p><p>首先，这与简单性有关。跳跃表更容易实现，并且与平衡树相比，有更少的边界情况。它们不需要在插入和删除操作后重新结构化/重新分配（例如树旋转），使它们成为对性能要求高的数据库Redis非常吸引人的选择。</p><p>由于其设计，跳跃表提供了接近平衡树的性能，而不需要平衡操作。虽然AVL树提供了很好的性能，但平衡操作在大量读写情况下可能成为瓶颈，这种情况在Redis等数据库中非常常见。</p><p>此外，跳跃表支持快速插入、删除和查找操作，只需要几个层次变化，使它们成为有序数据结构的理想选择。</p><p>跳跃表在Redis中的应用不仅仅是有序集合，还涉及到Redis集群特性的内部。在Redis集群中，跳跃表用于处理不同节点上哈希槽的分布。</p><p>这使Redis集群能够快速定位要分布给特定节点的给定数据，从而提高集群中数据操作的效率。</p><p>请记住，每种技术都根据性能、功能、简单性等因素做出决策。Redis使用跳跃表的决策是一个有趣的例子，适合用正确的工具。</p><h1 id="主题：1-4-跳跃表在Redis中的优势"><a href="#主题：1-4-跳跃表在Redis中的优势" class="headerlink" title="主题：1.4 跳跃表在Redis中的优势"></a><strong>主题</strong>：1.4 跳跃表在Redis中的优势</h1><p>在Redis中使用跳跃表带来了几个优势，特别是在处理项目列表时。使用跳跃表在Redis中的关键优势包括：</p><p><strong>1. 高效的搜索操作：</strong>跳跃表具有对数时间复杂度的搜索时间，使其非常有效以搜索元素。而不是按顺序搜索列表中的一个项目，我们可以有效地跳过节点，从而获得更快的搜索时间。这使跳跃表在有序集合中具有显著优势。</p><p><strong>2. 简单的实现：</strong>跳跃表比平衡搜索树更容易实现。例如，一个二叉搜索树需要在每次插入和删除后执行复杂的平衡操作。相比之下，跳跃表以概率维持平衡，因此不需要在每次变异后执行复杂的重新平衡操作。</p><p><strong>3. 快速插入和删除操作：</strong>跳跃表支持快速插入、删除和搜索操作。特别是在Redis中，数据操作非常频繁，这些操作的效率对性能至关重要。</p><p><strong>4. 高效的范围查询：</strong>跳跃表在范围查询方面非常有效，这对有序集合来说是关键的要求。例如，获取范围、找到元素的排名、最近的较低和较高排名项等操作要快得多并更简单。</p><p><strong>5. 动态重新分配：</strong>跳跃表具有一个非常好的特性，即可以动态重新组织自身。当元素添加或删除时，跳跃表可以动态重建它们的层次。</p><p>这些优势对Redis性能的提升至关重要，使其能够有效地处理大量数据集。</p><h1 id="主题：1-5-跳跃表在Redis中的缺点"><a href="#主题：1-5-跳跃表在Redis中的缺点" class="headerlink" title="主题：1.5 跳跃表在Redis中的缺点"></a><strong>主题</strong>：1.5 跳跃表在Redis中的缺点</h1><p>尽管跳跃表为Redis带来了许多好处，但可能出现的一些挑战：</p><p><strong>1. 空间使用：</strong>跳跃表倾向于使用更多空间，因为每个跳跃表节点都维护多个指针，这增加了内存占用。然而，Redis通过限制跳跃表节点可以具有的最大层次数来解决这个问题。</p><p><strong>2. 随机性：</strong>跳跃表的一个特点是其概率性。跳跃表的节点层次在插入时随机选择。虽然这种随机化有好处，但它导致跳跃表结构的不可预测性。</p><p><strong>3. 不适合小数据集：</strong>跳跃表在管理大型、有序数据集时表现出色，因为它们的操作时间复杂度是对数。但对于小数据集，维护跳跃表指针的开销以及增加的空间使用可能不被认可。</p><p><strong>4. 理解难度：</strong>虽然不是直接缺点，但跳跃表的概念可能对不熟悉它的人来说有些吓人。这可能使理解和诊断Redis性能变得复杂。</p><p><strong>5. 缺乏广泛使用：</strong>跳跃表不像哈希表、AVL树或B-树那样广泛使用或研究。这可能导致理解和修改数据结构变得略显困难。</p><p>尽管存在这些挑战，Redis以优雅的方式实现了跳跃表，获得了这些好处而不受重大负面影响。</p><h1 id="主题：1-6-在Redis中跳跃表的回顾和评估"><a href="#主题：1-6-在Redis中跳跃表的回顾和评估" class="headerlink" title="主题：1.6 在Redis中跳跃表的回顾和评估"></a><strong>主题</strong>：1.6 在Redis中跳跃表的回顾和评估</h1><p>让我们对每个部分进行回顾：</p><p><strong>1.1 跳跃表简介：</strong>我们讨论了跳跃表的基本结构和概念，包括它们通常使用的地方以及为什么。</p><p><strong>1.2 跳跃表在Redis中的应用：</strong>我们关注了Redis如何利用跳跃表，尤其是在处理有序集合时。</p><p><strong>1.3 在Redis中跳跃表的应用：</strong>我们深入探讨了在Redis环境中跳跃表的常见用例，从简单的有序集合到Redis集群内部。</p><p><strong>1.4 跳跃表在Redis中的优势：</strong>我们检查了使用跳跃表的主要优势，例如在搜索、插入和删除操作中的效率、实现简单性以及动态重新分配功能。</p><p><strong>1.5 跳跃表在Redis中的缺点：</strong>我们还讨论了它们的缺点，包括额外的空间使用、随机性、复杂性以及这些方面在理解、维护和使用跳跃表在Redis中所带来的挑战。</p><p>为了进一步巩固您的理解，我将为您提供一些简短的评估问题：</p><ol><li>你能解释为什么在Redis中使用跳跃表吗？</li><li>跳跃表如何在Redis中处理有序集合？</li><li>在Redis中实现跳跃表时可能出现的挑战是什么？</li></ol><p><strong>问题：</strong>为什么在Redis中使用跳跃表？<br><strong>答案：</strong> 跳跃表在Redis中使用是因为它们可以维护元素以有效的顺序进行操作，如搜索、插入和删除。这对于操作如获取范围、确定元素的排名、获取较低或较高排名项等操作非常重要。</p><p><strong>问题：</strong>跳跃表如何在Redis中处理有序集合？<br><strong>答案：</strong> 在Redis中，跳跃表处理有序集合的优势在于它们能够有效地执行范围查询，并且能够快速检索元素的排名、最近的较低和较高排名项。这些能够快速插入、删除和搜索元素的能力也在处理有序集合时发挥作用。</p><p><strong>问题：</strong>在Redis中实现跳跃表时可能出现的挑战是什么？<br><strong>答案：</strong> 在实现跳跃表时，可能会遇到以下挑战：每个节点可以维护多个指针，因此空间使用可能会增加。它们的概率性质可能导致跳跃表结构的不可预测性。对于不熟悉它的人来说，它们可能会复杂，而且它们的优势可能在处理小数据集时不被充分利用。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/redis-interview1/">https://programmerscareer.com/redis-interview1/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 面试：如何用Redis实现分布式锁</title>
      <link href="/zh-cn/redis-interview2/"/>
      <url>/zh-cn/redis-interview2/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>深入探讨 Redis 的基本知识，并详细了解其数据类型和发布/订阅功能。</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="1-1-深入了解-Redis"><a href="#1-1-深入了解-Redis" class="headerlink" title="1.1 深入了解 Redis"></a>1.1 <strong>深入了解 Redis</strong></h1><p>Redis（Remote Dictionary Server）是一个开源的内存数据结构存储系统，用作数据库、缓存和消息代理。它具有内置的复制、Lua脚本、LRU淘汰、事务和多种持久化级别。值得注意的是，Redis可以处理多种数据结构，例如字符串、哈希、列表、集合、有序集合（范围查询）、位图等。</p><p>先讨论一下 <strong>Redis 的核心特性</strong>。</p><ol><li><strong>性能</strong>：Redis 将数据库完全存储在内存中，仅在持久化时使用磁盘，这使其处理数据非常快速。</li><li><strong>持久性</strong>：Redis 提供了 RDB（Redis 数据库文件）和 AOF（追加只写文件）两种持久化方式，可以按时间间隔或按每次更改记录进行持久化。</li><li><strong>原子操作</strong>：Redis 的操作，例如 APPEND、INCR、等，是原子的，这意味着它们完全或不执行。这确保了数据的完整性，即使处于并发环境中。</li><li><strong>数据结构</strong>：Redis 不仅仅是一个简单的键值存储，它是一个数据结构服务器，支持字符串、哈希、列表、集合和更多的数据结构。</li><li><strong>发布/订阅功能</strong>：Redis 包含内置的发布/订阅命令，用于消息和队列系统，使用发布/订阅范式。</li><li><strong>脚本</strong>：Redis 允许脚本化在服务器端使用 Lua，将原子命令转换为强大的脚本来处理数据。</li></ol><p>接下来是 <strong>Redis 数据类型</strong>。 Redis 支持多种数据类型：</p><ul><li><strong>字符串</strong>：Redis 中的字符串可以存储任何数据，例如 JPEG 图像或序列化的 Ruby 对象。</li><li><strong>列表</strong>：Redis 中的列表是有序值的序列。思考它像链表。</li><li><strong>集合</strong>：Redis 中的集合是无序集合的字符串，其中添加和删除项目发生在常时间内。集合不能包含重复的成员。</li><li><strong>有序集合</strong>：每个成员在有序集合中都与一个分数相关，用于对集合元素进行排序，从小到大的分数。</li><li><strong>哈希</strong>：它们是键值对的映射，其中键和值都是字符串。</li></ul><p>Redis 的功能和特性使它成为一个多功能的系统，用于缓存、会话缓存、全页缓存、消息队列应用程序、排行榜和计数、实时分析等。</p><h1 id="1-2-了解数据库锁"><a href="#1-2-了解数据库锁" class="headerlink" title="1.2 了解数据库锁"></a>1.2 <strong>了解数据库锁</strong></h1><p>在我们深入了解如何使用 Redis 实现分布式锁之前，了解数据库锁的基本概念是必要的。</p><p>在数据库中，特别是允许并发事务（同时事务）的数据库中，锁是一个关键角色，用于维护数据的一致性并防止数据异常。</p><p>简单地说，<strong>锁</strong> 在数据库的上下文中是数据库为数据分配的标记或标记。这个锁控制数据的访问和修改。</p><p>详细说明：</p><ul><li><strong>共享锁</strong>（S 锁）允许读操作，并且可以读取数据库中的数据，但不能修改它。其他事务可以同时获取共享锁并读取数据，但是不能写入它。因此，共享锁帮助维护数据的一致性，确保数据在读操作期间不会被其他事务更改。</li><li><strong>排他锁</strong>（X 锁）也称为“写锁”。如果一个排他锁被持有，那么不仅可以读取数据，还可以修改它。然而，其他事务不能获取任何锁（共享或排他），即使是在同一数据上。排他锁用于维护数据的完整性，确保数据在被修改时不会被其他事务访问。</li></ul><p>在锁的概念中，处理潜在的 <strong>死锁</strong> 是一个主要挑战。死锁是两个或多个事务处于无限等待状态的状态，其中每个事务都在等待其他事务释放资源。解决死锁涉及其检测和实现方案，例如“等待死”或“被挑战”方案，这是一个更深的主题。</p><h1 id="主题：1-3-分布式锁的需要"><a href="#主题：1-3-分布式锁的需要" class="headerlink" title="主题：1.3 分布式锁的需要"></a><strong>主题：1.3 分布式锁的需要</strong></h1><p>在数据库中，锁已经为多个进程或事务访问和避免冲突访问共享数据提供了一种方法。</p><p>现在，想象一下在分布式系统中的场景。分布式系统是指位于网络上的多个计算机之间通过传递消息来通信和协调操作的系统。</p><p>在这样的环境中，使用常规锁就不足够了。这就是分布式锁的需要。</p><p>分布式锁或全局锁允许多个分布式进程同步其操作，通常用于避免在分布式系统中访问共享资源时的冲突。换句话说，它在网络上的多个节点或系统上工作，并确保在任何时候只有一个客户端可以拥有锁。</p><p>分布式锁的高级使用场景包括：</p><ol><li><strong>微服务架构</strong>，其中多个独立的应用程序在相互通信时，分布式锁可以控制访问共享资源。</li><li><strong>数据复制或分片</strong> 经常需要确保写操作在多个位置或数据库上的一致性。</li><li><strong>分布式事务的协调</strong> 在多个微服务和数据库上。</li><li><strong>解决复杂的真实世界问题</strong>，例如领导选举、任务分发和同步、和确保幂等性在分布式系统中。</li><li><strong>服务发现协议</strong>，其中微服务需要知道其他的存在，需要一个可靠的机制来避免竞争和冲突。这些协议通常使用分布式锁来避免冲突而更新公共注册表。</li></ol><p>这些只是几个例子，并且有许多其他的分布式锁使用场景在分布式系统中。</p><p>请记住，分布式锁并不无挑战——一致性、可用性和网络分区（CAP 定理）都有其部分要满足。但是，随着我们进展，我们将更深入地了解如何使用 Redis 在我们的后续课程中实现分布式锁。</p><h1 id="主题：1-4-使用-Redis-实现分布式锁"><a href="#主题：1-4-使用-Redis-实现分布式锁" class="headerlink" title="主题：1.4 使用 Redis 实现分布式锁"></a><strong>主题：1.4 使用 Redis 实现分布式锁</strong></h1><p>首先，要了解的是分布式锁应该满足以下属性：</p><ul><li>互斥性：任何时候只有一个客户端可以持有锁。</li><li>死锁自由：最终，每个锁请求都应该成功。</li><li>容错性：如果持有锁的客户端崩溃，系统应该恢复。</li></ul><p>Redis 提供了 SETNX、EXPIRE 等命令，可能会创造锁系统。但是，锁的过期和释放的客户端不是持有锁的客户端可能会导致问题。因此，为了解决和克服这些问题，引入了 Salvatore Sanfilippo（Redis 的创造者）所提出的 Redlock（Redis 分布式锁）算法。</p><p>Redlock 算法的工作原理如下：</p><ol><li>当客户端想要获取某些资源的锁时，它生成一个唯一的随机字符串（值）。</li><li>这个客户端试图在所有的 N Redis 主节点上使用 SETNX 命令（如果键不存在）并附加一个时间到生命（TTL）。</li><li>如果客户端在大多数的实例上成功地设置它（&gt; N/2），它认为锁已成功获取。</li><li>如果锁设置失败在大多数的实例上，客户端将尝试从所有的实例中删除键（即使在那些它初次成功地设置的地方），等待一个随机的延迟，然后再次尝试步骤 1-3。</li><li>要释放锁，它只需要发送 DEL 命令来删除键。</li></ol><p>通过这样的方式，您可以创建一个健壮的分布式锁系统。请记住，该算法的成功主要取决于同步的时钟在 Redis 节点上，因为锁的 TTL 值与其关联。</p><h1 id="主题：1-5-Redis-事务"><a href="#主题：1-5-Redis-事务" class="headerlink" title="主题：1.5 Redis 事务"></a><strong>主题：1.5 Redis 事务</strong></h1><p>Redis 事务允许执行一组命令在一个步骤中。首先，所有的命令都会排队，然后使用最后一个命令，所有的命令都会按顺序执行。 Redis 事务使用两个主要命令：<code>MULTI</code> 和 <code>EXEC</code>。</p><p>下面是 Redis 事务的一个例子：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MULTI  </span><br><span class="line">INCR foo  </span><br><span class="line">INCR bar  </span><br><span class="line">EXEC</span><br></pre></td></tr></tbody></table></figure><p>在这个例子中，我们在键 ‘foo’ 和 ‘bar’ 上增加值，并在事务中执行这个增量操作。<code>MULTI</code> 是事务块的开始命令，<code>EXEC</code> 是事务块的结束命令并触发执行。</p><p>Redis 事务具有“所有或者没有”的性质。这意味着如果一个命令失败，所有的命令都会回滚。要注意的是，Redis 命令很少会失败，因为它们在命令的语法检查中总是会先发生，在命令被排队之前。</p><p>从锁的角度来看，要注意的是 Redis 使用了“乐观锁定”——锁不会在事务的执行过程中持有。相反，您可以使用 <code>WATCH</code> 命令在一个或多个键上。如果这些键在事务执行之前被其他客户端修改，则事务会被取消，允许安全地处理竞争条件。</p><p>请记住以下原则：</p><ul><li>Redis 事务是原子的，意味着所有的命令都会执行或者不会执行。</li><li>Redis 使用乐观锁定来处理并发事务。</li></ul><h1 id="主题：1-6-实践案例——在真实世界应用中使用-Redis-分布式锁"><a href="#主题：1-6-实践案例——在真实世界应用中使用-Redis-分布式锁" class="headerlink" title="主题：1.6 实践案例——在真实世界应用中使用 Redis 分布式锁"></a><strong>主题：1.6 实践案例——在真实世界应用中使用 Redis 分布式锁</strong></h1><p>分布式锁在多个系统、进程或线程之间的协调和同步中被广泛使用。下面是一些真实世界的使用案例：</p><ol><li><strong>电子商务平台</strong>：分布式锁的一个常见用例是在线购物平台中的库存管理。当多个用户同时试图购买库存中的最后一件商品时，分布式锁可以用来确保只有一个购买操作成功，防止过售。</li><li><strong>银行系统</strong>：分布式锁可以在金融事务中发挥重要作用。例如，考虑两个操作（借贷）在同时进行时。需要确保这些操作在原子方式下进行，以防止余额不一致。</li><li><strong>在线票务预订</strong>：分布式锁可确保单个座位不会被多个用户在并发预订操作中预订。</li><li><strong>分布式系统的主节点选举</strong>：在分布式系统中，分布式锁可用于处理故障转移，并选择新的主节点当前主节点失败时。</li></ol><p>观察这些使用案例，可以看出分布式锁满足复杂、分布式应用系统中维持数据一致性、完整性和协调之间的优先要求。</p><h1 id="主题：1-7-回顾和评估"><a href="#主题：1-7-回顾和评估" class="headerlink" title="主题：1.7 回顾和评估"></a><strong>主题：1.7 回顾和评估</strong></h1><p>在会话中，我们深入了解了 Redis、其内置支持的分布式锁和其在实际应用中的应用。我们还深入了解了 Redis 事务并获取了有关其参与分布式锁的见解。</p><p>我们已经覆盖了许多主题，例如：</p><ul><li>Redis 深入研究：我们扩展了基本知识，深入研究 Redis 的特性，例如其数据类型和 Pub/Sub 功能。</li><li>数据库锁的理解：我们获取了数据库锁的总体了解，其利用和类型。</li><li>分布式锁的需要：我们看到了分布式锁的需要并了解了它们在大规模应用中的作用。</li><li>使用 Redis 实现分布式锁：我们讨论了如何使用 Redis 实现分布式锁。</li><li>Redis 事务：我们讨论了 Redis 事务、其命令和如何与分布式锁协作。</li><li>Redis 分布式锁的实际应用：我们浏览了各种使用案例场景，其中 Redis 分布式锁已被应用。</li></ul><p><strong>例子问题：</strong> 假设您正在开发一个在线票务预订系统。存在一种情况，多个用户同时预订同一座位。如何使用 Redis 分布式锁来防止这种情况？</p><p>这是我们如何解决这个问题的例子：</p><p>首先，我们将在预订过程开始时为座位实现锁定。这个锁将防止其他用户预订同一座位。</p><p>下面是如何在 Redis 中实现这个：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET lock:seat_id value NX EX 30</span><br></pre></td></tr></tbody></table></figure><p>在这条命令中，<code>lock:seat_id</code> 是锁定标识符（其中 seat_id 是预订座位的 ID），<code>value</code> 是用于识别处理过程的唯一字符串，<code>NX</code> 告诉 Redis 只在键不存在时设置键，并且<code>EX 30</code> 为锁定设置了 30 秒的过期时间。</p><p>命令的返回值将是 <code>OK</code> 或 <code>None</code>。如果返回值是 <code>OK</code>，则表明我们成功获取了锁定。如果它是 <code>None</code>，则表明另一个进程已经获取了锁定。</p><p>现在，测试你的理解。</p><p><strong>简单问题（3/10）：</strong> 为什么在大规模应用中需要分布式锁定系统？</p><p><strong>中等问题（6/10）：</strong> Redis 事务的主要原则是什么？</p><p><strong>复杂问题（9/10）：</strong> 如何解决分布式系统中的故障转移问题，例如，使用 Redis 分布式锁？</p><hr><p><strong>简单问题（3/10）：</strong> 在大规模应用中，我们需要分布式锁定系统来处理并发和保证分布式系统中数据的完整性。例如，如果多个客户同时试图访问和修改同一块数据，分布式锁可帮助确保只有一个客户可以访问和修改该数据，从而防止竞争条件、不一致和其他潜在问题。</p><p><strong>中等问题（6/10）：</strong> Redis 事务的主要原则如下：</p><ol><li>Redis 事务提供了一种执行批量命令的原子方式。</li><li>使用 <code>MULTI</code> 命令开始事务，使用 <code>EXEC</code> 命令执行事务。</li><li>使用 <code>WATCH</code> 命令可以实现乐观锁定。它帮助取消事务，如果监视的键已更改。</li><li>在事务中命令失败时，Redis 仍然执行事务中的其余命令。</li></ol><p><strong>复杂问题（9/10）：</strong> 分布式锁可在分布式系统中处理故障转移时发挥重要作用。在节点故障（其中节点在集群中失败）的情况下，我们必须选择新的主节点。分布式锁可用于确保选举过程无冲突并且只有一个节点被选为新的主节点。我们可以使用前面相似的锁定模式，其中锁表示主节点。谁成功获取了锁就成为新的主节点。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/redis-interview2/">https://programmerscareer.com/redis-interview2/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka interviews: How does Kafka send messages reliably?</title>
      <link href="/kafka-interview1/"/>
      <url>/kafka-interview1/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Have you ever been asked a similar question in an interview? Or you will meet in the future, let’s explore and master it together</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-How-Does-Kafka-Work"><a href="#Topic-1-1-How-Does-Kafka-Work" class="headerlink" title="Topic: 1.1 How Does Kafka Work?"></a><strong>Topic</strong>: 1.1 How Does Kafka Work?</h1><p>Apache Kafka is an open-source stream-processing software platform developed by LinkedIn and later donated to the Apache Software Foundation. The project aims to provide a unified, high-throughput, low-latency platform for handling real-time data feeds. It is written in Scala and Java.</p><p>The Kafka ecosystem consists of producers, brokers, consumers, topics, and Zookeeper:</p><p><strong>Producers</strong>: Producers are components that push raw messages to Kafka brokers. Producers can send messages to a specific topic or allow Kafka to do the routing and load balancing.</p><p><strong>Brokers</strong>:&nbsp;Kafka brokers are the heart of the system;&nbsp;they receive messages from producers, assign offsets to them, and commit the messages to storage on disk.</p><p><strong>Consumers</strong>: Consumers read from brokers. However, unlike traditional messaging systems, consumers pull messages from brokers.</p><p><strong>Topics and Partitions</strong>: Topics are feeds of messages in specific categories. Kafka topics are divided into a number of partitions, which contain records in an unchangeable sequence. Partitions allow you to parallelize topics by splitting the data across multiple nodes.</p><p><strong>Zookeeper</strong>: Zookeeper manages and coordinates the Kafka cluster. ZooKeeper service is used to maintain naming and configuration data and to provide flexible and robust synchronization within distributed systems.</p><p>A simple analogy for the working of Kafka is a messaging system. Think of it like a postman (producer) delivering mail letters (messages) to specific mailboxes (topics). The mail agency (Kafka) sorts out and maintains these letters, and finally, the residents (consumers) pick up their mail from the mailboxes.</p><h1 id="Topic-1-2-Kafka-Producers"><a href="#Topic-1-2-Kafka-Producers" class="headerlink" title="Topic:&nbsp;1.2 Kafka Producers"></a><strong>Topic:</strong>&nbsp;1.2 Kafka Producers</h1><p>Kafka Producers are responsible for publishing or writing data (known as records) to one or more Kafka topics.&nbsp;Producers play a crucial role in feeding Kafka brokers with data.</p><p>Here’s how Kafka Producers work:</p><p><strong>Creating a Producer:</strong>&nbsp;The producers are created with certain properties like the broker’s address, the key serializer, and the value serializer. Brokers use these properties to identify the correct topic and understand how to parse the messages.</p><p><strong>Writing Data:</strong>&nbsp;After creating a producer, it can start sending records to the specified topic. A record in Kafka contains a&nbsp;<strong>key</strong>&nbsp;and a&nbsp;<strong>value</strong>. These are byte arrays. The key, which is optional, is used in determining the specific partition of the topic where the message will be written. If a key isn’t provided, Kafka uses a round-robin method to write to a partition.</p><p><strong>Partitioning:</strong>&nbsp;The producers publish data to different partitions in a round-robin way or a semantically meaningful manner. When the key is null, data is sent round-robin. If a key is present, all messages for that key will go to the same partition (if the number of partitions does not change).</p><p><strong>Serialization:</strong>&nbsp;Kafka messages are byte arrays. Therefore, whatever data format you have, you must convert it to bytes when it’s sent to Kafka. We call this process serialization. Therefore, whenever a producer is sending a record, it needs to convert the objects into bytes.</p><p><strong>Acknowledgements and Retries:</strong>&nbsp;In a distributed system, machines fail. Kafka provides mechanism of acknowledgements and retries. Kafka can be set to acknowledge a write once it has been written to the leader (ack=1), all followers (ack=all), or none at all (ack=0).</p><p>From the producer configurations, it’s clear that we can adjust the reliability and durability guarantees by choosing the number of acknowledgements (acks) and specifying whether the producer should retry sending messages.</p><p>A deep understanding of Kafka Producers is&nbsp;key to leveraging effectively the power of Kafka&nbsp;and to implementing reliable and efficient event-driven systems.</p><h1 id="Topic-1-3-Reliable-Message-Delivery-—-Basics"><a href="#Topic-1-3-Reliable-Message-Delivery-—-Basics" class="headerlink" title="Topic: 1.3 Reliable Message Delivery — Basics"></a><strong>Topic</strong>: 1.3 Reliable Message Delivery — Basics</h1><p>Reliable message delivery is a critical aspect of any message-oriented middleware. Kafka provides strong durability guarantees and fault-tolerance to ensure reliable message delivery.</p><p>The basics of reliable message delivery in Kafka revolve around these main concepts:</p><p><strong>Producers and Message Acknowledgments:</strong>&nbsp;As we’ve learned before, Producers send messages to Kafka brokers. These messages can be acknowledged in different ways, controlled by the&nbsp;<code>acks</code>&nbsp;property of the producers. This level of acknowledgement impacts the durability of the messages. An ack of ‘1’ means that the message is considered written successfully once written to the leader’s log. An ack of ‘all’ means that the message is considered written successfully once all in-sync replicas have applied it to their log.</p><p><strong>Replication and In-sync replicas:</strong>&nbsp;Replication is a key feature in ensuring message durability. Each partition in Kafka has multiple replicas, one of which is elected as the leader. All writes and reads go through the leader. The rest are followers, and their main job is to replicate the leader. Only when a message is written to all in-sync replicas, it is considered committed and hence, successfully written.</p><p><strong>Consumer Offsets and Delivery Semantics:</strong>&nbsp;Consumers read message from Kafka topics at their own pace and keep track of what messages they have read by storing the offset of messages. Kafka provides three delivery semantics: at most once, at least once, and exactly once. By storing and managing offsets properly, Kafka ensures that messages are delivered at least once.</p><p><strong>Committed and Uncommitted Messages:</strong>&nbsp;Messages in Kafka are considered committed once they’re written successfully to the log on all in-sync replicas. Consumers can only consume committed messages. This ensures that consumers always get complete, correct data. Messages can be written to the log but not viewable to consumers until they’re committed, protecting against data inconsistencies and partial data in case of a failure.</p><h1 id="Topic-1-4-Kafka-Brokers-and-Topic-Replication"><a href="#Topic-1-4-Kafka-Brokers-and-Topic-Replication" class="headerlink" title="Topic:&nbsp;1.4 Kafka Brokers and Topic Replication"></a><strong>Topic:</strong>&nbsp;1.4 Kafka Brokers and Topic Replication</h1><p>Kafka Brokers, as we’ve previously learned, are the heart of the system, handling receiving messages from producers, assigning offsets to them, and committing the messages to storage on disk. Now, let’s dig deeper.</p><p>A Kafka cluster is composed of multiple brokers. Each broker can handle data and requests from many clients because topics are partitioned and replicas are distributed across multiple broker instances.</p><p><strong>Topic Replication</strong>: Replication is a crucial feature in Kafka for reliability and fault-tolerance. Each topic can have multiple replicas allowing it to be stored on multiple brokers. This means that even if a broker goes down, the topic data is still available from the other broker holding another replica.</p><p>Replicas of a Kafka topic partition are distributed to different brokers in the cluster. Having replicas makes Kafka fault-tolerant.</p><p><strong>Leader and Follower</strong>:&nbsp;For a partition, one replica will serve as the Leader, and the rest will be Followers. The Leader handles all read and write requests for the partition, while Followers passively replicate the leader. If the Leader fails, one of the Followers will automatically become the new Leader.</p><p><strong>In-Sync Replica(ISR)</strong>: If a follower remains too far behind the leader (configurable by a parameter), the leader will remove the follower from the list of ISR (in-sync replica). Only members in the ISR list can be elected as the leader.</p><p><strong>Replication and Reliability</strong>: The role played by each broker in a partition’s replication is vital for the delivery semantics Kafka provides. Reading and writing to a broker ensures durability of records, and a broker’s failure doesn’t affect data integrity.</p><h1 id="Topic-1-5-Ins-and-Outs-of-Kafka-Consumers"><a href="#Topic-1-5-Ins-and-Outs-of-Kafka-Consumers" class="headerlink" title="Topic: 1.5 Ins and Outs of Kafka Consumers"></a><strong>Topic</strong>: 1.5 Ins and Outs of Kafka Consumers</h1><p>Kafka Consumers are applications that read and process data from Kafka topics. The role and functionality of Kafka consumers is vital in maintaining the reliability and fault tolerance of Kafka as a distributed system.</p><p>Here are some key aspects of Kafka Consumers:</p><p><strong>Consumer Groups:</strong>&nbsp;Multiple consumers can form a ‘Consumer Group’. As a part of the group, they share the load of consuming messages, each consumer reading from one or more partitions of a topic. This provides both load balancing and fault tolerance features to Kafka.</p><p><strong>Consuming Messages:</strong>&nbsp;Consumers read the messages from a topic and process it. They maintain the offset of the next message they expect to read.</p><p><strong>Offsets and Consumer Position:</strong>&nbsp;Each consumer group maintains its offset or position — a record of which messages have been consumed. If a consumer has processed a message successfully, the offset will be advanced. So, even if a consumer crashes, it can pick up where it left off, increasing the system’s fault tolerance and resiliency.</p><p><strong>Rebalancing</strong>: When a consumer stops or a new consumer joins a Kafka consumer group, a rebalancing protocol is initiated. The protocol ensures that consumers leave gracefully if they are planning to stop, while new consumers join smoothly without affecting the message consumption process within the group.</p><p><strong>Delivery Semantics:</strong>&nbsp;based on how the consumers manage the offsets and commits, Kafka provides three semantics for message delivery — at most once, at least once, and exactly once. It’s important to design consumer applications such that they’re capable of handling these semantics accurately and consistently.</p><p>In a Kafka data flow, Consumers play a significant role in driving real-time processing systems. Getting a solid grasp of Kafka Consumers is key to leveraging Kafka’s full potential for building robust and scalable data processing systems.</p><h1 id="Topic-1-6-How-does-Kafka-Send-Messages-Reliably"><a href="#Topic-1-6-How-does-Kafka-Send-Messages-Reliably" class="headerlink" title="Topic: 1.6 How does Kafka Send Messages Reliably?"></a><strong>Topic</strong>: 1.6 How does Kafka Send Messages Reliably?</h1><p>Kafka’s primary responsibility is to reliably transfer records from producers (which write the data) to consumers (which read the data). Here’s a breakdown of how Kafka ensures reliable message delivery:</p><p><strong>Replication and Redundancy</strong>: Kafka ensures message durability through its topic replication feature. A Kafka topic is divided into partitions, and each partition can be replicated across multiple nodes called brokers. This means the same message can live in multiple places, providing a high level of redundancy.</p><p><strong>Leader and Follower</strong>: For every partition of Kafka, the broker can play two types of roles: leader and follower. All read and writes are served by the leader, and followers passively replicate the leader. If a leader fails, a follower can take its place and serve data to consumers,&nbsp;therefore providing business continuity.</p><p><strong>Acknowledgments (ACKs)</strong>: ACKs play a significant role in reliability. When a producer sends a message, it can choose to receive an acknowledgment after the message is written to the leader’s log (acks=1), or after it’s written to all in-sync replicas (acks=all). This choice contributes to a trade-off between performance and resilience.</p><p><strong>In-sync Replicas (ISRs)</strong>: Kafka enforces that only replicas which are in-sync can be elected as leader. An ISR is a replica that has fully caught up with the partition leader, and hasn’t lagged behind the leader’s log for more than a specified time. Ensuring the leader is always from ISR gives Kafka a strong consistency as it guarantees any message that was written to the leader and acknowledged, will not be lost as long as the number of failures is within the replication factor.</p><p><strong>Consumer Offsets</strong>: Kafka consumers maintain their offset (the position from where they have read). Even if a consumer fails, it can resume reading messages from the offset it has kept track of, thereby minimizing data loss.</p><p>In summary, Kafka guarantees the reliable delivery of messages by dividing data across multiple nodes for redundancy, ensuring data persistence through acknowledgments, maintaining ISR list for consistency, and utilizing&nbsp;offsets for effective consumption.</p><h1 id="Topic-1-7-Best-Practices-for-Reliable-Messaging-in-Kafka"><a href="#Topic-1-7-Best-Practices-for-Reliable-Messaging-in-Kafka" class="headerlink" title="Topic: 1.7 Best Practices for Reliable Messaging in Kafka"></a><strong>Topic</strong>: 1.7 Best Practices for Reliable Messaging in Kafka</h1><p>The reliability of a Kafka cluster greatly depends on how well it is managed and the practices in place regarding messaging. Here are some best practices for reliable messaging in Kafka:</p><p><strong>Monitor Your Cluster</strong>: Be sure to keep an eye on your Kafka cluster. This includes tracking things like the number of uncommitted messages, data rate in and out of each broker, topic and partition count, and under-replicated partitions. Monitoring will help you identify potential issues before they become serious.</p><p><strong>Set Appropriate Retention Periods</strong>: Keep in mind that increasing the retention period increases storage and heap use. Balance needs accordingly to avoid resource constraints.</p><p><strong>Sensible Partitioning of Topics</strong>: Choose the number of partitions with thought. While more partitions allow greater parallelism, they also imply more open server connections and greater Zookeeper overhead.</p><p><strong>Reasonable Replication Factors</strong>: Higher replication factor boosts redundancy and thus reliability, but it also increases storage requirements. Choose a replication factor that matches the level of fault tolerance needed.</p><p><strong>Proper Acknowledgement Policies</strong>: Use the correct acknowledgment policy (‘acks’) based on your application requirements. For critical data, consider using ‘acks=all’ to ensure data is replicated to all in-sync replicas before confirmation.</p><p><strong>Effective Use of In-Sync Replicas (ISRs)</strong>: Configure your ISR settings to ensure you have the right balance between latency and durability guarantees. Make sure min.insync.replicas is set as per your needs, so you don’t lose data during failovers.</p><p><strong>Consumer Offset Management</strong>: Make sure consumers commit their offsets regularly. This avoids rebroadcasting massive amounts of data if a failure occurs. But don’t commit too frequently, since each commit is a call to Zookeeper.</p><p>To sum up, achieving reliable messaging with Kafka is crucial, but it requires a balance between operational requirements, resource usage, and application-specific needs.</p><h1 id="Topic-1-8-Kafka’s-Message-Delivery-Semantics"><a href="#Topic-1-8-Kafka’s-Message-Delivery-Semantics" class="headerlink" title="Topic: 1.8 Kafka’s Message Delivery Semantics"></a><strong>Topic</strong>: 1.8 Kafka’s Message Delivery Semantics</h1><p>In Kafka, message delivery semantics govern how messages are delivered from the producer to the consumer. Kafka provides three types of delivery semantics:</p><p><strong>1. At Most Once</strong>: In this case, the messages are delivered to the consumer at most once. This means that messages may be lost, but they are never redelivered or duplicated. This approach is fastest because it involves the least coordination between the producer and Kafka. However, it is not as reliable as other methods because any failure between the time Kafka sends the message and the consumer reads it will result in the loss of that message.</p><p><strong>2. At Least Once</strong>: Messages are delivered at least once to the consumer. But, in certain situations, messages may be redelivered, resulting in duplicates. This method is more reliable than ‘at most once’ because it ensures messages are not lost. However, it has the risk of duplicate messages due to potential redelivery. For idempotent processing, this can be perfectly fine.</p><p><strong>3. Exactly Once</strong>: This&nbsp;ensures that each message is delivered exactly once — no losses, no duplicates. However, it’s the slowest and most resource-intensive option because of the transactions needed to keep track of the progress. This is typically used in critical systems where message loss or duplication can lead to significant issues.</p><p>These delivery semantics determine how resilient and reliable your Kafka-based system will be. The choice between speed, consistency, and reliability is yours to make depending on the use case of your application.</p><h1 id="Topic-1-9-Review-and-Assessments"><a href="#Topic-1-9-Review-and-Assessments" class="headerlink" title="Topic: 1.9 Review and Assessments"></a><strong>Topic</strong>: 1.9 Review and Assessments</h1><p>We’ve covered a great deal in our Kafka curriculum, let’s do a brief round-up of those lessons:</p><ol><li><strong>How Kafka Works</strong>: We learned how various components of Kafka interact with each other to provide a robust, scalable, and fault-tolerant messaging system.</li><li><strong>Kafka Producers</strong>: We delved into how Kafka Producers send messages and explored their crucial configurations.</li><li><strong>Reliable Message Delivery Basics</strong>: We understood the fundamental concepts involved in ensuring message durability and reliability in Kafka.</li><li><strong>Kafka Brokers &amp; Topic Replication</strong>: We dived into the functioning of Kafka Brokers and learned how Topic replication furthers reliability.</li><li><strong>Kafka Consumers</strong>: We navigated the complexities of Kafka Consumers, Consumer groups, and ascertained their role in maintaining reliability.</li><li><strong>How Kafka Sends Messages Reliably</strong>: Unraveled Kafka’s internal mechanisms for ensuring reliable message delivery.</li><li><strong>Best Practices for Reliable Messaging in Kafka</strong>: We have discussed practical ways to optimize Kafka’s message delivery for reliability.</li><li><strong>Kafka’s Message Delivery Semantics</strong>: Finally, we looked at the three types of delivery semantics, their significance, and use cases.</li></ol><p>Now, it’s time to assess your understanding and application of this knowledge. We can proceed with some practice problems and analysis of real-world scenarios where Kafka is extensively used. This will help reinforce what you’ve learned and enable you to better incorporate Kafka into your systems.</p><p>Example Problem: List and explain the three different delivery semantics in Kafka?</p><p><strong>Solution</strong>:</p><ol><li><strong>At Most Once</strong>: Messages are delivered at most once, meaning they could be lost but will not be redelivered resulting in duplicates. This method is the fastest, but is less reliable as messages could be lost.</li><li><strong>At least Once</strong>: Messages are delivered at least once, which means that messages are assured to be delivered, but there’s a possibility of duplicates due to potential redelivery. This method is more reliable, but the duplication could potentially be an issue.</li><li><strong>Exactly Once</strong>: In this case, messages are delivered exactly once, meaning there are no losses or duplicates. This method is the most reliable, but also the slowest because of the overhead of keeping track of the delivery state of each message.</li></ol><p>Are you ready for the test questions? Let’s proceed.</p><h2 id="Question-1"><a href="#Question-1" class="headerlink" title="Question 1"></a>Question 1</h2><p>What is the role of a Kafka Producer in a Kafka cluster?</p><h2 id="Question-2"><a href="#Question-2" class="headerlink" title="Question 2"></a>Question 2</h2><p>Explain the concept of Topic replication in Kafka. Why is it important?</p><h2 id="Question-3"><a href="#Question-3" class="headerlink" title="Question 3"></a>Question 3</h2><p>What are In-Sync Replicas (ISRs) in Kafka?</p><h2 id="Question-4"><a href="#Question-4" class="headerlink" title="Question 4"></a>Question 4</h2><p>Mention some of the best practices for reliable messaging in Kafka.</p><h2 id="Question-5"><a href="#Question-5" class="headerlink" title="Question 5"></a>Question 5</h2><p>How does Kafka ensure reliable message delivery?</p><h2 id="Answer-1"><a href="#Answer-1" class="headerlink" title="Answer 1"></a>Answer 1</h2><p>A Kafka producer’s role in a Kafka cluster is to publish data or messages to one or more Kafka topics. The messages sent by producers are appended to the committed log at the end and are assigned a unique offset number.</p><h2 id="Answer-2"><a href="#Answer-2" class="headerlink" title="Answer 2"></a>Answer 2</h2><p>Topic replication is a feature in Kafka to ensure that messages in the cluster remain available during the unavailability of a broker (due to a failure or being taken down for maintenance). Each topic can be replicated across a configurable number of Kafka brokers to ensure redundancy. This helps in ensuring no message loss and high data availability.</p><h2 id="Answer-3"><a href="#Answer-3" class="headerlink" title="Answer 3"></a>Answer 3</h2><p>In-Sync Replicas (ISRs) are the set of replicas that are up-to-date with the leader replica. Any replica that has not sent a fetch request to the leader for some configurable time is removed from the ISR set. If a follower fails to fetch from the leader, it will be out of ISR and won’t be considered for producing data to clients.</p><h2 id="Answer-4"><a href="#Answer-4" class="headerlink" title="Answer 4"></a>Answer 4</h2><p>Some of the best practices for reliable messaging in Kafka include choosing the right message delivery semantics for your use case, following the principle of least privilege with permissions, using compaction for long-term topics with key-value data, monitoring and setting alerts for critical metrics, keeping your Kafka cluster and client libraries up-to-date, etc.</p><h2 id="Answer-5"><a href="#Answer-5" class="headerlink" title="Answer 5"></a>Answer 5</h2><p>Kafka ensures reliable message delivery through several mechanisms like replication, in-sync replica sets, acknowledgements, and configurable delivery semantics. The producers wait for acknowledgements that a message has been written to the full set of in-sync replicas. If a message fails to be written, the producer will automatically retry. The consumers maintain an offset to track their progress through each topic.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/kafka-interview1/">https://programmerscareer.com/zh-cn/kafka-interview1/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL interviews: Briefly describe the primary and secondary synchronization mechanism of MySQL</title>
      <link href="/mysql-interview1/"/>
      <url>/mysql-interview1/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>let’s structure curriculum on primary/secondary synchronization mechanism in MySQL and understanding what happens if the synchronization fails</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-Introduction-to-Database-Synchronization"><a href="#Topic-1-1-Introduction-to-Database-Synchronization" class="headerlink" title="Topic: 1.1 Introduction to Database Synchronization"></a><strong>Topic</strong>: 1.1 Introduction to Database Synchronization</h1><p>Database synchronization is a critical concept in the world of databases. The complexity of maintaining accurate, consistent data across multiple platforms, databases, or systems has always been a challenge. This is where database synchronization shines.</p><p>When we talk about database synchronization, we’re referring to the process of ensuring that the data in two or more databases is consistent. This usually means that the data in all databases should be the same, reflecting all updates in any of the databases. For example, in a banking system, a customer’s account balance should be the same whether it’s checked online, at an ATM, or at a branch. If the customer makes a withdrawal at a branch, this should be immediately reflected in the balance that’s seen online and at ATMs. This real-time accuracy is achieved through synchronization of the various databases involved.</p><p>Some of the key benefits of synchronization include:</p><ul><li><strong>Data Consistency</strong>: Database synchronization ensures that data remains consistent across all platforms. This is critical in many sectors, like finance and healthcare, where data accuracy is paramount.</li><li><strong>Efficiency</strong>: By ensuring that changes in one database are reflected in all others, synchronization aids in making systems more efficient and data more reliable. Redundancy is reduced, and users always have access to the latest data, no matter where they’re accessing it from.</li><li><strong>Scalability</strong>: As a system grows in size, so does its data. Database synchronization allows for easy scaling of databases as data input increases. Multiple servers can be synced to handle more data, improving the system’s overall performance.</li><li><strong>Backup</strong>: Synchronization can serve as a form of data backup. If one server goes down, the data is not lost because it’s mirrored in a different server. This increases data reliability and system durability.</li></ul><p>In the next part of the curriculum, we’ll take a closer look at the primary and secondary architecture models in database systems, including MySQL. Stay tuned!</p><h1 id="Topic-1-2-Understanding-Primary-Secondary-Architectures"><a href="#Topic-1-2-Understanding-Primary-Secondary-Architectures" class="headerlink" title="Topic: 1.2 Understanding Primary/Secondary Architectures"></a><strong>Topic</strong>: 1.2 Understanding Primary/Secondary Architectures</h1><p>In many database systems, and particularly in MySQL, a popular structure is the&nbsp;<strong>Primary/Secondary Architecture</strong>, also known as the Master/Slave architecture.</p><p>Before we delve into the architecture specifics, let’s briefly discuss what each component represents.</p><ul><li><strong>Primary Database (Master Database)</strong>: This is the original or main database. Any changes or updates made here are also reflected in the secondary database(s). The primary database is typically in read-write mode and is often where most of the application operations take place.</li><li><strong>Secondary Database (Slave Database)</strong>: These are the replicas(s) of the primary database. The secondary database often exists to enhance reliability, data recovery, and load balancing. They replicate the data in the primary database, and while some applications allow two-way synchronization (updates on either database are reflected in the other), many secondary databases are read-only.</li></ul><p>In a MySQL environment, the primary database logs the updates performed on it in a binary log (binlog). This log serves as a written history of all changes and can be used to replicate these changes to the secondary database. Pretty cool, right?</p><p>When an event or a transaction is executed on the primary server, nothing happens immediately on the secondary server. Instead, the event is first written to the binary log on the primary server.</p><p>The secondary server has a component named I/O Thread which connects to the primary server and copies the binary log events to its relay log almost instantly.</p><p>Another component named the SQL thread reads the events from the relay log and applies them to the secondary server. This way, the same events are executed in the same sequence on the secondary server and thus, the data on both servers is consistent.</p><p>This model provides benefits such as backup provision, analytics performance, read scaling, and high availability. However, it requires careful management to ensure data consistency and avoid conflicts.</p><p>In our following lesson modules, we’ll dive deeper into other specifics of this synchronization mechanism and how to handle potential issues efficiently.</p><h1 id="Topic-1-3-Synchronization-Mechanisms-in-MySQL"><a href="#Topic-1-3-Synchronization-Mechanisms-in-MySQL" class="headerlink" title="Topic: 1.3 Synchronization Mechanisms in MySQL"></a><strong>Topic</strong>: 1.3 Synchronization Mechanisms in MySQL</h1><p>MySQL has a rich set of mechanisms to ensure data is kept consistent across different databases. Here are the key elements involved in MySQL synchronization:</p><p><strong>1. Binary Logging:</strong>&nbsp;The binary log records all changes made to the MySQL data. This includes data changes such as table creation operations or changes to table data, as well as how long each statement took that caused a change. This plays a key role in synchronizing the data.</p><p><strong>2. Replication:</strong>&nbsp;Replication is one of the most popular features used in MySQL. It allows data from one MySQL database server (the primary server) to be replicated to one or more MySQL database servers (the secondary servers). Replication is asynchronous by default, which brings a great level of flexibility. But you can also optionally setup semi-synchronous replication.</p><p><strong>3. Global Transaction Identifiers (GTIDs):</strong>&nbsp;GTIDs make tracking transactions much easier. When a transaction occurs, it is given a GTID which is unique across all servers. The primary benefit of GTIDs is to enable much simpler automated failover and increased reliability.</p><p><strong>4. Group Replication:</strong>&nbsp;Group Replication enhances MySQL replication. It provides built-in detection of servers that crash or become unreachable and can reconfigure the group, primary elections and automatic distributed recovery from other group members so business operations don’t have to be halted.</p><p><strong>5. InnoDB ReplicaSet:</strong>&nbsp;For smaller scale setups that do not require highly available systems, a lighter method for failover management called InnoDB ReplicaSet can be deployed. It provides easy to use command-line tools to set up and administer smaller scale replicasets.</p><p><strong>6. Semisync Replication:</strong>&nbsp;Semisync replication provides an option for a commit to return successfully to a client only if the data to be replicated was sent to another replica. Semisync replication can be used to prevent data loss due to a lost or crashed primary by blocking transactions until a replica acknowledges that it has written the events to its replica log. Thus, we can say SemiSynchronous Replication is a compromise between the high durability of synchronous replication and the low latency of asynchronous replication.</p><p>MySQL achieves data consistency with these synchronization mechanisms. These mechanisms ensure the replicas receive updates made on the primary, resulting in data harmony across prospective data-crunching pipelines.</p><p>Up next, we’ll delve into the consequences of synchronization failure and how to detect and mitigate these occurrences.</p><h1 id="Topic-1-4-Consequences-of-Synchronization-Failure"><a href="#Topic-1-4-Consequences-of-Synchronization-Failure" class="headerlink" title="Topic: 1.4 Consequences of Synchronization Failure"></a><strong>Topic</strong>: 1.4 Consequences of Synchronization Failure</h1><p>In any system where synchronization is vital, such as in a Primary/Secondary setup in MySQL, failure of this synchronization can lead to various issues. Here are some potential consequences of synchronization failure:</p><p><strong>1. Data Inconsistency</strong>: This is one of the most immediate and visible impacts of a synchronization failure. In a banking application, for example, you might end up with different account balance values in different databases, which could lead to major financial implications.</p><p><strong>2. Service Interruptions</strong>: If servers are not properly synchronized, services relying on the database could face performance issues or even complete failure. This can disrupt the availability of applications and can lead to a poor user experience.</p><p><strong>3. Data Corruption</strong>: In worst-case scenarios, synchronization failure could even lead to data corruption. This happens if, for instance, two users simultaneously modify the same data but those modifications are not synchronized properly.</p><p>Understanding the symptoms of synchronization failure is as important as understanding its consequences. Symptoms can include an increase in the number of errors or exceptions in your logs, a sudden drop in performance, or inconsistencies in your data when comparing between the primary and secondary databases.</p><p>Mitigation strategies usually start with detecting the failure through regular checks of the database health or configuring alerts for specific error codes related to replication failure. Once detected, quick response is required to diagnose the cause of the issue and taking corrective actions.</p><p>The nature of those corrective actions will depend on the specific issue and the configuration of the database and could range from a simple database restart to a more drastic full data resync or even failover to a different server.</p><p>Now, we know that preventing problems is better than fixing them. This takes us to our next topic, which is about best practices to prevent synchronization failures from happening in the first place.</p><h1 id="Topic-1-5-Preventing-Synchronization-Failures"><a href="#Topic-1-5-Preventing-Synchronization-Failures" class="headerlink" title="Topic: 1.5 Preventing Synchronization Failures"></a><strong>Topic</strong>: 1.5 Preventing Synchronization Failures</h1><p>Preventing synchronization failures in MySQL databases involves careful planning, monitoring, and application of best practices to ensure consistency of your data. Here are some vital steps to achieve this:</p><p><strong>1. Regular Monitoring:</strong>&nbsp;Regularly monitor your database health and performance. This includes monitoring the status of your replication, checking the status and error logs, and setting up alerts for various replication events.</p><p><strong>2. Use Reliable Networks:</strong>&nbsp;Network failures can cause major synchronization issues. Therefore, ensure that your primary and secondary servers are connected via a reliable network. Consider using redundant network paths for increased availability.</p><p><strong>3. Thorough Error Handling in Applications:</strong>&nbsp;Your application should also be well-equipped to handle errors, including those from the database. Thorough error handling can prevent instances of synchronization failures due to application errors.</p><p><strong>4. Use GTIDs:</strong>&nbsp;As we discussed earlier, Global Transaction Identifiers (GTIDs) can be very handy in preventing synchronization failures as they provide a consistent way to track each replication event across all servers.</p><p><strong>5. Regular Backups:</strong>&nbsp;Regularly back up your database. Backups are your last line of defence in case of catastrophic failures. Also, validate your backups by restoring them in a separate environment to make sure they’re good.</p><p><strong>6. Test Failover Scenarios:</strong>&nbsp;Regularly test your failover scenarios under controlled conditions to understand what the potential issues can be during actual failover scenarios. This helps in minimizing the RTO (Recovery Time Objective) when an actual outage happens.</p><p><strong>7. Use Semisynchronous Replication:</strong>&nbsp;As we’ve discussed in the previous lessons, semisynchronous replication can also help prevent “commit succeed inconsistencies”. In this approach, the primary server waits until at least one secondary server has received and logged the changes to its relay log.</p><p><strong>8. Keep Binlogs Until All Replicas Have processed Them:</strong>&nbsp;This can prevent issues where a primary crashes and a backup primary is then promoted which is at an earlier point in the replication stream.</p><p>By applying these strategies, you can drastically reduce the chances of encountering synchronization failures in your MySQL environment.</p><p>We’ll proceed to real-world scenarios in our next topic to bridge the gap between theory and practice.</p><h1 id="Topic-1-6-Synchronization-Failures-Case-Study"><a href="#Topic-1-6-Synchronization-Failures-Case-Study" class="headerlink" title="Topic:&nbsp;1.6 Synchronization Failures Case Study"></a><strong>Topic:</strong>&nbsp;1.6 Synchronization Failures Case Study</h1><p>To better understand how synchronization failures occur in real world scenarios, let’s use a hypothetical case reflective of problems that may be faced in practice:</p><p>Let’s assume we have a tech startup with a mobile app that has a rapidly growing user base. The company uses a primary-secondary MySQL setup to manage its user data. One day, they released a new feature that led to a surge in database writes due to increased user operations.</p><p>Although this was a happy problem given the app’s success, it led to an unexpected issue: the secondary server began lagging behind the primary. As user operations increased, delays in the secondary server’s processing of the binary logs from the primary led to this lag. This is termed as replication lag.</p><p>This is a common issue in synchronized MySQL setups. In this scenario, the failure wasn’t a sudden crash but a growing lag, which is often harder to detect immediately. Users began to notice inconsistencies in their app experience. For example, a user might delete a post but still see it in their feed because read operations directed at the delayed secondary server still found the post there.</p><p>The company eventually detected the issue through their monitoring systems noticing an increasing replication lag and took immediate action. Their response involved:</p><ul><li><strong>Scaling their database setup</strong>: They added more secondary servers and optimized their distribution of read operations among these servers to handle the load better.</li><li><strong>Buffering writes</strong>: They implemented a queue system for non-critical write operations, thus reducing immediate load on the database.</li><li><strong>Optimizing their app operations</strong>: They found that many concurrent read and write operations were not necessary and reworked their app logic to reduce these.</li></ul><p>Through this situation, the company learned the hard way about the importance of actively monitoring the health of their database setup, anticipating scaling requirements, and optimizing app operations to reduce unnecessary database loads.</p><p>The issues faced in this scenario and the steps taken to rectify them are typical to many real-world applications. From this case study, we see the importance of the preventive and mitigative measures we talked about in the previous lessons.</p><p>In our next session, we will revisit and review the key concepts we have learned in our lessons, reinforce them with some practical assignments, and evaluate your understanding with some assessments.</p><h1 id="Topic-1-7-Review-and-Assessments"><a href="#Topic-1-7-Review-and-Assessments" class="headerlink" title="Topic: 1.7 Review and Assessments"></a><strong>Topic</strong>: 1.7 Review and Assessments</h1><h2 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h2><p>Let’s recap the key concepts we’ve covered throughout this course:</p><ol><li>Database Synchronization: We started by understanding the need for database synchronization, its benefits, and potential challenges. This concept is crucial for maintaining data consistency across multiple database instances.</li><li>Primary/Secondary Architectures: We explored the commonly used primary/secondary architecture in MySQL. This setup allows data to be replicated from a primary server to one or more secondary servers.</li><li>Synchronization Mechanisms in MySQL: We dived into the mechanisms used by MySQL to achieve synchronization, including binary logging and replication.</li><li>Consequences of Synchronization Failure: We discussed the potential impacts of synchronization failure, from data inconsistency to service interruptions and even data corruption.</li><li>Preventing Synchronization Failures: We learned about various strategies and best practices to prevent these failures, like regular monitoring, GTIDs, and reliable network connections.</li><li>Synchronization Failures Case Study: We studied a real-world scenario to understand how such failures can occur and the steps to handle them.</li></ol><h2 id="Assessments"><a href="#Assessments" class="headerlink" title="Assessments"></a>Assessments</h2><p>Now, let’s test your understanding with some questions:</p><ol><li>Why is synchronization necessary in a database system? And specifically, in a primary/secondary set up?</li><li>What are the key mechanisms MySQL uses to achieve synchronization?</li><li>What could be the potential consequences of a synchronization failure?</li><li>Describe some strategies to prevent synchronization failures in MySQL databases.</li><li>In the case study we discussed, how did the company detect the issue? And what were their responses to handle the situation?</li></ol><p>Please, take your time to answer these questions. Your understanding of these concepts is more important than speed.</p><hr><p><strong>1. Why is synchronization necessary in a database system? And specifically, in a primary/secondary set up?</strong></p><p>Synchronization is essential in a database system to ensure data consistency across multiple database instances. In a primary/secondary setup, it allows data to be replicated from a primary server to one or more secondary servers to enhance performance and deliver reliable, redundant data storage.</p><p><strong>2. What are the key mechanisms MySQL uses to achieve synchronization?</strong></p><p>MySQL achieves synchronization through binary logging and related replication techniques. The primary server produces a binary log of all data changes. Secondary servers fetch this log and apply the changes, thus achieving synchronization with the primary server.</p><p><strong>3. What could be the potential consequences of a synchronization failure?</strong></p><p>The consequences could include data inconsistency across servers, service interruptions, and in severe cases, data corruption. This could lead to a unreliable system, and negatively impact users’ experience.</p><p><strong>4. Describe some strategies to prevent synchronization failures in MySQL databases.</strong></p><p>Preventive strategies include regular monitoring of database health and performance, using reliable network connections, thorough error handling in applications, employing Global Transaction Identifiers (GTIDs), conducting regular backups, testing failover scenarios, semisynchronous replication, and making sure to keep binary logs until all replicas have processed them.</p><p><strong>5. In the case study we discussed, how did the company detect the issue? And what were their responses to handle the situation?</strong></p><p>The company detected the issue through their monitoring systems noticing an increasing replication lag. Their response involved scaling their database setup by adding more secondary servers, implementing a queue system for buffering writes and reducing immediate load on the database, and optimizing their app operations to reduce unnecessary database loads.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview1/">https://programmerscareer.com/zh-cn/mysql-interview1/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL interviews: Briefly describe gap locks in MySQL</title>
      <link href="/mysql-interview10/"/>
      <url>/mysql-interview10/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Have you ever been asked a similar question in an interview? Or you will meet in the future, let’s explore and master it together</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-Deep-Dive-into-MySQL"><a href="#Topic-Deep-Dive-into-MySQL" class="headerlink" title="Topic: Deep Dive into MySQL"></a><strong>Topic</strong>: Deep Dive into MySQL</h1><p>MySQL is a widely used, open-source Relational Database Management System (RDBMS). It uses a relational database and SQL (Structured Query Language) to manage its data. The “My” in MySQL is named after co-founder Michael Widenius’s daughter, My.</p><p>MySQL database is a stable, reliable and powerful solution with advanced features like:</p><ul><li>Robust Transactional Support</li><li>Replication &amp; Failover Cluster Support</li><li>Workflow Control &amp; Scheduled Job</li><li>Query Caching</li><li>Advanced Replication Technology</li></ul><p>That makes MySQL an excellent choice for applications that demand complete data protection and real-time analytics like financial, banking, e-commerce, CRM, ERP applications and many more.</p><p>Next, let’s start understanding databases from a theoretical perspective. For the sake of simplicity, let’s imagine a database as a big, digital filing cabinet full of file folders. The file folders represent tables. Within each table is the real data, represented as records. Each record includes information about a single entity.</p><p>For example, if you own a business, you might have a database with a table for Customers, another for Order, and so on. Each row in the Customers table would represent a single customer, and each row in the Orders table would represent a single order.</p><h1 id="Topic-Exploring-MySQL-Transactions"><a href="#Topic-Exploring-MySQL-Transactions" class="headerlink" title="Topic: Exploring MySQL Transactions"></a><strong>Topic</strong>: Exploring MySQL Transactions</h1><p>Transactions are a fundamental concept of all database systems. A transaction in MySQL is a group of SQL statements that are executed as if they were one single unit. A transaction follows the ACID model which stands for Atomicity, Consistency, Isolation, and Durability. This model ensures the reliability of database transactions.</p><p>For example, if you’re transferring money from one bank account to another, it involves several operations such as debiting money from one account and crediting that money to another. Here, transactions make sure these operations (credit and debit) happen entirely or not at all. If one operation fails, the whole transaction fails, ensuring data integrity.</p><p>Our next step is to learn about locking mechanisms in MySQL, which are closely related to transactions. In the context of databases, a lock is a flag associated with a record. This flag can regulate whether the record can be read from or written to.</p><p>It is locking that allows many users to access the database at the same time without conflict. When a record or a table is locked, it means some transaction is accessing the data and should not be interrupted.</p><h1 id="Topic-Introduction-to-Locking-in-MySQL"><a href="#Topic-Introduction-to-Locking-in-MySQL" class="headerlink" title="Topic: Introduction to Locking in MySQL"></a><strong>Topic</strong>: Introduction to Locking in MySQL</h1><p>In the realm of databases, “Locking” is an essential feature that ensures consistency and order in concurrent data access. In MySQL, the InnoDB storage engine supports several types of locks at different levels to make sure transactions do not interfere with each other in an undesired manner.</p><p>Locking is particularly crucial when there are several transactions trying to access and manipulate the same piece of data. When we say a transaction “locks” a piece of data, it prevents other transactions from making conflicting changes to that data until the lock is released.</p><p>There are two primary types of locks:</p><ol><li><strong>Shared Locks (S)</strong>: This is a read-only lock. More than one shared lock can be held for a particular piece of data as long as there’s no exclusive lock.</li><li><strong>Exclusive Locks (X)</strong>: An exclusive lock is a write lock. When a transaction holds an exclusive lock on data, no other transaction can read or write the data until the lock is released.</li></ol><p>Locking in MySQL can take place at three levels:</p><ul><li><strong>Row-level locks</strong>: These locks are placed on rows of data. This is the finest level of locking granularity and allows the highest degree of concurrency.</li><li><strong>Page-level locks</strong>: These locks are placed on blocks of rows called “pages”. Page-level locks are less fine-granular than row-level locks and offer a medium degree of concurrency.</li><li><strong>Table-level locks</strong>: These locks are placed on an entire table. This is the coarsest level of locking, and it offers the lowest degree of concurrency. You typically want to avoid table-level locks in high transaction environments because they can become a bottleneck.</li></ul><p>Once we understand these basic locking concepts, we can dig deeper into some advanced types of locks in MySQL, including gap locks.</p><h1 id="Topic-Row-Locks-and-Table-Locks-in-MySQL"><a href="#Topic-Row-Locks-and-Table-Locks-in-MySQL" class="headerlink" title="Topic: Row Locks and Table Locks in MySQL"></a><strong>Topic</strong>: Row Locks and Table Locks in MySQL</h1><p>To ensure data integrity while allowing for maximum concurrency, MySQL employs two types of locks: row-level locks and table-level locks. Each of these has its own place and purpose.</p><p><strong>Row-Level Locks</strong></p><p>Row-level locking is more granular and is used when a specific row of the table is being updated. This means that only the rows involved in an operation are locked and not the entire table. This allows for a higher degree of concurrency, where multiple transactions can access different rows from the same table simultaneously.</p><p>InnoDB supports row-level locking. It sets locks automatically during read and write operations but it doesn’t lock the entire table.</p><p><strong>Example</strong>: If you’re updating a specific record in an Employee Table, such a locking mechanism would only block transactions trying to modify that particular Employee record. However, tasks that involve other Employee records can proceed unhindered.</p><p><strong>Table-Level Locks</strong></p><p>Table-level locking is less granular. It locks the entire table during a particular database operation. Most often MySQL applies such locks during write operations.</p><p>Whilst this locking method allows for simple management and less memory use, the level of concurrency is low when compared to row-level locks. Thus, table-level locks can be inefficient for high concurrency use cases, where many transactions need to access the same table simultaneously.</p><p>By understanding the inner workings of these two types of locks, you are one step closer to mastering database manipulation with MySQL. Having this knowledge will also help when we delve into more complex topics like gap locks.</p><h1 id="Topic-Discussing-Gap-Locks-in-MySQL"><a href="#Topic-Discussing-Gap-Locks-in-MySQL" class="headerlink" title="Topic: Discussing Gap Locks in MySQL"></a><strong>Topic</strong>: Discussing Gap Locks in MySQL</h1><p>Gap locking is a crucial MySQL mechanism used to prevent phantom rows. A phantom row is a row that matches a query’s WHERE clause; however, it is not initially seen or changed by the transaction.</p><p>Let’s imagine a situation where we have a transaction that selects rows in a specific range with the intention of later updating those rows. During this operation, another transaction inserts a new row into that range, creating what we refer to as a “phantom” row. Without gap locks, the first transaction won’t be aware of the new row added by the second one and may lead to data inconsistency.</p><p>This is where gap locks prove beneficial!</p><p>A gap lock is a lock on a gap between index records. More explicitly, it’s a lock on the range of index records. Gap locks in MySQL prevent other transactions from inserting new rows into the gap locked by a transaction providing repeatable reads.</p><p>Suppose you have an index on a column and you run the following statement in a REPEATABLE READ isolation level:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM table_name WHERE index_column &gt; 100 FOR UPDATE;</span><br></pre></td></tr></tbody></table></figure><p>MySQL will put a next-key lock on all index records where&nbsp;<code>index_column</code>&nbsp;is greater than 100 and a gap lock on the gap following those index records.</p><p>Remember, though, that gap locks are a double-edged sword! While they can ensure consistency, they might also introduce lock waits or even deadlocks if not managed properly.</p><h1 id="Topic-Example-Scenarios-for-Gap-Locks"><a href="#Topic-Example-Scenarios-for-Gap-Locks" class="headerlink" title="Topic: Example Scenarios for Gap Locks"></a><strong>Topic</strong>: Example Scenarios for Gap Locks</h1><p>To understand gap locks better, let’s go with an example scenario. Assume we have a table&nbsp;<code>orders</code>&nbsp;and it has a bunch of rows.</p><p>Scenario 1:<br>For instance, let’s consider the following SQL statement,</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM orders WHERE id &gt; 3 FOR UPDATE;</span><br></pre></td></tr></tbody></table></figure><p>With this query in a transaction, MySQL will put an exclusive next-key lock on all records where id &gt; 3. That implies that no other transaction can insert any new records with the id value &gt; 3 into the&nbsp;<code>orders</code>&nbsp;table till the first transaction is completed.</p><p>Scenario 2:<br>Now let’s consider another SQL statement,</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO orders (id, item) VALUES (102, 'New_Item');</span><br></pre></td></tr></tbody></table></figure><p>If we try to execute this statement while the earlier transaction (with the SELECT … FOR UPDATE statement) is still active, it will have to wait till the first transaction is completed. This is because of the gap lock applied by the first transaction, which doesn’t allow any new records with id &gt; 3.</p><p>These example scenarios illustrate how gap locks control the concurrent transactions, ensuring consistent data state and eliminating phantom reads under certain transaction isolation levels like REPEATABLE READ or SERIALIZABLE.</p><p>With this understanding, we can now move forward to more intricate details about traversing the Locking Labyrinth in MySQL.</p><h1 id="Topic-Traversing-the-Locking-Labyrinth"><a href="#Topic-Traversing-the-Locking-Labyrinth" class="headerlink" title="Topic: Traversing the Locking Labyrinth"></a><strong>Topic</strong>: Traversing the Locking Labyrinth</h1><p>Locks in MySQL form an intricate labyrinth where each lock plays an essential role, but it could cause confusion, delay, or even deadlocks if not handled properly.</p><p>Here’s a simplified view on how the main types of locks interact with each other:</p><ol><li><strong>Shared Locks and Exclusive Locks</strong>:</li></ol><ul><li>A shared lock allows other transactions to read (shared lock) the locked object but not to write (exclusive lock) it.</li><li>An exclusive lock prevents other transactions from reading/writing the locked object.</li><li>Additional shared locks can be applied to an object that’s already been shared-locked, but requests for exclusive locks will wait.</li></ul><ol><li><strong>Table Locks and Row Locks</strong>:</li></ol><ul><li>Table locks are straightforward but offer less specificity, leading to higher chances of transaction delay.</li><li>Row locks provide higher concurrency as they only lock specific rows in a table.</li></ul><ol><li><strong>Gap Locks and Next-Key Locks</strong>:</li></ol><ul><li>Gap locks prohibit insertion into a specific range of index records. They team up with row locks (or next-key locks) to prevent phantom reads in REPEATABLE READ or SERIALIZABLE isolation levels.</li></ul><ol><li><strong>Intent Locks</strong>:</li></ol><ul><li>Intent locks indicate the kind of lock a transaction intends to acquire (shared or exclusive) before it actually obtains it. They are a notification mechanism, not a control mechanism.</li></ul><ol><li><strong>Auto-Increment Lock</strong>:</li></ol><ul><li>Auto-increment locks are used to maintain the sequence of auto-increment values. They avoid conflicts when multiple transactions attempt to insert into an auto-increment column simultaneously.</li></ul><p>Navigating this labyrinth successfully requires a clear understanding of each lock type and how transactions connect and affect each other.</p><h1 id="Topic-Review-and-Assessments"><a href="#Topic-Review-and-Assessments" class="headerlink" title="Topic: Review and Assessments"></a><strong>Topic</strong>: Review and Assessments</h1><p>Over the past lessons, we’ve covered a lot of ground on MySQL and its locking mechanisms. Let’s briefly revisit these concepts to ensure a solid understanding:</p><ol><li><strong>Deep Dive into MySQL</strong>: We started by getting to know MySQL’s interface, commands, and how it differs from other SQL implementations, setting a strong foundation for the learning process that followed.</li><li><strong>Exploring MySQL Transactions</strong>: We delved into the core concept of transactions in MySQL, discussing its consistency and isolation levels, which ensures data accuracy and concurrency.</li><li><strong>Introduction to Locking in MySQL</strong>: We introduced the concept of locking in MySQL, which is crucial in maintaining data integrity and concurrency control.</li><li><strong>Row Locks and Table Locks</strong>: We explored row-level locks and table-level locks and their significance in MySQL in managing concurrent transactions.</li><li><strong>Discussing Gap Locks in MySQL</strong>: We took a deep dive into gap locks, including what they are, how they work, and their importance in preventing phantom reads.</li><li><strong>Example Scenarios for Gap Locks</strong>: We walked through common scenarios where gap locks are beneficial to understand their practical implementation.</li><li><strong>Traversing the Locking Labyrinth</strong>: We discussed the interaction and influence among the various types of locks in MySQL, a complex but interesting topic.</li></ol><h2 id="Example-Problem"><a href="#Example-Problem" class="headerlink" title="Example Problem:"></a>Example Problem:</h2><p>Consider a scenario where you have a high traffic database and you constantly find yourself running into deadlocks. Your task is to identify a plausible solution to minimize these occurrences.</p><p><strong>Solution</strong>: Potential solutions could be reducing transaction time, ensuring transactions access tables in the same order, or even increasing the innodb_lock_wait_timeout value. Also, making sure that the most precise locks are used can help reduce the chances of encountering deadlocks.</p><h2 id="Simple-Problem"><a href="#Simple-Problem" class="headerlink" title="Simple Problem:"></a>Simple Problem:</h2><p>Consider a transaction that reads and writes several records in a table. What type of lock (row-level, table-level, or gap lock) would you use to ensure minimal blocking in a database with high traffic, with the condition that phantom reads should be avoided?</p><h2 id="Advanced-Problem"><a href="#Advanced-Problem" class="headerlink" title="Advanced Problem:"></a>Advanced Problem:</h2><p>In a ticket booking system, there can be concurrent transactions trying to book the same seat at the same time. How would you handle this situation using MySQL’s locking mechanisms to ensure a fair system?</p><h2 id="Expert-Problem"><a href="#Expert-Problem" class="headerlink" title="Expert Problem:"></a>Expert Problem:</h2><p>In the context of MySQL, how might you deal with a deadlock scenario in a banking application where two transactions attempt to transfer money between two accounts concurrently?  </p><hr><p><strong>Simple Problem Solution</strong>:<br>For this scenario, using a row-level lock mechanism would be the most efficient. It will provide the necessary locking to ensure data integrity while avoiding unnecessary blocking of unrelated rows in high traffic situations. Furthermore, including the “FOR UPDATE” clause in the SELECT statement could avoid phantom reads.</p><p><strong>Advanced Problem Solution</strong>:<br>In a ticket booking system, to ensure a fair system, we can use the SELECT FOR UPDATE command. This will place exclusive nex-key locks on all index records the search encounters, thus preventing other transactions from inserting a new row in the gap covered by the record locks. It will also select the seat’s current status, and if it’s available, the transaction will update it as booked, ensuring that the seat can’t be double-booked.</p><p><strong>Expert Problem Solution</strong>:<br>In a banking application where two transactions are concurrently attempting to transfer money, we may run into a deadlock scenario. To handle this situation, we could use a fixed order in accessing the accounts. For instance, transactions could access the account with the lower ID first. This will prevent a deadlock as both transactions won’t wait for each other indefinitely, eliminating the circular wait condition for deadlock.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview10/">https://programmerscareer.com/zh-cn/mysql-interview10/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL interviews: What is the difference between a unique index and a normal index? What are the advantages and disadvantages of using indexes?</title>
      <link href="/mysql-interview11/"/>
      <url>/mysql-interview11/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Let’s dive into the review and assessment of understanding “Unique Index” and “Normal Index” in MySQL.  </p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-Understanding-Indexes-in-MySQL"><a href="#Topic-Understanding-Indexes-in-MySQL" class="headerlink" title="Topic: Understanding Indexes in MySQL"></a><strong>Topic</strong>: Understanding Indexes in MySQL</h1><p>In any relational database management system like MySQL, efficient access to data is one of the key aspects, especially when dealing with large amounts of data. The efficiency we’re concerned about is the speed and ease with which our system can locate and retrieve the data we need. This is where&nbsp;<strong>Indexes</strong>&nbsp;come into play.</p><p>You can think of an index as if it were an index at the back of a book. Suppose you wanted to look up a specific topic in a book. You have two choices:</p><ol><li>You could scan through each page until you find the topic.</li><li>You could go to the index, find the page number of the topic, and then flip directly to that page.</li></ol><p>The second method is faster, isn’t it? In the database world, scanning through all the data is called a&nbsp;<strong>full table scan</strong>. If you have millions of rows, this can take a very long time. But if you have an index, MySQL can use it to locate the data much more quickly — just like you used the book’s index to find your topic.</p><p>An index creates an entry for each value and thus it will be much quicker to retrieve data. Keep in mind, however, that while indexes speed up querying, they can slow down the speed of writing operations (INSERT, UPDATE, DELETE) because each time we write, we need to update the index as well. Therefore, we need to maintain a balance and only use indexing on columns that will be frequently searched against.</p><h1 id="Topic-Normal-Indexes-in-MySQL"><a href="#Topic-Normal-Indexes-in-MySQL" class="headerlink" title="Topic: Normal Indexes in MySQL"></a><strong>Topic</strong>: Normal Indexes in MySQL</h1><p>Now that we have a good understanding of what an index is and the role it plays in MySQL, let’s delve into one specific type of index, which is a&nbsp;<strong>Normal Index</strong>.</p><p>A Normal Index, also known as a Non-unique Index, allows you to speed up the query process by creating an index on one or more columns of your database table. Unlike a Unique Index, a Normal Index does not impose any constraints on the values you can have in the column. In other words, a Normal Index allows duplicated values in the column(s) it is indexed on.</p><p>To illustrate, let’s say we have a&nbsp;<code>Students</code>&nbsp;table that has columns&nbsp;<code>ID, Name, Age, and Address</code>. While querying data, we often use the&nbsp;<code>WHERE</code>&nbsp;clause to filter data. For example:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`SELECT * FROM Students WHERE Age = 20`</span><br></pre></td></tr></tbody></table></figure><p>Without an index, MySQL would have to go through every row in the&nbsp;<code>Students</code>&nbsp;table to find the ones where&nbsp;<code>Age</code>&nbsp;is equal to 20. This can be time-consuming and inefficient. If we create a Normal Index on the&nbsp;<code>Age</code>&nbsp;column, MySQL can use this index to quickly locate the relevant rows.</p><p>Creating a Normal Index in MySQL is pretty straightforward, you use the&nbsp;<code>CREATE INDEX</code>&nbsp;command, followed by the name you want to give to the index, and the table and column you want to create it on.</p><p>Here’s an example of how you’d create an index on the&nbsp;<code>Age</code>&nbsp;column in the&nbsp;<code>Students</code>&nbsp;table:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX age_index ON Students (Age);</span><br></pre></td></tr></tbody></table></figure><p>Remember, while Normal Indexes can undeniably speed up read operations, they also take up storage space and can slow down write operations (INSERT, UPDATE, DELETE) as they need to be updated each time a write operation occurs. Therefore, they should be used thoughtfully and strategically.</p><h1 id="Topic-Unique-Indexes-in-MySQL"><a href="#Topic-Unique-Indexes-in-MySQL" class="headerlink" title="Topic: Unique Indexes in MySQL"></a><strong>Topic</strong>: Unique Indexes in MySQL</h1><p>Now that we have a solid grasp on Normal Indexes, it’s time to discuss&nbsp;<strong>Unique Indexes</strong>&nbsp;in MySQL.</p><p>A Unique Index is a type of index that enforces a constraint that all values in the index must be different. This means, a Unique Index doesn’t allow duplicate values in the column (or combination of columns) it is indexed on, making it useful when you want to prevent duplication in certain fields.</p><p>For example, consider a Users table in a database where every user is supposed to have a unique email address. In such a scenario, a Unique Index on the email column would ensure that two users cannot have the same email.</p><p>The syntax to create a Unique Index is just slightly different than a Normal Index:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE UNIQUE INDEX index_name ON table_name (column_name);</span><br></pre></td></tr></tbody></table></figure><p>You can replace&nbsp;<code>index_name</code>&nbsp;with the name you want to give to the index,&nbsp;<code>table_name</code>&nbsp;with the name of the table in which you want to create the index, and&nbsp;<code>column_name</code>&nbsp;should be replaced by the name of the column on which you want to create the index.</p><p>For example, to create a unique index on the&nbsp;<code>Email</code>&nbsp;column in the&nbsp;<code>Users</code>&nbsp;table, you would write:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE UNIQUE INDEX email_index ON Users (Email);</span><br></pre></td></tr></tbody></table></figure><p>Every time a new email is inserted or an existing one is updated in the Users table, MySQL will check the unique index, and if it finds another row with the same email value, it won’t allow the change to be made.</p><p>Keep in mind, a Unique Index not only helps in ensuring data integrity but, just like a Normal Index, it can also help in improving the performance of data retrieval operations.</p><h1 id="Topic-The-Differences-Between-Normal-Indexes-and-Unique-Indexes"><a href="#Topic-The-Differences-Between-Normal-Indexes-and-Unique-Indexes" class="headerlink" title="Topic: The Differences Between Normal Indexes and Unique Indexes"></a><strong>Topic</strong>: The Differences Between Normal Indexes and Unique Indexes</h1><p>As we’ve discussed in the previous sessions, indexes are integral to efficient data operations in databases. We’ve also looked at two specific types of indexes:&nbsp;<strong>Normal Indexes</strong>&nbsp;(or non-unique indexes) and&nbsp;<strong>Unique Indexes</strong>. Both of these index types fulfill different roles and it’s important to understand the differences.</p><ol><li><strong>Uniqueness</strong>: The foremost difference lies in the name itself — Normal Indexes in MySQL allow duplication in the column or set of columns. In contrast, a Unique Index will prevent the insertion of a new row with a duplicate index column value.</li><li><strong>Usage</strong>: Normal indexes are mainly used to increase the speed of operations in MySQL. Unique indexes, however, serve a dual purpose. They can both increase operational efficiencies and maintain data integrity by rejecting duplicate values.</li><li><strong>Constraints</strong>: When you insert a row in a table that has a Unique Index, MySQL first checks whether inserting the new data will violate the uniqueness constraint. If it does, MySQL rejects the change and issues an error. In contrast, with Normal Indexes, MySQL does not perform such checks.</li></ol><p>It’s crucial to know when to use which type of index. When you need to speed up queries on a large dataset, a Normal Index would do the job. But if you need to ensure data consistency in a column where each value must be unique, you would use a Unique Index, even though it will consume more resources to enforce the uniqueness constraint.</p><h1 id="Topic-Optimizing-SQL-Queries-with-Indexes"><a href="#Topic-Optimizing-SQL-Queries-with-Indexes" class="headerlink" title="Topic: Optimizing SQL Queries with Indexes"></a><strong>Topic</strong>: Optimizing SQL Queries with Indexes</h1><p>Enhancing the performance of our database by organizing its data is one of the primary objectives of using indexes in MySQL. When used properly, indexes can significantly speed up data retrieval operations. Here are some pointers on how to optimize your SQL queries using indexes:</p><ol><li><strong>Index the Search Fields</strong>: It seems pretty straightforward, but it’s worth repeating. If you are frequently searching a particular field in the table, consider indexing it. This could vastly improve your database performance.</li><li><strong>Consider Index Size</strong>: The smaller the index (in terms of data size), the faster it is. Therefore, indexed columns with smaller data types will usually be faster than those with larger data types. For example, an INT is faster than a VARCHAR, and a VARCHAR is faster than a TEXT.</li><li><strong>Limit Indexes on Write-Heavy Tables</strong>: Indexes can slow down write operations (like INSERT, UPDATE, and DELETE statements) because every time you modify the data, the index also needs to be updated. If a table is frequently updated, consider minimizing the number of indexes.</li><li><strong>Composite Indexes</strong>: They consist of more than one column and can speed data retrieval when you’re filtering on multiple columns in your WHERE clause. The trick is they work on the left-most prefix basis. That means the order of columns in the index matters.</li><li><strong>Use Explain Plan</strong>: MySQL’s EXPLAIN statement can show you how the MySQL optimizer would execute your query, helping you understand whether the database is able to utilize the index or not, and allowing you to optimize your queries further.</li></ol><p>That concludes our lesson on how to optimize your SQL queries using indexes.</p><h1 id="Topic-Common-Pitfalls-with-Indexes"><a href="#Topic-Common-Pitfalls-with-Indexes" class="headerlink" title="Topic: Common Pitfalls with Indexes"></a><strong>Topic</strong>: Common Pitfalls with Indexes</h1><p>Indexes in MySQL are powerful tools that can significantly speed up your queries. However, there are a few common pitfalls that you should be aware of when working with them.</p><ol><li><strong>Too Many Indexes</strong>: Having numerous indexes can be counterproductive. Every index that you add increases the amount of time that MySQL spends updating and managing these indexes. This can slow down write operations. Hence, it’s important to have only necessary indexes.</li><li><strong>Not Understanding Cardinality</strong>: Cardinality is the number of unique values in the index. If the cardinality is low (meaning there are many repeated values), the index may not be very effective. You should pay attention to the cardinality of your indexes and consider if an alternative column might serve as a better index.</li><li><strong>Indexing the Wrong Column</strong>: Indexing should be done based on the columns that you will be searching or sorting on frequently. Indexing the wrong column can lead to inefficient queries.</li><li><strong>Ignoring the Query Execution Plan</strong>: The query execution plan provided by MySQL’s&nbsp;<code>EXPLAIN</code>&nbsp;statement can offer valuable insights into how your query will be executed and which indexes are used. Ignoring this information can lead to inefficient indexes or missed opportunities for optimization.</li><li><strong>Using Large String Indexes</strong>: Indexes on large VARCHAR or TEXT columns can consume a lot of memory and slow down your queries. This is where indexing a prefix of a column (<code>INDEX(column(10))</code>) can be useful.</li></ol><p>Remember, the secret to effective indexing lies in understanding your data and how your application queries it. An optimal number of well-chosen indexes can make your database perform dramatically better.</p><h1 id="Topic-Review-and-Assessments"><a href="#Topic-Review-and-Assessments" class="headerlink" title="Topic: Review and Assessments"></a><strong>Topic</strong>: Review and Assessments</h1><p>We’ve learned a lot about MySQL indexes, including what they are, their types (normal and unique indexes), how they are used in query optimization, as well as some common misconceptions and pitfalls when implementing them.</p><p>Now it’s time for a quick assessment. This will reinforce your learning and help highlight any areas we might need to revisit.</p><p><strong>Example Problem:</strong><br>To see how well you’ve grasped the topic, let’s go through an example problem.</p><p>We have a&nbsp;<code>students</code>&nbsp;table in our MySQL database with the following structure:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">| id (INT) | name (VARCHAR) | class (VARCHAR) | age (INT) |</span><br></pre></td></tr></tbody></table></figure><p>You need to frequently run a query to find students in a specific&nbsp;<code>class</code>. How can you optimize this query?</p><p><strong>Solution:</strong><br>To optimize this query, we could add an index on the&nbsp;<code>class</code>&nbsp;column. As we’re frequently searching this field, having an index could significantly increase the performance of our query.</p><p>Here’s the SQL statement to do this:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX idx_students_class ON students (class);</span><br></pre></td></tr></tbody></table></figure><p>Now, let’s test your understanding:</p><ol><li><strong>Simple Problem (Difficulty: 3/10)</strong>: What SQL statement would you use to add an index on the&nbsp;<code>age</code>&nbsp;column in the&nbsp;<code>students</code>&nbsp;table?</li><li><strong>Complex Familiar Problem (Difficulty: 6/10)</strong>: What factors should you consider before deciding to add an index?</li><li><strong>Complex Unfamiliar Problem (Difficulty: 9/10)</strong>: The&nbsp;<code>students</code>&nbsp;table also has a&nbsp;<code>registration_date</code>&nbsp;column (date type) and you’re running queries to find students who registered in a particular year. What type of index could you use to optimize this query and how would you create it?</li></ol><hr><ol><li><strong>Simple Problem</strong>: To add an index on the&nbsp;<code>age</code>&nbsp;column in the&nbsp;<code>students</code>&nbsp;table, you would use the statement:</li></ol><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX idx_students_age ON students(age);</span><br></pre></td></tr></tbody></table></figure><ol><li><strong>Complex Familiar Problem</strong>: Before adding an index, consider:</li></ol><ul><li>The column’s cardinality: High cardinality columns (columns with many unique values) are best-suited for indexing.</li><li>Your application’s read-write ratio: If the application performs many more reads than writes, indexing is beneficial. But if your application performs many write operations (insert, update, delete), the cost of maintaining the index could outweigh the benefits.</li><li>The column’s data type: Indexing on smaller data type columns is faster.</li></ul><ol><li><strong>Complex Unfamiliar Problem</strong>: In the case of running queries to find students who registered in a particular year, you could create an index on the&nbsp;<code>YEAR(registration_date)</code>. MySQL allows creating an index on a function or expression, known as a Functional Index.</li></ol><p>To create a functional index in MySQL 8.0+, you could use the following statement:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX idx_students_registration_year ON students((YEAR(registration_date));</span><br></pre></td></tr></tbody></table></figure><p>This way, MySQL would directly map the year to the row in the index, thus speeding up your queries.</p><p>Please note that creating an index on a function or expression is supported in MySQL 8.0 and later. If you’re using an earlier version of MySQL, you would need to add a separate column for the year and then index that column.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview11/">https://programmerscareer.com/zh-cn/mysql-interview11/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL Interviews: Briefly describe the occurrence scenarios of dirty reading and phantom reading. How does InnoDB solve phantom reading?</title>
      <link href="/mysql-interview12/"/>
      <url>/mysql-interview12/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Have you ever been asked a similar question in an interview? Or you will meet in the future, let’s explore and master it together</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-Introduction-to-Problems-in-Database-Transactions"><a href="#Topic-1-1-Introduction-to-Problems-in-Database-Transactions" class="headerlink" title="Topic: 1.1 Introduction to Problems in Database Transactions"></a><strong>Topic</strong>: 1.1 Introduction to Problems in Database Transactions</h1><p>As we dive into the complexities of database transactions, it’s essential to acknowledge that these operations are not always straightforward. Their primary purpose is to execute a series of operations so that the database morphs from one consistent state to another. However, with simultaneous transactions, we encounter a plethora of issues that need to be resolved for maintaining consistency and integrity.</p><p>One such challenge arises due to the concurrency of transactions. To maintain the&nbsp;<strong>ACID</strong>&nbsp;properties (Atomicity, Consistency, Isolation, and Durability) of transactions, the database systems must handle the concurrent execution of transactions properly. The failure to ensure proper management can lead to several problems:</p><ol><li><strong>Dirty Reading</strong>: This problem occurs when one transaction reads changes made by another transaction that hasn’t been committed yet. If the latter transaction is rolled back for some reason, the former would have read an invalid value.</li><li><strong>Non-Repeatable Read</strong>: This occurs when a single transaction reads the same row multiple times and gets different data each time as other transactions are updating this row simultaneously.</li><li><strong>Phantom Read</strong>: This scenario is a variation of non-repeatable read where a transaction performs two identical queries, but the second result set includes additional rows that weren’t present in the first result set, added by a different transaction.</li></ol><p>These transaction control problems disrupt the smooth functionality of the database transactions and affect data integrity. In the following lessons, we’ll do a deep dive into the scenarios involving dirty reads and phantom reads and understand the solutions, including those offered by InnoDB engine in MySQL.</p><h1 id="Topic-1-2-Understanding-Dirty-Reading"><a href="#Topic-1-2-Understanding-Dirty-Reading" class="headerlink" title="Topic: 1.2 Understanding Dirty Reading"></a><strong>Topic</strong>: 1.2 Understanding Dirty Reading</h1><p>The term “dirty read” in the context of a database involves one transaction reading uncommitted or “dirty” data from another transaction. Picture this: Transaction 1 modifies a certain row but hasn’t committed it yet. Now, before Transaction 1 is either committed or rolled back, Transaction 2 comes along and reads the uncommitted change. This phenomenon is known as a dirty read.</p><p>Why is this a problem? Well, suppose Transaction 1 is eventually rolled back. In that case, the change is undone, but Transaction 2 has already read the uncommitted data, leading to inconsistencies and potentially invalid results in the database.</p><p>Here’s a simple example for clarity:</p><p><strong>Step 1:</strong></p><ul><li>Transaction 1 modifies a row in the&nbsp;<code>orders</code>&nbsp;table, updating the&nbsp;<code>order_status</code>&nbsp;from ‘Pending’ to ‘Shipped’.</li></ul><p><strong>Step 2:</strong></p><ul><li>Before Transaction 1 commits, Transaction 2 reads the&nbsp;<code>order_status</code>&nbsp;for the same row and finds it as ‘Shipped’.</li></ul><p><strong>Step 3:</strong></p><ul><li>Transaction 1 encounters an error and executes a ROLLBACK operation, changing&nbsp;<code>order_status</code>&nbsp;back to ‘Pending’.</li></ul><p><strong>Step 4:</strong></p><ul><li>Transaction 2, however, proceeds with the ‘Shipped’ status, hence reading data that never should have existed.</li></ul><p>Dirty read can lead to significant errors, particularly in data analysis or reporting processes where accuracy is paramount.</p><h1 id="Topic-1-3-Understanding-Phantom-Reading"><a href="#Topic-1-3-Understanding-Phantom-Reading" class="headerlink" title="Topic: 1.3 Understanding Phantom Reading"></a><strong>Topic</strong>: 1.3 Understanding Phantom Reading</h1><p>Like dirty reading, phantom reading is another concurrency problem that arises in database transactions. Phantom reading typically occurs when a transaction re-queries data it has already queried, but finds new rows that were not there in the initial read.</p><p>These “phantom” rows are the result of another transaction that inserted or updated some rows after our original transaction began and before it ended.</p><p>To visualise this, let’s consider a simple example:</p><p><strong>Step 1:</strong></p><ul><li>Transaction 1 retrieves all rows from the&nbsp;<code>orders</code>&nbsp;table where&nbsp;<code>order_status</code>&nbsp;is ‘Pending’.</li></ul><p><strong>Step 2:</strong></p><ul><li>Meanwhile, Transaction 2 inserts a new row in the&nbsp;<code>orders</code>&nbsp;table with&nbsp;<code>order_status</code>&nbsp;as ‘Pending’ and commits.</li></ul><p><strong>Step 3:</strong></p><ul><li>Now, Transaction 1 re-runs the same retrieval query. This time, it finds the row inserted by Transaction 2 — this is a phantom row.</li></ul><p>The problem of phantom reads persists mostly in lower isolation levels such as “Read Committed” but not in higher isolation levels like “Serializable”. This is due to the use of exclusive range locks that prohibit the insertion of new rows in the read range for “Serializable” isolation level.</p><p>However, these higher levels of isolation come with their own problems such as lower concurrency and higher contention. Therefore, the selection of transaction isolation level often involves a trade-off between performance and consistency. But don’t worry, technologies like InnoDB provide ways to handle these situations.</p><h1 id="Topic-1-4-The-Role-of-InnoDB-in-Handling-Phantom-Reads"><a href="#Topic-1-4-The-Role-of-InnoDB-in-Handling-Phantom-Reads" class="headerlink" title="Topic: 1.4 The Role of InnoDB in Handling Phantom Reads"></a><strong>Topic</strong>: 1.4 The Role of InnoDB in Handling Phantom Reads</h1><p>The InnoDB storage engine plays a crucial role in handling transaction problems, including phantom reads, in MySQL. It does so by using&nbsp;<strong>multi-version concurrency control (MVCC)</strong>, which allows multiple transactions to access the same row without affecting each other’s work.</p><p>Each transaction sees a snapshot of the database at the start of its work, keeping concurrent transactions isolated from each other. This contributes to maintaining the ‘I’ (Isolation) part of the ACID properties in MySQL InnoDB.</p><p>Moreover, you can also set different isolation levels in MySQL to customize the balance between read consistency, concurrency, and performance. These isolation levels are READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, and SERIALIZABLE.</p><p>The Repeatable Read level is the default level in InnoDB, which guarantees that all reads within the same transaction will see a snapshot of the database as it was at the start of the transaction. This feature effectively prevents phantom reads.</p><p>However, in some business scenarios, the Serializable level, providing the highest data consistency but at the cost of concurrency and performance, might be required.</p><p>In the later stage of this curriculum, we will discuss in detail how InnoDB implements the ACID properties and the customization of these transaction properties as per user requirements.</p><h1 id="Topic-1-5-Transaction-Isolation-Levels"><a href="#Topic-1-5-Transaction-Isolation-Levels" class="headerlink" title="Topic: 1.5 Transaction Isolation Levels"></a><strong>Topic</strong>: 1.5 Transaction Isolation Levels</h1><p>Transaction Isolation Levels play a central role in how a database management system like MySQL manages concurrency and protects transactions from potential problems like dirty reading, non-repeatable read, and phantom reading.</p><p>In MySQL, there are four preset isolation levels, each with a different level of protection versus performance trade-off:</p><ol><li><strong>READ UNCOMMITTED</strong>: This is the lowest level of isolation, and it allows transactions to see uncommitted changes made by other transactions. This means a transaction can see “dirty” data that another transaction may later roll back, leading to dirty reads.</li><li><strong>READ COMMITTED</strong>: This level guarantees that any data read is committed at the moment it is read. Thus, it prevents dirty reads. However, if a transaction reads the same row twice, it could see different values if another transaction modifies that row between the reads, leading to non-repeatable read.</li><li><strong>REPEATABLE READ</strong>: This is the default isolation level in InnoDB. It prevents both dirty reads and non-repeatable reads by ensuring that all reads of the same row for a single transaction return the same result, unless the row was changed by that transaction itself.</li><li><strong>SERIALIZABLE</strong>: This is the highest level of isolation. It locks the rows that a transaction reads, preventing other transactions from accessing them (read or write) until the first transaction is finished. While this level prevents dirty reads, non-repeatable reads, and phantom reads, it significantly reduces concurrency.</li></ol><p>Understanding these isolation levels is key to managing concurrent transactions effectively. In the coming topics, we will discuss some techniques and practices for implementing concurrency control based on these isolation levels.</p><h1 id="Topic-1-6-Strategies-to-Implement-Concurrency-Control"><a href="#Topic-1-6-Strategies-to-Implement-Concurrency-Control" class="headerlink" title="Topic: 1.6 Strategies to Implement Concurrency Control"></a><strong>Topic</strong>: 1.6 Strategies to Implement Concurrency Control</h1><p>Concurrency control in databases aims to allow multiple transactions to access the database without conflicts or errors simultaneously. To implement concurrency control effectively, there are several strategies we can leverage:</p><ol><li><strong>Lock-Based Protocols</strong>: This common method works by giving a transaction lock access to a data item when it needs. There are exclusive and shared locks. The former doesn’t permit another transaction to access the data; the latter does but only for reading purposes.</li><li><strong>Timestamp-Based Protocols</strong>: This approach involves assigning a timestamp to each transaction, ensuring that earlier transactions get priority in case of conflict.</li><li><strong>Validation-Based Protocols</strong>: Also known as optimistic concurrency control, this method allows transactions to execute without restriction and validates the transactions only at commit time.</li><li><strong>Multiversion Concurrency Control (MVCC)</strong>: Primarily used in InnoDB, MVCC allows each user connected to the database to view the database from a consistent snapshot set at the start of their transaction.</li><li><strong>Granularity of Data</strong>: This decides the size of the data item for locking — from a single row to the entire database.</li></ol><p>Each of these strategies has its strengths and trade-offs. For example, lock-based protocols can create performance issues due to lock contention, while MVCC can provide high concurrency with reduced need for locking at the potential cost of increased storage.</p><p>It’s important to choose a strategy that aligns with your application’s needs and considerations, such as performance, consistency, and complexity.</p><h1 id="Topic-1-7-Review-and-Assessments"><a href="#Topic-1-7-Review-and-Assessments" class="headerlink" title="Topic: 1.7 Review and Assessments"></a><strong>Topic</strong>: 1.7 Review and Assessments</h1><p>You’ve done a fantastic job exploring the crucial aspects of database transactions, understanding the concept of concurrency control, the problems it poses, and the various strategies employed to handle such issues.</p><p>By now, we’ve journeyed through understanding the necessity of handling simultaneous transactions — concurrency control. We’ve identified potential challenges like dirty reading, non-repeatable read, and phantom read, which basically involve how transactions handle changes in data from other transactions.</p><p>We took a deep dive into what dirty reading is, how it occurs, and its implications on database transactions. Similarly, we had an in-depth discussion into the occurrence scenarios of phantom readings and the issues it can cause.</p><p>We investigated the role of the InnoDB storage engine in MySQL, specifically how it implements a ‘consistent read’ to manage phantom readings.</p><p>We further dissected the concept of Transaction Isolation Levels, understanding how configuring different transaction isolation levels can in turn affect the occurrence of dirty and phantom reads.</p><p>We also touched upon the various strategies employed to handle concurrency issues — for instance, transaction scheduling and using various types of lock-based<br>protocols.</p><p>As we wrap up this unit, let’s revisit some of these key concepts covered through an assessment to evaluate your understanding of dirty reading, phantom reading, and the methods used by InnoDB to resolve these issues.</p><p>Alright, let’s move on to the three assessment problems. Try to solve each one, and I’ll provide the solutions afterward.</p><h2 id="Simple-Problem-Difficulty-3-10"><a href="#Simple-Problem-Difficulty-3-10" class="headerlink" title="Simple Problem (Difficulty: 3/10)"></a>Simple Problem (Difficulty: 3/10)</h2><p>Suppose you have two transactions happening simultaneously where transaction 1 reads a data object, and transaction 2 updates it later. Identify the kind of reading problem that could occur here and explain your reasoning.</p><h2 id="Complex-Familiar-Problem-Difficulty-6-10"><a href="#Complex-Familiar-Problem-Difficulty-6-10" class="headerlink" title="Complex Familiar Problem (Difficulty: 6/10)"></a>Complex Familiar Problem (Difficulty: 6/10)</h2><p>In the context of database transactions, how does the InnoDB storage engine in MySQL handle phantom readings? Describe how ‘consistent read’ contributes to managing these phantom reads.</p><h2 id="Complex-Unfamiliar-Problem-Difficulty-9-10"><a href="#Complex-Unfamiliar-Problem-Difficulty-9-10" class="headerlink" title="Complex Unfamiliar Problem (Difficulty: 9/10)"></a>Complex Unfamiliar Problem (Difficulty: 9/10)</h2><p>You are the database manager of a banking system. Two transactions are happening concurrently, one where the customer ‘A’ transfers an amount to customer ‘B’, and the other where the bank calculates the total balance of customer ‘A’. Due to the concurrency of these separate transactions, the bank balance calculation occurs before the transfer transaction is complete. Explain the issues that could arise in this scenario.</p><hr><h2 id="Simple-Problem-Difficulty-3-10-1"><a href="#Simple-Problem-Difficulty-3-10-1" class="headerlink" title="Simple Problem (Difficulty: 3/10)"></a>Simple Problem (Difficulty: 3/10)</h2><p>This problem is associated with a ‘dirty read’. A dirty read is a concept in Database Management where a transaction (Transaction 1) is allowed to read data from a row that has been modified by another transaction (Transaction 2) but not yet committed. So, if Transaction 2 rolls back the change, Transaction 1 will have read data that is considered not to have existed.</p><h2 id="Complex-Familiar-Problem-Difficulty-6-10-1"><a href="#Complex-Familiar-Problem-Difficulty-6-10-1" class="headerlink" title="Complex Familiar Problem (Difficulty: 6/10)"></a>Complex Familiar Problem (Difficulty: 6/10)</h2><p>The InnoDB storage engine in MySQL uses ‘consistent read’ for handling phantom readings. Consistent read is a non-locking read used by InnoDB select operations to provide a point-in-time snapshot of the data. It’s done by applying multi-version concurrency control (MVCC) where multiple versions of a record are stored. This way, users can view the database without lock-induced delays.</p><h2 id="Complex-Unfamiliar-Problem-Difficulty-9-10-1"><a href="#Complex-Unfamiliar-Problem-Difficulty-9-10-1" class="headerlink" title="Complex Unfamiliar Problem (Difficulty: 9/10)"></a>Complex Unfamiliar Problem (Difficulty: 9/10)</h2><p>In the given scenario, a non-repeatable read may occur. Non-repeatable reads happen when a transaction reads the same row twice and gets different data each time. In this case, the bank balance calculating transaction may first calculate the balance before any transaction occurs then repeat the reading process after customer ‘A’ has transferred the amount to customer ‘B’. Hence the first and second read will result in different balances for customer ‘A’.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview12/">https://programmerscareer.com/zh-cn/mysql-interview12/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL interviews: What is the difference between a clustered index and a non-clustered index?</title>
      <link href="/mysql-interview13/"/>
      <url>/mysql-interview13/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Have you ever been asked a similar question in an interview? Or you will meet in the future, let’s explore and master it together</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-Introduction-to-Clustered-and-Non-Clustered-Indexes"><a href="#Topic-1-1-Introduction-to-Clustered-and-Non-Clustered-Indexes" class="headerlink" title="Topic: 1.1 Introduction to Clustered and Non-Clustered Indexes"></a><strong>Topic</strong>: 1.1 Introduction to Clustered and Non-Clustered Indexes</h1><p>Knowing how your data is stored and retrieved can greatly impact the performance of your databases. More specifically, understanding&nbsp;<em>how</em>&nbsp;MySQL makes use of indexes is crucial to this understanding. This is where the concepts of&nbsp;<strong>Clustered</strong>&nbsp;and&nbsp;<strong>Non-Clustered Indexes</strong>&nbsp;come into play.</p><p>Indexes, as you may have learned from your prerequisite studies, are a vital component of databases. They are essentially lookup tables that the database engine utilizes to speed up the data retrieval process, much like how an index in a book helps you quickly locate information without having to read each page.</p><p>Now, let’s specifically dive into what clustered and non-clustered indexes are:</p><p><strong>Clustered Indexes</strong>:</p><p>Just as it sounds, a clustered index dictates the&nbsp;<em>physical order of data in a table</em>. To understand this better, consider a clustered index as a dictionary. In a dictionary, words are not randomly scattered across but are stored alphabetically, so you can quickly jump to a section for a particular letter and find the word you’re looking for. In the context of a database, this “word” is your data row. MySQL, in fact, organizes rows of data based on the clustered index so that retrieval is faster. Please note that there can only be one clustered index per table.</p><p><strong>Non-Clustered Indexes</strong>:</p><p>Non-clustered indexes, on the other hand, do not dictate the physical order of data. Yet, they carry a ‘pointer’ to the data. To understand better, if a clustered index is like a dictionary, then a non-clustered index can be considered like an index in a book. The index points you to the pages where information resides, but it doesn’t contain the information itself. This means that once the database engine looks through the non-clustered index, it must perform extra work to ‘go’ to the data row, compared to a clustered index where the data resides with the index. Hence, data retrieval via non-clustered indexes may be slower. However, you can have multiple non-clustered indexes, which can be beneficial for a variety of data retrieval scenarios.</p><h1 id="Topic-1-2-Clustered-Indexes-Explained"><a href="#Topic-1-2-Clustered-Indexes-Explained" class="headerlink" title="Topic: 1.2 Clustered Indexes Explained"></a><strong>Topic</strong>: 1.2 Clustered Indexes Explained</h1><p>Clustered indexes are all about the physical storage of data. When you create a clustered index on a table, the rows of the table are stored on disk in the same order as the index key. There can only be one clustered index per table, and if you don’t explicitly define a clustered index, SQL Server will automatically create one for you. This is known as a heap.</p><p>The structure of a clustered index is also known as a B+ tree structure. At the root of the tree, which is the topmost level, you have the root node. This root node then branches out into multiple leaf nodes at the bottom-most level. These leaf nodes contain the actual data rows in the order of the index.</p><p>A primary key constraint automatically creates a clustered index on that particular column. However, in some cases, you might want to manually create a clustered index on a non-primary-key column. This depends on your requirements. For example, if you have a table with employees’ data and constantly query data in the order of employees’ hire date, it might be beneficial to create a clustered index on the hire date column to speed up these queries.</p><p>Furthermore, the update of records in a table with a clustered index may be slower than that in a heap. That’s because when a record is updated in a table with a clustered index, the database might need to physically move the entire row to maintain the sort order.</p><h1 id="Topic-1-3-Non-Clustered-Indexes-Explained"><a href="#Topic-1-3-Non-Clustered-Indexes-Explained" class="headerlink" title="Topic: 1.3 Non-Clustered Indexes Explained"></a><strong>Topic</strong>: 1.3 Non-Clustered Indexes Explained</h1><p>So now we have a good understanding of what a clustered index is and how it sorts and stores data on disk. But sometimes, we don’t always want to retrieve data based on the (single) clustered index. That’s where the&nbsp;<strong>non-clustered index</strong>&nbsp;comes into play.</p><p>A non-clustered index is markedly different from a clustered index. For starters, creating a non-clustered index does not rearrange the physical order of data in the table. Instead, it creates a distinct object within the database that houses a sorted list of pointers that point to the data in the table.</p><p>Here’s a neat example to illustrate. Imagine a book — rather than looking through every page for a particular topic, you would generally turn to the book’s index, right? It guides you straight to the pages that contain your specified topic. That quick directing is the function a non-clustered index performs!</p><p>The architecture of a non-clustered index is similar to a clustered one — a B-tree data structure with root nodes, intermediate level nodes, and leaf nodes. However, the leaf nodes of a non-clustered index consist only of the index columns and a pointer to the corresponding row in the data table. You can have multiple non-clustered indexes on a single table, with each catering to a specific query you want to speed up.</p><p>In MySQL, a non-clustered index is essentially all secondary indexes you create, with each of them containing a copy of the primary key columns for the rows where the search key matches.</p><h1 id="Topic-1-4-Differences-Between-Clustered-and-Non-Clustered-Indexes"><a href="#Topic-1-4-Differences-Between-Clustered-and-Non-Clustered-Indexes" class="headerlink" title="Topic: 1.4 Differences Between Clustered and Non-Clustered Indexes"></a><strong>Topic</strong>: 1.4 Differences Between Clustered and Non-Clustered Indexes</h1><p>With a solid understanding of what clustered and non-clustered indexes are, let’s now clarify the key differences between the two:</p><ol><li><strong>Order of Data</strong>: A clustered index determines the physical order of data in a table. On the other hand, a non-clustered index doesn’t alter the way the records are stored but creates a separate object within a database that points back to those original records.</li><li><strong>Number of Indexes</strong>: A table can have only one clustered index, but multiple non-clustered indexes. Remember, the more indexes, the more disk space required.</li><li><strong>Data Retrieval Speed</strong>: Clustered indexes can lead to faster data retrieval than non-clustered, but that’s not always the case. If a non-clustered index covers a query (meaning, the query’s data can all be served from the index’s leaf nodes), it can retrieve data faster despite having a few extra hoops to jump through.</li><li><strong>Update Performance</strong>: Clustered indexes can slow down updates, while non-clustered indexes often have little effect on performance.</li><li><strong>Storage Space</strong>: As non-clustered indexes are stored separately from the table data, they require additional storage. Each non-clustered index is a separate disk structure that stores a sorted array of column values, whereas a clustered index is the actual table data and forms the lowest level of an index.</li></ol><p>In the grand scheme of databases — the speed at which data can be retrieved, the efficiency of storage, the quickness of updates — all of these factors rely heavily on proper indexing. Being clear on when and why to use either clustered and non-clustered indexes puts you in control of optimizing your database performance.</p><h1 id="Topic-1-5-Choosing-the-Right-Index"><a href="#Topic-1-5-Choosing-the-Right-Index" class="headerlink" title="Topic: 1.5 Choosing the Right Index"></a><strong>Topic</strong>: 1.5 Choosing the Right Index</h1><p>Great job! Now that we know what clustered and non-clustered indexes are and the key differences between them, let’s dive into choosing the right index.</p><p>Choosing the right index for performance optimization in MySQL comes down to understanding the queries that will be executed against your database. It’s not just about whether to use clustered or non-clustered indexes, but also includes understanding columns and their cardinality.</p><p>Here are a few key points to help you decide:</p><ol><li><strong>Choose a Clustered Index for Wide Column Queries</strong>: Since clustered indexes are essentially the table data itself, they are excellent for wide column queries because of the reduced number of reads required.</li><li><strong>Choose a Non-Clustered Index for Specific Column Queries</strong>: Non-clustered indexes are useful when you need to retrieve a smaller subset of columns often. In such cases, creating a non-clustered index on these columns can be beneficial.</li><li><strong>High-Cardinality Columns</strong>: When a column has a high cardinality (each row is unique), using it as a clustered index can result in quicker look-ups.</li><li><strong>Low-Cardinality Columns</strong>: For low-cardinality columns (many rows share the same value), usage of non-clustered indexes is generally more efficient.</li><li><strong>Data Modification Operations</strong>: If your application entails frequent modifications (INSERT, UPDATE, DELETE operations), non-clustered indexes might be a better choice since they don’t impact the physical ordering of the data on disk.</li><li><strong>Space Considerations</strong>: Since non-clustered indexes are separate disk structures, they consume additional storage space. If storage space is a constraint, clustered indexes might be a better fit, albeit at the cost of speed, in some cases.</li></ol><p>Remember, the best strategy is always dictated by the specific workload at hand. It’s essential to continuously monitor and analyze performance and adjust your indexing strategy accordingly.</p><h1 id="Topic-1-6-Examples-and-Use-cases"><a href="#Topic-1-6-Examples-and-Use-cases" class="headerlink" title="Topic: 1.6 Examples and Use-cases"></a><strong>Topic</strong>: 1.6 Examples and Use-cases</h1><p>Wonderful! Well done so far. To solidify the understanding, let’s look at a few real-world examples and use-cases.</p><p>Starting with a basic example, let’s say you directly manage an online bookstore. You have a&nbsp;<code>Books</code>&nbsp;table that contains the following columns:&nbsp;<code>BookID</code>,&nbsp;<code>Title</code>,&nbsp;<code>Author</code>,&nbsp;<code>Genre</code>,&nbsp;<code>Price</code>, and&nbsp;<code>PublicationDate</code>.</p><ol><li><strong>Using a Clustered Index</strong>: Let’s say customers frequently search books by the&nbsp;<code>BookID</code>&nbsp;in your store. To enhance the speed of these common pull requests, you can use a clustered index on the&nbsp;<code>BookID</code>&nbsp;column. Since a clustered index determines the physical order of data in a table, row look-ups can be significantly faster.</li><li><strong>Using a Non-Clustered Index</strong>: On the flip side, if customers often look up books by&nbsp;<code>Genre</code>&nbsp;or&nbsp;<code>Author</code>, it could be beneficial to create a non-clustered index on these columns. As mentioned, non-clustered indexes are particularly useful when you need to retrieve a smaller subset of columns, which perfectly fits our case here.</li></ol><p><strong>Use-case</strong>: Suppose your database has a&nbsp;<code>Customers</code>&nbsp;table storing millions of records, and you frequently need to retrieve customer information based on&nbsp;<code>CustomerID</code>. A clustered index on&nbsp;<code>CustomerID</code>&nbsp;can speed up these look-ups dramatically. However, if business needs require you to retrieve records based not just on&nbsp;<code>CustomerID</code>&nbsp;but also, let’s say,&nbsp;<code>LastName</code>&nbsp;and&nbsp;<code>ZipCode</code>, then non-clustered indexes on&nbsp;<code>LastName</code>&nbsp;and&nbsp;<code>ZipCode</code>&nbsp;can be more efficient.</p><p>Keep in mind that these are just examples and the actual implementation may greatly vary depending on factors like data size, query complexity, and hardware capabilities. Understanding when to use clustered and non-clustered indexes — predicated on intelligent database design — is a crucial aspect of managing SQL databases.</p><h1 id="Topic-1-7-Review-and-Assessments"><a href="#Topic-1-7-Review-and-Assessments" class="headerlink" title="Topic: 1.7 Review and Assessments"></a><strong>Topic</strong>: 1.7 Review and Assessments</h1><p>Amazing progress! Let’s review the main concepts we’ve covered and then move onto some assessments.</p><ol><li><strong>Clustered Index</strong>: This type of index determines the physical order of data in a table. A table can have only one clustered index.</li><li><strong>Non-Clustered Index</strong>: This type of index is a separate disk structure referencing the table data, which helps speed up the queries that are not covered by clustered index. A table can have multiple non-clustered indexes.</li><li><strong>High vs. Low Cardinality</strong>: High-cardinality refers to columns with unique values on most, if not all, rows. Clustered indexes on high-cardinality columns can result in quicker look-ups. Low-cardinality refers to columns where many rows share the same value. Non-clustered indexes are generally more efficient for such columns.</li><li><strong>Choosing the Right Index</strong>: This depends on various factors including query types, cardinality, data modification needs, and space constraints.</li></ol><p>Now, let’s assess our understanding with a few questions:</p><ol><li>What is the key difference between a clustered and a non-clustered index?</li><li>In which case would a non-clustered index be a more suitable choice over a clustered index?</li><li>What do high-cardinality and low-cardinality mean and how do they affect the choice of index type?</li></ol><hr><p><strong>Question</strong>: What is the key difference between a clustered and a non-clustered index?<br><strong>Answer</strong>: The key difference between a clustered and a non-clustered index lies in the way they store and reference data. A clustered index determines the physical order of data in a table, essentially being the table itself, whereas a non-clustered index is a separate structure that points to the data located elsewhere in the database.</p><p><strong>Question</strong>: In which case would a non-clustered index be a more suitable choice over a clustered index?<br><strong>Answer</strong>: A non-clustered index would be more suitable when the database needs to support a lot of search queries on columns that are not part of the clustered index. Moreover, non-clustered indexes would also be preferable when the table undergoes frequent changes as changes do not result in the entire table needing to be reorganized, unlike with a clustered index.</p><p><strong>Question</strong>: What do high-cardinality and low-cardinality mean and how do they affect the choice of index type?<br><strong>Answer</strong>: Cardinality refers to the uniqueness of data values in a column. High cardinality means a column contains a large percentage of totally unique values, and low cardinality means a column contains many repeated values. High-cardinality columns are good candidates for a clustered index, whilst indexes on low-cardinality columns, where the column values are very repetitive, are less effective.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview13/">https://programmerscareer.com/zh-cn/mysql-interview13/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL Interviews: What are database transactions and why does MySQL use InnoDB as the default option</title>
      <link href="/mysql-interview14/"/>
      <url>/mysql-interview14/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Have you ever been asked a similar question in an interview? Or you will meet in the future, let’s explore and master it together</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-—-Deep-Dive-into-Transactions"><a href="#Topic-1-1-—-Deep-Dive-into-Transactions" class="headerlink" title="Topic 1.1 — Deep Dive into Transactions"></a>Topic 1.1 — Deep Dive into Transactions</h1><p>In simple terms, a transaction is a unit of work performed within a database management system (or similar system) against a database, and treated in a reliable way independent of other transactions.</p><p>A transaction generally represents any change in the database. More technically, a transaction is a sequence of database operations that constitutes a logical unit of work.</p><p>Consider the example of transferring funds from one bank account to another. This operation requires two steps:</p><ol><li>Withdrawal in one account.</li><li>Deposit in another.</li></ol><p>Both steps must be complete for the transaction to be considered complete. If something were to happen in between these two operations, like a server failure, the transaction would be considered incomplete, and the database must be rolled back to its previous, consistent state.</p><p>This way, transactions help maintain the&nbsp;<strong>Integrity</strong>&nbsp;of a database by ensuring that sets of related operations either all occur, or none occur. The concept of transactions ties in closely with the principles of ACID (Atomicity, Consistency, Isolation, Durability), providing a framework to ensure reliable processing of data.</p><h1 id="Topic-1-2-—-MySQL-and-Transactions"><a href="#Topic-1-2-—-MySQL-and-Transactions" class="headerlink" title="Topic 1.2 — MySQL and Transactions"></a>Topic 1.2 — MySQL and Transactions</h1><p>MySQL is a DBMS that provides support for managing transactions. What does this mean? It means that MySQL allows you to group a certain set of actions together in such a way that either all actions are executed or none of them are. This is especially crucial in scenarios where the failure of an intermediate step might lead to database inconsistency.</p><p>Consider again the example of transferring funds between two bank accounts. Let’s now say we’re working with a MySQL database that manages these transactions. Let’s go step by step:</p><ol><li>User A initiates a transaction by requesting to transfer $100 to User B.</li><li>MySQL starts a transaction.</li><li>MySQL debits $100 from User A’s account balance.</li><li>MySQL attempts to credit $100 to User B’s account.</li><li>Here we consider two scenarios:</li></ol><ul><li>If the operation is successful, MySQL commits the transaction, and the database shows the updated balances for both users.</li><li>If there’s a failure (maybe due to a server crash or an unforeseen issue), MySQL rolls back the transaction. The result? The database remains in its initial state, with no changes to User A or User B’s account balances. The database remains consistent.</li></ul><p>In this way, MySQL plays a critical role in ensuring secure and consistent transactions by adhering to the principles of ACID.</p><p>Remember, MySQL’s power to handle transactions isn’t provided out of the box with every setup, but requires particular types of storage engines. We’ll explore this in more depth in the upcoming subjects.</p><h1 id="Topic-1-3-—-Introduction-to-InnoDB"><a href="#Topic-1-3-—-Introduction-to-InnoDB" class="headerlink" title="Topic 1.3 — Introduction to InnoDB"></a>Topic 1.3 — Introduction to InnoDB</h1><p>Now that we understand the vital role that transactions play in maintaining database integrity and how MySQL handles transactions, it’s time to explore InnoDB.</p><p>InnoDB is a storage engine for MySQL. MySQL users initially had to choose between two major types of storage engines — MyISAM and InnoDB. Each engine came with its own advantages and disadvantages. However, MyISAM, an earlier engine, did not support transactions. InnoDB, on the other hand, offers full transaction support, involving multiple statements with commit and rollback. InnoDB also provides row-level locking, which increases multi-user concurrency and performance, and features such as consistent reads, foreign key constraints, and ACID compliance, which we’ve touched on already.</p><p>Since the MySQL 5.5 release, InnoDB has been the default MySQL storage engine, unless otherwise specified. This decision was made largely based on InnoDB’s robustness and full-featured design.</p><p>So, InnoDB’s strong transaction support, along with its other features, makes it a powerful choice for extensive and complex database systems.</p><h1 id="Topic-1-4-—-Advantages-of-InnoDB"><a href="#Topic-1-4-—-Advantages-of-InnoDB" class="headerlink" title="Topic&nbsp;1.4 — Advantages of InnoDB."></a>Topic&nbsp;<strong>1.4 — Advantages of InnoDB</strong>.</h1><p>InnoDB’s main advantage is in its robust handling of transactions alongside its row-level locking capabilities. This makes it a powerful choice for extensive and complex database systems with a high number of concurrent users.</p><p>Let’s break down some of these advantages:</p><ol><li><strong>Reliability and Durability — ACID Compliance:</strong>&nbsp;Like I mentioned before, InnoDB’s transaction complies with the ACID model, thanks to its commit, rollback, and crash-recovery capabilities. It ensures that your transactions are reliable and your data is durable.</li><li><strong>Row-level locking:</strong>&nbsp;Unlike table-level locking(MyISAM uses it), row-level locking is more efficient as it allows higher concurrency and great performance in a multi-user environment.</li><li><strong>InnoDB Buffer Pool:</strong>&nbsp;The Buffer Pool is the memory space that InnoDB uses to cache data and indices of its tables. This feature reduces the I/O operations, which makes the system faster and more performant.</li><li><strong>Foreign Key Constraints:</strong>&nbsp;InnoDB supports the use of foreign key constraints for referential integrity. When the data in one table relies on data from another table, you can prevent erroneously removing critical data with foreign key constraints.</li><li><strong>Automatic Crash Recovery:</strong>&nbsp;InnoDB has the capability to recover from a crash automatically. Critical data being updated in a crash will not be lost, due to the engine’s automatic replay of its logs.</li></ol><p>These are only a few of many advantages InnoDB brings to your MySQL database. Depending on your specific needs, there may be more benefits relevant to your use case.</p><h1 id="Topic-1-5-—-InnoDB-vs-MyISAM"><a href="#Topic-1-5-—-InnoDB-vs-MyISAM" class="headerlink" title="Topic 1.5 — InnoDB vs MyISAM"></a>Topic 1.5 — InnoDB vs MyISAM</h1><p>InnoDB and MyISAM are both storage engines for MySQL, but they have some significant differences. Understanding these differences is crucial when deciding which storage engine to use for your specific use-case.</p><p>Let’s compare them across a few key parameters:</p><ol><li><strong>Transactions:</strong>&nbsp;As we’ve discussed before, InnoDB supports transactions, whereas MyISAM does not. So, if you require transactional integrity, you should opt for InnoDB.</li><li><strong>Locking:</strong>&nbsp;InnoDB implements row-level locking while MyISAM implements table-level locking. Row-level locking allows higher concurrency and thus offers better performance for operations that require frequent, small data modifications.</li><li><strong>Foreign Key Constraints:</strong>&nbsp;Foreign key constraints, part of referential integrity, are supported in InnoDB but not in MyISAM.</li><li><strong>Full-Text Search:</strong>&nbsp;Full-text search is an operation that searches through a large collection of data and returns results that match one or more keywords. MyISAM has built-in full-text search support, which makes it a good option if this is your primary requirement.</li><li><strong>Data safety:</strong>&nbsp;InnoDB uses a transaction log to ensure data safety (ACID compliance), while MyISAM does not.</li><li><strong>Compression:</strong>&nbsp;InnoDB supports table compression, allowing your table data and associated indexes to be compressed to conserve disk space, which can also increase I/O efficiency and performance.</li></ol><p>Most importantly, remember that there’s no such thing as a universally “right” choice between InnoDB and MyISAM. The suitable engine depends on your specific situation and requirements.</p><h1 id="Topic-1-6-—-Case-studies-Real-world-examples-and-scenarios-where-data-integrity-and-transactions-matter"><a href="#Topic-1-6-—-Case-studies-Real-world-examples-and-scenarios-where-data-integrity-and-transactions-matter" class="headerlink" title="Topic 1.6 — Case studies: Real-world examples and scenarios where data integrity and transactions matter"></a>Topic 1.6 — Case studies: Real-world examples and scenarios where data integrity and transactions matter</h1><p>Transactions and data integrity are critical in many real-world applications. To illustrate their importance in practical scenarios, let’s consider a few case studies.</p><p><strong>Online Banking and Financial Services:</strong></p><ol><li>In an online banking system, suppose a customer is transferring money from their savings account to their checking account. This process comprises two separate tasks ‒ reducing the balance of the savings account and increasing the balance of the checking account. Both tasks need to happen together. If there’s a system failure after the savings account was debited but before the checking account was credited, the customer would lose money. The ACID properties of a transaction ensure that either both actions occur or neither do, maintaining the integrity of the data.</li></ol><p><strong>Ecommerce Platforms:</strong></p><ol><li>Consider a customer placing an order on an eCommerce site. The process involves checking the inventory, confirming the payment, updating the inventory, and confirming the order. Any error or failure at one stage should halt the entire process. Transactions provide a secure pathway for these operations, ensuring consistent data throughout.</li></ol><p><strong>Airlines Reservation System:</strong></p><ol><li>When a seat on a flight is booked, the system first checks the availability of seats, reserves a seat, then accepts payment. If the reservation system crashes after a seat has been reserved but before the payment confirmation, it could lead to a loss for the airline. With transactions, a failure in a later stage would automatically roll back the previous stages, freeing up the seat for a different customer.</li></ol><p>These are just a few scenarios where transactions, aided by the robust capabilities of InnoDB, ensure data integrity. In critical systems where data consistency is paramount, the support provided by InnoDB proves incredibly useful.</p><h1 id="Topic-1-7-—-MySQL-Interviews-Why-are-database-transactions-important-and-why-is-InnoDB-the-default-option-in-MySQL"><a href="#Topic-1-7-—-MySQL-Interviews-Why-are-database-transactions-important-and-why-is-InnoDB-the-default-option-in-MySQL" class="headerlink" title="Topic 1.7 — MySQL Interviews: Why are database transactions important and why is InnoDB the default option in MySQL?"></a>Topic 1.7 — MySQL Interviews: Why are database transactions important and why is InnoDB the default option in MySQL?</h1><p>Transactions are an essential concept in database systems. They serve to protect an organization’s information in the event of system failures such as a power outage, software crash, or something more nefarious like malicious attacks.</p><p>A transaction is a sequence of one or more operations performed as a single logical unit of work. The operations can include reading database records, modifying these records, or even manipulating the data within a set of parameters.</p><p>Transactions in database systems are managed with the acronym ACID, which stands for Atomicity, Consistency, Isolation, and Durability.</p><ul><li><strong>Atomicity:</strong>&nbsp;Guarantees that either all the changes a transaction makes are committed to the database, or if an error occurs, none of the changes is committed.</li><li><strong>Consistency:</strong>&nbsp;Ensures that a transaction doesn’t leave the database in an inconsistent state after it runs.</li><li><strong>Isolation:</strong>&nbsp;Ensures that one transaction does not interfere with another.</li><li><strong>Durability:</strong>&nbsp;Ensures that committed updates persist, even in the face of power loss or a system crash.</li></ul><p>Now, why is InnoDB the default option for MySQL?</p><p>InnoDB storage engine provides a robust and reliable way to handle transactions. It has several features such as the support for ACID-compliant transactions, row-level locking, and real-world implementations like foreign keys that make it the default engine for MySQL.</p><p>Moreover, InnoDB offers crash recovery capabilities and provides hardware acceleration using Solid State Disks (SSDs) or hard disks.</p><p>In a nutshell, the strength of InnoDB lies in its broadly applicable set of features, including transactions, reliability, and performance optimizations, which are suitable for most workloads.</p><h1 id="Topic-1-8-—-Review-and-Assessments"><a href="#Topic-1-8-—-Review-and-Assessments" class="headerlink" title="Topic 1.8 — Review and Assessments"></a>Topic 1.8 — Review and Assessments</h1><p>Over the course of our lessons, we’ve covered:</p><ul><li><strong>Transactions</strong>&nbsp;and their importance in maintaining data integrity,</li><li>How MySQL supports transactions and the benefits of such support,</li><li>An introduction to&nbsp;<strong>InnoDB</strong>, its advantages, and why it is the default storage engine in MySQL,</li><li>The differences between InnoDB and MyISAM,</li><li>Real-world instances where data integrity and transactions are crucial,</li><li>And a run-through of common MySQL interview questions and responses.</li></ul><p>Just to recap, transactions are a critical concept in database systems. They exist to protect the integrity of data in the event of system failures.</p><p>InnoDB is the default storage engine for MySQL due to its support for ACID-compliant transactions, its feature set that provides reliability and performance optimization, and its real-word implementations that further enforce data integrity. These features provide InnoDB an advantage over MyISAM, especially in the context of applications where data integrity and reliability are paramount.</p><p>For this assessment, I will provide a set of questions and problems related to the topics that we covered. They will range from simple to complex, so make sure to think critically and take your time.</p><p><strong>Question 1 (3/10 difficulty):</strong></p><p>What are the four properties of a transaction known as ACID?</p><p><strong>Question 2 (6/10 difficulty):</strong></p><p>Explain the importance of transactions in maintaining data integrity within a database.</p><p><strong>Question 3 (9/10 difficulty):</strong></p><p>Discuss why InnoDB is the default option in MySQL compared to MyISAM. Include the benefits of InnoDB in your answer.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview14/">https://programmerscareer.com/zh-cn/mysql-interview14/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL interviews: What are the transaction isolation levels? What are the tradeoffs?</title>
      <link href="/mysql-interview15/"/>
      <url>/mysql-interview15/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Have you ever been asked a similar question in an interview? Or you will meet in the future, let’s explore and master it together</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-Introduction-to-Transaction-Isolation-Levels"><a href="#Topic-1-1-Introduction-to-Transaction-Isolation-Levels" class="headerlink" title="Topic 1.1: Introduction to Transaction Isolation Levels"></a><strong>Topic 1.1: Introduction to Transaction Isolation Levels</strong></h1><p>Alright, let’s embark on our journey of understanding Transaction Isolation Levels in MySQL!</p><p>So, let’s start with the basics.</p><p>In any database system that allows concurrent transactions, Transaction Isolation Levels determine the extent to which one transaction must be isolated from another. They are vital as they help manage concurrent transactions, prevent data inconsistencies, and ensure the integrity of data in any transaction-based system.</p><p>The ANSI/ISO SQL standard defines four levels of transaction isolation with respective phenomena prevention:</p><ol><li><strong>Read Uncommitted</strong>: This is the lowest level of isolation, in which one transaction might see not-yet-committed changes made by another transaction.</li><li><strong>Read Committed</strong>: It guarantees that any data read is committed at the moment it is read. It doesn’t prevent other transactions from modifying the data.</li><li><strong>Repeatable Read</strong>: This level ensures that if a transaction reads data that is then modified by another transaction, the first transaction will retrieve the same data regardless of any subsequent reads.</li><li><strong>Serializable</strong>- This level offers the highest data protection, it achieves this by performing transactions serially, or one after another. But this might lead to performance issues.</li></ol><p>It’s also important to know that MySQL, with InnoDB storage engine, only supports&nbsp;<strong>Repeatable Read (the default isolation level)</strong>, Read Committed, and Serializable.</p><p>Each isolation level comes with its pros and cons, solving some problems while potentially introducing others. This is a necessary trade-off to balance performance and accuracy in managing concurrent transactions.</p><h1 id="Topic-1-2-Read-Uncommitted-Level"><a href="#Topic-1-2-Read-Uncommitted-Level" class="headerlink" title="Topic 1.2: Read Uncommitted Level"></a><strong>Topic 1.2: Read Uncommitted Level</strong></h1><p>In “Read Uncommitted,” the transaction may read data that’s still in a state of being modified by another running transaction and not yet committed to the database. That’s where this isolation level inherits its name — the data it reads is not committed yet.</p><p>Consider the scenario: Let’s imagine a transaction is modifying some rows of a table:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">UPDATE Inventory   </span><br><span class="line">SET Quantity = Quantity - 10   </span><br><span class="line">WHERE ItemName = 'Apples';</span><br></pre></td></tr></tbody></table></figure><p>While this transaction is still ongoing, another transaction reads data from the same table. According to the Read Uncommitted level, it will see the uncommitted changes containing mutated data that the first transaction was processing, leading to what is called a “Dirty Read.”</p><p>There might be an instance where the first transaction fails (and a rollback is initiated), making those changes null and void. But the second transaction that already read the uncommitted data proceeds with the flawed, inaccurate data. This can cause serious data inconsistencies.</p><p>In terms of performance, however, “Read Uncommitted” is typically faster than the other, higher isolation levels because it doesn’t have to issue locks on the read data to prevent it from being modified or read.</p><p>Now the downside of “Read Uncommitted” comes into view. It cannot guarantee accuracy and consistency of data because, as we said earlier, it allows “Dirty Reads.”</p><p>In real-world applications, this isolation level is generally avoided unless performance is the most important factor and data accuracy is not a major concern.</p><h1 id="Topic-1-3-Read-Committed-Level"><a href="#Topic-1-3-Read-Committed-Level" class="headerlink" title="Topic 1.3: Read Committed Level"></a><strong>Topic 1.3: Read Committed Level</strong></h1><p>As the name suggests, the “Read Committed” level allows a transaction to see only those changes that have been committed by other transactions before it begins to read. As a result, it solves the “Dirty Read” problem we talked about in the “Read Uncommitted” isolation level.</p><p>Let’s illustrate this with a simple example:</p><p>Consider two accounts, ‘A’ and ‘B’, with current balances of $500 and $200, respectively. Suppose a transaction is initiated to transfer $100 from account ‘A’ to account ‘B’. During this process, account ‘A’’s balance reduces to $400 even before the transaction is completed.</p><p>In the “Read Uncommitted” isolation level, if another transaction tries to calculate the total balance of both accounts simultaneously, it might end up adding the intermediate state of account ‘A’ (i.e., $400) and the original state of account ‘B’ (i.e., $200), leading to an incorrect total balance of $600.</p><p>However, with the “Read Committed” isolation level, the second transaction waits until the first transaction is completely finished. Therefore, it correctly calculates the total balance as $700 ($400 in account ‘A’ + $300 in account ‘B’).</p><p>So, under the “Read Committed” isolation level, one transaction won’t see uncommitted changes of other transactions, which is a great step towards maintaining data consistency.</p><p>However, now we have another problem, called “Non-Repeatable Read.” This occurs when, during the lifespan of a single transaction, it tries to read the same row twice but gets different data each time. This scenario is possible if, between the first and second read, another transaction modifies that row and commits the change.</p><h1 id="Topic-1-4-Repeatable-Read-Level"><a href="#Topic-1-4-Repeatable-Read-Level" class="headerlink" title="Topic 1.4: Repeatable Read Level"></a><strong>Topic 1.4: Repeatable Read Level</strong></h1><p>In a “Repeatable Read” isolation level, not only are the changes made by other transactions invisible until they’re committed (as we saw in “Read Committed”) but also, once a transaction reads some data, that data cannot change for the duration of that transaction.</p><p>In other words, the same SELECT query, when run multiple times within the same transaction, will return the exact same result, regardless of any other concurrent transactions. This constraint solves the “Non-repeatable Read” issue.</p><p>Let’s take an example:</p><p>Consider a situation where a transaction reads some rows from a table. Then, an independent transaction modifies some of those rows and commits the change. If the first transaction tries to read the same rows again, according to the “Read Committed” isolation level, it notices these changes.</p><p>But, in the “Repeatable Read” isolation level, the first transaction is unaware of any changes committed by the second transaction during its lifetime. Therefore, reading the same rows yields the same result.</p><p>Although it solves the “Dirty Read” and “Non-repeatable Read” problems, it’s prone to a different problem: the “Phantom Read” issue, which we will discuss in our next section.</p><h1 id="Topic-1-5-Serializable-Level"><a href="#Topic-1-5-Serializable-Level" class="headerlink" title="Topic 1.5: Serializable Level"></a><strong>Topic 1.5: Serializable Level</strong></h1><p>The “Serializable” level is the most stringent of all, providing the highest data consistency. It handles not only “Dirty Reads” and “Non-Repeatable Reads,” like the “Repeatable Read” level but also takes care of the “Phantom Reads” issue.</p><p>First, let’s understand what “Phantom Reads” are. It’s a phenomenon that occurs when, in the middle of a transaction, new rows are added or existing ones are removed by another transaction. It’s named as such because these records appear or disappear as if they were “phantoms.”</p><p>For example, consider a transaction that reads some rows from a table. An independent transaction, in the meantime, adds some new rows to that table and commits the change. If the first transaction reads the same table again, it sees new rows, which are like “phantoms.”</p><p>With the “Serializable” isolation level, such situations are impossible. When a transaction is run at this level, it behaves as if no other transactions even exist, eliminating any concurrency-related issues.</p><p>However, there’s a cost for such precision. The “Serializable” isolation level sharply reduces concurrency because it locks the datasets it reads. Therefore, it can lead to significant performance degradation for large databases.</p><p>In a nutshell, the “Serializable” isolation level ensures absolute data integrity at the expense of performance.</p><p>Having discussed each specific isolation level, it’s crucial to note that the level you choose ultimately depends on the nature of your application. It’s always about balancing between performance and data integrity.</p><h1 id="Topic-1-6-MySQL-Transaction-Isolation-Levels-Explanation"><a href="#Topic-1-6-MySQL-Transaction-Isolation-Levels-Explanation" class="headerlink" title="Topic 1.6: MySQL Transaction Isolation Levels Explanation."></a><strong>Topic 1.6: MySQL Transaction Isolation Levels Explanation</strong>.</h1><p>As we have discussed earlier, the four available transaction isolation levels that can be used in MySQL are Read Uncommitted, Read Committed, Repeatable Read, and Serializable. Each of these levels offers a different balance of data consistency, concurrency, and performance.</p><p>Yet, the question remains: how does MySQL implement these levels internally?</p><p>Well, MySQL mainly uses locking to ensure data consistency and isolation between concurrent transactions. It employs different types of locks such as shared and exclusive locks, depending on the requirements of the individual transaction and the isolation level set.</p><p>Without going too much into the nitty-gritty details, let’s understand what these locks are:</p><ol><li><strong>Shared Locks (S Locks)</strong>: Shared locks are held when a transaction merely reads a record and doesn’t modify it. More than one transaction can hold a shared lock for the same record at the same time.</li><li><strong>Exclusive Locks (X Locks)</strong>: Exclusive locks are held when a transaction modifies a record. Only one transaction can hold an exclusive lock to a record at a given time.</li></ol><p>These locks apply to the&nbsp;<em>read data</em>&nbsp;in order to maintain isolation and prevent data inconsistencies. For example:</p><ul><li>In the&nbsp;<strong>Read Uncommitted</strong>&nbsp;level, no locks are held that prevent other transactions from writing to the record.</li><li>In the&nbsp;<strong>Read Committed</strong>&nbsp;level, shared locks are placed but released as soon as the row has been read.</li><li>In the&nbsp;<strong>Repeatable Read</strong>&nbsp;level, shared locks are placed and retained until the transaction is completed.</li><li>In the&nbsp;<strong>Serializable</strong>&nbsp;level, shared locks are placed, and no other transaction can modify or insert new records until the transaction is finished.</li></ul><p>So, depending on which isolation level is being used, the MySQL engine will acquire and release these locks differently to achieve the desired level of isolation at the expense of concurrency and vice versa.</p><p>That said, this mechanism is just the tip of the iceberg. The actual implementation is much more complex and involves many other factors such as lock escalation, deadlock detection, log buffering, and more.</p><h1 id="Topic-1-7-Case-Studies"><a href="#Topic-1-7-Case-Studies" class="headerlink" title="Topic 1.7: Case Studies"></a>Topic 1.7: Case Studies</h1><p>In this section, we’ll look at the practical uses of different Transaction Isolation Levels, tying all of our learning together wit real-world scenarios.</p><p>The most suitable isolation level primarily depends on the specific read/write workload and the business requirements of each application. In real-world settings, we need to strike a balance between concurrency (the ability to allow multiple users to access the database simultaneously) and isolation (the degree to which each individual transaction is isolated from others).</p><p>Let’s look at a few scenarios:</p><p><strong>Scenario 1: Banking System</strong></p><p>For a banking system that is dealing with transactional data such as bank transfers, it would be catastrophic if dirty or non-repeatable reads occurred. Imagine if you withdrew money from an ATM, but due to a concurrent transaction, the system failed to immediately register the deduction. You could potentially withdraw more money than you have — a lovely scenario for us, but not for the banks!</p><p>So for such systems, a high level of isolation like&nbsp;<code>SERIALIZABLE</code>&nbsp;or&nbsp;<code>REPEATABLE READ</code>&nbsp;is often used, despite the potential impact on performance.</p><p><strong>Scenario 2: E-commerce Application</strong></p><p>For an e-commerce application, allowing dirty reads could result in selling more products than available. However, if we are strict on isolation level, it could slow down the application and affect the user experience. An isolation level like&nbsp;<code>READ COMMITTED</code>&nbsp;is frequently used here, trading off strict isolation for increased concurrency.</p><p><strong>Scenario 3: Data Analysis</strong></p><p>In data analysis or reporting scenarios where we are reading large volumes of data but not modifying it, a lower isolation level like&nbsp;<code>READ UNCOMMITTED</code>&nbsp;can often be used. This reduces the overhead of locks and allows for higher throughput.</p><p>Keep in mind that there’s no one-size-fits-all answer, it always depends on the specific requirements and circumstances of the system being built.</p><h1 id="Topic-1-8-Interview-ready"><a href="#Topic-1-8-Interview-ready" class="headerlink" title="Topic 1.8: Interview-ready"></a>Topic 1.8: Interview-ready</h1><p><strong>Question:</strong>&nbsp;Explain Transaction Isolation Levels.</p><p><strong>Answer:</strong>&nbsp;Transaction Isolation Levels control the degree of locking that occurs when selecting data from a database. The type of locks placed on data items affects the database’s concurrency level and consistency, which is vital in transaction processing. There are four standard transaction isolation levels defined in the SQL standard: Read Uncommitted, Read Committed, Repeatable Read, and Serializable.</p><p><strong>Question:</strong>&nbsp;What are the pros and cons of each Transaction Isolation Level?</p><p><strong>Answer:</strong></p><ul><li><strong>Read Uncommitted:</strong>&nbsp;Transactions may read changes made by others that have not yet been committed, leading to dirty reads and other inconsistencies. The benefit is less need for locks, leading to better performance.</li><li><strong>Read Committed:</strong>&nbsp;This level allows transactions to see only committed changes from other transactions. This prevents dirty reads but can still lead to non-repeatable reads or phantom reads. It usually offers a good balance between consistency and performance.</li><li><strong>Repeatable Read:</strong>&nbsp;Guarantees that any data read cannot change, avoiding dirty and non-repeatable reads, but can still result in phantom reads.</li><li><strong>Serializable:</strong>&nbsp;The highest level of isolation. Guarantees that transactions occur in a completely isolated manner. Avoids dirty reads, non-repeatable reads, and phantom reads but can lead to performance degradation due to extensive locking.</li></ul><p><strong>Question:</strong>&nbsp;When might you use each Isolation Level?</p><p><strong>Answer:</strong></p><ul><li><strong>Read Uncommitted:</strong>&nbsp;Data analysis tasks where seeing uncommitted changes is permissible and performance is critical.</li><li><strong>Read Committed:</strong>&nbsp;Applications where maintaining a high degree of concurrency is more important than the possibility of occasional inconsistencies, such as some low-impact e-commerce applications.</li><li><strong>Repeatable Read:</strong>&nbsp;Scenarios where it’s vital to maintain a consistent picture of data across multiple reads, such as certain financial applications.</li><li><strong>Serializable:</strong>&nbsp;Only used when strictly necessary due to performance implications, such as applications that manage highly sensitive data.</li></ul><p>These are just a few examples of potential interview questions. Remember, a deep understanding of these concepts will allow you to adapt to whatever specific questions your interviewer may ask.</p><h1 id="Topic-1-9-Review-and-Assessments"><a href="#Topic-1-9-Review-and-Assessments" class="headerlink" title="Topic&nbsp;1.9: Review and Assessments"></a>Topic&nbsp;<strong>1.9: Review and Assessments</strong></h1><p>Understanding transaction isolation levels is fundamental when you’re dealing with database transactions. So far, we’ve explored different transaction isolation levels, their uses, advantages, and potential pitfalls.</p><p>To solidify your understanding, let’s go through a quick review with some questions:</p><p><strong>1. Explain the four Transaction Isolation Levels as per the SQL standard.</strong></p><p>_Your Answer: ______</p><p><strong>2. Describe a scenario in which you would use the REPEATABLE READ isolation level.</strong></p><p>_Your Answer: ______</p><p><strong>3. ‘A dirty read occurs when a transaction reads the uncommitted data of another transaction.’ True or False?</strong></p><p>_Your Answer: ______</p><p><strong>4. Which transaction isolation level has the strictest locking, leading to the most substantial effects on transaction performance? Why?</strong></p><p>_Your Answer: ______</p><p><strong>5.</strong>&nbsp;==<strong>‘Phantom reads can occur at the Read Committed level.’ True or False?</strong>==</p><p>_Your Answer: ______</p><p>Take your time to answer these questions, reflect on your responses, and compare them with what we’ve covered in the lessons. When you’re ready, we can discuss your answers together. If you have any uncertainties or need a deeper explanation of any topics, don’t hesitate to ask. Let’s ensure you’ve mastered this concept!</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview15/">https://programmerscareer.com/zh-cn/mysql-interview15/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL interviews: What are ACID in a database?</title>
      <link href="/mysql-interview2/"/>
      <url>/mysql-interview2/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>I will prepare an outline of the topics for learning MySQL, particularly focusing on the ACID properties in a database.</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-ACID-in-theory"><a href="#Topic-1-1-ACID-in-theory" class="headerlink" title="Topic: 1.1 ACID in theory"></a>Topic: 1.1 ACID in theory</h1><p>ACID is an acronym used to define a set of properties that guarantee reliable processing of database operations, particularly within a transaction model.</p><p>The elements of ACID stand for:</p><ul><li><strong>Atomicity</strong>: This means that a transaction must be treated as a single unit, which either succeeds completely or fails entirely. If any part of a transaction fails, the entire transaction fails, and any changes made during the transaction are rolled back (returned back to their previous state).</li><li><strong>Consistency</strong>: Consistency ensures that a transaction brings a database from one valid state to another valid state. It doesn’t allow the transaction to leave the database in an inconsistent state.</li><li><strong>Isolation</strong>: Isolation assures that transactions are securely and independently processed at the same time without any interaction.</li><li><strong>Durability</strong>: As the name implies, durability makes sure that the result or effect of a committed transaction survives future system failures.</li></ul><p>It is through these core properties that databases maintain the integrity and consistency of data across all transactions.</p><h1 id="Topic-1-2-ACID-in-practice"><a href="#Topic-1-2-ACID-in-practice" class="headerlink" title="Topic: 1.2 ACID in practice"></a>Topic: 1.2 ACID in practice</h1><p>The ACID properties play a crucial role in maintaining the reliability and integrity of data in a MySQL database. Now, let’s see how they work in practice.</p><ul><li><strong>Atomicity</strong>: MySQL ensures atomicity with the help of transactions. In a MySQL database, a transaction is a set of SQL statements that are executed as a single unit. This means that either all the SQL statements within a transaction are executed, or none of them are. If a failure occurs at any point during a transaction, any changes that were made during that transaction are rolled back, and the database is returned to its previous state.</li><li><strong>Consistency</strong>: The consistency property in MySQL ensures that only valid data following all rules and constraints is written into the database. If a transaction results in invalid data, the entire transaction is rolled back and the database remains unchanged. This ensures that the database transitions from one consistent state to another.</li><li><strong>Isolation</strong>: In MySQL, concurrent transactions are isolated from each other. This means that the execution of one transaction doesn’t affect the execution of others. MySQL uses locks and different isolation levels to achieve isolation. This prevents problems like dirty reads, non-repeatable reads, and phantom reads.</li><li><strong>Durability</strong>: MySQL ensures durability by writing changes permanently to disk storage before a transaction is marked as successful. This means once a user has been notified of a successful transaction, they can be confident that the transaction has been permanently recorded and will survive any subsequent server failures or restarts.</li></ul><p>In understanding these, it’s important to note that MySQL gives you the flexibility to define transaction boundaries that fit your application’s requirements by providing different configurations.</p><h1 id="Topic-1-3-Atomicity-in-MySQL"><a href="#Topic-1-3-Atomicity-in-MySQL" class="headerlink" title="Topic: 1.3 Atomicity in MySQL"></a>Topic: 1.3 Atomicity in MySQL</h1><p>Atomicity is one of the key properties of ACID in database systems. It ensures that a transaction is treated as a single unit of work that either completely succeeds or fails. There is no state where a transaction is left partially complete.</p><p>In MySQL, transactions often encompass several SQL commands. Atomicity guarantees that if a problem such as a power outage, system crash, or network issue takes place after a few commands of a transaction have been executed, then those commands are undone. It’s like the transaction never happened. On the other hand, if all the commands in a transaction are executed successfully, the transaction is considered successfully committed to the database.</p><p>Here is an example of how atomicity works in a MySQL transaction:</p><p>Let’s say we are running a book store and we’re updating the quantity of books in our inventory and sales records. The transaction could look something like this:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">START TRANSACTION;  </span><br><span class="line">UPDATE Inventory SET Quantity = Quantity - 1 WHERE BookID = 100;  </span><br><span class="line">UPDATE Sales SET TotalSold = TotalSold + 1 WHERE BookID = 100;  </span><br><span class="line">COMMIT</span><br></pre></td></tr></tbody></table></figure><p>In this transaction, we have two UPDATE statements. Both these statements should succeed for the transaction to commit successfully. If either one fails, for instance due to a system crash or a network error, the entire transaction is rolled back due to the principle of atomicity, ensuring our inventory and sales records stay consistent.</p><p>Atomicity is a powerful property that ensures our database operations are safe and reliable.</p><h1 id="Topic-1-4-Consistency-in-MySQL"><a href="#Topic-1-4-Consistency-in-MySQL" class="headerlink" title="Topic: 1.4 Consistency in MySQL"></a>Topic: 1.4 Consistency in MySQL</h1><p>Consistency in database systems ensures that database transactions bring the system from one consistent state to another. This means that if a transaction is executed that violates the database’s consistency rules, the entire transaction will be rolled back and the database will remain unchanged.</p><p>In MySQL, consistency is preserved by using constraint systems. Constraints are rules enforced on columns in a table that prevent invalid data from being entered into them. There are several types of constraints, including:</p><ul><li><strong>Unique constraints</strong>: These ensure that all the values in a column are unique.</li><li><strong>Primary key constraints</strong>: These uniquely identify each record in the table.</li><li><strong>Foreign key constraints</strong>: These maintain referential integrity by ensuring the link between two tables is valid.</li><li><strong>Not null constraints</strong>: These ensure a column cannot have a NULL value.</li><li><strong>Check constraints</strong>: These ensure that all values in a column meet specific conditions.</li></ul><p>Here’s an example showing how a unique constraint ensures consistency:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE Employees (  </span><br><span class="line">    ID int NOT NULL,  </span><br><span class="line">    Name varchar(255) NOT NULL,  </span><br><span class="line">    Age int,  </span><br><span class="line">    PRIMARY KEY (ID),  </span><br><span class="line">    UNIQUE (Name)  </span><br><span class="line">);</span><br></pre></td></tr></tbody></table></figure><p>In the above example, the&nbsp;<code>UNIQUE (Name)</code>&nbsp;constraint ensures that no two employees can have the same name, promoting consistency. If we try to insert two employees with the same name, MySQL will not allow it and the consistency of the database will be preserved.</p><h1 id="Topic-1-5-Isolation-in-MySQL"><a href="#Topic-1-5-Isolation-in-MySQL" class="headerlink" title="Topic: 1.5 Isolation in MySQL"></a>Topic: 1.5 Isolation in MySQL</h1><p>Isolation is the “I” in ACID and it means that each transaction should occur in isolation from each other. This means that the execution of one transaction does not impact the execution of others. Isolation is vital in databases to prevent a number of issues that can arise when transactions are executed concurrently.</p><p>Concurrent transactions in MySQL are managed by a specific mechanism known as locking. MySQL provides different types of locks, including shared locks (read locks) and exclusive locks (write locks). The type of lock used depends on whether the transaction is read or write.</p><p>MySQL also supports multiple isolation levels which are:</p><ul><li>READ UNCOMMITTED: The lowest level of isolation. Transactions can see uncommitted changes from other transactions, often leading to issues like dirty reads.</li><li>READ COMMITTED: A somewhat higher level of isolation. Transactions can only see changes from other transactions that have been committed.</li><li>REPEATABLE READ: The default isolation in MySQL. Guarantees that all reads within a single transaction will return the same data, even if changes are made during the transaction.</li><li>SERIALIZABLE: The highest level of isolation. Transactions are executed serially, in other words, one after the other.</li></ul><p>Here is an example to illustrate isolation in MySQL:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- Starting a transaction  </span><br><span class="line">START TRANSACTION;  </span><br><span class="line">-- Reading data  </span><br><span class="line">SELECT * FROM table_name WHERE condition;  </span><br><span class="line">-- Attempting to read the same data will yield the same result,  </span><br><span class="line">-- irrespective of changes to the data by other transactions  </span><br><span class="line">SELECT * FROM table_name WHERE condition;  </span><br><span class="line">-- Committing the transaction  </span><br><span class="line">COMMIT;</span><br></pre></td></tr></tbody></table></figure><p>In the example above, under the repeatable-read isolation level, the two SELECT statements will give the same result even if there are changes made by other transactions because the changes made by the other transactions will not be visible to this transaction until it is committed.</p><h1 id="Topic-1-6-Durability-in-MySQL"><a href="#Topic-1-6-Durability-in-MySQL" class="headerlink" title="Topic: 1.6 Durability in MySQL"></a>Topic: 1.6 Durability in MySQL</h1><p>The term ‘Durability’ in the context of database systems (the ‘D’ in ACID) concerns the permanence of data once a transaction has been committed. If a transaction has been successfully committed, durability guarantees that the changes made by that transaction will survive any subsequent failures, such as power loss, system crash, or other unexpected shutdowns.</p><p>MySQL ensures durability by writing all transactional changes to a binary log before the changes are actually made. This binary log serves as a historical record of all data modifications, which can be used to recreate the state of the data from any point in time.</p><p>Whenever a transaction is committed in MySQL, all the changes made by that transaction are first written to the binary log, and then MySQL proceeds with actually carrying out the changes. If a system failure occurs, MySQL can replay the binary log up to the point of the last committed transaction, ensuring that all committed transactions are durable.</p><p>Let’s consider an example where a record is being updated in a table:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">START TRANSACTION;  </span><br><span class="line">UPDATE Employees SET Salary = Salary + 5000 WHERE ID = 100;  </span><br><span class="line">COMMIT;</span><br></pre></td></tr></tbody></table></figure><p>In the above transaction, an employee’s salary is being updated. Once the&nbsp;<code>COMMIT</code>&nbsp;statement is executed, the update is immediately written to the binary log before the actual update takes place. This ensures that even if a system crash occurs after the update, the transaction will not be lost.</p><h1 id="Topic-1-7-Transactional-Control-in-MySQL"><a href="#Topic-1-7-Transactional-Control-in-MySQL" class="headerlink" title="Topic: 1.7 Transactional Control in MySQL"></a><strong>Topic</strong>: 1.7 Transactional Control in MySQL</h1><p>Transactional control is a way to manage ACID properties and refers to the operations and commands used to control transactions. In MySQL, the transactional control commands include START TRANSACTION, COMMIT, and ROLLBACK.</p><ul><li><code>START TRANSACTION</code>: Marks the start of a transaction.</li><li><code>COMMIT</code>: Marks the end of a transaction, and permanently saves any changes made since the last COMMIT or START TRANSACTION.</li><li><code>ROLLBACK</code>: Reverses any changes made since the last COMMIT or START TRANSACTION.</li></ul><p>Here’s an example of transactional control in action in MySQL:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">-- Starting a transaction  </span><br><span class="line">START TRANSACTION;  </span><br><span class="line">-- Inserting data into the table  </span><br><span class="line">INSERT INTO Customers (Name, Email) VALUES ('John Doe', 'johndoe@example.com');  </span><br><span class="line">-- If something went wrong with the previous statement, we can roll back (reverse) the transaction  </span><br><span class="line">ROLLBACK;  </span><br><span class="line">-- Now let's try again, this time without any mistakes  </span><br><span class="line">START TRANSACTION;  </span><br><span class="line">INSERT INTO Customers (Name, Email) VALUES ('John Doe', 'johndoe@example.com');  </span><br><span class="line">-- Since everything went well, we can now commit the transaction (finalise and save our changes)  </span><br><span class="line">COMMIT;</span><br></pre></td></tr></tbody></table></figure><p>In this example, the&nbsp;<code>ROLLBACK</code>&nbsp;statement was used to reverse a transaction that had some errors. Once the issues were resolved, the transaction was tried again, and once successful, the&nbsp;<code>COMMIT</code>&nbsp;statement was used to finalise and save the changes.</p><p>Transactional control helps maintain the ACID properties by providing the capability to group one or more statements together into a single transaction, giving greater control over how data is managed and ensuring data integrity.</p><h1 id="Topic-1-8-Advanced-Topics-in-MySQL"><a href="#Topic-1-8-Advanced-Topics-in-MySQL" class="headerlink" title="Topic: 1.8 Advanced Topics in MySQL"></a><strong>Topic</strong>: 1.8 Advanced Topics in MySQL</h1><p>Once you have a solid understanding of ACID principles and how they are implemented in MySQL, there are several more advanced topics you might also consider exploring further to enhance your MySQL expertise. Some notable areas include but not limited to:</p><ul><li><strong>Indexing:</strong>&nbsp;Indexes are used in MySQL to speed up the retrieval of data from databases. An index in a database is similar to an index at the end of a book — it helps you find information more quickly.</li><li><strong>Stored procedures:</strong>&nbsp;These are pre-written SQL statements stored under a name and executed as a unit. They help to avoid repetitive writing of SQL code that is often required.</li><li><strong>Data types:</strong>&nbsp;MySQL has several datatypes to accommodate a wide variety of data. From alphanumeric strings, date and time, numerical values, and more complex data types like JSON and spatial data types are available in MySQL.</li><li><strong>Handling NULL values:</strong>&nbsp;NULL values in a database can be quite tricky to handle. They represent missing or unknown data. MySQL provides several functions like IS NULL, IS NOT NULL, IFNULL(), and COALESCE() to handle NULL values.</li><li><strong>Joins and Unions:</strong>&nbsp;Joins are used to combine rows from two or more tables based on a related column. They are frequently used in databases as it’s rarely the case that all data needed is in one table. Unions are used to combine the result set of two or more SELECT statements.</li><li><strong>Security:</strong>&nbsp;Dealing with user permissions and secure connections to MySQL database are an integral part of any database management.</li></ul><h1 id="Topic-1-9-Review-and-Assessments"><a href="#Topic-1-9-Review-and-Assessments" class="headerlink" title="Topic: 1.9 Review and Assessments"></a><strong>Topic</strong>: 1.9 Review and Assessments</h1><p>Here’s a summary of what we’ve learned throughout these lessons:</p><ol><li><strong>ACID in Theory:</strong>&nbsp;We learned about the ACID properties (Atomicity, Consistency, Isolation, Durability) and their importance in database systems.</li><li><strong>ACID in Practice:</strong>&nbsp;We went beyond theory to understand how these properties are implemented in MySQL and how they help ensure data integrity and consistency.</li><li><strong>Atomicity in MySQL:</strong>&nbsp;We explored Atomicity in MySQL with practical examples and saw how it ensures that a database operation either completes in its entirety or does not occur at all.</li><li><strong>Consistency in MySQL:</strong>&nbsp;We learned how MySQL ensures data remains consistent before and after any SQL operation.</li><li><strong>Isolation in MySQL:</strong>&nbsp;We discussed the concept of Isolation and its importance in concurrent database processing.</li><li><strong>Durability in MySQL:</strong>&nbsp;We learned what Durability means in terms of a MySQL database, and observed how MySQL ensures that changes to data survive any subsequent failures.</li><li><strong>Transactional Control in MySQL:</strong>&nbsp;We understood how to manage ACID properties using transactional control in MySQL. We, majorly, understood the usage of START TRANSACTION, COMMIT, and ROLLBACK.</li><li><strong>Advanced Topics in MySQL:</strong>&nbsp;We dived into more advanced topics like indexing, stored procedures, data types, and more to expand our understanding of MySQL.</li></ol><p>I would recommend revisiting each of these topics and ensuring you have a solid understanding.</p><p>here are some assessment questions to test your understanding of ACID properties and Transactional Control in MySQL:</p><p><strong>Question 1: What is Atomicity in MySQL? How is it implemented in practice?</strong></p><p><strong>Question 2: What does Consistency in MySQL mean and how does MySQL ensure data remains consistent before and after any SQL operation?</strong></p><p><strong>Question 3: How is Isolation achieved in MySQL especially during concurrent database processing?</strong></p><p><strong>Question 4: What does the Durability property entail in MySQL?</strong></p><p><strong>Question 5: In terms of transactional control in MySQL, discuss the importance of the commands START TRANSACTION, COMMIT, and ROLLBACK.</strong></p><hr><h2 id="Answer-1"><a href="#Answer-1" class="headerlink" title="Answer 1:"></a>Answer 1:</h2><p>Atomicity in MySQL signifies that a transaction must be treated as a single, indivisible unit, which means either it is fully completed or not executed at all. In practice, MySQL implements atomicity using the START TRANSACTION, COMMIT, and ROLLBACK commands. If a transaction is committed, all changes made are permanent. If a transaction is rolled back, no changes are made.</p><h2 id="Answer-2"><a href="#Answer-2" class="headerlink" title="Answer 2:"></a>Answer 2:</h2><p>Consistency in MySQL ensures that all changes to data bring the database from one valid state to another, maintaining database rules and integrity. MySQL employs several mechanisms to ensure consistency. These include defined table schemas, predefined rules, triggers, and constraints like primary key, foreign key, unique, not null, and check constraints.</p><h2 id="Answer-3"><a href="#Answer-3" class="headerlink" title="Answer 3:"></a>Answer 3:</h2><p>Isolation in MySQL ensures that concurrently executing transactions result in a system state that would be obtained if transactions were executed sequentially i.e., one after the other. MySQL achieves this using various isolation levels and locking mechanisms.</p><h2 id="Answer-4"><a href="#Answer-4" class="headerlink" title="Answer 4:"></a>Answer 4:</h2><p>The Durability property in MySQL ensures that once a transaction is committed, it will remain so, even in cases of system failure, power loss, crash or error. This is typically achieved through the use of database backups and transaction logs that can be used to restore the database to its state right before the failure occurred.</p><h2 id="Answer-5"><a href="#Answer-5" class="headerlink" title="Answer 5:"></a>Answer 5:</h2><p>In MySQL, START TRANSACTION signifies the operation’s starting point. COMMIT means the changes made in the current transaction are made permanent. ROLLBACK signifies that if any error occurs during the processing of any SQL command, then the already executed SQL commands are reverted to maintain the database integrity. Together, these commands help in managing ACID properties during a transaction in a MySQL setting.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview2/">https://programmerscareer.com/zh-cn/mysql-interview2/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL interviews: How does MySQL design indexes and optimize queries?</title>
      <link href="/mysql-interview3/"/>
      <url>/mysql-interview3/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>let’s sketch out a thorough curriculum for gaining a deep understanding of MySQL, focusing specifically on index design and query optimization</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-MySQL-Overview"><a href="#Topic-MySQL-Overview" class="headerlink" title="Topic: MySQL Overview"></a><strong>Topic</strong>: MySQL Overview</h1><p>A major part of the digital world consists of databases, and MySQL is one of the premiere players in this realm. So, what really is MySQL?</p><p>MySQL is a relational database management system. But what separates MySQL from the others? It is open-source, meaning it is free for anyone to use and modify. This has led to its widespread adoption across the globe by developers and organizations alike.</p><p>You’ll often find MySQL backing up the data necessities of websites, applications, and even aiding in scientific research. Its flexibility in supporting a range of data types, offering a surfeit of functions that manipulate and extract data, and having a robust security system has solidified its importance in the world of databases.</p><p>Most importantly, MySQL has a reputation for being extremely reliable and fast when it comes to data retrieval and management, making it a favourite among many.</p><p>In the heart of MySQL is the Structured Query Language, SQL, giving users the power to manipulate databases effectively. We can create, retrieve, update, delete data, and perform other intricate analyses through SQL commands.</p><p>The upcoming topics will help familiarize you with SQL, both the basics and more complex commands, in MySQL as we progress in our curriculum.</p><p>Understanding MySQL is fundamental to grasping future topics like database schemas, principles of database design, and specific topics like designing indexes and query optimization in MySQL.</p><h1 id="Topic-SQL-in-MySQL-Basics"><a href="#Topic-SQL-in-MySQL-Basics" class="headerlink" title="Topic: SQL in MySQL (Basics)"></a><strong>Topic</strong>: SQL in MySQL (Basics)</h1><p>SQL, or Structured Query Language, is the backbone of all relational database management systems, including MySQL. It is the language we use to communicate and interact with databases. Let’s take a look at some of the fundamental SQL commands that you will need to work with MySQL databases.</p><ul><li><strong>SELECT</strong>: This command is the one we use the most — it allows us to select data from the database. It can be as simple as&nbsp;<code>SELECT * FROM people;</code>, which would select and display all the data from the “people” table. Alternatively, you might choose to select only certain columns, say, first names and lastnames:&nbsp;<code>SELECT firstname, lastname FROM people;</code>.</li><li><strong>INSERT INTO</strong>: This command allows us to insert new data into our database. For example,&nbsp;<code>INSERT INTO people (firstname, lastname) VALUES('John', 'Doe');</code>, would insert a new person with the first name of John and the last name of Doe.</li><li><strong>UPDATE</strong>: As the name suggests, with this command, we can update existing data. For instance,&nbsp;<code>UPDATE people SET age=30 WHERE firstname='John' AND lastname='Doe';</code>, would update the age of all people named John Doe to 30.</li><li><strong>DELETE</strong>: A word of caution, this command deletes data! Its use should not be taken lightly. An example usage:&nbsp;<code>DELETE FROM people WHERE firstname='John' AND lastname='Doe';</code>, would delete all the records for people named John Doe.</li><li><strong>CREATE</strong>,&nbsp;<strong>ALTER</strong>, and&nbsp;<strong>DROP</strong>: These commands are used to manipulate the schema or structure of the database itself, and not the stored data. CREATE lets us make new tables, ALTER allows changing table structures, and DROP deletes tables.</li></ul><p>Getting well-versed with these commands will provide a strong foundation to dive deeper into more advanced commands of SQL in MySQL.</p><p>Remember, practice makes perfect. Try running these commands and understanding their outcomes.</p><h1 id="Topic-SQL-in-MySQL-Advanced"><a href="#Topic-SQL-in-MySQL-Advanced" class="headerlink" title="Topic: SQL in MySQL (Advanced)"></a><strong>Topic</strong>: SQL in MySQL (Advanced)</h1><p>While the basic SQL commands provide a solid foundation, mastering MySQL truly comes through understanding and utilizing its more advanced tools. Here are a few advanced MySQL commands that will let you manipulate your databases more effectively:</p><ul><li><strong>JOIN</strong>: SQL’s JOIN clause allows you to combine rows from two or more tables based on a common field. There are several types of JOIN commands — INNER JOIN, LEFT JOIN, RIGHT JOIN, FULL OUTER JOIN, etc. An example of a JOIN command:&nbsp;<code>SELECT Orders.OrderID, Customers.CustomerName FROM Orders INNER JOIN Customers ON Orders.CustomerID = Customers.CustomerID;</code>. This command will combine and display order IDs and customer names from the Orders and Customers tables where the customerIDs match.</li><li><strong>GROUP BY</strong>: This command is used with the aggregate functions COUNT, MAX, MIN, SUM, and AVG to group the result set by one or more columns. An example:&nbsp;<code>SELECT COUNT(animal_type), animal_type FROM animal GROUP BY animal_type;</code>&nbsp;will show the number of each type of animal in the ‘animal’ table.</li><li><strong>HAVING</strong>: This acts like a WHERE clause, but for aggregate functions. A basic example:&nbsp;<code>SELECT COUNT(product_id), product_name FROM products GROUP BY product_name HAVING COUNT(product_id) &gt; 5;</code>&nbsp;will show the product names and their quantities from the ‘products’ table, but only for those where the count of the product_id is greater than 5</li><li><strong>UNION</strong>: The UNION operator is used to combine the result-set of two or more SELECT statements. Each SELECT statement within the UNION must have the same number of columns, and the columns must also have similar data types. Also, the columns in each SELECT statement must be ordered in the exact same way. For example:&nbsp;<code>SELECT column_name(s) FROM table1 UNION SELECT column_name(s) FROM table2;</code>.</li><li><strong>CASE</strong>: This allows for conditional statements in SQL. For example:&nbsp;<code>SELECT CASE WHEN age &lt; 18 THEN 'Children' WHEN age BETWEEN 18 AND 65 THEN 'Adults' ELSE 'Seniors' END AS age_group FROM people;</code>&nbsp;will categorize people in the ‘people’ table into age groups based on their age.</li></ul><p>Mastering these commands will take you a long way in harnessing the full power of MySQL.</p><p>Remember, to master these, hands-on practice is key.</p><h1 id="Topic-Database-Schemas-in-MySQL"><a href="#Topic-Database-Schemas-in-MySQL" class="headerlink" title="Topic: Database Schemas in MySQL"></a><strong>Topic</strong>: Database Schemas in MySQL</h1><p>Behind every efficient database is a well-crafted schema. A database schema is an abstract blueprint of your database structure — it demonstrates how data is organized and accessed. So let’s get into it!</p><p>When you think of a database, visualize it as a whole chest of drawers. In MySQL terminology, tables within that chest become a part of our database schema. They bear the actual data that we interact with via SQL commands.</p><p>Now each drawer, or table, further contains divisions, referred to as columns or fields in MySQL. Each column represents a type of data within a table. For example, in a table (or drawer) storing employee information, different categories of information like Employee ID, Name, Job Position, etc., become different columns.</p><p>Finally, the actual individual pieces of data stored in each ‘division’ are called records or rows. For instance, the information related to a specific employee (John Doe, ID 12345, Position Manager) becomes a row in the Employee table.</p><p>Designing database schemas may sound straightforward enough — make a table for each type of data, right? Unfortunately, not! An efficiently designed schema mitigates redundancy, prevents data anomalies, and optimizes resource usage.</p><p>MySQL strongly implements the principles of the relational database, arranging data in tables that are inter-linked. This brings us to concepts like Primary Keys and Foreign Keys which help establish connections between tables (we will get in detail during the Database Design lesson).</p><p>Today’s lesson provides a foundation for the following ones where we will discuss principles of database design, indexes, and query optimization.</p><h1 id="Topic-Principles-of-Database-Design"><a href="#Topic-Principles-of-Database-Design" class="headerlink" title="Topic: Principles of Database Design"></a><strong>Topic</strong>: Principles of Database Design</h1><p>Designing a database goes beyond just deciding tables, columns, and using SQL commands. A well-designed database ensures efficient and reliable data storage and retrieval. Let’s go through some of the fundamental principles of database design:</p><ul><li><strong>Entity-Relationship (ER) Model</strong>: Think of entities as ‘things’ or ‘objects’ that are relevant to your database (like employees in a company database). Relationships define how these entities interact with each other. Diagrammatically representing these entities and their relationships gives us an ER model, a foundational step in database design.</li><li><strong>Normalization</strong>: This is the process of organizing a database to eliminate redundancy and improve data integrity. There are several normal forms (first, second, third, BCNF), each with prerequisites that must be met.</li><li><strong>Primary Key</strong>: Every table must have a column (or a set of columns), known as the Primary Key, that uniquely identifies every record in the table.</li><li><strong>Foreign Key</strong>: This is a field (or collection of fields) in one table, that is a primary key in another table. The foreign key is used to prevent actions that would destroy the links between tables.</li><li><strong>Atomicity</strong>: It’s the idea that an operation either completely succeeds or fails. You don’t want a database update to be ‘partially’ done — it either does fully or not at all.</li><li><strong>Security</strong>: Databases often hold sensitive data. Properly designed databases have multiple layers of security including authorization, access control, and encryption.</li><li><strong>Backup and Recovery</strong>: Data is valuable. A well-designed database includes strategies for regular backup and efficient recovery in case of data loss.</li><li><strong>Scalability and Performance</strong>: A good database design also takes into consideration scalability (will the database handle growth in data volume?) and performance (how quickly can the system respond to queries?).</li></ul><p>Understanding these principles will go a long way in being able to design a database that is robust, reliable, and efficient.</p><h1 id="Topic-MySQL-Indexes"><a href="#Topic-MySQL-Indexes" class="headerlink" title="Topic: MySQL Indexes"></a><strong>Topic</strong>: MySQL Indexes</h1><p>Indexes are a critical aspect of database design that boost the speed of data retrieval operations on a database table. Similar to the index in a book, an index in MySQL allows the database system to find the data without having to scan every row in the database table.</p><p>Here are some key points to remember about indexes in MySQL:</p><ul><li>Indexes are used to find rows with specific column values faster. Without an index, MySQL must begin with the first row and then read through the entire table to find the relevant rows.</li><li>Indexes are also used to enforce UNIQUEness constraints, and to aid efficient sorting and grouping.</li><li>Indexes can be classified based on their structure: B-Tree, Hash, RTree, and Full-text.</li><li>The most commonly used index structure is the BTree (Balanced Tree), which sorts the data for fast retrieval in a way that ensures the tree remains balanced, hence optimizing search times.</li><li>Indexing comes at a cost: although data retrieval is faster, data modification operations (such as INSERT, UPDATE, DELETE) will become slower due to the additional operations required to maintain the index.</li><li>Not all fields need an index. Only fields that you are likely to use in a WHERE, ORDER BY, GROUP BY, or JOIN clause will benefit from an index.</li></ul><p>Understanding and properly implementing indexes can greatly improve the performance of your database operations.</p><h1 id="Topic-Designing-Indexes-in-MySQL"><a href="#Topic-Designing-Indexes-in-MySQL" class="headerlink" title="Topic: Designing Indexes in MySQL"></a><strong>Topic</strong>: Designing Indexes in MySQL</h1><p>Designing indexes is a vital aspect of efficient database management. Here we’re going to talk about how MySQL designs indexes and what strategies it employs to improve overall performance.</p><p>Creating the right index is more of an art than a science, and it usually involves a trade-off between query speed and write speed.</p><p>Steps to consider while designing indexes:</p><p><strong>Choosing the right columns:</strong>&nbsp;An index can include multiple columns, but it’s essential to consider the column order. MySQL can only use an index if the query involves the leftmost column of the index.</p><p><strong>Considering the data type:</strong>&nbsp;The smaller the data type, in terms of storage, the smaller the index, and therefore, the faster the queries.</p><p><strong>Consider the cardinality:</strong>&nbsp;High cardinality columns, meaning columns that contain many unique values, tend to have more efficient indexes.</p><p><strong>Understanding your workload:</strong>&nbsp;If your application performs lots of SELECT queries, more indexes can be beneficial. On the other hand, if your application does more INSERT, UPDATE, and DELETE operations, more indexes could slow it down.</p><p><strong>Analyzing your queries:</strong>&nbsp;Use MySQL’s EXPLAIN statement to understand how your indexes are being used and where improvements can be made.</p><p>Remember that indexes are a vital part of database design. They can significantly increase the performance of your database, so it’s definitely worth considering whenever you’re querying large amounts of data.</p><h1 id="Topic-MySQL-Query-Optimization"><a href="#Topic-MySQL-Query-Optimization" class="headerlink" title="Topic: MySQL Query Optimization"></a><strong>Topic</strong>: MySQL Query Optimization</h1><p>An essential part of managing any database is ensuring that it functions efficiently. When dealing with significant amounts of data, queries can become time-consuming. Therefore, optimizing these queries in MySQL is crucial to improving the overall performance of your database system.</p><p>In MySQL, query optimization involves multiple steps:</p><ol><li><strong>Parsing</strong>: MySQL starts by parsing the SQL query to ensure its syntax is correct, and the database objects exist.</li><li><strong>Pre-processing</strong>: Next, MySQL decides the order of table reads, which is vital for multi-table queries. It also determines the indexes to use.</li><li><strong>Optimization</strong>: MySQL then applies various optimization strategies to make the query more efficient. The most notable is the use of indexes, but MySQL also leverages other techniques like merging multiple similar queries into one, reducing temporary tables, and choosing efficient routes for joining tables.</li><li><strong>Execution</strong>: Finally, MySQL executes the query and returns the result. The actual execution is a balance between fetching the data from the storage engine and processing the SQL command.</li></ol><p>Understanding how MySQL optimizes queries helps in writing efficient SQL code and designing better database schemas. It can significantly reduce query execution time, especially for complex queries and large databases.</p><p>Remember to use the&nbsp;<strong>EXPLAIN</strong>&nbsp;statement in MySQL, which can provide insights on how to optimize your queries better. It shows how MySQL plans to execute a query, which can help identify bottlenecks or areas for improvement.</p><h1 id="Topic-Review-and-Assessments"><a href="#Topic-Review-and-Assessments" class="headerlink" title="Topic: Review and Assessments"></a><strong>Topic</strong>: Review and Assessments</h1><p>After journeying through the intricate landscape of MySQL, it’s a good time for a thorough revision of every topic covered, and subsequently, evaluating your practical knowledge through assessments.</p><p>To recap:</p><ol><li>We started with&nbsp;<strong>1.1 MySQL Overview</strong>, understanding MySQL role as a robust database management system.</li><li>We then moved into the essence of MySQL,&nbsp;<strong>1.2 SQL in MySQL (Basics)</strong>&nbsp;and&nbsp;<strong>1.3 SQL in MySQL (Advanced)</strong>, mastering the rudimentary and the more complex SQL commands used in MySQL.</li><li>We studied the structure of databases through the concept of&nbsp;<strong>1.4 Database Schemas in MySQL</strong>.</li><li>Understanding the&nbsp;<strong>1.5 Principles of Database Design</strong>&nbsp;helped us grasp the structure ensuring databases function effectively.</li><li>With&nbsp;<strong>1.6 MySQL Indexes</strong>&nbsp;we comprehended the significance of indexes in speeding up data retrieval.</li><li>Then we learned how to enhance performance by&nbsp;<strong>1.7 Designing Indexes in MySQL</strong>.</li><li>Lastly, we explored how MySQL optimises queries to improve database performance in&nbsp;<strong>1.8 MySQL Query Optimization</strong>.</li></ol><p>Now, if you’d like to test your understanding, you can say&nbsp;<strong>“/test”</strong>&nbsp;to undertake an assessment. Remember, this assessment is designed to help solidify your knowledge and identify areas that might need a bit more attention. Don’t stress about it — it’s a tool for learning, not a final exam.</p><p>Let’s proceed with the assessment.</p><h2 id="Question-1"><a href="#Question-1" class="headerlink" title="Question 1:"></a>Question 1:</h2><p>State the difference between&nbsp;<code>CHAR</code>,&nbsp;<code>VARCHAR</code>, and&nbsp;<code>TEXT</code>&nbsp;data types in MySQL?</p><h2 id="Question-2"><a href="#Question-2" class="headerlink" title="Question 2:"></a>Question 2:</h2><p>Explain what a&nbsp;<code>JOIN</code>&nbsp;operation is in MySQL, and list its different types.</p><h2 id="Question-3"><a href="#Question-3" class="headerlink" title="Question 3:"></a>Question 3:</h2><p>What are&nbsp;<code>NULL</code>&nbsp;values in MySQL, and how can you check for such values in a database table?</p><hr><h2 id="Answer-1"><a href="#Answer-1" class="headerlink" title="Answer 1:"></a>Answer 1:</h2><p><code>CHAR</code>&nbsp;and&nbsp;<code>VARCHAR</code>&nbsp;are both used to store string values in MySQL, with main differences being:</p><ul><li><code>CHAR</code>&nbsp;is a fixed length data type, meaning that it reserves the specified amount of space regardless of the actual size of the data. It’s faster for read operations because MySQL knows exactly where to find the value of a&nbsp;<code>CHAR</code>&nbsp;column.</li><li><code>VARCHAR</code>&nbsp;is a variable length data type. It consumes space proportional to the size of the data stored. It saves on storage if you’re dealing with strings of varying lengths.</li><li><code>TEXT</code>&nbsp;is also a data type for storing strings, but it’s meant for storing large amounts of text. The length of the string is not fixed, similar to&nbsp;<code>VARCHAR</code>.</li></ul><h2 id="Answer-2"><a href="#Answer-2" class="headerlink" title="Answer 2:"></a>Answer 2:</h2><p>A&nbsp;<code>JOIN</code>&nbsp;operation in MySQL combines rows from two or more tables based on a related column between them. Types of&nbsp;<code>JOIN</code>&nbsp;include:</p><ul><li><code>INNER JOIN</code>: Returns records that have matching values in both tables being joined.</li><li><code>LEFT JOIN</code>&nbsp;(or&nbsp;<code>LEFT OUTER JOIN</code>): Returns all records from the left table and the matched records from the right table. If no match is found, the result is&nbsp;<code>NULL</code>&nbsp;on the right side.</li><li><code>RIGHT JOIN</code>&nbsp;(or&nbsp;<code>RIGHT OUTER JOIN</code>): Returns all records from the right table and the matched records from the left table. If no match is found, the result is&nbsp;<code>NULL</code>&nbsp;on the left side.</li><li><code>FULL JOIN</code>&nbsp;(or&nbsp;<code>FULL OUTER JOIN</code>): Returns all records when there is a match in the left table or the right table records.</li></ul><h2 id="Answer-3"><a href="#Answer-3" class="headerlink" title="Answer 3:"></a>Answer 3:</h2><p><code>NULL</code>&nbsp;values in MySQL represent missing or unknown data. You can check for&nbsp;<code>NULL</code>&nbsp;values in a database table using the&nbsp;<code>IS NULL</code>&nbsp;or&nbsp;<code>IS NOT NULL</code>&nbsp;clauses in your SQL statement.</p><p>Remember, when dealing with&nbsp;<code>NULL</code>, it’s not a value; it’s a state indicating that the value is unknown or missing, so&nbsp;<code>NULL</code>&nbsp;does not equal&nbsp;<code>NULL</code>.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview3/">https://programmerscareer.com/zh-cn/mysql-interview3/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL Interviews: Why does MySQL use B+ trees for indexing</title>
      <link href="/mysql-interview4/"/>
      <url>/mysql-interview4/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Have you ever been asked a similar question in an interview? Or you will meet in the future, let’s get started together</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-Why-Indexing"><a href="#Topic-1-1-Why-Indexing" class="headerlink" title="Topic 1.1: Why Indexing?"></a><strong>Topic 1.1: Why Indexing?</strong></h1><p>Just like an index in a book helps us find information quickly without having to read the entire book, an index in a database helps the database application find data quickly without having to search every row in a database table every time a database table is accessed. Indexes significantly speed up data retrieval process, which leads to better application performance.</p><p>Indexes are crucial in large tables for optimizing ‘SELECT’ queries and where clauses, as they minimize the number of pages the system must go through to find pertinent data.</p><p>However, they do come with their fair share of cautions. Indexes, while improving read performance, can slow down write (insert, update, delete) performance. This is because every time data changes, indices need to be updated. This is also why having too many indices can actually harm database performance.</p><p>In a nutshell, a good index is all about creating the right balance. We want to keep queries fast and productive, but without overloading the system with performance hampering index maintenance.</p><h1 id="Topic-1-2-Types-of-Indexes-in-MySQL"><a href="#Topic-1-2-Types-of-Indexes-in-MySQL" class="headerlink" title="Topic 1.2: Types of Indexes in MySQL"></a><strong>Topic 1.2: Types of Indexes in MySQL</strong></h1><p>MySQL utilizes various types of indexes to boost the query performance. Here are the common ones:</p><ul><li><strong>Primary Index:</strong>&nbsp;This index mandates that the column contains only unique, non-null values. Each table can only possess one primary index.</li><li><strong>Unique Index:</strong>&nbsp;This type of index prevents the field from having duplicate values if the column does not contain null values. Except for permit null values, the unique index is almost the same as the primary index.</li><li><strong>Index (or Normal Index):</strong>&nbsp;It allows duplicate and null values in the column. It’s the basic type of index in MySQL.</li><li><strong>Full-text Index:</strong>&nbsp;If you’re dealing with text data and often use full-text search, then this index comes in handy.</li><li><strong>Composite Index (or Multiple-column index):</strong>&nbsp;If you use multiple columns in WHERE clauses, creating a composite index on those fields can speed up the query performance.</li></ul><p>These index types serve different purposes, and understanding them helps us utilize them properly to make sure that the database we are creating or managing performs in the most optimal way.</p><h1 id="Topic-1-3-B-Trees-Explained"><a href="#Topic-1-3-B-Trees-Explained" class="headerlink" title="Topic 1.3: B+ Trees Explained"></a><strong>Topic 1.3: B+ Trees Explained</strong></h1><p>At its core, a B+ Tree is a type of self-balancing search tree that maintains sorted data and allows for efficient insertion, deletion, and search operations.</p><p>In contrast to binary search trees (BST), where each node has at most two children (left and right), a B+ Tree is a multileveled tree where each node can have multiple children, typically more than two. The important features of a B+ Tree are:</p><ol><li>All data is stored at the leaf level.</li><li>All leaf nodes are at the same depth, ensuring balance.</li><li>All leaf nodes are linked, allowing for efficient range queries.</li><li>Non-leaf nodes store copies of the keys to guide the search.</li></ol><p>The combination of these characteristics makes B+ Trees particularly well-suited for systems with large amounts of data and a significant number of read operations, such as databases or filesystems.</p><p>Each node in a B+ Tree contains a number of keys and pointers. The keys act as separation values which divide its subtrees. For example, if a node contains the values [10, 20, 30] it has four child nodes (subtrees).</p><p>One fundamental property in a B+ tree is that if a node has&nbsp;<code>n</code>&nbsp;keys, it will have&nbsp;<code>n+1</code>&nbsp;pointers (children). Another property is that all keys of a B+ tree are sorted.</p><p>As B+Trees rise in popularity due to their high efficiency in accessing, storing, and retrieving data, they’ve become closely linked with the database world, including MySQL.</p><h1 id="Topic-1-4-Advantages-of-B-Trees"><a href="#Topic-1-4-Advantages-of-B-Trees" class="headerlink" title="Topic 1.4: Advantages of B+ Trees"></a><strong>Topic 1.4: Advantages of B+ Trees</strong></h1><p>let’s delve deeper into the advantages B+ Trees bring about to Databases, especially MySQL:</p><ol><li><strong>Efficient Disk Read/Write Operations:</strong>&nbsp;Each node in a B+ Tree contains multiple keys and pointers packed together on a single disk block, this significantly reduces the I/O operations for reading or writing large ranges of data. So, you can scan large portions of data using minimum disk reads.</li><li><strong>Faster Search Time:</strong>&nbsp;As B+ Trees are height-balanced, an equal number of comparisons leads to all leaf nodes, making data retrieval quicker. The time complexity of search in a B+ Tree is logarithmic, making search operations efficient.</li><li><strong>Effective Insertions and Deletions:</strong>&nbsp;The data structure of B+ Trees enables them to remain balanced and ordered during both data insertions and deletions. This result in minimum disk space wastage and maximum performance efficiency.</li><li><strong>Ascending/Descending Sort Order Retrieval:</strong>&nbsp;The leaf nodes of B+ Tree are linked together. This feature significantly helps in quicker sequential reading of data in either ascending or descending sort order, which is a common operation in databases.</li><li><strong>Great for both Equality and Range Retrieval:</strong>&nbsp;With its self-balancing property and minimum and maximum keys in each page, B+ Trees are phenomenal when it comes to equality and range queries.</li><li><strong>Multilevel Indexing:</strong>&nbsp;B+ Trees can be adapted to perform multi-level indexing, further boosting search performance and reducing disk I/O operations.</li></ol><h1 id="Topic-1-5-B-Trees-in-MySQL-Indexing"><a href="#Topic-1-5-B-Trees-in-MySQL-Indexing" class="headerlink" title="Topic 1.5: B+ Trees in MySQL Indexing"></a><strong>Topic 1.5: B+ Trees in MySQL Indexing</strong></h1><p>Let’s now understand why and how MySQL uses B+ Trees for indexing in depth.</p><p>In MySQL, particularly when using the InnoDB storage engine, B+ Trees are used for primary and secondary indexing which enhances the database’s performance by significantly reducing the data access time.</p><p>Here’s how it works:</p><ol><li><strong>Primary Indexing</strong>: MySQL uses B+ Trees as a primary index to uniquely identify each row, which is ordered by the primary key. The leaf nodes of the B+ Tree store the actual data, and the values of primary key act as a pointer to the data. So, whenever a direct search is performed on the primary key, MySQL quickly navigates through the B+ Tree to find and retrieve the actual data from the disk.</li><li><strong>Secondary Indexing</strong>: The secondary index in a MySQL table is also a B+ Tree. The only difference compared to the primary index is that its leaf nodes don’t store actual data but rather they store pointers to the primary key. So, when there is a search performed using a secondary index, MySQL uses the B+ Tree of the secondary Index to find the primary key first, then uses this primary key to navigate the primary B+ Tree to fetch the actual data. Although this involves navigating two B+ Trees, it is still pretty fast and efficient.</li></ol><p>The advantage of using B+ trees in MySQL indexing is that it reduces the number of disk accesses required to find an item, which greatly improves performance because disk accesses are time-consuming compared to in-memory operations.</p><h1 id="Topic-1-6-MySQL-Indexing-Best-Practices"><a href="#Topic-1-6-MySQL-Indexing-Best-Practices" class="headerlink" title="Topic 1.6: MySQL Indexing Best Practices"></a><strong>Topic 1.6: MySQL Indexing Best Practices</strong></h1><p>Building on our understanding of B+ Trees, let’s now go through some best practices when it comes to MySQL indexing. Effective indexing is absolutely crucial in order to keep your database queries running smoothly and promptly.</p><ol><li><strong>Understand Your Data:</strong>&nbsp;Before you even start indexing, it’s crucial to understand thoroughly the data you’re working with. What columns are often queried together? Which columns appear commonly in your WHERE clauses? This understanding helps guide your indexing strategy.</li><li><strong>Use the EXPLAIN Keyword:</strong>&nbsp;When optimizing your indexes, use the EXPLAIN keyword in SQL to understand how the database is interpreting your query. This can give you insights into how the SQL optimizer will use your indexes and where improvements can be made.</li><li><strong>Be Mindful of Index Overhead:</strong>&nbsp;While indexes speed up search queries they also involve cost. They take up space, and also, each time you modify the data in your tables (INSERT, UPDATE, DELETE), indexes need to be updated. This might slow down these operations.</li><li><strong>Index Columns Used in WHERE Clauses:</strong>&nbsp;Columns that are frequently used in WHERE clauses in the queries are usually good candidates for indexing.</li><li><strong>Use Multi-Column Indexes Effectively:</strong>&nbsp;MySQL allows you to create an index on multiple columns together. When you create such an index, MySQL can use it when queries involve the first column, or the first and the second column, or all the columns in the index.</li><li><strong>Use Appropriate Index for Different Storage Engines</strong>: If you are using InnoDB, note that it stores its rows on the disk based on the primary key. Thus, the choice of the primary key can have a big impact on the performance of InnoDB tables.</li></ol><p>Remember, these are just guidelines and the best practices can vary based on your exact use case.</p><h1 id="Topic-1-7-Real-World-Case-Studies"><a href="#Topic-1-7-Real-World-Case-Studies" class="headerlink" title="Topic 1.7: Real World Case Studies"></a><strong>Topic 1.7: Real World Case Studies</strong></h1><p>Great! We’re progressing nicely through our structured course. It’s always helpful to bolster our learning with practical examples. So, let’s delve into a few case studies highlighting the use of MySQL indexing and B+ Trees.</p><ol><li><strong>E-commerce Systems</strong>: Consider the case of an online retail system like Amazon. These platforms manage a tremendous volume of data, pertaining to goods, user details, transaction details, etc. Given the enormous number of products and the frequency of transactions, the speed of data retrieval is paramount. Here, MySQL indexing plays a major role. Effective usage of primary, unique, and full-text indexes significantly speeds up the querying process, providing an efficient, seamless user experience. The use of B+ Trees for indexing allows the system to handle millions of items without a significant drop in performance.</li><li><strong>Social Media Platforms</strong>: Social media platforms like Facebook or Twitter also make extensive use of indexing. Every time we open our feed, the system queries a vast database to fetch relevant posts. Imagine finding a needle in a haystack — that’s what it would be like for the system to retrieve our personalized feed without indexing. Proper indexing allows these services to rapidly deliver the data we need each time we log in or refresh our feed.</li><li><strong>Search Engines</strong>: Google, Yahoo, Bing, and many other search engines also use extensive indexing to provide fast and accurate search results. Without the use of proficient indexing strategies, it would be impossible to get instant search results from the vast world of the internet.</li></ol><p>These are just a snapshot of the real-world applications where indexing and B+ Trees play a major role. Whether you are developing a website, an app, or any platform dealing with large amounts of data, understanding and using these structures effectively can make a significant difference in performance and efficiency.</p><h1 id="Topic-1-8-Potential-Interview-Questions-and-Answers"><a href="#Topic-1-8-Potential-Interview-Questions-and-Answers" class="headerlink" title="Topic 1.8: Potential Interview Questions and Answers"></a><strong>Topic 1.8: Potential Interview Questions and Answers</strong></h1><p>Alright, moving forward. Let’s prepare for some potential interview questions about MySQL indexing and B+ Trees. Having a good grip on these concepts can help you perform well in your job applications, and it’s always better to be ready!</p><p>Here are some questions with answers</p><ol><li><strong>Why is indexing important in databases?</strong><br> Indexing enhances database efficiency by providing swift data retrieval methods. An index in a database works similarly to an index in a book, enabling faster access to data. Without indexing, to find data, the database would need to dig through every record in a table — termed a full table scan — which can be time and resource-intensive.</li><li><strong>What is a B+ Tree?</strong><br> A B+ Tree is a type of data structure used in databases for storing data in a sorted and efficient manner. It is a balanced tree structure where all leaf nodes are at the same level, making searches, insertions, and deletions efficient, even for large sets of data.</li><li><strong>How does MySQL use B+ Trees for indexing?</strong><br> MySQL uses B+ Trees as the default indexing scheme in its InnoDB storage engine. Both primary and secondary indexes in InnoDB are stored as B+ Trees. The leaf nodes of a primary index’s B+ Tree contain the row data for the table, while the leaf nodes of a secondary index’s B+ Tree contain the primary key values for the respective rows.</li><li><strong>What are some best practices for MySQL indexing?</strong><br> Important best practices include understanding your data before indexing, using the EXPLAIN keyword to understand query execution, indexing columns used in WHERE clauses, making effective use of multi-column indexes, considering index overhead, and using appropriate indexes depending on the storage engine.</li><li><strong>Can you give an example where indexing significantly improves performance?</strong><br> E-commerce platforms can be a good example here. They have to manage loads of data — user details, product details, transactions, etc. Indexing can help sort and retrieve this data quickly, improving the search and transaction efficiency and enhancing the user experience.</li></ol><h1 id="Topic-1-9-Review-and-Assessments"><a href="#Topic-1-9-Review-and-Assessments" class="headerlink" title="Topic 1.9: Review and Assessments"></a><strong>Topic 1.9: Review and Assessments</strong></h1><p>Perfect, reaching the last part of the course, we’ll now review the key concepts we covered and engage in some self-assessments.</p><p>Let’s recap what we’ve learned:</p><ul><li><strong>Why Indexing</strong>: We’ve understood the key role played by indexing in improving the efficiency and speed of data retrieval in databases.</li><li><strong>Types of Indexes in MySQL</strong>: We’ve explored the various types of indexes in MySQL, including primary, unique, full-text, simple, and composite indexes and where they are used.</li><li><strong>B+ Trees</strong>: We’ve deep-dived into the structure of B+ Trees, how they function and the efficiency they offer in storing and retrieving data.</li><li><strong>B+ Trees in MySQL Indexing</strong>: We’ve seen how MySQL uses B+ Trees as an indexing structure, focusing on the InnoDB storage engine.</li><li><strong>MySQL Indexing Best Practices</strong>: We’ve probed into how to use indexing effectively for the best performance tips.</li><li><strong>Real-world applications</strong>: We’ve looked at how indexing and B+ Trees are applied in real-world examples, including in social media platforms, search engines, and E-commerce systems.</li></ul><p>Now, for assessments, here are a few quiz questions and small projects:</p><p>Quiz Questions:</p><ol><li>What is the role of indexing in databases?</li><li>Briefly describe the structure of a B+ Tree and how it works.</li><li>What is the difference between a primary and secondary index in MySQL?</li><li>What are three best practices when using indexing in MySQL?</li></ol><p>Small Projects:</p><ol><li>Take a small dataset (you can create or download one). Implement MySQL indexing and observe the performance difference when retrieving data.</li><li>Consider an E-commerce database with tables storing user information, product details, and transaction history. Design a basic schema with indexing and illustrate how different types of MySQL indexes are used.</li></ol><p>Happy learning!</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview4/">https://programmerscareer.com/zh-cn/mysql-interview4/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DataBase interviews: Briefly describe the difference between optimistic locks and pessimistic locks and the usage scenarios</title>
      <link href="/mysql-interview5/"/>
      <url>/mysql-interview5/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Have you ever been asked a similar question in an interview? Or you will meet in the future, let’s explore and master it together</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-Introduction-to-MySQL-and-Locking-Mechanisms"><a href="#Topic-1-1-Introduction-to-MySQL-and-Locking-Mechanisms" class="headerlink" title="Topic 1.1: Introduction to MySQL and Locking Mechanisms"></a>Topic 1.1: Introduction to MySQL and Locking Mechanisms</h1><p>Let’s embark on a new journey of learning about&nbsp;<strong>MySQL</strong>&nbsp;and&nbsp;<strong>Locking Mechanisms</strong>.</p><p>MySQL is one of the world’s most renowned open-source relational database management systems (RDBMS). It’s popular for web-based applications and online publishing and is a central component of the LAMP open-source web application software stack.</p><p>Now let’s talk a bit about why we need locking mechanisms in databases. Imagine a scenario where two individuals are attempting to withdraw money from the same bank account simultaneously. If there isn’t a mechanism to prevent it, they could both check the account balance at the same time, see that there are sufficient funds, and proceed to withdraw more money than is actually in the account. This is known as a race condition and could lead to serious data integrity issues. This is where locking mechanisms come into play!</p><h1 id="Topic-1-2-Overview-of-Locking-Mechanisms"><a href="#Topic-1-2-Overview-of-Locking-Mechanisms" class="headerlink" title="Topic 1.2: Overview of Locking Mechanisms"></a>Topic 1.2: Overview of Locking Mechanisms</h1><p>So, let’s dive deeper into the world of Locking Mechanisms in MySQL. As mentioned before, locking contributes significantly to maintaining data integrity, especially in multi-user database environments.</p><p>Locking in databases essentially controls how transactions are accessed so that each transaction sees a consistent snapshot of the data it is accessing. The main types of locking used in MySQL are:</p><ol><li><strong>Shared Locks (Read Locks)</strong>: Shared locks are used when executing a read operation on data. They allow concurrent transactions to read (select) a resource with the guarantee that no transactions will be able to write (update/delete) it.</li><li><strong>Exclusive Locks (Write Locks)</strong>: Exclusive locks are issued when executing a data modification operation. They make sure that the transaction that holds the lock is the only transaction that can read or write to the resource.</li></ol><p>In the next chapters, we will venture into two popular types of locking mechanisms-&nbsp;<strong>Optimistic Locking</strong>&nbsp;and&nbsp;<strong>Pessimistic Locking</strong>. The choice of which to use generally depends on the specific requirements of your system, such as the probability of concurrent transactions conflicting.</p><h1 id="Topic-1-3-Understanding-Optimistic-Locking"><a href="#Topic-1-3-Understanding-Optimistic-Locking" class="headerlink" title="Topic 1.3: Understanding Optimistic Locking"></a>Topic 1.3: Understanding Optimistic Locking</h1><p>Time to take a closer look at&nbsp;<strong>Optimistic Locking</strong>. This is a strategy that can be implemented in multi-user databases to handle simultaneous updates.</p><p>Optimistic Locking works on the assumption that multiple transactions can complete without affecting each other; therefore, it allows multiple transactions to access the same record for edits. This method is useful in systems where there is low contention for data.</p><p>Here’s a simple way how Optimistic Locking works:</p><ol><li>A record is fetched from the database for an update.</li><li>Just before the update, the application checks if another user has changed the record since it was last fetched.</li><li>If the record was not updated by others, the application can perform its update and everything proceeds smoothly.</li><li>If the record was updated by someone else, the application typically either informs the user and aborts the transaction or automatically retries the transaction.</li></ol><p>The main advantage of optimistic locking is its higher efficiency. It avoids the overhead of acquiring and releasing locks and avoids having transactions wait for locks.</p><p>However bear in mind, nothing comes without a flip side! In an environment where contention for data is high and there are many updates to data, there could be many transaction collisions leading to a lot of rollbacks, which could lead to performance issues.</p><h1 id="Topic-1-4-Understanding-Pessimistic-Locking"><a href="#Topic-1-4-Understanding-Pessimistic-Locking" class="headerlink" title="Topic 1.4: Understanding Pessimistic Locking"></a>Topic 1.4: Understanding Pessimistic Locking</h1><p>Let’s navigate into the sea of&nbsp;<strong>Pessimistic Locking</strong>&nbsp;now. This mechanism in MySQL is based on a completely different assumption from Optimistic Locking. It assumes that conflict is likely to happen and therefore enforces stringent controls to prevent this.</p><p>Here’s how Pessimistic Locking works:</p><ol><li>When a record is fetched for updating, an exclusive lock is immediately acquired.</li><li>Until the lock is released, no other transaction can update this record.</li><li>The lock is released when the transaction is completed, and other transactions can then acquire the lock for this record.</li></ol><p>Pessimistic Locking is a surefire way to prevent conflicts, as it does not allow another transaction to proceed if it can result in a conflict. It’s a good fit for environments where contention for data is high and records are frequently updated.</p><p>But remember, every coin has two sides! The downside of this approach is that it can lead to reduced concurrency and can impact system performance as transactions may be held waiting for locks for extended periods.</p><h1 id="Topic-1-5-Comparing-Optimistic-and-Pessimistic-Locking"><a href="#Topic-1-5-Comparing-Optimistic-and-Pessimistic-Locking" class="headerlink" title="Topic 1.5: Comparing Optimistic and Pessimistic Locking."></a><strong>Topic 1.5: Comparing Optimistic and Pessimistic Locking.</strong></h1><p>You now are familiar with both Optimistic and Pessimistic Locking, and understanding when to use each one can significantly influence the performance and reliability of your applications.</p><p><strong>Optimistic Locking</strong>&nbsp;assumes conflicts are rare and mostly avoids the need for acquiring and releasing locks. It can result in higher performance under low contention scenarios because it causes fewer blocks. However, for systems where contention is high, and conflicts are frequent, the cost and frequency of rollbacks can degrade performance.</p><p>On the other hand,&nbsp;<strong>Pessimistic Locking</strong>&nbsp;assumes conflicts will commonly occur and uses locks to prevent them. This strategy can be advantageous in high contention scenarios because it avoids the need for conflict-resolution related rollbacks. However, the wait time associated with acquiring locks can degrade performance.</p><p>So, the golden rule is:</p><blockquote><p><em>Opt for Optimistic Locking when conflicts are rare.<br>Opt for Pessimistic Locking when conflicts are expected.</em></p></blockquote><p>That’s a brief comparison of Optimistic and Pessimistic Locking in MySQL.</p><h1 id="Topic-1-6-Use-Case-Scenarios-for-Locking-Mechanisms"><a href="#Topic-1-6-Use-Case-Scenarios-for-Locking-Mechanisms" class="headerlink" title="Topic: 1.6 Use Case Scenarios for Locking Mechanisms"></a>Topic: 1.6 Use Case Scenarios for Locking Mechanisms</h1><p>Fantastic! We now understand the primary locking mechanisms let’s look at some real-world scenarios where these mechanisms could be beneficial.</p><ol><li><strong>A banking system</strong>:<br> Imagine a banking application where transactions happen regularly. These transactions need to be consistent and secure. In such cases, a Pessimistic Locking mechanism is favourable as it ensures that once a user starts a transaction, no one else can modify the data, ensuring data integrity.</li><li><strong>A ticket booking application</strong>:<br> Consider an online ticket booking system where multiple users are trying to book a limited number of tickets. Here, Optimistic Locking could be beneficial as it would allow multiple users to access the ticket booking function concurrently.</li><li><strong>A content management system</strong>:<br> If you’re working on a Content Management System where users are updating their blog posts/articles, Optimistic Locking can be a good choice. Since the odds of two users trying to edit the same article at the same time are comparatively low, the system can handle those occasional conflicts.</li><li><strong>A Stock trading application</strong>:<br> In a Stock trading application where a split-second delay could mean significant financial loss, Pessimistic Locking could help by instantly blocking other transactions until one completes.</li></ol><p>Remember, the decision to use Optimistic or Pessimistic Locking depends greatly on the nature of the application, the likelihood of conflicts, the level of concurrency required, and the tolerance for delay.</p><h1 id="Topic-1-7-Review-and-Assessments"><a href="#Topic-1-7-Review-and-Assessments" class="headerlink" title="Topic: 1.7 Review and Assessments"></a>Topic: 1.7 Review and Assessments</h1><ol><li><strong>Introduction to MySQL and Locking Mechanisms</strong>: We discussed how MySQL functions, the importance of locking mechanisms, and how it helps with concurrent database accesses.</li><li><strong>Overview of Locking Mechanisms</strong>: We looked at a variety of locking mechanisms, their importance in maintaining data integrity, and handling concurrent access.</li><li><strong>Understanding Optimistic Locking</strong>: We did a deep dive into the concept of optimistic locking, its pros and cons, and its implementation in MySQL.</li><li><strong>Understanding Pessimistic Locking</strong>: We explored pessimistic locking, including its strengths, weaknesses, and how it can be implemented in MySQL.</li><li><strong>Comparing Optimistic and Pessimistic Locking</strong>: We compared these two locking mechanisms and concluded that the choice highly depends on the particular use-cases and system requirements.</li><li><strong>Use Case Scenarios for Locking Mechanisms</strong>: We looked through possible real-life application scenarios where these locking mechanisms can offer benefits.</li></ol><h2 id="Example-Problem"><a href="#Example-Problem" class="headerlink" title="Example Problem:"></a>Example Problem:</h2><p>Let’s take an example: you have a banking database in MySQL with a table named ‘Account’ storing users’ account balance. Two different financial transactions are trying to deduct money from the same account simultaneously. How would you handle this situation using both optimistic and pessimistic locking mechanisms in MySQL?</p><p><strong>Answer</strong>:</p><p>For&nbsp;<strong>Optimistic Locking</strong>, you can handle this by using a version column in the Account table. Here’s how:</p><ul><li>Transactions first read the account balance and note down the version. Before they update the account, they check if the version is still the same. If the version had changed, that would mean that another transaction has updated the account balance in the meantime, and therefore, the current transaction is rolled back. This way, we avoid inconsistent deductions.</li></ul><p>For&nbsp;<strong>Pessimistic Locking</strong>, you would lock the account for every financial transaction. Here’s how:</p><ul><li>Transactions lock the account immediately upon reading the account balance. Only one transaction can hold the lock at a time, and it holds it until it finishes updating the account balance. All other transactions that attempt to read the account balance while the lock is held will be blocked until the lock is released.</li></ul><p>Now let’s test your knowledge.</p><p><strong>Question 1 (Easy):</strong></p><p>In what scenario would you choose Optimistic Locking over Pessimistic Locking?</p><p><strong>Question 2 (Intermediate):</strong></p><p>What could be a potential downside of using Pessimistic Locking in a high throughput system, and how could this downside be mitigated?</p><p><strong>Question 3 (Hard):</strong></p><p>Can you describe a scenario where neither Optimistic nor Pessimistic Locking is suitable, and a different locking or concurrency control mechanism would be required?</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview5/">https://programmerscareer.com/zh-cn/mysql-interview5/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Database interviews:What are the necessary conditions for a deadlock to occur? How do I resolve deadlocks?</title>
      <link href="/mysql-interview6/"/>
      <url>/mysql-interview6/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Have you ever been asked a similar question in an interview? Or you will meet in the future, let’s explore and master it together</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-Introduction-to-Deadlocks"><a href="#Topic-1-1-Introduction-to-Deadlocks" class="headerlink" title="Topic: 1.1 Introduction to Deadlocks"></a><strong>Topic: 1.1 Introduction to Deadlocks</strong></h1><p>Deadlocks are a condition in a multithreading environment when two or more threads are unable to proceed because each is waiting for the others to release resources. In the context of a MySQL database, a deadlock occurs when two or more transactions mutually hold and request for locks, creating a cycle of dependencies.</p><p>In a transaction, a thread might need to lock multiple tables or rows, which can sometimes lead to a situation where the thread needs a resource that’s locked by another thread. Meanwhile, that thread might be waiting for a resource locked by the first thread. This is known as a deadlock.</p><p>Let me illustrate this with a simple story:</p><p>Imagine two comic book fans, Alice and Bob. Alice has the latest ‘Superbot’ comic which Bob wants. At the same time, Bob has the newest ‘Megagirl’ comic, which Alice wants. Now, Alice is not willing to give up her ‘Superbot’ comic until she has the ‘Megagirl’ comic in her hands, and Bob too, won’t give up his ‘Megagirl’ comic until he has the ‘Superbot’ comic. So, both are waiting for each other to let go of their comics, which results in a deadlock.</p><p>In terms of database transactions, Alice and Bob could be transactions, and the comic books could be the locked resources.</p><h1 id="Topic-1-2-Understanding-Necessary-Conditions-for-a-Deadlock"><a href="#Topic-1-2-Understanding-Necessary-Conditions-for-a-Deadlock" class="headerlink" title="Topic: 1.2 Understanding Necessary Conditions for a Deadlock"></a><strong>Topic: 1.2 Understanding Necessary Conditions for a Deadlock</strong></h1><p>To understand how deadlocks occur, we need to be familiar with Coffman’s Conditions, which are a set of four conditions that must all hold for a deadlock to occur. These are named after Edward G. Coffman, Jr., who first articulated them. The conditions are:</p><ol><li><strong>Mutual Exclusion</strong>: At least one resource must be held in a non-shareable mode. This means only one process (or thread) can use the resource at any given time. If another process requests the resource, the requesting process must be delayed until the resource has been released.</li><li><strong>Hold and Wait (Resource Holding)</strong>: A process must be holding at least one resource and waiting to acquire additional resources that are currently being held by other processes.</li><li><strong>No Preemption</strong>: Resources cannot be forcibly removed from the processes holding them until the resources are used to completion. The resources can only be released voluntarily by the process holding them.</li><li><strong>Circular Wait</strong>: A circular chain of processes exists where each process holds one resource while requesting another resource held by another process in the chain. Essentially, there’s a process P1 that is waiting for a resource that is held by process P2, and P2 is waiting for a resource held by P1. This makes a circular chain of waiting processes.</li></ol><p>These 4 conditions inherently provide a logical structure to understand and structure the prevention policies. By ensuring that at least one of the above conditions never occurs, we can prevent the formation of deadlocks.</p><h1 id="Topic-1-3-Detecting-Deadlocks-in-MySQL"><a href="#Topic-1-3-Detecting-Deadlocks-in-MySQL" class="headerlink" title="Topic 1.3: Detecting Deadlocks in MySQL"></a><strong>Topic 1.3: Detecting Deadlocks in MySQL</strong></h1><p>In MySQL, the InnoDB storage engine automatically detects deadlocks and resolves them by rolling back one of the transactions involved. Therefore, your application should always be ready to re-issue a transaction if it gets rolled back due to a deadlock.</p><p>When a deadlock occurs in MySQL, it’s immediately detected and resolved by the system. This is achieved by the&nbsp;<em>wait-for graph</em>&nbsp;deadlock detection mechanism, where MySQL maintains information about which transactions are waiting for locks held by which other transactions. With this approach, MySQL can check for cycles in the wait-for graph. If it detects a cycle, this indicates a deadlock, and it’ll roll back one of the transactions to break the deadlock.</p><p>To give you more insight into the situation, MySQL also provides diagnostic information when it detects and resolves a deadlock. This information can be obtained from the&nbsp;<code>SHOW ENGINE INNODB STATUS</code>&nbsp;command, which will showcase the latest deadlock error.</p><p>However, it’s important to note that deadlocks are not necessarily a sign of a design flaw or error. In some high concurrency systems, deadlocks may happen from time to time and can be considered a cost of doing business. But of course, if you are experiencing them frequently, it may be worth investigating further to see if there can be improvements in the transaction processing.</p><h1 id="Topic-1-4-Preventing-Deadlocks"><a href="#Topic-1-4-Preventing-Deadlocks" class="headerlink" title="Topic 1.4: Preventing Deadlocks"></a><strong>Topic 1.4: Preventing Deadlocks</strong></h1><p>Here are several strategies for preventing deadlocks:</p><ol><li><strong>Order Your Locks</strong>: Always lock tables in the same order. For example, if all your transactions lock the ‘orders’ table before the ‘products’ table, you won’t have one transaction locking ‘orders’ and a second transaction locking ‘product’ and waiting for ‘orders’.</li><li><strong>Keep Transactions Short and Fast</strong>: The shorter a transaction, the less likely it is to lock a row that’s needed by another transaction.</li><li><strong>Error Handling</strong>: Since InnoDB automatically detects deadlocks and rolls back a transaction, you need to be ready to catch that error in your code and retry the transaction.</li><li><strong>Use Lower Isolation Levels</strong>: If possible, use the Read Committed isolation level rather than Repeatable Read to lessen the chance of deadlocks.</li><li><strong>Avoid Hotspots</strong>: If you can avoid frequently updated rows, you can reduce the likelihood of deadlocks. For instance, instead of having a counter table that gets updated each time an operation is performed, consider using a different strategy to count operations.</li></ol><h1 id="Topic-1-5-Resolving-Deadlocks"><a href="#Topic-1-5-Resolving-Deadlocks" class="headerlink" title="Topic 1.5: Resolving Deadlocks"></a><strong>Topic 1.5: Resolving Deadlocks</strong></h1><p>When it comes to resolving deadlocks, the ideal circumstance is that deadlocks are detected and handled automatically by MySQL’s InnoDB storage engine. InnoDB uses a mechanism known as&nbsp;<em>wait-for graph</em>&nbsp;to detect deadlocks. When a deadlock happens, InnoDB chooses one of the transactions and kills it, thereby resolving the deadlock.</p><p>While this takes care of resolving the deadlock, it is important for application developers to handle these scenarios within the application. When InnoDB kills a transaction due to a deadlock, it raises an error that needs to be caught in your application, and, typically, the transaction that was terminated should be retried.</p><p>The automatic deadlock detection in InnoDB resolves deadlocks as they happen, but in certain cases, the detection and killing of a transaction can take substantial time, impacting your application’s performance. That is why it is also important to design your application to avoid deadlocks as much as possible.</p><p>Although it’s hard to prevent deadlocks entirely in high concurrency systems, trying to minimize them as much as possible will lead to a smoother and more efficient operation of your database system. Good coding practices, efficient design of your tables, and correctly applying transactions and lock controls, can help you avert most deadlocks.</p><h1 id="Topic-1-6-Troubleshooting-Deadlocks"><a href="#Topic-1-6-Troubleshooting-Deadlocks" class="headerlink" title="Topic 1.6: Troubleshooting Deadlocks"></a><strong>Topic 1.6: Troubleshooting Deadlocks</strong></h1><p>Investigating and troubleshooting deadlocks can provide valuable insights to prevent them or improve the response time. MySQL includes several tools that can assist in this process.</p><ol><li><strong>SHOW ENGINE INNODB STATUS</strong>: This command outputs a text-based report that includes information about the most recent deadlock if one has occurred. It’s essential to run this command as soon as possible after the deadlock because its information is lost with the next one.</li><li><strong>InnoDB Monitors</strong>: These are more detailed and extensive reports about InnoDB’s internal workings, including deadlocks. There are standard, lock, and mutex monitors.</li><li><strong>Performance Schema</strong>: MySQL’s Performance Schema can be configured to capture detailed data about events, including transaction events. This data is stored in tables and can be queried like other MySQL data.</li><li><strong>Binary Logs</strong>: MySQL’s binary logs can help determine the sequence of queries that led to the deadlock. These logs require that you have the binary log enabled and that you’re logging in ROW format.</li><li><strong>Error Log</strong>: Deadlocks are logged here if you have innodb_print_all_deadlocks configuration enabled.</li></ol><p>By analyzing these sources, you can determine which transactions were involved in a deadlock and what resources they were trying to access. In many cases, careful analysis may point to a better way to order locks or a better transaction size to prevent foreseeable deadlocks.</p><h1 id="Topic-1-7-Review-and-Assessments"><a href="#Topic-1-7-Review-and-Assessments" class="headerlink" title="Topic: 1.7&nbsp;Review and Assessments"></a>Topic: 1.7&nbsp;<strong>Review and Assessments</strong></h1><p><strong>Example Problem:</strong><br>Assume that you encounter a deadlock in your MySQL database. You decide to run the command&nbsp;<code>SHOW ENGINE INNODB STATUS</code>&nbsp;for more information.</p><p>The&nbsp;<code>LATEST DETECTED DEADLOCK</code>&nbsp;section gives you the following output:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">LATEST DETECTED DEADLOCK  </span><br><span class="line">------------------------  </span><br><span class="line">2022-08-24 23:08:02 7f3e6e2fd700  </span><br><span class="line">*** (1) TRANSACTION:  </span><br><span class="line">TRANSACTION 118945420, ACTIVE 22 sec inserting  </span><br><span class="line">mysql tables in use 1, locked 1  </span><br><span class="line">1700 lock struct(s), heap size 187648, 1249789 row lock(s), undo log entries 1  </span><br><span class="line">MySQL thread id 155, OS thread handle 0x7f3e6e3e7700, query id 25749768 localhost user  </span><br><span class="line">INSERT INTO customer (id, name, address) VALUES (3, 'John Doe', '123 Main St')  </span><br><span class="line">*** (1) WAITING FOR THIS LOCK TO BE GRANTED:  </span><br><span class="line">RECORD LOCKS space id 66873 page no 70541 n bits 600 index `id` of table `test`.`customer` trx id 118945420 lock mode S waiting up to 3 years total: 47.56T, and currently at 47.68T to rise above: 47.68T  </span><br><span class="line">*** (2) TRANSACTION:  </span><br><span class="line">TRANSACTION 118945416, ACTIVE (PREPARED) 13 sec committing, thread declared inside InnoDB 476  </span><br><span class="line">mysql tables in use 1, locked 1  </span><br><span class="line">1 lock struct(s), heap size 368, 0 row lock(s)  </span><br><span class="line">MySQL thread id 117, OS thread handle 0x7f3e6e2fd700, query id 25749765 localhost user  </span><br><span class="line">COMMIT  </span><br><span class="line">*** (2) HOLDS THE LOCK(S):  </span><br><span class="line">RECORD LOCKS space id 66873 page no 70541 n bits 600 index `id` of table `test`.`customer` trx id 118945416 lock mode S  </span><br><span class="line">*** (2) WAITING FOR THIS LOCK TO BE GRANTED:  </span><br><span class="line">RECORD LOCKS space id 66873 page no 70541 n bits 600 index `id` of table `test`.`customer` trx id 118945416 lock_mode X waiting up to 3 years total: 47.68T to rise above: 47.56T  </span><br><span class="line">*** WE ROLL BACK TRANSACTION (1)</span><br></pre></td></tr></tbody></table></figure><p>Based on this information, what is causing the deadlock and how could you potentially resolve it?</p><p><strong>Now let’s test your knowledge.</strong></p><p><strong>Question 1 — Simple Familiar Problem (Difficulty 3/10):</strong></p><p>What are the four conditions that must be present for a deadlock as per Coffman’s conditions? Provide a brief explanation of each condition.</p><p><strong>Question 2 — Complex Familiar Problem (Difficulty 6/10):</strong></p><p>What steps would you take to proactively prevent or minimize deadlock occurrences?</p><p><strong>Question 3 — Complex Unfamiliar Problem (Difficulty 9/10):</strong></p><p>Why does MySQL InnoDB engine automatically resolve deadlocks by rolling back a transaction? What are the advantages and potential disadvantages of this approach?</p><p><strong>Please always try to get to the answer by yourself first before asking for help.</strong></p><hr><p><strong>Solution for Example Problem</strong>:</p><p>The deadlock occurred because two transactions were each waiting for resource more than the individual ones. The transaction (1) was waiting for an S-mode (read) lock on the&nbsp;<code>id</code>&nbsp;index of the&nbsp;<code>customer</code>&nbsp;table, that was being held by transaction (2). At the same time, transaction (2) was waiting for an X-mode (write) lock on the very same resource while transaction (2) held an S-mode (read) lock.</p><p>This scenario means that neither transaction could proceed, resulting in a deadlock. The resolution could be to ensure the transactions request locks in the same order, as it is one of the well-known techniques to avoid deadlock.</p><p><strong>Solution to Question 1:</strong></p><p>Coffman’s deadlock conditions are as follows:</p><ol><li><strong>Mutual Exclusion:</strong>&nbsp;A resource can only be held by one process at a time.</li><li><strong>Hold and Wait:</strong>&nbsp;Processes already holding resources can request new resources.</li><li><strong>No Preemption:</strong>&nbsp;Only the process holding the resource can release it.</li><li><strong>Circular Wait:</strong>&nbsp;A circular chain of processes exists where each process holds a resource needed by the next process in the chain.</li></ol><p><strong>Solution to Question 2:</strong></p><p>Multiple approaches can be deployed to prevent or minimize deadlocks:</p><ol><li><strong>Setting Lock Timeout:</strong>&nbsp;By limiting how long a transaction waits to acquire a lock, you can minimize wait time and potentially resolve deadlocks.</li><li><strong>Ordering Locks:</strong>&nbsp;Having transactions request locks in a specific order can prevent deadlocks by eliminating the circular wait condition.</li><li><strong>Frequent Committing:</strong>&nbsp;Smaller transactions that commit frequently are less likely to clash with other transactions.</li><li><strong>Deadlock Detection Tools:</strong>&nbsp;Utilize built-in or third-party tools to determine when and why deadlocks occur so programmatic resolutions can be applied.</li></ol><p><strong>Solution to Question 3:</strong></p><p>When a deadlock occurs in MySQL, the InnoDB engine automatically chooses the smallest transaction (the one with fewest row locks) and rolls it back to break the deadlock</p><p><strong>Advantages:</strong></p><ol><li>This automatic resolution helps to keep the database running smoothly without manual intervention.</li></ol><p><strong>Potential Disadvantages:</strong></p><ol><li>If the transaction that is rolled back is large or critical, rolling it back might lead to data not being updated or saved correctly.</li><li>Continuous rollbacks due to deadlocks can negatively affect performance.</li><li>Not all business logic scenarios may suit automatic rollback.</li></ol><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview6/">https://programmerscareer.com/zh-cn/mysql-interview6/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL interviews: What is an SQL injection attack? How can such attacks be prevented?</title>
      <link href="/mysql-interview7/"/>
      <url>/mysql-interview7/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Here’s a proposed curriculum to study SQL injection attacks in MySQL and how to prevent them</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-Introduction-to-SQL-Injection-Attacks"><a href="#Topic-Introduction-to-SQL-Injection-Attacks" class="headerlink" title="Topic: Introduction to SQL Injection Attacks"></a>Topic: Introduction to SQL Injection Attacks</h1><p>SQL Injection, commonly referred to as SQLi, is one of the most notorious types of web application security vulnerabilities. It occurs when an attacker can insert malicious SQL statements into an entry field for execution or manipulation. Essentially, an SQLi attack takes advantage of a site’s vulnerable user inputs where SQL commands are parsed.</p><p>This attack can lead to unauthorized viewing of user lists, deletion of entire tables, and, in some cases, the attacker could gain administrative rights to a database, all through running malicious SQL statements on your database. SQLi is relatively easy to prevent but still happens quite frequently, with devastating effects.</p><p>An attacker can manipulate your SQL queries by inserting their own commands into a field that is incorporated into SQL statement. These attacks are successful when a web application doesn’t correctly validate input before it’s included in an SQL query.</p><p>For example, imagine a simple login function where a user must input their username and password. The SQL query related to this function might look something like this:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM users WHERE username = '[username]' AND password = '[password]';</span><br></pre></td></tr></tbody></table></figure><p>In this scenario, the attacker could submit “<code>admin'; --</code>“ as their username. Your query would then look like this:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM users WHERE username = 'admin'; --' AND password = '[password]';</span><br></pre></td></tr></tbody></table></figure><p>In SQL, anything after&nbsp;<code>--</code>&nbsp;is considered a comment and is ignored. So essentially, the attacker has successfully bypassed the password check and can log in as the&nbsp;<code>admin</code>.</p><p>Remember, this is just the simplest form of an SQLi — there exist much more complex SQLi methods that can have much more devastating impacts.</p><h1 id="Topic-Examples-of-SQL-Injection-Attacks"><a href="#Topic-Examples-of-SQL-Injection-Attacks" class="headerlink" title="Topic: Examples of SQL Injection Attacks"></a>Topic: Examples of SQL Injection Attacks</h1><p>SQL injection attacks come in all shapes and sizes. Here are some common examples:</p><p><strong>1. Retrieving hidden data:</strong><br>You can manipulate an SQL query to return additional results. Let’s assume we have a page displaying products filtered by category:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://example.com/products?category=Books</span><br></pre></td></tr></tbody></table></figure><p>which might be using this SQL query:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM products WHERE category = 'Books'</span><br></pre></td></tr></tbody></table></figure><p>An attacker could change the URL to:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://example.com/products?category=Books' OR '1'='1</span><br></pre></td></tr></tbody></table></figure><p>which might manipulate the SQL query to:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM products WHERE category = 'Books' OR '1'='1'</span><br></pre></td></tr></tbody></table></figure><p>Since ‘1’=’1’ is always true, it results in displaying all products, not just books.</p><p><strong>2. Subverting application logic:</strong></p><p>Let’s consider another scenario where an application checks a user’s login credentials using the following code:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM users WHERE username = '$username' AND password = '$password'</span><br></pre></td></tr></tbody></table></figure><p>A hacker can use SQLi to bypass the password check with the following inputs:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">' OR '1'='1' -- for username  </span><br><span class="line">randompassword for password</span><br></pre></td></tr></tbody></table></figure><p>This would look like:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM users WHERE username = '' OR '1'='1' --' AND password = 'randompassword'</span><br></pre></td></tr></tbody></table></figure><p>The ‘ — ‘ comments out the password checking portion of the SQL query, leading to an unauthorized login.</p><p><strong>3. UNION attacks:</strong></p><p>UNION operator can be used to retrieve data from other tables within the database. Let’s take an example of this URL:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://example.com/products?category=Books</span><br></pre></td></tr></tbody></table></figure><p>If the suspecting query is:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT price, name, description FROM products WHERE category = 'Books'</span><br></pre></td></tr></tbody></table></figure><p>The attacker might try:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://example.com/products?category=Books' UNION SELECT username, password FROM users --</span><br></pre></td></tr></tbody></table></figure><p>That could result in leaked user credentials.</p><p>Remember, these attacks heavily depend on the backend query structure and protection mechanisms in place. Not all websites or databases will be susceptible to these exact attacks. However, these examples should give you an idea of how SQLi exploits incorrect handling of user-supplied data to manipulate SQL queries.</p><h1 id="Topic-Understanding-the-Impact-of-SQL-Injection"><a href="#Topic-Understanding-the-Impact-of-SQL-Injection" class="headerlink" title="Topic: Understanding the Impact of SQL Injection"></a>Topic: Understanding the Impact of SQL Injection</h1><p>SQL injection can lead to various harmful outcomes, and the severity of damage largely depends on the privileges of the user account that the attacker has abused and what the database is used for. Here are some potential impacts of SQL injection attacks:</p><p><strong>1. Data Breach:</strong></p><p>One of the most direct and dangerous outcomes of an SQL injection attack is a data breach. If an attacker successfully exploits an SQL injection vulnerability, they might gain access to sensitive data stored in your database. This could include personally identifiable information (PII), financial data, proprietary business information, passwords, or more.</p><p><strong>2. Data Manipulation:</strong></p><p>SQL injection isn’t just about viewing data. An attacker could use it to modify or delete data in your database — this could range from altering prices or balances to deleting entire tables.</p><p><strong>3. Loss of Accountability and Non-Repudiation:</strong></p><p>Since SQL injection can allow an attacker to execute actions on your database under the guise of another user (or even an admin), it could lead to a loss of accountability. It would be difficult to trace actions back to the attacker, creating a non-repudiation issue.</p><p><strong>4. Damage to Reputation:</strong></p><p>Beyond the direct technical outcomes, a successful SQL injection attack could significantly damage your business’s reputation. Customers trust businesses with their data, and a breach could lead to a loss of that trust.</p><p><strong>5. Legal Consequences:</strong></p><p>Depending on the nature of the breached data and the jurisdiction, an SQL injection attack could also lead to legal consequences for the business. This could include fines, lawsuits, or both.</p><p>As you can see, the potential consequences of an SQL injection attack highlight the paramount importance of protecting against them. In the upcoming lessons, we’ll dive into how to do exactly that.</p><h1 id="Topic-Preventing-SQL-Injection-Attacks"><a href="#Topic-Preventing-SQL-Injection-Attacks" class="headerlink" title="Topic: Preventing SQL Injection Attacks"></a>Topic: Preventing SQL Injection Attacks</h1><p>Preventing SQL injection attacks is all about ensuring that the data flow between your application and your database is safe and secure. Here are some techniques that can be employed to help prevent SQL Injection attacks:</p><p><strong>1. Use Prepared Statements (Parameterized Queries):</strong></p><p>The most effective way to prevent SQL injection is to use prepared statements. A prepared statement defined with parameters ensures that the parameters are bound to the query and are not part of the query, which means an attacker can’t affect the query structure. This effectively eliminates all SQL injection attacks. Most web language nowadays has support for prepared statements.</p><p><strong>2. Use Stored Procedures:</strong></p><p>Much like a prepared statement, stored procedures also separate data from commands and queries. However, stored procedures have added benefits like improved performance and reusable code.</p><p><strong>3. Input Validation:</strong></p><p>While this approach alone is not enough to prevent SQL injection attacks, it’s still an essential step. By validating user input, we ensure it meets length, type, syntax, and business rules specifications.</p><p><strong>4. Least Privilege Principle:</strong></p><p>Don’t give a user account more privileges than it needs. If an account is only used to perform select statements within an application, don’t give it the ability to drop tables. If an attacker compromises a limited account, the potential damage is contained.</p><p><strong>5. Regular Updates and Patching:</strong></p><p>Keep your database management system (DBMS) and all your software updated and patched with the latest security fixes.</p><p>These are a few prevention mechanisms that can be put in place to ensure your database’s safety against SQL Injection attacks.</p><h1 id="Topic-Best-Practices-for-Preventing-SQL-Injection"><a href="#Topic-Best-Practices-for-Preventing-SQL-Injection" class="headerlink" title="Topic: Best Practices for Preventing SQL Injection"></a>Topic: Best Practices for Preventing SQL Injection</h1><p>In addition to those prevention mechanisms, here are more best practices that you can implement to avoid SQL injection vulnerabilities:</p><p><strong>1. Escaping User Input:</strong></p><p>Escaping data simply means treating it in such a way that it’s interpreted as plain data, not as part of the SQL query. This can be manually done with certain functions to escape special characters like quotes, or it might be implicitly taken care of by using prepared statements.</p><p><strong>2. Comprehensive Error Handling:</strong></p><p>Hackers often rely on error messages from the database to get clues about its structure. It’s best practice to avoid exposing these errors directly to the end user, instead, use a generic error message and log the specific error details in a secured file which developers can reference when needed.</p><p><strong>3. Employ Web Application Firewalls (WAFs):</strong></p><p>Web application firewalls can inspect the incoming data and identify malicious SQL code. They don’t substitute good coding practices but serve as an additional line of defense.</p><p><strong>4. Regular Code Reviews:</strong></p><p>Perform regular code reviews where security is one of the topics under scrutiny. This can help ensure secure coding practices are being followed and catch potential issues early in the development process.</p><p><strong>5. Conduct Testing and Use Security Tools:</strong></p><p>Regularly test your application, database, and infrastructure for security vulnerabilities. There are many automated tools available which can scan for SQL injection and other vulnerabilities.</p><p>Remember, security is a process, not a state. Regularly updating your skills and knowledge, keeping abreast of new vulnerabilities and attack techniques, and continually reviewing and improving your applications are all part of maintaining a robust security posture.</p><h1 id="Topic-Testing-for-SQL-Injection-vulnerabilities"><a href="#Topic-Testing-for-SQL-Injection-vulnerabilities" class="headerlink" title="Topic: Testing for SQL Injection vulnerabilities"></a>Topic: Testing for SQL Injection vulnerabilities</h1><p>Testing for SQL injection vulnerabilities forms a critical part of securing your applications and databases. It can be done both manually and by using automated tools. Here’s how:</p><p><strong>1. Manual Testing:</strong></p><p>Manual tests involve using techniques like injecting special characters into your application’s inputs and observing the application’s reaction.</p><p>For example, inputting a single quote mark&nbsp;<code>'</code>&nbsp;into a text field. If your application throws an SQL error, that’s a sign it might be vulnerable to SQL injection. On the other hand, if the application runs smoothly and the character appears in the output as it was entered, that’s an indication your application is properly handling input.</p><p>Remember that SQL injection can come in many different forms, and thorough manual testing might involve trying a wide range of inputs.</p><p><strong>2. Automated Testing with Security Tools:</strong></p><p>There are also various automated tools designed to assist with SQL injection detection. These tools can crawl your application and test various inputs for SQL injection vulnerabilities, saving time and providing a thorough assessment of your application. They can test known SQL injection techniques and generate reports of potential vulnerabilities.</p><p>Examples of such tools include SQLMap, Havij, and Netsparker.</p><p>While tests and automated tools can be extremely useful, they aren’t infallible. Even if a tool doesn’t find any vulnerabilities, that doesn’t necessarily mean your application is secure. It’s recommended to couple these methods with the prevention techniques and best practices we discussed in the previous lessons.</p><h1 id="Topic-Review-and-Assessments-on-SQL-Injection"><a href="#Topic-Review-and-Assessments-on-SQL-Injection" class="headerlink" title="Topic: Review and Assessments on SQL Injection"></a>Topic: Review and Assessments on SQL Injection</h1><h2 id="Review"><a href="#Review" class="headerlink" title="Review:"></a>Review:</h2><ol><li><strong>SQL Injection Attack:</strong>&nbsp;This is an attack method where an attacker tries to manipulate an SQL query by injecting malicious SQL code through user input.</li><li><strong>Preventive Measures:</strong>&nbsp;The primary mechanisms include prepared statements, stored procedures, input validation, enforcing least privilege, and regularly updating systems.</li><li><strong>Best Practices:</strong>&nbsp;These include escaping user input, comprehensive error handling, employing Web Application Firewalls (WAFs), regular code reviews, and using security tools.</li><li><strong>Testing for Vulnerabilities:</strong>&nbsp;Manual testing might involve trying a wide range of inputs. Automated tools like SQLMap also assist in detecting potential vulnerabilities.</li></ol><p>Now, let’s move on to the assessment.</p><h2 id="Assessment"><a href="#Assessment" class="headerlink" title="Assessment:"></a>Assessment:</h2><p>Below, I will provide a few short questions. These questions are designed to test your understanding and application of the concepts we’ve discussed.</p><ol><li><strong>What are the distinguishing signs that indicate a system may be vulnerable to an SQL Injection attack?</strong></li><li><strong>How can prepared statements be used to prevent SQL Injection attacks?</strong></li><li><strong>Why are comprehensive error handling and not exposing database errors to end-users important?</strong></li><li><strong>Describe at least two best practices that should be followed to protect against SQL Injection attacks.</strong></li></ol><hr><ol><li><strong>What are the distinguishing signs that indicate a system may be vulnerable to an SQL Injection attack?</strong><br> Answer: Systems may be prone to SQL Injection if they directly use input in SQL queries without proper cleansing or validation, expose database errors to end-users, or do not use parameterized queries or prepared statements. Signs might include unexpected behavior from user inputs such as a single quote causing errors, or certain inputs providing access or data retrieval that shouldn’t be possible.</li><li><strong>How can prepared statements be used to prevent SQL Injection attacks?</strong><br> Answer: Prepared statements separate SQL query structure from the data provided by the user. This stops attackers from manipulating the query structure because user input is not treated as part of the SQL command, making SQL injection attempts ineffective.</li><li><strong>Why are comprehensive error handling and not exposing database errors to end-users important?</strong><br> Answer: Exposing database errors to end users can provide attackers with useful information about your database structure or application design, which can be exploited for an attack. Besides, comprehensive error handling is important in preventing SQL Injection attacks as it allows systems to gracefully deal with issues that arise and can provide logging or other mechanisms to alert about possible attacks.</li><li><strong>Describe at least two best practices that should be followed to protect against SQL Injection attacks.</strong><br> Answer: Some best practices include:</li></ol><ul><li>Use of Prepared Statements or Parameterized Queries: These ensure user-provided input can’t alter the SQL query structure undesirably.</li><li>Input Validation: Inputs should be validated as being of the correct form before they are used. For example, if the system expects an integer, it should confirm the input is indeed an integer.</li><li>Other best practices can include proper error handling, regular system updates, adoption of least privilege principles, and more.</li></ul><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview7/">https://programmerscareer.com/zh-cn/mysql-interview7/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL interviews: When doesn’t MySQL use the index?</title>
      <link href="/mysql-interview8/"/>
      <url>/mysql-interview8/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Have you ever been asked a similar question in an interview? Or you will meet in the future, let’s explore and master it together</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-MySQL-Index-Deep-Dive"><a href="#Topic-MySQL-Index-Deep-Dive" class="headerlink" title="Topic: MySQL Index Deep Dive"></a>Topic: MySQL Index Deep Dive</h1><p>Detailed analysis of indexes in MySQL</p><p>Indexes in MySQL play an essential role in optimizing database search performance. To get a more in-depth understanding of indexes, let’s break down the concept further.</p><p>What exactly is an index in MySQL?<br>Think of an index as the equivalent of a book’s index. In a book, if you needed to find information, you’d refer to the index, which would quickly guide you to the relevant page containing the information you require.</p><p>In MySQL, an index is a data structure (most commonly a B-Tree) that improves the speed of data retrieval operations on a database table. Indexes are used to quickly locate data without having to search every row in a database table every time a database table is accessed.</p><p>They can be created using one or more columns of a database table, providing a basis for both rapid random lookups and efficient ordering of access to records.</p><p>Benefits of using indexes in MySQL:</p><ol><li><strong>Faster Data Retrieval:</strong>&nbsp;The primary advantage of using indexes is the speed they bring to data retrieval. Indexes enable the database application to find the record much faster.</li><li><strong>Order By Optimization:</strong>&nbsp;Indexes can also optimize the order by clause to sort the data more quickly.</li><li><strong>Better Performance:</strong>&nbsp;They significantly improve the performance of SELECT queries and WHERE clauses.</li></ol><p>However, keep in mind that while indexes speed up data retrieval, they slow down data modification operations like INSERT, DELETE, and UPDATE. This is because each time we modify data in the table, the indexes need to be updated as well.</p><h1 id="Topic-Types-of-Indexes-in-MySQL"><a href="#Topic-Types-of-Indexes-in-MySQL" class="headerlink" title="Topic: Types of Indexes in MySQL"></a>Topic: Types of Indexes in MySQL</h1><p>Understanding the different types of indexes available in MySQL like PRIMARY, UNIQUE, INDEX, FULLTEXT, and their usage.</p><p>There are several types of Indexes available in MySQL. Each type is used in specific scenarios and offers its own set of advantages. Let’s take a closer look at these different types:</p><ol><li><strong>PRIMARY Index:</strong>&nbsp;This is the main index of a table. Each MySQL table should have a primary index. The value in this index is unique and not null. In most cases, this is the primary key of your table.</li><li><strong>UNIQUE Index:</strong>&nbsp;As the name suggests, this index prevents two records from having identical values in a particular column. This helps maintain data integrity. It allows null values, but the uniqueness is still enforced.</li><li><strong>INDEX (or KEY):</strong>&nbsp;This is the simplest kind of index. It allows duplicates and null values. It’s generally used when you want to improve the performance of certain searches, and you don’t need to enforce uniqueness or non-nullability.</li><li><strong>FULLTEXT Index:</strong>&nbsp;This is an index that’s used for full-text searches. It’s a very powerful index type for searching text values. However, it’s a specialized type of index and only applies to text (not numbers or dates).</li></ol><p>Each of these indexes serves a specific purpose. The optimal usage of these indexes can greatly enhance the performance of your database.</p><p>Understanding when and where to use the appropriate index is crucial. It depends on various factors like the data stored, the integrity needed, the type of queries executed, and many others.</p><h1 id="Topic-MySQL-Index-Management"><a href="#Topic-MySQL-Index-Management" class="headerlink" title="Topic: MySQL Index Management"></a>Topic: MySQL Index Management</h1><p>Familiarizing ourselves with how to manage indexes in MySQL is a crucial skill for optimizing database performance.</p><p>There are several primary operations you can carry out when working with indexes:</p><h2 id="Creating-an-Index"><a href="#Creating-an-Index" class="headerlink" title="Creating an Index:"></a>Creating an Index:</h2><p>To create an index in MySQL, you could use the&nbsp;<code>CREATE INDEX</code>&nbsp;statement:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX index_name  </span><br><span class="line">ON table_name (column1, column2, …);</span><br></pre></td></tr></tbody></table></figure><p>For example, if we had a table named&nbsp;<code>Students</code>&nbsp;and we wanted to create an index on the&nbsp;<code>LastName</code>&nbsp;and&nbsp;<code>FirstName</code>&nbsp;columns, we would write:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE INDEX idx_students_name  </span><br><span class="line">ON Students (LastName, FirstName);</span><br></pre></td></tr></tbody></table></figure><h2 id="Dropping-an-Index"><a href="#Dropping-an-Index" class="headerlink" title="Dropping an Index:"></a>Dropping an Index:</h2><p>To delete an index in MySQL, you could use the&nbsp;<code>DROP INDEX</code>&nbsp;statement:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP INDEX index_name ON table_name;</span><br></pre></td></tr></tbody></table></figure><h2 id="Disabling-an-Index"><a href="#Disabling-an-Index" class="headerlink" title="Disabling an Index:"></a>Disabling an Index:</h2><p>In some cases, you might want to disable an index temporarily. MySQL allows you to disable an index using the&nbsp;<code>ALTER TABLE</code>&nbsp;statement:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE table_name DISABLE KEYS;</span><br></pre></td></tr></tbody></table></figure><p>To enable it again, you would use&nbsp;<code>ENABLE KEYS</code>:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE table_name ENABLE KEYS;</span><br></pre></td></tr></tbody></table></figure><h2 id="Renaming-an-Index"><a href="#Renaming-an-Index" class="headerlink" title="Renaming an Index:"></a>Renaming an Index:</h2><p>MySQL does not support direct renaming of an index. To rename an index, you would have to drop (delete) the index and then create it again with the new name.</p><p>Remember, while indexes are beneficial and may speed up data retrieval, they come with their own costs. Indexes take up storage space and slow down the speed of updating data (because when data is updated, indexes need to be updated as well).</p><h1 id="Topic-Optimizing-MySQL-with-Indexes"><a href="#Topic-Optimizing-MySQL-with-Indexes" class="headerlink" title="Topic: Optimizing MySQL with Indexes"></a>Topic: Optimizing MySQL with Indexes</h1><p>Understanding how to optimize MySQL performance using indexes is a crucial part of managing a database.</p><p>One of the key factors that affect the efficiency of your data retrieval operations is the proper use of indexes. But how do you know if your indexes are efficient? Enter the&nbsp;<code>EXPLAIN</code>&nbsp;command.</p><p>The&nbsp;<code>EXPLAIN</code>&nbsp;command in MySQL is a powerful tool to help understand how MySQL executes a query. By using the&nbsp;<code>EXPLAIN</code>&nbsp;command before a SQL statement, MySQL will return information about how it would process the statement and the order in which tables are read.</p><p>Here’s an example:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM Students WHERE LastName = "Smith";</span><br></pre></td></tr></tbody></table></figure><p>The output may return a lot of data, but what one needs to focus on are mainly three columns:</p><ol><li><strong>select_type:</strong>&nbsp;This tells us what type of select the query is.</li><li><strong>key:</strong>&nbsp;This tells us what index MySQL is using to run the query.</li><li><strong>rows:</strong>&nbsp;This tells us how many rows MySQL had to consider to give the result of the query.</li></ol><p>Another important thing to note is that different queries require different types of tuning. For example, a&nbsp;<code>SELECT</code>&nbsp;query that retrieves data may be optimized differently from an&nbsp;<code>UPDATE</code>&nbsp;query that modifies data.</p><p>As a general rule, indexing the columns that you often use in your&nbsp;<code>WHERE</code>,&nbsp;<code>JOIN</code>,&nbsp;<code>ORDER BY</code>, and&nbsp;<code>GROUP BY</code>&nbsp;clauses can significantly increase the speed of your&nbsp;<code>SELECT</code>&nbsp;queries.</p><p>However, keep in mind that indexes add overhead to the database when it comes to&nbsp;<code>INSERT</code>,&nbsp;<code>UPDATE</code>, and&nbsp;<code>DELETE</code>&nbsp;statements. Therefore, the number of indexes should be kept to a minimum to reduce overhead.</p><p>This understanding of SQL indexes and how to use the&nbsp;<code>EXPLAIN</code>&nbsp;command to analyze query performance is vital for managing and optimizing your MySQL database.</p><h1 id="Topic-When-MySQL-Doesn’t-Use-The-Index"><a href="#Topic-When-MySQL-Doesn’t-Use-The-Index" class="headerlink" title="Topic: When MySQL Doesn’t Use The Index"></a>Topic: When MySQL Doesn’t Use The Index</h1><p>Even though indexes are designed to optimize data retrieval, there are scenarios where MySQL doesn’t use an index even if one exists. Let’s dive into some of these scenarios:</p><ol><li><strong>Small Tables:</strong>&nbsp;In tables where the total number of rows is less, the MySQL optimizer may ignore the index and execute a full table scan instead. This is because reading the index first and then fetching the row may involve more overhead than simply reading every row directly.</li><li><strong>Poor Selectivity:</strong>&nbsp;Indexes with low selectivity (meaning the indexed column has many duplicate values) are less effective. If an indexed column can’t sufficiently narrow down the rows, MySQL may skip using the index in favor of a full table scan.</li><li><strong>NULL Values:</strong>&nbsp;If the indexed column has NULL values and the WHERE clause is IS NULL or IS NOT NULL, MySQL can’t use an index because comparison operators do not work with NULL.</li><li><strong>Not using the leftmost prefix of the index:</strong>&nbsp;MySQL can use an index efficiently when the WHERE clause uses the leftmost part of a multi-column index. However, when the query does not involve the leftmost part, MySQL can’t use the index effectively.</li><li><strong>LIKE Operator with Wildcards at the Start:</strong>&nbsp;When you use a LIKE operator in a WHERE clause and the pattern starts with a wildcard, MySQL can’t leverage the index.</li></ol><p>Remember, indexes are a great tool for optimizing data retrieval, but they are not always used. A solid understanding of how and when indexes are utilized by MySQL can inform your database design and query construction.</p><h1 id="Topic-Review-and-Assessments"><a href="#Topic-Review-and-Assessments" class="headerlink" title="Topic: Review and Assessments"></a>Topic: Review and Assessments</h1><p>We have now reached the end of our curriculum. Before we wrap up, let’s do a quick recap:</p><ul><li>We deep-dived into the concept of MySQL indexes.</li><li>We learned about the different types of indexes in MySQL.</li><li>We understood how to manage indexes in MySQL.</li><li>We saw how indexes can be used to optimize MySQL performance and how to evaluate this performance using the&nbsp;<code>EXPLAIN</code>&nbsp;command.</li><li>And, we delved into scenarios when MySQL may not use an index.</li></ul><p>Now, it’s time to put your knowledge to the test. Here are a few thought-provoking questions:</p><ol><li>What is the main purpose of an index in MySQL, and how does it enhance database performance?</li><li>Can you describe two different types of indexes in MySQL and when you would use them?</li><li>How would you disable and then re-enable an index in MySQL?</li><li>In what scenario would MySQL choose not to use an index even when it’s available?</li><li>Can you draft a SQL query using an EXPLAIN statement when querying data from a&nbsp;<code>employees</code>&nbsp;table based on an&nbsp;<code>employee_id</code>?</li></ol><p>Try to write down your answers, then compare them to your notes or any resources you’ve used throughout this journey. Reviewing your knowledge like this will reinforce your learning immensely.</p><p>Remember, mastering any subject is a matter of time, practice, and consistent effort. Keep striving!</p><hr><ol><li><strong>What is the main purpose of an index in MySQL and how does it enhance database performance?</strong><br> An index in MySQL is a data structure that improves the speed of data retrieval operations on a database table. It works similarly to an index in a book, enabling the database to find data without scanning each row of the database every time a database table is accessed. Indexes can dramatically improve database performance.</li><li><strong>Can you describe two different types of indexes in MySQL and when you would use them?</strong></li></ol><ul><li>PRIMARY index: This is a type of unique index where a column must contain unique and not null values. This is typically used for the primary key.</li><li>FULLTEXT index: This is used for full-text searches. It’s dedicated to the search of text through SQL queries where the search in the string localization pattern is complex.</li></ul><ol><li><strong>How would you disable and then re-enable an index in MySQL?</strong></li></ol><ul><li>To disable non-unique indexes:&nbsp;<code>ALTER TABLE table_name DISABLE KEYS;</code></li><li>To enable non-unique indexes:&nbsp;<code>ALTER TABLE table_name ENABLE KEYS;</code></li></ul><ol><li><strong>In what scenario would MySQL choose not to use an index even when it’s available?</strong><br> MySQL may choose not to use an index if it estimates that using the index would be slower than a full table scan. For example, if the table is small or the indexed column has very low selectivity (many repeated values), MySQL may prefer a full table scan.</li><li><strong>Can you draft a SQL query using an EXPLAIN statement when querying data from a</strong>&nbsp;<code>**employees**</code>&nbsp;<strong>table based on an</strong>&nbsp;<code>**employee_id**</code><strong>?</strong><br> Here’s a basic example:</li></ol><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM employees WHERE employee_id = 101</span><br></pre></td></tr></tbody></table></figure><p>Remember, practice is key in mastering these concepts. Don’t hesitate to dive deeper and try out these commands in a real MySQL environment to explore further!</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview8/">https://programmerscareer.com/zh-cn/mysql-interview8/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL interviews: How to tune MySQL performance</title>
      <link href="/mysql-interview9/"/>
      <url>/mysql-interview9/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Let we dive into tuning MySQL performance  </p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-Understanding-MySQL-Configuration"><a href="#Topic-Understanding-MySQL-Configuration" class="headerlink" title="Topic: Understanding MySQL Configuration"></a><strong>Topic: Understanding MySQL Configuration</strong></h1><p>One of the key aspects of tuning MySQL performance is understanding and appropriately adjusting its configuration. But first, let’s understand what we mean by “configuration” in MySQL.</p><p><strong>MySQL Configuration</strong>&nbsp;refers to the set of parameters and settings that dictate how MySQL operates. Some of these settings include variables controlling memory allocation, table cache size, and sort buffer size.</p><p>The configuration file for MySQL is typically named&nbsp;<code>my.cnf</code>, though the exact location of this file can vary depending on the operating system and MySQL version.</p><p>The&nbsp;<code>my.cnf</code>&nbsp;file contains several sections. The&nbsp;<code>[mysqld]</code>&nbsp;section contains server-specific settings, while the&nbsp;<code>[client]</code>&nbsp;section contains client-specific options. Any modifications to the settings in this file will affect the MySQL server’s operations.</p><p>Let’s consider a few important settings:</p><ul><li><strong>innodb_buffer_pool_size:</strong>&nbsp;This is a crucial setting if you’re using InnoDB storage engine. The buffer pool is where data and indexes are cached, so setting it appropriately can significantly improve performance.</li><li><strong>max_connections:</strong>&nbsp;This determines how many concurrent connections MySQL can handle. Be cautious, though — a high number here can cause MySQL to use up available resources quickly.</li><li><strong>query_cache_size:</strong>&nbsp;Query caching can help speed up response times, but it has to be used judiciously since it adds additional overhead to all query processing.</li></ul><p>To make changes, you would edit these parameters in the&nbsp;<code>my.cnf</code>&nbsp;file and then restart MySQL for the changes to take effect.</p><p>Understanding these configurations and how to fine-tune them based on your specific use case can greatly enhance your MySQL server’s performance.</p><h1 id="Topic-Tuning-Server-Settings"><a href="#Topic-Tuning-Server-Settings" class="headerlink" title="Topic: Tuning Server Settings"></a><strong>Topic: Tuning Server Settings</strong></h1><p>Now that we understand the fundamentals of MySQL configuration, let’s delve into some essential server settings that you can adjust to optimize the performance.</p><p>MySQL has a vast array of server variables you can set to affect its operation. It allows for a high degree of customization and tuning to suit the specific application and hardware environment. Here’s a look at some of the key variables:</p><p><strong>1. key_buffer_size:</strong>&nbsp;This variable determines the amount of memory allocated for caching MyISAM tables indexes in memory. If you’re using MyISAM tables, large values might improve performance.</p><p><strong>2. innodb_buffer_pool_size:</strong>&nbsp;As mentioned earlier, this setting is critical for systems using the InnoDB storage engine. It specifies the size of the memory buffer InnoDB uses to cache data and indexes of its tables.</p><p><strong>3. thread_cache_size:</strong>&nbsp;This variable is used to specify how many threads the server should cache for reuse. When a client disconnects, the client’s threads are put in the cache, and if clients connect, they can reuse the threads in the cache.</p><p><strong>4. table_open_cache:</strong>&nbsp;This variable sets the number of open tables for all threads. Increasing this value increases the number of file descriptors that mysqld requires.</p><p><strong>5. query_cache_size:</strong>&nbsp;It sets the size of the query cache. It is used to cache SELECT results and later return them without actual executing the same query once again.</p><p>Remember that configuration and tuning MySQL is more of an art than a science, consisting largely of incremental changes and continuous monitoring. Using tools like MySQLTuner or MySQL Workbench can be very handy to monitor your MySQL server’s performance and make necessary adjustments.</p><h1 id="Topic-Query-Optimization"><a href="#Topic-Query-Optimization" class="headerlink" title="Topic: Query Optimization"></a><strong>Topic: Query Optimization</strong></h1><p>Optimizing your SQL queries is one of the most effective ways to improve your MySQL server’s performance. Here are some strategies that could help:</p><ol><li><strong>Avoid Full Table Scans:</strong>&nbsp;Try your best to avoid full table scans by using indexes appropriately (more on this later). MySQL must read the entire table to find the relevant rows when a full table scan occurs, which can kill performance when dealing with large tables.</li><li><strong>Use EXPLAIN to Analyze Query Performance:</strong>&nbsp;The EXPLAIN statement in MySQL provides information about how MySQL executes queries. It is a beneficial debugging and optimization tool.</li><li><strong>Take Advantage of Indexes:</strong>&nbsp;Indexes are utilized to find rows with specific column values quickly. Without an index, MySQL must scan the entire table to locate the relevant rows.</li><li><strong>Limit Your Results:</strong>&nbsp;If you don’t need the entire result set for your operations, the use of LIMIT can significantly reduce the cost of a query.</li><li><strong>Normalize and De-normalize — As Needed:</strong>&nbsp;While normalization is generally a good thing as it reduces data redundancy, de-normalization may actually help in certain situations. For instance, if there are large tables and primary-key-to-primary-key joins, the joins might be slow. De-normalization might speed up such queries by allowing you to bypass those joins.</li></ol><h1 id="Topic-Optimizing-Schema-Objects"><a href="#Topic-Optimizing-Schema-Objects" class="headerlink" title="Topic: Optimizing Schema Objects"></a><strong>Topic: Optimizing Schema Objects</strong></h1><p>While server and query optimization, which we previously discussed, are crucial for MySQL performance, schema optimization is also a vital factor that shouldn’t be overlooked. Here’s what you should know:</p><p><strong>1. Table Type Selection:</strong>&nbsp;MySQL supports several storage engines, each with its pros and cons. The most commonly used are MyISAM and InnoDB. MyISAM is more straightforward and often performs better for read-heavy loads. In contrast, InnoDB supports advanced features like transactions and foreign keys and is better suited for write-heavy loads.</p><p><strong>2. Indexing:</strong>&nbsp;Indices are used to quickly locate data without needing to search every row in a database table each time a database table is accessed. They can speed up data retrieval but should be used judiciously, as each index you add increases the cost of inserting, updating, and deleting records.</p><p><strong>3. Normalization:</strong>&nbsp;It is the process of efficiently organizing data in a database with two goals — eliminate redundant data (for example, storing the same data in more than one table) and ensure data dependencies make sense. While normalization often improves performance, in some cases, you might need to consider denormalization for optimization purposes.</p><p><strong>4. Partitioning:</strong>&nbsp;Partitioning can be a powerful tool for improving performance in databases with large tables. It works by splitting a large table into smaller, more manageable pieces called partitions. Each partition stores a certain subset of your table’s data defined by a partitioning function.</p><p>Remember, the schema optimization should be tailored to the specific needs of your application and the characteristics of your workload. Make sure to monitor your database’s performance over time and adjust your schema as your application’s requirements evolve.</p><h1 id="Topic-Hardware-Consideration-and-Tuning"><a href="#Topic-Hardware-Consideration-and-Tuning" class="headerlink" title="Topic: Hardware Consideration and Tuning"></a><strong>Topic: Hardware Consideration and Tuning</strong></h1><p>MySQL performance can significantly be influenced by hardware components such as CPU, memory, disk storage, and network. Let’s take a closer look:</p><p><strong>1. CPU:</strong>&nbsp;The faster your server’s CPU can process data, the faster your MySQL performance will be. One technique is to balance the load across CPUs, a feature which MySQL supports.</p><p><strong>2. Memory:</strong>&nbsp;A MySQL server uses a lot of memory. The more memory you have, the more data you can cache, and the fewer disk I/O operations MySQL needs to perform, the more efficient it becomes. Consider adjusting the innodb_buffer_pool_size, which is the memory area that holds cached InnoDB data for both tables and indexes.</p><p><strong>3. Disk Storage:</strong>&nbsp;The type of disk you use affects MySQL performance. Solid State Drives (SSDs) typically have faster data access times compared to traditional Hard Disk Drives (HDDs). Remember that writing to disk is much slower than reading from memory. Therefore, it’s crucial to have enough memory to minimize disk writing operations.</p><p><strong>4. Network:</strong>&nbsp;Network latency can impact MySQL performance, especially in distributed systems where MySQL instances need to communicate over the network. Upgrading to a faster network technology can lower this latency and improve overall performance.</p><p>Optimizing hardware to cater to your MySQL database’s needs can significantly boost its performance. Remember to monitor your database over time to assess how well your hardware serves your needs. Sometimes, certain limitations can only be overcome by upgrading or adding more hardware resources.</p><h1 id="Topic-MySQL-Replication-Partitioning"><a href="#Topic-MySQL-Replication-Partitioning" class="headerlink" title="Topic: MySQL Replication &amp; Partitioning"></a><strong>Topic: MySQL Replication &amp; Partitioning</strong></h1><p><strong>MySQL Replication</strong>&nbsp;and&nbsp;<strong>Partitioning</strong>&nbsp;are two powerful tools in a developer’s arsenal to enhance database performance. Let’s break them down:</p><p><strong>1. MySQL Replication:</strong></p><p>MySQL replication is a process that enables you to maintain multiple copies of MySQL data by having them copied automatically from a master to a slave database. This can be helpful for many reasons, including facilitating a backup of data, creating a failover environment, or segregating the database in order to simplify routine tasks. Replication can also improve performance for high demand applications by distributing the load among multiple slave nodes.</p><p><strong>2. MySQL Partitioning:</strong></p><p>Partitioning is a process where large tables are divided into smaller ones, improving query performance and simplifying management tasks. MySQL has the capacity to divide tables into partitions, storing them separately. There are various ways to partition your data:</p><ul><li><strong>Range Partitioning:</strong>&nbsp;The table is partitioned into ranges determined by the partitioning function. The values falling into a range are stored in an assigned partition. For example, you might partition sales data into monthly ranges.</li><li><strong>List Partitioning:</strong>&nbsp;Similar to range partitioning, but the partition is selected based on columns matching one of a set of discrete value lists.</li><li><strong>Hash Partitioning:</strong>&nbsp;The partitioning function generates a hash value, which determines the partition.</li><li><strong>Key Partitioning:</strong>&nbsp;Similar to hash partitioning, but only certain column types can be used (integer, binary, or string types).</li><li><strong>Composite Partitioning:</strong>&nbsp;A mixture of range or list partitioning with hash or key partitioning.</li></ul><p>Understanding these concepts and implementing them can greatly enhance your database’s performance. Moreover, it also allows for more robustness and scalability in your systems.</p><h1 id="Topic-Review-Assessments"><a href="#Topic-Review-Assessments" class="headerlink" title="Topic: Review &amp; Assessments"></a><strong>Topic: Review &amp; Assessments</strong></h1><p>At this stage, it is important to recap everything that we have discovered so far.</p><p><strong>1. MySQL Configuration:</strong></p><p>We’ve learnt the importance of MySQL configuration and how to tune various parameters to improve performance. Each MySQL installation is unique, and fine-tuning it to suit individual needs can significantly boost performance.</p><p><strong>2. Tuning Server Settings:</strong></p><p>We delved into the different settings we can tune, related to memory, caches, and various other server settings for optimal efficiency.</p><p><strong>3. Query Optimization:</strong></p><p>We understood how MySQL processes queries and ways to write them more efficiently to save resources.</p><p><strong>4. Optimizing Schema Objects:</strong></p><p>The importance of optimizing MySQL schema objects such as tables and indexes for better performance was highlighted, along with techniques of doing so.</p><p><strong>5. Hardware Consideration and Tuning:</strong></p><p>We learned about the impact of hardware parameters such as CPU, memory, disk, and network on MySQL performance and how hardware resources can be optimized for better performance.</p><p>let’s go ahead with the assessments.</p><p><strong>6. MySQL Replication and Partitioning:</strong></p><p>We explored the concepts of MySQL replication and partitioning, understanding their utility in enhancing database performance.</p><p><strong>Assessment 1: MySQL Configuration</strong></p><p>What is meant by MySQL configuration and why is it significant in database management?</p><p><strong>Assessment 2: Server Settings</strong></p><p>Can you explain how changing server settings can help in optimizing the performance of a MySQL database?</p><p><strong>Assessment 3: Query Optimization</strong></p><p>What strategies can you employ to optimize your SQL queries?</p><p><strong>Assessment 4: Schema Objects</strong></p><p>Discuss the importance of optimizing schema objects in MySQL.</p><p><strong>Assessment 5: Hardware Considerations</strong></p><p>How does hardware impact MySQL performance? What parameters can be tuned for optimization?</p><p><strong>Assessment 6: Replication and Partitioning</strong></p><p>Explain the concepts of MySQL replication and partitioning. How do these techniques aid in enhancing database performance?</p><p>Please take some time to answer these questions</p><hr><p><strong>Assessment 1: MySQL Configuration</strong></p><p>MySQL configuration involves customizing settings that determine how MySQL operates. It’s significant because the right configuration can ensure efficient use of system resources, faster query execution, and generally improved performance.</p><p><strong>Assessment 2: Server Settings</strong></p><p>Changing server settings, such as increasing buffer sizes or limiting the maximum connections, can greatly improve MySQL performance. For instance, increasing the buffer size can allow more data to be stored in memory, reducing disk I/O. However, all changes should be made considering the cargo of the system resources.</p><p><strong>Assessment 3: Query Optimization</strong></p><p>To optimize SQL queries, one can use strategies such as selecting only necessary fields, using joins appropriately, creating indexes for faster search, using limit where possible, and avoiding the use of wildcard ‘%’ at the beginning of a query.</p><p><strong>Assessment 4: Schema Objects</strong></p><p>Optimizing schema objects can significantly speed up queries. Techniques such as appropriate indexing, choosing suitable data types, and normalizing the database can improve performance.</p><p><strong>Assessment 5: Hardware Considerations</strong></p><p>Hardware directly impacts MySQL performance. The CPU speed affects how fast queries are processed, and plenty of memory allows for larger caches and buffers — reducing disk I/O. Faster disks also decrease I/O wait time. To tune it, you can add more memory, use faster disks, or even distribute your database across several machines.</p><p><strong>Assessment 6: Replication and Partitioning</strong></p><p>MySQL replication is a process where data from one MySQL database server (the master) is replicated to one or more MySQL database servers (the slaves). It increases data security, improves performance for high-volume sites, and is part of a good backup strategy.</p><p>Partitioning is a database design technique which is used to improves performance, manageability, simplifies maintenance and reduce the cost of storing large amounts of data. It works by breaking down a single table, which is stored in one file or area of disk, into smaller members, each of which can be managed and accessed individually.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/mysql-interview9/">https://programmerscareer.com/zh-cn/mysql-interview9/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis interviews: The application, advantages and disadvantages of skiplists in Redis</title>
      <link href="/redis-interview1/"/>
      <url>/redis-interview1/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Have you ever been asked a similar question in an interview? Or you will meet in the future, let’s explore and master it together</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-Introduction-to-Skip-Lists"><a href="#Topic-1-1-Introduction-to-Skip-Lists" class="headerlink" title="Topic: 1.1 Introduction to Skip Lists"></a><strong>Topic</strong>: 1.1 Introduction to Skip Lists</h1><p>Skip lists are fascinating data structures. They were designed with simplicity and speed in mind.</p><p>A&nbsp;<strong>Skip List</strong>&nbsp;is a probabilistic data structure that allows efficient search, insertion, and removal operations. It’s quite similar to a sorted linked list, but the genius of Skip Lists lies in how they enhance the speed of the operations.</p><p>The primary idea of a Skip List is to “skip” a significant number of elements rather than traversing a linked list to find an element. It uses a hierarchy of linked lists that connect progressively with a fraction of the elements. This fraction reduces as we climb the Skip List hierarchy, which gives us an efficient search operation.</p><p>Skip Lists shine in big data scenarios. They have an average-case and worst-case search and insertion time complexity of O(log n), which makes them super efficient!</p><p>While they may not have the same popularity as more common data structures, Skip Lists have significant applications, one of which includes being used in databases like Redis. The next lessons will help us delve deeper into how Redis leverages Skip Lists.</p><h1 id="Topic-1-2-Skip-Lists-in-Redis"><a href="#Topic-1-2-Skip-Lists-in-Redis" class="headerlink" title="Topic: 1.2 Skip Lists in Redis"></a><strong>Topic</strong>: 1.2 Skip Lists in Redis</h1><p>Redis, a well-known open-source, in-memory data structure project, implements skip lists in its codebase for certain use cases. One of the most notable is the Sorted Set data type.</p><p>A Sorted Set in Redis is a set where every element is associated with a ‘score’. Despite how one could achieve this with a traditional hash map, the power of Sorted Sets is that they are always sorted by this score. This is where skip lists come in.</p><p>Redis choses to implement this Sorted Set with a combination of a hash table and a skip list. The hash table allows Redis to quickly lookup an element in the set, and the skip list maintains the elements sorted by their scores, allowing for fast retrieval of ranges of elements, finding the rank of an element, etc.</p><p>The union, intersection, and difference operations over Sorted Sets that involve multiple keys are also implemented with skip lists. Furthermore, when Redis needs to iterate over a large Sorted Set, it will use the skip list instead of the hash table to do so because of the improved efficiency.</p><p>Skip lists provide efficient search and insertion operations which is crucial for the performance requirements of Redis.</p><h1 id="Topic-1-3-The-Application-of-Skip-Lists-in-Redis"><a href="#Topic-1-3-The-Application-of-Skip-Lists-in-Redis" class="headerlink" title="Topic: 1.3 The Application of Skip Lists in Redis"></a><strong>Topic</strong>: 1.3 The Application of Skip Lists in Redis</h1><p>Redis leverages skip lists extensively, particularly when it comes to sorted sets. But why did Redis choose skip lists considering there are many other data structures that could have been utilized, like binary search trees or AVL Trees? There are a few reasons for this.</p><p>First, it comes down to simplicity. Skip lists are easier to implement and have fewer edge cases compared to balanced trees. They don’t require restructuring/redistribution (like tree rotations) after insertions and deletions, making them an appealing choice for a high-performance database like Redis.</p><p>Due to their design, skip lists provide near-balanced tree performance without requiring balancing operations. While AVL Trees offer good performance, the balancing operation can become a bottleneck in heavy read-write situations, which are common in databases like Redis.</p><p>Moreover, skip lists support quick insertion, deletion, and lookups with just a few level changes, making them an optimal choice for sorted data structures.</p><p>The use of Skip Lists in Redis goes beyond sorted sets and into the internals of the Redis Cluster feature. Skip lists in Redis are used to handle the distribution of hash slots across different nodes in a Redis Cluster.</p><p>This allows the Redis Cluster to quickly locate the right node to distribute a given piece of data, which increases the efficiency of data operations across the cluster.</p><p>Remember, each technology makes decisions based on a range of factors including performance, functionality, simplicity, and so on. Redis’s decision to use skip lists is a fascinating example of the right tool for the right job!</p><h1 id="Topic-1-4-The-Advantages-of-Skip-Lists-in-Redis"><a href="#Topic-1-4-The-Advantages-of-Skip-Lists-in-Redis" class="headerlink" title="Topic: 1.4 The Advantages of Skip Lists in Redis"></a><strong>Topic</strong>: 1.4 The Advantages of Skip Lists in Redis</h1><p>The use of skip lists in Redis offers several advantages, particularly when dealing with trimmed lists of items. Key benefits of using skip lists in Redis include:</p><p><strong>1. Efficient Search Operations:</strong>&nbsp;Skip lists have logarithmic search times making them highly efficient for searching for elements. Instead of sequentially searching an item in a list, we can efficiently skip nodes resulting in faster search times. This makes Skip Lists particularly advantageous for Sorted Sets.</p><p><strong>2. Simplicity of Implementation:</strong>&nbsp;Skip lists are simpler to implement than balanced search trees. A binary search tree, for instance, requires complex balancing after every insertion and deletion. Skip lists, on the other hand, maintain balance probabilistically, hence eliminating the need for complex rebalancing operations after every mutation.</p><p><strong>3. Fast Insertion and Deletion Operations:</strong>&nbsp;Skip lists support quick insertions, deletions, and search operations. Especially in Redis, where data operations are frequent, the efficiency of these operations plays a vital role.</p><p><strong>4. Efficient Range Queries:</strong>&nbsp;Skip Lists are especially efficient at range queries, a key requirement for sorted sets. For instance, fetching ranges, finding rank of elements, closest lower and higher rank items, etc., are much faster and simpler with skip lists.</p><p><strong>5. Dynamic Resizing:</strong>&nbsp;Skip lists have an excellent feature of reorganizing themselves dynamically. When an element is added or removed, skip lists can rebuild their layers dynamically.</p><p>These advantages have been crucial in reinforcing the performance of Redis, allowing it to handle large sets of data with speed and efficiency.</p><h1 id="Topic-1-5-The-Disadvantages-of-Skip-Lists-in-Redis"><a href="#Topic-1-5-The-Disadvantages-of-Skip-Lists-in-Redis" class="headerlink" title="Topic: 1.5 The Disadvantages of Skip Lists in Redis"></a><strong>Topic</strong>: 1.5 The Disadvantages of Skip Lists in Redis</h1><p>While skip lists provide numerous benefits for Redis, a few challenges can arise:</p><p><strong>1. Space Usage:</strong>&nbsp;Skip lists tend to use more space than other data structures. Every node in a skip list maintains several pointers to other nodes, which increases the memory footprint. However, Redis addresses this by limiting the maximum number of levels a skip list node can have.</p><p><strong>2. Randomness:</strong>&nbsp;One of the characteristics of a skip list is its probabilistic nature. The levels of the nodes of a skip list are chosen at random during insertion. While this randomization has benefits, it leads to the unpredictability of the skip list structure.</p><p><strong>3. Not Ideal for Small Datasets:</strong>&nbsp;Skip lists excel when managing large, sorted datasets due to their logarithmic operation time complexity. However, for small datasets, the overhead of maintaining skip list pointers and the increased space usage may not be justified.</p><p><strong>4. Difficulty in Understanding:</strong>&nbsp;While not a direct disadvantage, the concept of skip lists can be daunting for those unfamiliar with it. This can complicate the process of understanding and troubleshooting Redis performance.</p><p><strong>5. Lack of Wide Use:</strong>&nbsp;Skip Lists are not as widely used or studied as hash tables, AVL trees, or B-trees. This can lead to a slightly higher difficulty in understating and making modifications to the data structure.</p><p>Despite these challenges, Redis implements skip lists elegantly, gaining the benefits without suffering significant setbacks.</p><h1 id="Topic-1-6-Review-and-Assessments-of-Skip-Lists-in-Redis"><a href="#Topic-1-6-Review-and-Assessments-of-Skip-Lists-in-Redis" class="headerlink" title="Topic: 1.6 Review and Assessments of Skip Lists in Redis"></a><strong>Topic</strong>: 1.6 Review and Assessments of Skip Lists in Redis</h1><p>Let’s conduct a review of each section:</p><p><strong>1.1 Introduction to Skip Lists:</strong>&nbsp;We discussed the basic structure and concept of skip lists, including where they are typically used and why.</p><p><strong>1.2 Skip Lists in Redis:</strong>&nbsp;We focused on how Redis leverages skip lists, particularly when dealing with sorted sets.</p><p><strong>1.3 The Application of Skip Lists in Redis:</strong>&nbsp;We dove deeper into the everyday use-cases of skip lists in a Redis environment, from simple sorted sets to the internals of Redis Cluster.</p><p><strong>1.4 The Advantages of Skip Lists in Redis:</strong>&nbsp;We examined the major benefits of using skip lists, such as its efficiency in search, insertion, and deletion operations, simplicity in implementation, and dynamic resizing capability.</p><p><strong>1.5 The Disadvantages of Skip Lists in Redis:</strong>&nbsp;We also addressed their downsides, including additional space usage, randomness, complexity, and the challenge these aspects pose in understanding, maintaining, and utilizing skip lists in Redis.</p><p>Now, to further cement your understanding, I’m going to provide some short assessment questions:</p><ol><li>Can you explain why Skip Lists are used in Redis?</li><li>How are Skip Lists advantageous in handling sorted sets in Redis?</li><li>What challenges can arise while implementing Skip Lists in Redis?</li></ol><hr><p><strong>Question</strong>: Can you explain why Skip Lists are used in Redis?<br><strong>Answer</strong>: Skip Lists are used in Redis because they maintain elements in a sorted order with efficient operations like search, insertion, and deletion. This is important for operations like fetching ranges, establishing ranks of elements, and getting items of lower or higher rank.</p><p><strong>Question</strong>: How are Skip Lists advantageous in handling sorted sets in Redis?<br><strong>Answer</strong>: Skip Lists are advantageous in handling sorted sets in Redis due to their ability to perform range queries, and retrieval of the rank of elements, closest lower and higher rank items efficiently. This ability to quickly insert, delete, and search elements also plays a role in handling sorted sets.</p><p><strong>Question</strong>: What challenges can arise while implementing Skip Lists in Redis?<br><strong>Answer</strong>: Challenges that can arise while implementing Skip Lists in Redis include increased space usage because each node can maintain several pointers. Their probabilistic nature can lead to unpredictability of the skip list structure. They can be complex to understand for those unfamiliar with them, and their advantages might not be justified for small datasets.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/redis-interview1/">https://programmerscareer.com/zh-cn/redis-interview1/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis interviews: how to implement Distributed Locks with Redis</title>
      <link href="/redis-interview2/"/>
      <url>/redis-interview2/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Let’s draft a learning plan for Redis with a focus on implementing Distributed Locks.</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-Deep-Dive-into-Redis"><a href="#Topic-1-1-Deep-Dive-into-Redis" class="headerlink" title="Topic: 1.1 Deep Dive into Redis."></a><strong>Topic: 1.1 Deep Dive into Redis</strong>.</h1><p>Redis, which stands for Remote Dictionary Server, is an open-source, in-memory data structure store used as a database, cache, and message broker. It has built-in replication, Lua scripting, LRU eviction, transactions, and various levels of on-disk persistence. Interestingly, Redis can handle multiple types of data structures like strings, hashes, lists, sets, sorted sets with range queries, bitmaps, and more.</p><p>First, let’s discuss some of the&nbsp;<strong>core features of Redis</strong>.</p><ol><li><strong>Performance</strong>: Redis holds its database entirely in memory and uses disk only for persistence, enabling it to process data very quickly.</li><li><strong>Persistence</strong>: Redis gives you the option with RDB (Redis DataBase file) and AOF (Append Only File) to persist your data either periodically or by logging every change.</li><li><strong>Atomic Operations</strong>: Redis operations like APPEND, INCR, etc., are atomic, meaning they’re completed entirely or not executed at all. This ensures data integrity, even in concurrent environments.</li><li><strong>Data Structures</strong>: Redis isn’t just a simple key-value store; it’s a data structures server that supports strings, hashes, lists, sets, and more.</li><li><strong>Pub/Sub Capabilities</strong>: Redis includes built-in commands for messaging and queueing systems, using the Publish/Subscribe paradigm.</li><li><strong>Scripting</strong>: Redis allows for scripting in Lua, effectively turning atomic commands into powerful scripts to process data on the server-side.</li></ol><p>Next is&nbsp;<strong>Redis data types</strong>. Redis supports a variety of data types:</p><ul><li><strong>Strings</strong>: They are the simplest data type in Redis and can store any data, for example, a JPEG image or a serialized Ruby object.</li><li><strong>Lists</strong>: A list in Redis is a series of ordered values. Think of it as a linked-list.</li><li><strong>Sets</strong>: An unordered collection of strings with the addition and removal of items happening in constant time. A set can’t have repeated members.</li><li><strong>Sorted sets</strong>: Every member of Sorted Sets is associated with score, which is used to sort the set elements from smallest to largest score.</li><li><strong>Hashes</strong>: They are maps composed of fields associated with values, where both the field and the value are strings.</li></ul><p>Redis’s functionality and features make it a versatile system used in caching, session caching, full page cache, message queue applications, leaderboards and counting, real-time analytics, and much more.</p><h1 id="Topic-1-2-Understanding-Locks-in-Databases"><a href="#Topic-1-2-Understanding-Locks-in-Databases" class="headerlink" title="Topic: 1.2 Understanding Locks in Databases."></a><strong>Topic: 1.2 Understanding Locks in Databases</strong>.</h1><p>As we’re gradually progressing toward understanding Distributed Locks with Redis, understanding the basic concept of locks in databases is essential.</p><p>In databases, especially databases that allow concurrent transactions (simultaneous transactions), locks play a vital role in maintaining the consistency of data and preventing data anomalies.</p><p>In simple terms, a&nbsp;<strong>lock</strong>&nbsp;in the context of a database is a mark or flag that the database assigns to a piece of data (which could be a row, a table, or even an entire database). This lock serves to control the access and modifications by concurrent transactions.</p><p>Understand that locks are generally of two types:&nbsp;<strong>Shared Locks</strong>&nbsp;(S locks) — which allow read operations, and&nbsp;<strong>Exclusive Locks</strong>&nbsp;(X locks) — which allow write operations.</p><p>Detailed explanation:</p><ul><li><strong>Shared Locks</strong>&nbsp;are also referred to as ‘Read Locks’. If a shared lock is held on data, it can be read by the transaction holding the lock, but it cannot modify it. Other transactions can also acquire shared locks and read the data, but none can write into it. Thus, shared locks help maintain a level of consistency when the data is being read by ensuring that the data isn’t altered by any other transaction during the read operation.</li><li><strong>Exclusive Locks</strong>, on the other hand, are also known as ‘Write Locks’. If an exclusive lock is held on data, not only can the transaction read the data, it can also modify it. However, no other transaction can acquire any lock (shared or exclusive) on the same data. Exclusive locks, thus, serve to maintain data integrity by ensuring that no other transaction accesses the data while it is being modified.</li></ul><p>In the concept of “locking”, a major challenge is dealing with potential&nbsp;<strong>deadlocks</strong>, which is a state where two or more transactions are waiting indefinitely for each other to release resources. Solving deadlocks involves their detection and implementing approaches like ‘wait-die’ or ‘wound-wait’ schemes, which is a deeper topic.</p><h1 id="Topic-1-3-The-Need-for-Distributed-Locks"><a href="#Topic-1-3-The-Need-for-Distributed-Locks" class="headerlink" title="Topic: 1.3 The Need for Distributed Locks"></a><strong>Topic: 1.3 The Need for Distributed Locks</strong></h1><p>You have already learned about the function of locks in databases. They provide a way to regulate access and prevent conflicts when many processes/transactions are trying to read and write to shared data.</p><p>Now imagine a scenario where you aren’t working with a single database, but a distributed system. A&nbsp;<strong>distributed system</strong>&nbsp;is one where components located on networked computers communicate and coordinate their actions only by passing messages.</p><p>In such an environment, merely using regular locks won’t suffice. Herein lays the necessity for&nbsp;<strong>distributed locks</strong>.</p><p>A&nbsp;<strong>distributed lock</strong>&nbsp;or global lock allows multiple distributed processes to synchronize their operations, typically to prevent conflicts while accessing shared resources in a distributed system. In other words, it works across multiple systems or nodes in a network and ensures that only a single client can own a lock at a time, no matter where the client is in the network.</p><p>Some high-level use cases of distributed locks are:</p><ol><li>In a&nbsp;<strong>microservices architecture</strong>, where multiple independent applications are communicating with each other, distributed locks can regulate access to shared resources.</li><li><strong>Data replication or sharding</strong>&nbsp;often require ensuring the consistency of write operations across several locations/databases.</li><li><strong>Coordinating distributed transactions</strong>&nbsp;across various microservices and databases.</li><li>Solving complex real-world problems like leader election, task distribution and synchronization, and ensuring idempotency in distributed systems.</li><li><strong>Service discovery protocols</strong>&nbsp;where microservices need to know about other’s presence require a reliable mechanism to avoid race conditions and conflicts. These protocols often use distributed locks to avoid conflicts while updating the common registry.</li></ol><p>These were just a few examples, and there are many more situations where distributed locks come into play in a distributed system.</p><p>Please remember that distributed locks aren’t without challenges — consistency, availability, and network partitions (CAP theorem) all have their part to play. But as we progress, we’ll delve deeper into understanding how we can implement distributed locks using Redis in our further lessons.</p><h1 id="Topic-1-4-Implementing-Distributed-Locks-using-Redis"><a href="#Topic-1-4-Implementing-Distributed-Locks-using-Redis" class="headerlink" title="Topic: 1.4 Implementing Distributed Locks using Redis."></a><strong>Topic: 1.4 Implementing Distributed Locks using Redis</strong>.</h1><p>First and foremost, it’s crucial to understand that a distributed lock should satisfy the following properties:</p><ul><li>Mutual Exclusion: At any point in time, only one client can hold a lock.</li><li>Deadlock Free: Eventually, every lock request must succeed.</li><li>Fault Tolerant: If a client holding a lock crashes, the system should recover.</li></ul><p>Redis provides commands (such as SETNX, EXPIRE) that can potentially create a locking system. But issues regarding expiry of lock key and releasing of lock by a client other than the one holding it can ensue. Therefore, to address and overcome these issues, the&nbsp;<strong>Redlock (Redis distributed lock)</strong>&nbsp;algorithm was introduced by Salvatore Sanfilippo (creator of Redis).</p><p>The workings of the Redlock algorithm are as follows:</p><ol><li>When a client wishes to acquire a lock with some resource, it generates a unique random string (value).</li><li>This client then tries to acquire the lock in all the N Redis masters using the SETNX command (set value if the key doesn’t exist) and attaching a time-to-live (TTL) with it.</li><li>If the client succeeds in setting it on the majority of masters (&gt; N/2), it considers the lock to be acquired successfully.</li><li>If the lock setting fails in the majority of instances, the client will try to delete the key from all the instances (even from those where it initially succeeded), waits for a random delay, and then tries steps 1–3 again.</li><li>To release a lock, it simply sends a DEL command to delete the key.</li></ol><p>With this, you can create a robust distributed locking system with Redis. Remember, the success of this algorithm rests heavily on synchronized clocks across the Redis nodes as TTL values are associated with locks.</p><h1 id="Topic-1-5-Redis-Transactions"><a href="#Topic-1-5-Redis-Transactions" class="headerlink" title="Topic: 1.5 Redis Transactions"></a><strong>Topic: 1.5 Redis Transactions</strong></h1><p>Redis transactions allow the execution of a group of commands in a single step. First, all commands are queued, and with a final command, all of them are run sequentially. Redis transactions use two primary commands:&nbsp;<code>MULTI</code>&nbsp;and&nbsp;<code>EXEC</code>.</p><p>Here’s an example of a Redis transaction:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MULTI  </span><br><span class="line">INCR foo  </span><br><span class="line">INCR bar  </span><br><span class="line">EXEC</span><br></pre></td></tr></tbody></table></figure><p>In this example, we’re incrementing the values of both ‘foo’ and ‘bar’ keys, and this increment operation is done in a transaction.&nbsp;<code>MULTI</code>&nbsp;is the command that marks the start of the transaction block and&nbsp;<code>EXEC</code>&nbsp;marks the end and triggers the execution.</p><p>Redis transactions have the ‘all-or-nothing’ property. This means if a command fails, all the commands in the transaction are rolled back. It’s important to note that Redis commands don’t fail often because they have been designed to fail during the syntax check of the command, which always happens before the command is queued.</p><p>From a locking perspective, it’s critical to note that Redis uses “optimistic locking” — locks are not held during the execution of the transaction. Instead, you can use the&nbsp;<code>WATCH</code>&nbsp;command on one or more keys. If those keys are modified by another client before your transaction executes, your transaction will be canceled, allowing you to handle race conditions safely.</p><p>Keep these principles in mind:</p><ul><li>Redis transactions are atomic, meaning all commands are executed or none are.</li><li>Redis uses optimistic locking to handle concurrent transactions.</li></ul><h1 id="Topic-1-6-Case-Study-—-Using-Redis-Distributed-Locks-in-Real-world-Applications"><a href="#Topic-1-6-Case-Study-—-Using-Redis-Distributed-Locks-in-Real-world-Applications" class="headerlink" title="Topic: 1.6 Case Study — Using Redis Distributed Locks in Real-world Applications"></a><strong>Topic: 1.6 Case Study — Using Redis Distributed Locks in Real-world Applications</strong></h1><p>Distributed locks are used in a variety of applications that require coordination and synchronization across multiple systems, processes, or threads. Here are some real-world use cases:</p><ol><li><strong>E-commerce Platform</strong>: A popular use case for distributed locking is inventory management in an online shopping platform. When multiple users attempt to purchase the last item in stock simultaneously, distributed locks can be used to ensure that only one purchase operation for that item succeeds, preventing overselling.</li><li><strong>Banking Systems</strong>: Distributed locks can play a crucial role in financial transactions. For instance, consider a scenario in which two operations (debit and credit) are performed concurrently. It’s necessary to ensure that these operations are done in an atomic way to prevent inconsistencies in the balance.</li><li><strong>Online Ticket Booking</strong>: A distributed lock can ensure that a single seat can’t be booked by multiple users in a concurrent booking operation.</li><li><strong>Master Election in Distributed Systems</strong>: In a distributed system, distributed locks can be used to handle fail-overs by electing a new master node when the existing master node fails.</li></ol><p>Looking at these use cases, it’s clear that distributed locks cater to the needs of a complex, distributed application system where maintaining data consistency, integrity, and coordination among various services is the top priority.</p><h1 id="Topic-1-7-Review-and-Assessments"><a href="#Topic-1-7-Review-and-Assessments" class="headerlink" title="Topic: 1.7 Review and Assessments"></a><strong>Topic: 1.7 Review and Assessments</strong></h1><p>Over the course of our sessions, we’ve gained a rich understanding of Redis, its built-in support for distributed locks, and how it’s leveraged in real-world applications. We’ve also dived deep into Redis transactions and gained insights into how they participate in distributed locks.</p><p>We have covered numerous concepts, such as:</p><ul><li>Deep dive into Redis: We expanded on the basics, diving deeper into Redis’s features like its data types and Pub/Sub capabilities.</li><li>Understanding Locks in Databases: We got a general overview of locks in databases, their utility, and types.</li><li>Need for Distributed Locks: We saw the need for Distributed Locks and their role in enhancing performance in large-scale applications.</li><li>Implementing Distributed Locks with Redis: We discussed how we can achieve distributed locks using Redis.</li><li>Redis Transactions: We covered transactions in Redis, its commands, and how they work alongside distributed locks.</li><li>Real-world applications of Redis Distributed Locks: We looked at various use case scenarios where Redis Distributed Locks have been applied.</li></ul><p><strong>Example Problem</strong>: Assume you’re developing an online ticket booking system. There is a scenario in which a single seat is being booked by multiple users simultaneously. How would you prevent this scenario using Redis distributed locks?</p><p>Here’s how we might solve this problem:</p><p>First, we would implement a lock on the seat when a user begins the booking process. This lock would prevent other users from booking the same seat.</p><p>Here’s an example of how we could implement this in Redis:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET lock:seat_id value NX EX 30</span><br></pre></td></tr></tbody></table></figure><p>In this command,&nbsp;<code>lock:seat_id</code>&nbsp;is the lock identifier (where the seat_id is the ID of the seat being booked),&nbsp;<code>value</code>&nbsp;is a unique string to identify the process that has the lock,&nbsp;<code>NX</code>&nbsp;tells Redis to only set the key if it doesn’t already exist, and&nbsp;<code>EX 30</code>&nbsp;sets an expiration for the lock of 30 seconds.</p><p>The return value of the command will either be&nbsp;<code>OK</code>&nbsp;or&nbsp;<code>None</code>. If the return value is&nbsp;<code>OK</code>, it means we successfully acquired the lock. If it’s&nbsp;<code>None</code>, it means another process has the lock.</p><p>Now let’s test your understanding.</p><p><strong>Simple Problem (3/10)</strong>: Why do we need a distributed locking system in a large-scale application?</p><p><strong>Moderate Problem (6/10)</strong>: What are the key principles to remember about Redis transactions?</p><p><strong>Complex Problem (9/10)</strong>: How would you solve a common problem in distributed systems, such as the fail-over scenario, using distributed locks in Redis?</p><hr><p><strong>Simple Problem (3/10)</strong>: We need a distributed locking system in large-scale applications to handle concurrency and to ensure data integrity in a distributed system. For instance, if multiple clients are trying to access and modify the same piece of data simultaneously, a distributed lock helps ensure that only one client can access and modify that data at a time, thus preventing race conditions, inconsistencies, and other potential issues.</p><p><strong>Moderate Problem (6/10)</strong>: The key principles to remember about Redis transactions are as follows:</p><ol><li>Redis transactions provide a way to execute a batch of commands atomically.</li><li>The&nbsp;<code>MULTI</code>&nbsp;command is used to start a transaction, and&nbsp;<code>EXEC</code>&nbsp;is used to execute the transaction.</li><li>The&nbsp;<code>WATCH</code>&nbsp;command can be used to implement optimistic locking. It helps abort the transaction if the watched key has changed.</li><li>If a command fails within a transaction, Redis still executes the rest of the commands in the transaction.</li></ol><p><strong>Complex Problem (9/10)</strong>: Distributed locks can play a crucial role in handling fail-overs in a distributed system. In the event of a fail-over (where a node in a cluster fails), we have to elect a new master node. A distributed lock can be used to ensure that the election process proceeds without conflicts and that only one node is elected as the new master. We could use a similar locking pattern as earlier, where the lock represents the master node. Whichever node can successfully acquire the lock becomes the new master.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/redis-interview2/">https://programmerscareer.com/zh-cn/redis-interview2/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis interviews: If the Redis master node is down, how do you recover the data?</title>
      <link href="/redis-interview3/"/>
      <url>/redis-interview3/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Let’s outline your tailored curriculum to learn about Redis. This plan will particularly focus on the scenario when the Redis master node goes down and the process to recover the data.</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-Redis-Architecture"><a href="#Topic-Redis-Architecture" class="headerlink" title="Topic: Redis Architecture"></a><strong>Topic</strong>: Redis Architecture</h1><p>Redis stands for Remote Dictionary Server. It’s an open-source, in-memory data structure store that can be used as a database, cache, and message broker. One of the main reasons Redis performs so well is because it does all its operations in memory and avoids seeking time needed for disk operations.</p><p>Redis supports a variety of data structures like strings, hashes, sets, lists, etc. Let’s dive a bit deeper into the architecture of Redis.</p><h2 id="Redis-Server-and-Client"><a href="#Redis-Server-and-Client" class="headerlink" title="Redis Server and Client"></a>Redis Server and Client</h2><p>Fundamentally, the Redis data store system comprises two main roles: a Redis client and a Redis server.</p><p>The&nbsp;<strong>Redis client</strong>&nbsp;is a standalone application that connects to a Redis server and executes commands against the server. The client could be anything from a small script that connects to Redis to manage application sessions, to a massive system that uses Redis for caching data in memory for speedy access.</p><p>The&nbsp;<strong>Redis server</strong>, on the other hand, is the powerhouse. It is where your data lives, where data is cached into memory, where data structures are maintained, and the server processes all the commands a client sends over.</p><h2 id="Redis-Data-Structures"><a href="#Redis-Data-Structures" class="headerlink" title="Redis Data Structures"></a>Redis Data Structures</h2><p>The fundamental principle to understand about Redis architecture is that it is a&nbsp;<strong>key-value</strong>&nbsp;data store — which means every piece of data you store in a Redis server will contain a key and a value. What sets Redis apart is the types of values it can store. Redis supports a variety of data structures such as:</p><ul><li><strong>Strings</strong></li><li><strong>Hashes</strong></li><li><strong>Lists</strong></li><li><strong>Sets</strong></li><li><strong>Sorted sets</strong></li></ul><p>Each data structure has its own set of commands for managing the data. For example, if you’re working with a list, you can execute commands like&nbsp;<code>LPUSH</code>,&nbsp;<code>LRANGE</code>, etc. to manipulate the list. These data structures make Redis extremely versatile, allowing it to solve many different types of problems efficiently.</p><h2 id="Persistence-—-A-Glimpse"><a href="#Persistence-—-A-Glimpse" class="headerlink" title="Persistence — A Glimpse"></a>Persistence — A Glimpse</h2><p>One of the key components of Redis architecture is its ability to persist data to disk. Imagine if all the data you’d stored in memory was wiped out if your Redis server shutdown — not very efficient, is it? To mitigate this, Redis provides a few different strategies for persisting data to disk such that it can be recovered in the event of a shutdown or failure. We’ll cover this aspect in more detail in the upcoming lesson.</p><p>Now that we have an understanding of the basics of Redis architecture, we’ll gradually dig deeper into more sophisticated concepts like data replication, backups, and high availability with Redis Sentinel in subsequent lessons.</p><h1 id="Topic-Replication-in-Redis"><a href="#Topic-Replication-in-Redis" class="headerlink" title="Topic: Replication in Redis"></a><strong>Topic</strong>: Replication in Redis</h1><p>Replication is a mechanism that allows your data to be automatically copied from a master server to one or more replica servers. Replication offers two main benefits:</p><ul><li><strong>Performance Improvement</strong>: You can distribute read traffic away from the master server to replica servers. This allows the master server to handle fewer requests and improves overall performance.</li><li><strong>Data Redundancy</strong>: Your data will be stored on multiple servers, providing a fail-safe option should the master server go down. This fault tolerance is crucial in production environments.</li></ul><h2 id="Understanding-Master-Replica-Configuration-in-Redis"><a href="#Understanding-Master-Replica-Configuration-in-Redis" class="headerlink" title="Understanding Master-Replica Configuration in Redis"></a>Understanding Master-Replica Configuration in Redis</h2><p>When replication is set up in Redis, it follows a master-replica configuration. The master server contains the original copy of the data, and this data is duplicated to the replica servers.</p><p>Setting up replication in Redis is straightforward. Basically, this involves setting up a master server and then connecting one or more replicas with the&nbsp;<code>SLAVEOF</code>&nbsp;command, specifying the master server’s IP and port.</p><p>Let’s understand how changes in the master are propagated to the replicas:</p><ol><li>When a change occurs in the master’s data set (for instance, a write operation), the master server will send the command to the connected replicas.</li><li>Each replica will receive the command and execute it, thereby making its data set up-to-date with the master’s.</li></ol><p>It’s important to understand that data operations are&nbsp;<strong>asynchronous</strong>&nbsp;— the master will not wait for replicas to acknowledge receipt and execution of commands. However, the master does keep track of which commands were acknowledged by each replica.</p><p>This replication scheme provides a robust mechanism for data redundancy and performance scaling. However, it’s not without challenges, as what if the master node goes down? How do you ensure high availability and data consistency? How does Redis handle these scenarios? We will discuss these topics in more detail in the subsequent lessons.</p><h1 id="Topic-In-depth-into-Redis-Persistence"><a href="#Topic-In-depth-into-Redis-Persistence" class="headerlink" title="Topic: In-depth into Redis Persistence"></a><strong>Topic</strong>: In-depth into Redis Persistence</h1><p>As we discussed earlier, Redis operates largely in the memory space, providing rapid access and modification of data. However, persisting the data becomes crucial to prevent data loss in case of a server crash or shutdown. Redis incorporates methods to save data in memory to disk, which are&nbsp;<strong>RDB</strong>&nbsp;and&nbsp;<strong>AOF</strong>.</p><h2 id="RDB-Redis-Database-Backup"><a href="#RDB-Redis-Database-Backup" class="headerlink" title="RDB (Redis Database Backup)"></a>RDB (Redis Database Backup)</h2><p>RDB persistence performs point-in-time snapshots of your dataset at specified intervals. Here’s how it works:</p><ul><li>Redis will fork a child process.</li><li>The child process will then write the entire data set to disk (to an RDB file), thereby capturing a snapshot of the data at that moment.</li></ul><p>The frequency at which these snapshots are taken can be configured. For example, you could configure Redis to save to disk if at least one change was made in the past 15 minutes.</p><p>RDB’s are perfect for backups. If you ever need to rebuild your database, having point-in-time snapshots is very handy.</p><h2 id="AOF-Append-Only-File"><a href="#AOF-Append-Only-File" class="headerlink" title="AOF (Append Only File)"></a>AOF (Append Only File)</h2><p>AOF persistence, on the other hand, logs every write operation received by the server, which can then be played back when the server starts. The way it works is pretty straightforward:</p><ul><li>When a command that modifies the dataset in some way is received, it gets appended to the AOF buffer.</li><li>Redis frequently writes this AOF buffer data to disk.</li></ul><p>You can configure the frequency at which data in the AOF buffer is written to disk.</p><p>Compared with RDB, AOF files are more durable as they’re append-only. This means that even if a power outage or crash happens during a write, you’ll likely have a full history of commands up until shortly before the outage. Whereas with RDB, you might lose more data since it snapshots less frequently (depending on your save conditions).</p><h2 id="Choosing-Between-RDB-and-AOF"><a href="#Choosing-Between-RDB-and-AOF" class="headerlink" title="Choosing Between RDB and AOF"></a>Choosing Between RDB and AOF</h2><p>There’s not a one-size-fits-all answer to this. It depends on the nature of your application and how critical your data is. Some prefer RDB for faster backups that can be easily moved around. Others prefer AOF for a higher level of durability.</p><p>Redis actually allows you to use both RDB and AOF at the same time! If you enable both, Redis will write to the RDB file while iterating the dataset for AOF rewriting, thus generating a “snapshot” of the database at the start of the AOF rewriting process.</p><p>You can consider this as a hybrid approach, enjoying the benefits of both the methods.</p><h1 id="Topic-Redis-Backups"><a href="#Topic-Redis-Backups" class="headerlink" title="Topic: Redis Backups"></a><strong>Topic</strong>: Redis Backups</h1><p>Without reliable and regular backups, your data is at risk of loss, especially in the event of hardware or software failure. For Redis, the snapshotting feature, or Redis Database Backup (RDB), provides a robust way to backup your data. It provides a consistent and compact point-in-time snapshot of your Redis data.</p><p>The RDB persistence model operates by saving the dataset to disk at different time intervals that you can specify. These intervals could be, for instance, every fifteen minutes if at least five keys changed, or, every hour if at least one key changed, and so forth.</p><h2 id="Creating-Backups"><a href="#Creating-Backups" class="headerlink" title="Creating Backups"></a>Creating Backups</h2><p>Redis allows you to manually produce an RDB file at any time by using the&nbsp;<code>SAVE</code>&nbsp;or&nbsp;<code>BGSAVE</code>&nbsp;commands.</p><p>The&nbsp;<code>SAVE</code>&nbsp;command operates synchronously and will block all other clients, so for production environments, it’s better to use the&nbsp;<code>BGSAVE</code>&nbsp;command, which will fork a new process to save the data while your Redis server continues to serve client requests.</p><p>It is worth noting that this process can consume a lot of I/O and CPU depending upon the size of your data.</p><h2 id="Restoring-from-Backups"><a href="#Restoring-from-Backups" class="headerlink" title="Restoring from Backups"></a>Restoring from Backups</h2><p>Restoring an RDB file is as simple as stopping your Redis server, replacing the RDB file with your backup, and restarting the server again.</p><p>Upon startup, Redis will load the data from the RDB file into memory and continue normal operation. Actions like writing new data to the Redis store or reading from the store cannot be done until the data is loaded into memory.</p><p>Understanding backups is a critical aspect of Redis as it forms the foundation of any disaster recovery plan. It’s essential to have regular and reliable backups to safeguard your data and ensure the smooth operation of your applications.</p><h1 id="Topic-Redis-Sentinel"><a href="#Topic-Redis-Sentinel" class="headerlink" title="Topic: Redis Sentinel"></a><strong>Topic</strong>: Redis Sentinel</h1><p>Now, let’s discuss an important aspect of Redis, the Redis Sentinel system. It helps fulfill two main functions —&nbsp;<strong>monitoring</strong>&nbsp;and&nbsp;<strong>automated failover</strong>. Let’s take a closer look at both.</p><p><strong>Monitoring</strong>: Redis Sentinel continuously checks if your master and replica instances are working as expected. It not only confirms the availability of instances (up and running) but also validates that they are functioning correctly (able to accept connections and respond to queries).</p><p><strong>Automated Failover</strong>: If your master node fails, the Sentinel system will automatically detect this and begin the failover process. This process involves choosing a replica, promoting it to be the new master, and reconfiguring the other replicas to use the new master.</p><p>These features provide high availability and resilience to Redis environments. Now, utilizing the Sentinel system involves a series of steps:</p><ol><li><strong>Setting up the Sentinel Nodes</strong>: First, we need to create Sentinel nodes, which are separate instances of Redis running in Sentinel mode. A minimum of three Sentinel nodes is recommended for a robust setup.</li><li><strong>Configuring Sentinel Nodes</strong>: The Sentinel nodes need to be configured to monitor a master. You do this by specifying your master’s IP and port.</li><li><strong>Validate Setup</strong>: After configuring, you should validate your setup by checking whether your Sentinel nodes are correctly monitoring your master and its replicas.</li></ol><p>With this setup complete, the Sentinel system will perform its monitoring and automatic failover duties as described above.</p><p>Worth noting is the concept of&nbsp;<strong>Quorum</strong>, which represents the minimum number of Sentinel nodes that need to agree for failover to take place. For instance, if you have five Sentinel nodes, a quorum could be three. Meaning at least three Sentinel nodes need to agree that the master is indeed not functioning and a failover should be initiated.</p><p>Redis Sentinel provides great value for endeavours requiring high availability for Redis. In the next lesson, we will handle the scenario of Master Node failures, common reasons behind it, and how Redis mitigates such incidents.</p><h1 id="Topic-Redis-Master-Node-Failure-—-An-Overview"><a href="#Topic-Redis-Master-Node-Failure-—-An-Overview" class="headerlink" title="Topic: Redis Master Node Failure — An Overview"></a><strong>Topic</strong>: Redis Master Node Failure — An Overview</h1><p>Master Node failures, while infrequent, may pose a challenge for a Redis infrastructure that’s not configured for such events. It is pivotal to understand the potential reasons behind such failures and devise strategies to handle them.</p><p>There can be several causes for master node failure, including:</p><ol><li><strong>Hardware Failures</strong>: This can be a physical damage, or wear and tear on the hard disk. Sometimes, the memory components might fail leading to server crashes.</li><li><strong>Network Disruptions</strong>: Disturbances in the network connection could cause the Master Node (or any node for that matter) to lose connection with the other nodes. This can be a temporary glitch or a permanent problem depending on the underlying infrastructure.</li><li><strong>Disk Full Errors</strong>: Redis may shut down if the disk gets full to prevent data inconsistency.</li><li><strong>Software Errors / Server Overload</strong>: Bugs in software or an overload on the server could potentially cause a crash, leading to master node failure.</li></ol><p>When a master node fails, the key concern becomes how to ensure uninterrupted service. This is where the Redis Sentinel system and Redis replication come to play.</p><p>If a failure is detected, the Sentinel system will start an automatic failover process. The failover process involves promoting a replica to be the new master that other replicas will be automatically reconfigured to use as their new master.</p><p>Understanding the potential reasons behind master node failure and the subsequent recovery mechanisms is important to maintain high availability in Redis.</p><p>In the next lesson, we will delve deeper into the Redis Master Node Data Recovery process following a Redis Master node failure.</p><h1 id="Topic-Redis-Master-Node-Data-Recovery"><a href="#Topic-Redis-Master-Node-Data-Recovery" class="headerlink" title="Topic: Redis Master Node Data Recovery"></a><strong>Topic</strong>: Redis Master Node Data Recovery</h1><p>In a scenario where a master node in Redis goes down due to certain unforeseen events, the process of data recovery from backups becomes crucial in ensuring smooth operation.</p><p>As we learned earlier, the first response to a master node failure is the Redis Sentinel system initializing an automatic failover procedure. One of the replicas will be promoted to the role of the master, and the other replicas will be reconfigured to now connect to this new master.</p><p>However, we also need to consider the process of restoring the original master node and adding it back to the system once it is operational again. After the issue with the failed master is resolved, and the original master node is restored, it will connect back to the system as a replica, perform a synchronization and then can be reconfigured back.</p><p>Now, what happens to the data that was written on the replica (now master) during the downtime? This depends on your persistence configuration:</p><ol><li><strong>AOF (Append Only File) Persistence Configuration</strong>: In case of AOF, all write operations are logged, and if a master node goes down, the AOF file continues to log these operations on the replica. Once the master is restored and synchronized with this replica, it will also receive these write operations, ensuring that no data is lost.</li><li><strong>RDB (Redis Database Backup) Persistence Configuration</strong>: In the case of RDB, snapshots are taken at configurable intervals. So, any data written between two snapshots could potentially be lost if a failure occurs.</li></ol><p>In a nutshell, the mechanism to handle master node failure effectively in Redis largely depends on the configurations, Sentinel system, and persistence settings. You can choose the strategy that best applies to your use-case and aligns more closely with your data safety requirements.</p><h1 id="Topic-Review-and-Assessments"><a href="#Topic-Review-and-Assessments" class="headerlink" title="Topic: Review and Assessments"></a><strong>Topic</strong>: Review and Assessments</h1><p>We have navigated a thorough exploration of various aspects of Redis. Let’s recap the core concepts we’ve covered:</p><ol><li><strong>Redis Architecture</strong>: We began by understanding the underlying architecture of Redis.</li><li><strong>Replication in Redis</strong>: Studied the concept of data replication in Redis and how it’s achieved.</li><li><strong>Redis Persistence</strong>: Went in-depth into the process of data persistence in Redis and why it’s significant.</li><li><strong>Redis Backups</strong>: Learned how to establish backups in Redis and understood their role in data recovery.</li><li><strong>Redis Sentinel</strong>: Comprehended the principle of the Redis Sentinel and its function in maintaining high availability.</li><li><strong>Master Node Failure</strong>: Discussed probable reasons for Master Node failure in Redis.</li><li><strong>Master Node Data Recovery</strong>: Understood the detailed process when a master node in Redis experiences downtime.</li></ol><p>Now, it’s essential to review and reassess our understanding of these topics. This is where interactive assessments come into play. They present an opportunity to check your comprehension, apply learned knowledge, and rectify if any gaps remain.</p><p>Example Problem: Assume you’re setting up a data storage system for your application. You decided to use Redis and need to configure it. You’ve two servers available to use. How would you assure data safety and high availability?</p><p>Now let’s test your knowledge.</p><h2 id="Problem-1"><a href="#Problem-1" class="headerlink" title="Problem 1:"></a>Problem 1:</h2><p>Given what you’ve learned about the internals of Redis, describe the building blocks of Redis architecture.</p><h2 id="Problem-2"><a href="#Problem-2" class="headerlink" title="Problem 2:"></a>Problem 2:</h2><p>Explain the role of Redis Sentinel and how it helps maintain high availability in Redis infrastructure.</p><h2 id="Problem-3"><a href="#Problem-3" class="headerlink" title="Problem 3:"></a>Problem 3:</h2><p>What steps would Redis take in the event of a master node failure?</p><p>For each question, please share your answers.</p><hr><p>The&nbsp;<strong>Example Problem</strong>&nbsp;was: Assume you’re setting up a data storage system for your application. You decided to use Redis and need to configure it. You’ve two servers available to use. How would you assure data safety and high availability?</p><p>To ensure data safety and high availability, you could set up a Redis environment as per these steps:</p><ol><li><strong>Use both servers</strong>: Install Redis on both servers. One will act as the master, and the other will be a replica (slave).</li><li><strong>Data Persistence</strong>: Configure data persistence mechanisms on both servers. This will ensure that changes in data are stored and not lost, providing data safety. For instance, you may choose RDB for less granular but less resource-intensive backups, or AOF for highly granular backups at cost of more resource use.</li><li><strong>Master-Replica Replication</strong>: Set the second server as a replica of the first one. It means that all data written to the master will also be written to the replica. This is important in the case of server 1 (designated as master) goes down.</li><li><strong>Redis Sentinel</strong>: To maintain high availability, use Redis Sentinel. Sentinel will monitor both servers, and if the master goes down, Sentinel will promote the replica to be the master.</li><li><strong>Configure Your Application</strong>: Configure your application to send write operations to the master, and read operations can be balanced between the two servers.</li></ol><p>These steps will provide a balance between high availability (through replication and Redis Sentinel) and data safety (through data persistence mechanisms).</p><p><strong>Problem 1</strong>: The building blocks of Redis architecture include:</p><ul><li><strong>Redis Clients</strong>: These are applications or users that send commands to Redis to perform operations with the data stored in it.</li><li><strong>Redis Server</strong>: This is where Redis is installed and running. It’s responsible for storing data in memory and performing operations with it.</li><li><strong>Data Structures</strong>: Redis supports several types of data structures, including strings, lists, sets, sorted sets, and others. Each structure has specific commands associated with it.</li><li><strong>Database Persistence</strong>: Redis provides two mechanisms for database persistence — RDB and AOF. RDB takes snapshots of your dataset at specified intervals. AOF logs every write operation received by the server.</li><li><strong>Replication</strong>: This is the process of setting up master-slave nodes to ensure data redundancy. If the master node fails, one of the slaves is promoted to be the new master.</li></ul><p><strong>Problem 2</strong>: Redis Sentinel is renowned for its primary functionality of monitoring Redis instances. It can identify when a master node fails and will begin a failover process. The Sentinel system will promote a replica to be the new master and reconfigure all other replicas to use the new master. Applications are also notified about the new master to redirect their queries.</p><p><strong>Problem 3</strong>: When a Redis Master Node fails:</p><ol><li>The Redis Sentinel (if configured) detects the failure of the Master node.</li><li>One of the Sentinels initiates a failover and other Sentinels acknowledge this.</li><li>Redis Sentinel will elect a replica to be promoted as the new master.</li><li>Other replicas will be reconfigured to use the new master.</li><li>After resolving the issue, the failed master will join back as a replica to the current master. It will require a full synchronization with the new master.</li></ol><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/redis-interview3/">https://programmerscareer.com/zh-cn/redis-interview3/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis interviews: how to prevent cache avalanche and cache penetration with Redis</title>
      <link href="/redis-interview4/"/>
      <url>/redis-interview4/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Focusing on cache prevention aspects, let’s explore and master it together</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-Detailed-Study-of-Cache-Penetration"><a href="#Topic-1-1-Detailed-Study-of-Cache-Penetration" class="headerlink" title="Topic&nbsp;1.1: Detailed Study of Cache Penetration"></a><strong>Topic</strong>&nbsp;1.1: Detailed Study of Cache Penetration</h1><p>Cache Penetration, also known as cache miss or cache busting, is a scenario where requests bypass the cache and directly hit the database. It typically occurs when the request queries data that is not stored in our cache.</p><p>Imagine a shopping website where people can search for products. The cache may contain popular searched items for faster retrieval. However, fur users searching for a rare product not in the cache, the system has to query from the database. This is a case of cache penetration.</p><p>This might not sound like a serious issue, but imagine a scenario where a high volume of traffic queries for items that are not in the cache. It would lead to a substantial amount of database hits and might eventually lead to the database crashing due to the amount of load.</p><p>An even severe case of cache penetration is when attackers can precisely predict that certain requests won’t be cached and bombard our system with those requests, causing our database to be the primary hit point and, eventually, it might crash the system.</p><p>Cache penetration is something that should be avoided for smooth and efficient system functioning. Luckily, Redis provides powerful strategies to mitigate cache penetration, and we will explore them in the upcoming topic.</p><h1 id="Topic-1-2-Strategies-to-prevent-Cache-Penetration-using-Redis"><a href="#Topic-1-2-Strategies-to-prevent-Cache-Penetration-using-Redis" class="headerlink" title="Topic 1.2: Strategies to prevent Cache Penetration using Redis"></a><strong>Topic 1.2</strong>: Strategies to prevent Cache Penetration using Redis</h1><p>Redis offers powerful strategies to prevent cache penetration, ensuring efficient system performance even under high load. These strategies primarily focus on reducing direct hits to the database, hence mitigating cache penetration.</p><p>One common strategy is implementing a&nbsp;<strong>Default Cache Value</strong>. When a query for non-existent data occurs, instead of letting the request go straight to the database, it can be handled at the cache level by returning a default value. This means the database won’t take a hit when data is not in the cache, thus preventing cache penetration.</p><p>Another powerful strategy is the use of&nbsp;<strong>Bloom Filters</strong>. A Bloom filter is a probabilistic data structure that can be used to test whether an element is a member of a set. This implies it can quickly identify whether the data requested exists in our database or not. If the Bloom filter says that the item doesn’t exist, we can immediately return a default value without having to query our database or even our cache.</p><p>When setting up these strategies, it’s important to keep the trade-offs in mind. The use of a Bloom filter introduces a small chance of a false positive. However, the benefits often greatly outweigh the minimal error probability.</p><h1 id="Topic-1-3-Deep-Dive-into-Cache-Avalanche"><a href="#Topic-1-3-Deep-Dive-into-Cache-Avalanche" class="headerlink" title="Topic 1.3: Deep Dive into Cache Avalanche"></a><strong>Topic 1.3: Deep Dive into Cache Avalanche</strong></h1><p>Cache Avalanche is a type of system failure that occurs when a large number of cache items expire simultaneously, and multiple requests for these data items hit the database, potentially causing it to crash due to the high load.</p><p>Think about a scenario where a website caches its daily deals, and all the cache items are set to expire at midnight. As the clock hits 12:00 AM, all the cache items become invalid. The first set of users who try to access these deals post-midnight cause the system to fetch the new deals from the database and populate the cache.</p><p>However, imagine a scenario where millions of users try to access these deals simultaneously soon as the cache becomes invalid. This could potentially flood the database with requests, leading it to become unresponsive or even crash — that’s a Cache Avalanche effect.</p><p>While Cache Avalanche might sound catastrophic, there are strategies which we can employ to prevent it from happening. Understanding these techniques will make the systems we design more robust and reliable.</p><h1 id="Topic-1-4-Preventing-Cache-Avalanche-using-Redis"><a href="#Topic-1-4-Preventing-Cache-Avalanche-using-Redis" class="headerlink" title="Topic 1.4: Preventing Cache Avalanche using Redis"></a><strong>Topic 1.4</strong>: Preventing Cache Avalanche using Redis</h1><p>Preventing a Cache Avalanche effectively means preventing a horde of requests from reaching our database simultaneously. Redis offers many practical strategies for this.</p><p>The first technique is to use&nbsp;<strong>TTL (Time To Live) staggering</strong>. Instead of setting the same TTL for all cache items, we can slightly stagger or randomize their TTL values. This introduces differences in the expiry times, thereby reducing the risk of many items expiring simultaneously.</p><p>Another major strategy is to use&nbsp;<strong>Cache Warming</strong>. Cache warming is the practice of loading data into the cache before it’s needed. For instance, if we know certain cache items are likely to expire soon, we can preemptively refresh them during periods of low demand to avoid an avalanche during peak times.</p><p>Finally, it might be beneficial to consider using&nbsp;<strong>Fallback Caching</strong>. In this approach, even when a cache item is known to have expired, the old (expired) value is returned while the cache is updated in the background. This prevents sudden database loads due to simultaneous cache misses.</p><p>It’s key to understand that no single strategy is a silver bullet in every scenario. The actual implementation might require a combination of these strategies depending upon the specifics of the use-case.</p><h1 id="Topic-1-5-Redis-Transactions-with-Cache-prevention"><a href="#Topic-1-5-Redis-Transactions-with-Cache-prevention" class="headerlink" title="Topic 1.5: Redis Transactions with Cache prevention"></a><strong>Topic 1.5</strong>: Redis Transactions with Cache prevention</h1><p>Redis is not just an in-memory database, but it can also support transactions — a series of commands that are executed sequentially, stopping only if an error is encountered in one of the commands.</p><p>Redis transactions use a two-step process :</p><ol><li><strong>QUEUING commands</strong>: Commands are queued up using the&nbsp;<code>MULTI</code>&nbsp;command. Nothing is executed at this stage; Redis merely keeps track of all the commands that are within this transaction.</li><li><strong>EXECUTING commands</strong>: When the&nbsp;<code>EXEC</code>&nbsp;command is issued, Redis then executes all the commands queued up in the exact order.</li></ol><p>Redis transactions are employed to ensure that all cache operations (like reads, writes, or updates) are atomic — which means they get executed fully or not at all. This is crucial to maintain the cache consistency and prevent dirty reads, which can also help mitigate the effects of cache penetration.</p><p>Let’s take an example. Suppose you are implementing a leaderboard system and want to update the score of a player atomically. Here’s how a transaction could be used to achieve that:</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MULTI  </span><br><span class="line">    GET player_score  </span><br><span class="line">    INCR player_score  </span><br><span class="line">EXEC</span><br></pre></td></tr></tbody></table></figure><p>By wrapping both GET and INCR commands within a transaction, we ensure that if any other client reads the score, they will always get a consistent value.</p><p>Using transactions in Redis alongside cache prevention techniques, be it for penetration or avalanche, can significantly improve the consistency and reliability of our caching layer.</p><h1 id="Topic-1-6-Real-world-applications-of-Redis-Cache-Prevention"><a href="#Topic-1-6-Real-world-applications-of-Redis-Cache-Prevention" class="headerlink" title="Topic 1.6: Real-world applications of Redis Cache Prevention"></a><strong>Topic 1.6</strong>: Real-world applications of Redis Cache Prevention</h1><p>Redis and its cache prevention mechanisms are frequently used in a variety of real-world applications to handle sizable loads without bringing down the backend database. Here are a few examples:</p><ul><li><strong>E-commerce websites</strong>: Websites like Amazon use Redis for caching product details and recommendations for faster retrieval. Measures to prevent cache penetration and cache avalanches are crucial to handle the simultaneous user load, especially during festive sales.</li><li><strong>Social media platforms</strong>: Platforms like Twitter and Instagram use Redis to cache user data and feed information. The high volume of simultaneous reads and writes makes Redis an excellent choice for these platforms.</li><li><strong>Leaderboard systems</strong>: On gaming platforms, user scores and rankings are updated in real-time and need to be accessed by many clients simultaneously. Redis’s ability to handle atomic transactions ensures score consistency across clients, even under high load.</li><li><strong>Online ticketing services</strong>: During high-demand events, ticketing services can experience a massive surge in traffic, which can lead to database failure if not handled correctly. Redis’s cache management capabilities can effectively prevent these scenarios.</li></ul><p>In all these examples, cache optimization measures like staggering the TTL, warming the cache, and using fallback values are employed to protect the system from potential cache penetration and cache avalanches.</p><h1 id="Topic-1-7-Review-and-Assessments"><a href="#Topic-1-7-Review-and-Assessments" class="headerlink" title="Topic 1.7: Review and Assessments"></a><strong>Topic 1.7</strong>: Review and Assessments</h1><p><strong>Cache Penetration</strong>&nbsp;occurs when frequent requests are made for non-existent data, causing each request to reach the database since it’s not available in the cache. It can lead to excessive and unnecessary database load. Redis provides various mechanisms to prevent it, such as NULL caching and Bloom filters.</p><p><strong>Cache Avalanche</strong>&nbsp;happens when multiple cached data expires simultaneously, leading to a barrage of hits to the database. Redis provides strategies like TTL staggering, cache warming, and fallback caching to handle Cache Avalanches.</p><p><strong>Redis Transactions</strong>&nbsp;play an important role in maintaining data integrity and consistency during multiple read or write operations. By queuing multiple commands and executing them atomically, redis transactions prevent dirty reads and provide higher reliability.</p><p>Redis and its techniques for preventing cache penetration and avalanches are frequently used in high-traffic, real-world applications like e-commerce websites, social media platforms, real-time leaderboard systems, and online ticketing services.</p><p>Let’s begin with the assessments.</p><p><strong>Question 1</strong></p><p>Explain, in your own words, what Cache Penetration is. Why is it a problem, and how does Redis help prevent it?</p><p><strong>Question 2</strong></p><p>Describe a real-world scenario where Redis Transactions might be useful. How would utilizing transactions in that scenario promote data consistency?</p><p><strong>Question 3</strong></p><p>Consider a high-traffic e-commerce website, and describe how the Cache Avalanche can be dealt with effectively using Redis.</p><hr><p><strong>Answer to Question 1</strong></p><p>Cache Penetration refers to the scenario where frequent requests for non-existing data are passed to the database since the cache does not hold these values. It can lead to unnecessary database load and degrade performance. Redis helps prevent Cache Penetration primarily by using NULL caching, where you store the “NULL” keyword for a certain duration when the value queried in the database returns NULL.</p><p><strong>Answer to Question 2</strong></p><p>In a social media platform like Twitter, when a user ‘likes’ a tweet, the total number of likes for the tweet and the user’s liked tweets both need to be updated. This scenario requires multiple write operations and if not handled atomically, can lead to inconsistent data. Redis Transactions can queue these multiple write commands and execute them atomically to maintain data integrity and consistency.</p><p><strong>Answer to Question 3</strong></p><p>In a high-traffic e-commerce website like Amazon, a Cache Avalanche can occur when many cached products details or user recommendations expire simultaneously, leading to a sudden increase in database load. Redis effectively handles this by TTL staggering where each key-value pair in the cache has slightly different expiration times, or by warming the cache where you refresh the cache with the most frequently accessed data before the old cache expires. This prevents a sudden surge in database queries.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/redis-interview4/">https://programmerscareer.com/zh-cn/redis-interview4/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis interviews: Briefly describe the advantages and disadvantages of RDB and AOF schemes in Redis persistence</title>
      <link href="/redis-interview5/"/>
      <url>/redis-interview5/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>let’s study Redis with a focus on the RDB and AOF persistence schemes.</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-Redis-Architecture"><a href="#Topic-Redis-Architecture" class="headerlink" title="Topic: Redis Architecture"></a><strong>Topic</strong>: Redis Architecture</h1><p>Now, imagine a system, lean and efficient, furnished to quickly store and retrieve data. Allow me to introduce the marvel that is Redis!</p><p>Redis, or Remote Dictionary Server, is an in-memory data structure store. It can be used as a database, cache and message broker. The “in-memory” part means that it primarily stores data in RAM, making data operations extremely fast since reading from and writing to the primary memory can be done at a swifter pace compared to disk storage.</p><p>Its structure is based on a server-client architecture. This means every Redis setup has a Redis server and one or more Redis clients; think of this as a conversation where the client constantly requests, and the server responds.</p><p>We have few components at play in the Redis Architecture:</p><ul><li><strong>Redis Clients</strong>: They could be different applications or multiple instances of the same application. They ask, and the server responds.</li><li><strong>Redis Server</strong>: The server manages the data store and responds to the commands by clients.</li><li><strong>Redis Data</strong>: At its core, Redis manages a data store — a crucial part of our Redis architecture.</li></ul><p>Now, as we have seen, Redis is an in-memory data structure. Yet, an essential feature of Redis is its ability to persist data on disk. It can log every write operation transmitted by the clients, thereby providing a high level of data safety for an in-memory database.</p><p>And that’s a brief overview of the Redis Architecture!</p><h1 id="Topic-Redis-Persistence-Overview"><a href="#Topic-Redis-Persistence-Overview" class="headerlink" title="Topic: Redis Persistence Overview"></a><strong>Topic</strong>: Redis Persistence Overview</h1><p>Redis, a in-memory data structure store used as a database, cache, and message broker, excels at handling data operations at lightning-fast speed. However, being in-memory raises the question of data volatility and persistence. How does Redis ensure your data longevity when it stores everything in RAM, which is volatile in nature?</p><p>Fret not! Redis takes care of this potential issue by offering two methods of ensuring data persistence:&nbsp;<strong>RDB (Redis Database)</strong>&nbsp;and&nbsp;<strong>AOF (Append Only File)</strong>.</p><ul><li><strong>RDB Persistence:</strong>&nbsp;This method takes a point-in-time snapshot of your dataset at specified intervals and saves it on a disk in a binary format. These “snapshots” are compact and quick to load, making RDB an excellent option for backups.</li><li><strong>AOF Persistence:</strong>&nbsp;The Append Only File logs all the write commands received by the server in a file. This file is read by Redis when it restarts to rebuild the state of data. Since all executed commands are saved by Redis, you can adjust the server’s data durability levels by syncing the file every time a command is written, every second, or hardly ever.</li></ul><p>Both methods come with their own pros and cons, the choice of which to use depends entirely on your specific use case. In some cases, a combination of both methods might be an ideal solution.</p><p>In the upcoming sections, we are going to discuss these persistence technologies in more detail. This will give you a deeper understanding of both so you can make an informed choice.</p><h1 id="Topic-Redis-RDB-Persistence"><a href="#Topic-Redis-RDB-Persistence" class="headerlink" title="Topic: Redis RDB Persistence"></a><strong>Topic</strong>: Redis RDB Persistence</h1><p>Let me unfold the story of&nbsp;<strong>RDB Persistence</strong>. RDB, which stands for Redis DataBase, is a very convenient persistence format in Redis. In this method, the Redis server creates point-in-time snapshots of your dataset at specified intervals. Think of it as creating periodic backups of your data that can come in super handy in certain scenarios.</p><p>RDB operates in a very straightforward manner. At configured intervals, the Redis parent process forks a child process. The parent process continues to serve clients, while the child process starts writing the RDB file on the disk. This way, the database can continue to handle client requests while the snapshot is being created.</p><p>When the child process finishes saving the RDB file, it replaces the old snapshot with the new one. The child process then exits and sends a success signal to the parent process. If an error occurs during saving, the child process sends an error signal back to the parent process.</p><p>RDB persistence has its own set of advantages:</p><ul><li>It’s perfect for disaster recovery. You can configure Redis to take snapshots every minute or every few seconds. If something disastrous occurs, you would lose a maximum of one minute’s worth of data.</li><li>The snapshots are created in a fraction of a second and are perfectl</li></ul><p>the RDB snapshotting process is fast and doesn’t affect the performance of the Redis server catering to write requests. Furthermore, it creates compact files that Redis can consume quickly during server start, reducing downtime.</p><p>But, as with everything else, RDB persistence does come with its caveats:</p><ul><li>RDB is a point-in-time snapshotting system, meaning it doesn’t record each individual write. So in the case of a crash or failure, you might lose some data that was not included in the last snapshot.</li><li>Despite being an automated process, snapshot generation can be resource-intensive for large databases, causing degradation of service during the snapshotting period.</li></ul><p>With this information in mind, it’s clear that while RDB has numerous benefits in terms of data backup and disaster recovery scenarios, it might not be the optimum solution for applications needing high durability.</p><p>Similar to a tale with two sides, this is only half of our persistence story. In the upcoming lesson, we’ll be exploring the ins and outs of the other method — AOF (Append Only File) persistence.</p><h1 id="Topic-Redis-AOF-Persistence"><a href="#Topic-Redis-AOF-Persistence" class="headerlink" title="Topic: Redis AOF Persistence"></a><strong>Topic</strong>: Redis AOF Persistence</h1><p>Now that we have a good understanding of RDB Persistence, let’s shift our focus to another method that Redis employs to persist data:&nbsp;<strong>Append Only File (AOF)</strong>.</p><p>Unlike RDB Persistence which creates point-in-time snapshots, AOF takes a more comprehensive approach. Every executed write command is logged by Redis. Literally, every single one. These are then saved to an&nbsp;<code>append-only file</code>, hence the name.</p><p>Now, when Redis restarts, it uses this file to restore its previous state. The commands are simply executed one after another to recreate the data.</p><p>One of the beauties of this approach is its durability. Since every write operation is logged, you’ve got quite an account of all the changes. It might also be music to your ears to know that Redis offers adjustable levels of durability:</p><ul><li>You can set Redis to sync this log file every time a command is written</li><li>Or, Redis could be set to sync the file every second</li><li>Or even, you can trust your luck (or perhaps the stability of your power supply) and hardly ever sync at all!</li></ul><p>Imagine that! Full control over your database persistence method!</p><p>Of course, AOF persistence has its own pros and cons. In the subsequent lesson, we’ll pit RDB and AOF against each other, compare their strengths, and help you understand when to use which.</p><h1 id="Topic-Redis-RDB-vs-AOF-Persistence"><a href="#Topic-Redis-RDB-vs-AOF-Persistence" class="headerlink" title="Topic: Redis RDB vs. AOF Persistence"></a><strong>Topic</strong>: Redis RDB vs. AOF Persistence</h1><p>When it comes to Redis and data persistence, RDB and AOF are the two knights in shining armor. However, they each have their strengths and weaknesses.</p><p>Firstly, RDB persistence creates point-in-time snapshots of your dataset at specified intervals. So in the event of an unexpected shutdown, you can restore your data to the last snapshot.</p><p>However, this could mean that data written after the most recent snapshot would be lost forever! While RDB file creation is fast and doesn’t use much memory, you can experience a performance hit when dealing with larger databases due to decreased input/output operations.</p><p>On the other hand, AOF persistence logs every write operation received by the server. This can be beneficial. Not a single piece of data is lost because everything is logged almost instantly. But, the log files can eventually become quite large, and the constant writing can introduce latency.</p><p>ltimately, the choice between RDB and AOF depends on your use-case. If you can’t afford to lose any data, AOF is the way to go. But if your data can be easily reconstituted and you need quicker backups and recovery, then RDB could be a better fit.</p><p>In many instances, using both RDB and AOF together will give you the benefits of both worlds. You’d have the durability of AOF and the speedy backups and data recovery of RDB.</p><h1 id="Topic-Implementing-Redis-Persistence"><a href="#Topic-Implementing-Redis-Persistence" class="headerlink" title="Topic: Implementing Redis Persistence"></a><strong>Topic</strong>: Implementing Redis Persistence</h1><p>Redis’ flexibility with persistence configurations is one of its strengths. You can opt for RDB, AOF or even both based on your needs. Here’s how you can do it:</p><ol><li><strong>Implementing RDB Persistence</strong>: Enabling RDB persistence primarily involves configuring how often you’d like Redis to save a snapshot of your database to disk. This is controlled by the&nbsp;<code>save</code>&nbsp;configuration directive in the Redis configuration file (<code>redis.conf</code>). The syntax is&nbsp;<code>save &lt;seconds&gt; &lt;changes&gt;</code>, where&nbsp;<code>&lt;seconds&gt;</code>&nbsp;specifies a certain number of seconds and&nbsp;<code>&lt;changes&gt;</code>&nbsp;specifies a minimum number of changes. You can have multiple&nbsp;<code>save</code>&nbsp;directives in the&nbsp;<code>redis.conf</code>&nbsp;file for finer control.</li><li><strong>Implementing AOF Persistence</strong>: To turn on AOF persistence, you’ll have to update the&nbsp;<code>appendonly</code>&nbsp;configuration directive in the&nbsp;<code>redis.conf</code>&nbsp;file to&nbsp;<code>yes</code>. Additionally,&nbsp;<code>appendfsync</code>&nbsp;is another significant directive which defines how often the data is written to the AOF file. It can be set to&nbsp;<code>always</code>&nbsp;(fsync every write),&nbsp;<code>everysec</code>&nbsp;(fsync every second), or&nbsp;<code>no</code>&nbsp;(fsync only when Redis decides).</li><li><strong>Using RDB and AOF Together</strong>: Both of these persistence methods can be used at the same time by enabling their respective directives in&nbsp;<code>redis.conf</code>. You get point-in-time snapshots from RDB and durability from AOF.</li></ol><p>And voila! You have configured Redis persistence according to your application’s needs. When in doubt, keep in mind the key differences between RDB and AOF persistence and their respective use-cases.</p><h1 id="Topic-Review-and-Assessments"><a href="#Topic-Review-and-Assessments" class="headerlink" title="Topic: Review and Assessments"></a><strong>Topic</strong>: Review and Assessments</h1><p>We’ve covered a lot over the course of these lessons:</p><ol><li><strong>Redis Architecture:</strong>&nbsp;We delved into the workings of Redis, especially as an in-memory data structure store.</li><li><strong>Redis Persistence Overview:</strong>&nbsp;We discussed how Redis handles data persistence and some of the inherent trade-offs.</li><li><strong>Redis RDB Persistence:</strong>&nbsp;We explored the RDB persistence scheme, how it works and when it can be beneficial.</li><li><strong>Redis AOF Persistence:</strong>&nbsp;Similarly, we looked at the AOF persistence scheme and its applications.</li><li><strong>Redis RDB vs. AOF:</strong>&nbsp;We compared both persistence schemes in terms of performance, data safety and use-cases.</li><li><strong>Implementing Redis Persistence:</strong>&nbsp;We put our knowledge into practice by chaining different types of persistence in different scenarios.</li></ol><p>I hope these lessons cleared your understanding of Redis, RDB and AOF. Now, it’s time to see how much you’ve learned. I will give a few questions to answer. Don’t worry if you can’t answer them all. The real learning often happens during the process of finding the answers, not demonstrating what you already know!</p><ol><li><strong>Describe the fundamental differences between AOF and RDB persistence.</strong></li><li><strong>In what situations would you prefer using AOF and when would you opt for RDB? Give specific examples.</strong></li><li><strong>What are some potential disadvantages of using these persistence methods?</strong></li></ol><p>Please take your time and type your answers.</p><hr><ol><li><strong>Describe the fundamental differences between AOF and RDB persistence.</strong></li></ol><p>RDB (Redis Database) and AOF (Append Only File) are the two types of persistence provided by Redis. The fundamental difference lies in how and when they save data.</p><ul><li><em>RDB</em>: This method captures a point-in-time snapshot of your dataset at specified intervals. It’s advantageous for backups and for quicker recovery after a restart.</li><li><em>AOF</em>: This approach logs every write operation received by the server, offering a more durable persistence method. AOF logs make Redis much more resistant to issues like power failures, as it maintains a complete log of all operations.</li></ul><ol><li><strong>In what situations would you prefer using AOF and when would you opt for RDB? Give specific examples.</strong></li></ol><p>Your choice between AOF and RDB depends on your specific project and what trade-offs you’re willing to make.</p><ul><li><em>RDB</em>: If you’re building a caching layer where data can be re-cached or recalculated from another store, the faster backups and recovery time of RDB is a clear advantage.</li><li><em>AOF</em>: If you’re building an application where every write is critical — for example, a messaging or collaboration application — the added durability of AOF would be a more suitable choice.</li></ul><ol><li><strong>What are some potential disadvantages of using these persistence methods?</strong></li></ol><p>Each persistence method comes with its own set of drawbacks:</p><ul><li><em>RDB</em>: While capturing snapshots of the data, Redis forks the server process, which can be system intensive. Moreover, you could lose a significant amount of data if Redis was to crash between snapshots. Also, bigger databases can take a long time and a lot of I/O to create the RDB snapshot.</li><li><em>AOF</em>: The log files can get significantly large with time because it records every operation. Moreover, AOF logs are usually larger than the equivalent RDB snapshots, and AOF can be slower than RDB when Redis restarts.</li></ul><p>Remember, these answers serve as a guide. When dealing with real-world projects, your specific context and requirements may lead you to different conclusions.</p><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/redis-interview5/">https://programmerscareer.com/zh-cn/redis-interview5/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis interviews: how many data structures does Redis have? How is ZSet implemented?</title>
      <link href="/redis-interview6/"/>
      <url>/redis-interview6/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>Have you ever been asked a similar question in an interview? Or you will meet in the future, let’s explore and master it together</p><span id="more"></span><blockquote class="colorquote warning"><p>Thank you for reading this article. More Interview Questions here:<br><a href="https://programmerscareer.com/software-interview-set/">https://programmerscareer.com/software-interview-set/</a></p></blockquote><h1 id="Topic-1-1-Detailed-Study-on-Redis-Data-Structures"><a href="#Topic-1-1-Detailed-Study-on-Redis-Data-Structures" class="headerlink" title="Topic: 1.1 Detailed Study on Redis Data Structures"></a><strong>Topic</strong>: 1.1 Detailed Study on Redis Data Structures</h1><p>Redis, an open-source, in-memory data structure store, provides us with a set of powerful and high-performance data structures. Our journey today starts with an in-depth exploration of these diverse data structures and the understanding of their functions.</p><p>Data structures in Redis are pre-built patterns that manage and organize data, which allow fast read and write operations. Redis provides several types of data structures, each one ideal for different types of data management needs. These include:</p><ol><li><strong>Strings</strong>: The simplest type of Redis data structure. They are binary safe and can contain any kind of data.</li><li><strong>Lists</strong>: These are simply lists of strings, sorted by insertion order.</li><li><strong>Sets</strong>: An unordered collection of unique strings.</li><li><strong>Hashes</strong>: Hashes are perfect to represent objects. They are maps between string fields and string values.</li><li><strong>Sorted sets (Zsets)</strong>: Every member of a Sorted Set is associated with a score, that is used to sort the set elements from the smallest to the greatest score.</li><li><strong>Bit arrays (Bitmaps)</strong>: They offer operations to manipulate arrays of bits.</li><li><strong>HyperLogLogs</strong>: a probabilistic data structure to estimate the cardinality of a set.</li><li><strong>Geospatial data (Geosets)</strong>: they enable you to store latitude, longitude, and associated names.</li></ol><ul><li><strong>Streams</strong>: they are a log data type that appends new items, like for logging or messaging.</li></ul><p>The choice of data structure depends on both the nature of the data and the kind of operations needed to manipulate that data effectively.</p><p>Understanding data structures and choosing the right one can drastically improve the performance of an application, making Redis an invaluable tool in our tech-stack.</p><h1 id="Topic-1-2-Number-of-Data-Structures-in-Redis"><a href="#Topic-1-2-Number-of-Data-Structures-in-Redis" class="headerlink" title="Topic: 1.2 Number of Data Structures in Redis"></a><strong>Topic</strong>: 1.2 Number of Data Structures in Redis</h1><p>As we have previously learned, Redis isn’t just your everyday key-value store, it’s more accurate to think of it as a data structures server. But you might be wondering, just how many data structures does Redis actually support?</p><p>The answer is, Redis importantly supports&nbsp;<strong>eight</strong>&nbsp;different types of data structures:</p><ol><li><strong>Strings</strong></li><li><strong>Lists</strong></li><li><strong>Sets</strong></li><li><strong>Sorted sets (Zsets)</strong></li><li><strong>Hashes</strong></li><li><strong>Bitmaps</strong></li><li><strong>HyperLogLogs</strong></li><li><strong>Geospatial data (Geosets)</strong></li><li><strong>Streams</strong></li></ol><p>Each of these data structures has a distinct identity, serves unique purposes, and provides different capabilities, thus allowing Redis to handle a wide range of data management tasks with exceptional speed and consistency.</p><h1 id="Topic-1-3-Understanding-Zset-in-Redis"><a href="#Topic-1-3-Understanding-Zset-in-Redis" class="headerlink" title="Topic: 1.3 Understanding Zset in Redis"></a><strong>Topic</strong>: 1.3 Understanding Zset in Redis</h1><p>In Redis,&nbsp;<strong>Sorted Sets</strong>, or&nbsp;<strong>Zsets</strong>, provide a fabulous combination of both Sets and Hashes. They take distinct aspects of these two data types, making this hybrid structure incredibly versatile.</p><p>A Sorted Set is, in essence, a Set, which guarantees that each element is unique. However, it also associates each element with a score, as in a hash. These scores are used to sort the set elements, from the smallest score to the greatest.</p><p>This might sound simple, but it has important implications. Redis can serve the Zset’s elements in the order of their score, providing a valuable resource for data range queries.</p><p>Just imagine a leader board in a game, where you must display top performers in ascending or descending order. A Zset would be the ideal data structure for such a use-case, as you can directly fetch data in the sorted manner.</p><p>That concludes the overview of Zsets! As we progress further, we’ll give you a live demonstration on how to implement and manipulate Zsets in Redis!</p><h1 id="Topic-1-4-Implementation-of-Zset-in-Redis"><a href="#Topic-1-4-Implementation-of-Zset-in-Redis" class="headerlink" title="Topic: 1.4 Implementation of Zset in Redis"></a><strong>Topic</strong>: 1.4 Implementation of Zset in Redis</h1><p>Zsets, as we learned before, are unique in their ability to associate each element with a score and inherently sort these elements based on that score. But we haven’t yet dived into how Zsets are implemented in Redis. So let’s unravel this mystery!</p><p>The implementation of Zsets is indeed quite fascinating. Redis utilizes two data structures internally to store a Zset:</p><ol><li><strong>HashTable</strong>&nbsp;where the element is the key and the score is the value.</li><li><strong>SkipList</strong>&nbsp;or&nbsp;<strong>Sorted Set</strong>&nbsp;where every node is an element in our Zset.</li></ol><p>When Zsets are small, with a maximum length of 128 items, and every element in the set is internal within a small integer range, Zsets are stored in a list representation called&nbsp;<strong>ziplist</strong>.</p><p>An interesting fact to note here is that the decision to use a HashTable or SkipList/Sorted Set does&nbsp;<em>not</em>&nbsp;affect the functionality of the Zset; it’s only for performance trade-offs.</p><p>Redis automatically switches between these internal data structures based on the contents of the Zset, optimizing for the fastest read, write, or combination of both, as necessary!</p><h1 id="Topic-1-5-Hands-on-with-Zset-in-Redis"><a href="#Topic-1-5-Hands-on-with-Zset-in-Redis" class="headerlink" title="Topic: 1.5 Hands-on with Zset in Redis"></a><strong>Topic</strong>: 1.5 Hands-on with Zset in Redis</h1><p>Alright, in Redis, you can perform various operations on Zsets:</p><ol><li><strong>zadd</strong>: This command allows you to add elements to a Zset. Each element added would be associated with a score. Here is how you can use it:</li></ol><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zadd myZset 1 "a"</span><br></pre></td></tr></tbody></table></figure><ol><li><strong>zrange</strong>: This command retrieves a range of elements, sorted by their scores. Here is how you would use it:</li></ol><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zrange myZset 0 -1</span><br></pre></td></tr></tbody></table></figure><ol><li><strong>zrem</strong>: This command helps you delete a specific element from the Zset:</li></ol><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zrem myZset "a"</span><br></pre></td></tr></tbody></table></figure><ol><li><strong>zrank</strong>: This command gives the rank of the element, indexed from 0. So, if you want to find out the rank of an element “a”, you can write:</li></ol><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zrank myZset "a"</span><br></pre></td></tr></tbody></table></figure><p>Remember, Redis is quite forgiving when it comes to syntax. It’s not case sensitive and doesn’t even mind if you forget to close your quotes in some cases!</p><h1 id="Topic-1-6-Advanced-Redis-Topics"><a href="#Topic-1-6-Advanced-Redis-Topics" class="headerlink" title="Topic: 1.6 Advanced Redis Topics"></a><strong>Topic</strong>: 1.6 Advanced Redis Topics</h1><p>After mastering the various data structures and commands in Redis, it’s now time to level up and explore some advanced aspects of Redis! 💪</p><p>Let’s start with&nbsp;<strong>Redis Persistence</strong>. Redis offers two types of persistence:</p><ol><li><strong>RDB</strong>&nbsp;(Redis Database Backup): This persistent method captures snapshots of your dataset at specified intervals.</li><li><strong>AOF</strong>&nbsp;(Append Only File): This persistent method logs every write operation received by the server, which when re-run, can reproduce the original dataset.</li></ol><p>Both persistence methods have their pros and cons, and the selection usually depends on the use-case requirements.</p><p>Next in line is&nbsp;<strong>Redis Transactions</strong>. Redis Transactions allow the execution of a group of commands in a single step. It uses ‘MULTI’ to indicate the start and ‘EXEC’ to indicate the end of a transaction.</p><p>Another significant aspect to discuss is Redis Security. By default, Redis has no authentication or security layer. However, Redis allows setting a password that clients must use to authenticate before being granted access.</p><p>It is also important to remember that Redis doesn’t support encrypted connections, and it’s advisable to use an SSL proxy in cases where data needs to be encrypted over the network.</p><p>Lastly, let’s shed light on&nbsp;<strong>Redis Pub/Sub</strong>&nbsp;model. Here, publishers send messages to specific channels without knowing or caring about the subscribers. Similarly, subscribers listen to specific channels without knowing or caring about the publishers. This leads to a highly decoupled and scalable system.</p><h1 id="Topic-1-7-Redis-in-Real-World-Applications"><a href="#Topic-1-7-Redis-in-Real-World-Applications" class="headerlink" title="Topic: 1.7 Redis in Real-World Applications"></a><strong>Topic</strong>: 1.7 Redis in Real-World Applications</h1><p>Redis, with its enviable set of features, finds use in a variety of real-world applications. Let’s look at a select few:</p><ol><li><strong>Caching</strong>: Due to its high-speed and the availability of rich data types, Redis is an ideal choice to implement caching in web applications. It considerably speeds up application response times.</li><li><strong>Session Storage</strong>: Websites that need to maintain information across multiple requests from a user often use Redis for session storage. The data types that Redis provides make it an ideal candidate.</li><li><strong>Message Queue Systems</strong>: Redis can function as a Message Queue System using its Lists and Pub/Sub model. A list in Redis can be used as a queue in which you can use atomic operations like LPUSH and RPOP to push and pop elements.</li><li><strong>Leaderboards and Counting</strong>: Redis works exceptionally well to manage leaderboards, especially if you are required to manage them in real-time. The Sorted Set data structure is designed to solve such problems.</li><li><strong>Real-time Analysis</strong>: You can use Redis for Real-time analysis like computing or analyzing statistics in live time for immediate viewing.</li></ol><p>A key point to note is that the flexibility of Redis doesn’t limit it to just these applications. It can also serve as a primary database, a job management system, a search engine and much more!</p><h1 id="Topic-1-8-Review-and-Assessments"><a href="#Topic-1-8-Review-and-Assessments" class="headerlink" title="Topic: 1.8 Review and Assessments"></a><strong>Topic</strong>: 1.8 Review and Assessments</h1><p>Let’s take a moment to review and practice what we’ve learned in the previous sections. It’s always a good idea to revisit the topics and start implementing them to solidify our understanding.</p><p>Up until now, we’ve learned about the various data types in Redis, performed hands-on operations for each data structure, dove into advanced topics, and saw how Redis is used in real-world applications.</p><p>A good methodology is for us to choose a real-world problem and try to solve it using Redis. You can try to implement a caching solution for a web application or set up a simple message queue system. Use the Redis commands we’ve learned to interact with the different data types and structures.</p><p>Now let’s test your knowledge of Redis.</p><p>1️⃣&nbsp;<strong>Basic Question</strong>&nbsp;(Difficulty: 3/10): What are the six data types that Redis supports?</p><p>2️⃣&nbsp;<strong>Intermediate Question</strong>&nbsp;(Difficulty: 6/10): In what situation would you use a Redis List over a Redis Set?</p><p>3️⃣&nbsp;<strong>Advanced Question</strong>&nbsp;(Difficulty: 9/10): How would you implement caching in a web application using Redis? Please describe a brief process of how it would work.</p><hr><p>1️⃣&nbsp;<strong>Basic Question Answer</strong>: Redis supports six data types, which are STRING, LIST, SET, ZSET (Sorted Set), HASH, and STREAM.</p><p>2️⃣&nbsp;<strong>Intermediate Question Answer</strong>: You would use a Redis List when the order of the data matters as Redis Lists maintain the order of elements based on how they are added. On the other hand, a Redis Set is an unordered collection. So, if you need to store a list of items in a specific order (like a timeline of comments on a blog post), you would use a Redis List.</p><p>3️⃣&nbsp;<strong>Advanced Question Answer</strong>: To implement caching in a web application using Redis, you could follow these steps:</p><ul><li>First, whenever a request is made to your web application, check if the requested data is in your Redis cache by trying to retrieve it using the request parameters as the key.</li><li>If the data is in Redis (a cache hit), retrieve it and return it in the response.</li><li>If the data is not in Redis (a cache hit), retrieve it from your primary database.</li><li>After retrieving it from your primary database, save it to your Redis cache with an expiration time so that it doesn’t indefinitely take up memory in your cache. Then return the data in the response.</li><li>Done correctly, this allows frequently requested data to be served from the Redis cache, significantly speeding up response times and reducing the load on your primary database.</li></ul><blockquote class="colorquote danger"><p>中文文章: <a href="https://programmerscareer.com/zh-cn/redis-interview6/">https://programmerscareer.com/zh-cn/redis-interview6/</a><br>Author: <a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>Note: If you choose to repost or use this article, please cite the original source.  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 面试：假设 Redis 的 master 节点宕机了，你会怎么进行数据恢复？</title>
      <link href="/zh-cn/redis-interview3/"/>
      <url>/zh-cn/redis-interview3/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>让我们制定您的定制课程计划，以学习 Redis。该计划将特别关注 Redis主节点故障时数据恢复的场景。</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h3 id="主题：Redis架构"><a href="#主题：Redis架构" class="headerlink" title="主题：Redis架构"></a><strong>主题</strong>：Redis架构</h3><hr><p>Redis 的全称是 Remote Dictionary Server，它是一个开源的内存数据结构存储，可以用作数据库、缓存和消息代理。其中一个主要原因是它在内存中执行所有操作并避免了磁盘操作所需的寻址时间。</p><p>Redis 支持各种数据结构，例如字符串、哈希、集合、列表等。让我们深入了解 Redis 架构。</p><h4 id="Redis-服务器和客户端"><a href="#Redis-服务器和客户端" class="headerlink" title="Redis 服务器和客户端"></a>Redis 服务器和客户端</h4><p>Redis 数据存储系统的基本角色有两个：Redis 客户端和 Redis 服务器。</p><p><strong>Redis 客户端</strong> 是一个独立的应用程序，与 Redis 服务器连接并执行命令。客户端可以是任何内容，从一个小的脚本来管理应用程序会话，到一个大型系统来使用 Redis 缓存数据以提高访问速度。</p><p><strong>Redis 服务器</strong> 是主要的功能单元。它是数据存储的位置，数据被缓存到内存中，数据结构被维护，并处理客户端发送的所有命令。</p><h4 id="Redis-数据结构"><a href="#Redis-数据结构" class="headerlink" title="Redis 数据结构"></a>Redis 数据结构</h4><p>了解 Redis 架构的核心原理是它是一个<strong>键值</strong>数据存储，这意味着您存储在 Redis 服务器中的每一项数据都包含一个键和一个值。Redis 的独特之处在于它可以存储各种值类型。Redis 支持以下数据结构：</p><ul><li><strong>字符串</strong></li><li><strong>哈希</strong></li><li><strong>列表</strong></li><li><strong>集合</strong></li><li><strong>有序集合</strong></li></ul><p>每种数据结构都有自己的命令集来管理数据。例如，如果您正在处理列表，则可以执行命令，例如 <code>LPUSH</code>、<code>LRANGE</code> 等来操作列表。这些数据结构使 Redis 非常灵活，能够有效地解决许多不同类型的问题。</p><h4 id="持久性——一瞥"><a href="#持久性——一瞥" class="headerlink" title="持久性——一瞥"></a>持久性——一瞥</h4><p>Redis 的一个关键组件是它能够将数据持久化到磁盘。想象一下，如果您的 Redis 服务器关闭时所存储的数据都会被清除——这不是非常有效的吗？为了避免这种情况，Redis 提供了一些持久化到磁盘的策略，以便在故或关闭时可以恢复数据。我们将在后续课程中详细讨论这个方面。</p><p>现在，我们已经了解了 Redis 基本架构的要素，我们将逐步深入更复杂的主题，例如数据复制、备份和 Redis Sentinel 高可用性等。</p><h3 id="主题：Redis-复制"><a href="#主题：Redis-复制" class="headerlink" title="主题：Redis 复制"></a><strong>主题</strong>：Redis 复制</h3><hr><p>复制是一种机制，允许您的数据自动复制从主服务器到一个或多个副本服务器。复制提供两大好处：</p><ul><li><strong>性能提升</strong>：您可以将读操作分发到副本服务器以分担主服务器的负载。这允许主服务器处理更少的请求并提高整体性能。</li><li><strong>数据冗余</strong>：您的数据将存储在多个服务器上，为了提供冗余选项，如果主服务器出现故障。这种容错性在生产环境中是必不可少的。</li></ul><h4 id="了解-Redis-主从复制配置"><a href="#了解-Redis-主从复制配置" class="headerlink" title="了解 Redis 主从复制配置"></a>了解 Redis 主从复制配置</h4><p>当在 Redis 中设置复制时，它遵循主从复制配置。主服务器包含数据的原始副本，并将其复制到副本服务器。</p><p>在 Redis 中设置复制是简单的。基本上，这涉及创建一个主服务器并然后将一个或多个从服务器连接到主服务器上使用 <code>SLAVEOF</code> 命令，指定主服务器的 IP 和端口。</p><p>让我们了解如何在主服务器上的变更传递到从服务器：</p><ol><li>当在主服务器上的数据集上发生变化（例如，写操作）时，主服务器会将命令发送到连接的从服务器。</li><li>每个从服务器将接收命令并执行它们，从而使其数据集与主服务器的数据集同步。</li></ol><p>要了解的重要是数据操作是<strong>异步</strong>的——主服务器不会等待从服务器确认并执行命令。然而，主服务器会记录哪些命令被每个从服务器确认。</p><p>这种复制方案提供了一种强大的数据冗余和性能缩放机制。然而，它并不无挑战，例如，如果主节点出现故障怎么办？如何确保高可用性和数据一致性？Redis 是如何处理这些场景的？我们将在后续课程中详细讨论这些问题。</p><h3 id="主题：Redis持久化深入分析"><a href="#主题：Redis持久化深入分析" class="headerlink" title="主题：Redis持久化深入分析"></a><strong>主题</strong>：Redis持久化深入分析</h3><hr><p>Redis主要在内存空间操作数据，提供快速访问和修改数据。然而，数据的持久化变得至关重要，以防止服务器崩溃或关闭时的数据丢失。Redis 包含两种方法来将内存中的数据保存到磁盘上，即 RDB 和 AOF。</p><h4 id="RDB-Redis-数据库备份"><a href="#RDB-Redis-数据库备份" class="headerlink" title="RDB (Redis 数据库备份)"></a>RDB (Redis 数据库备份)</h4><p>RDB 持久化通过定期将数据集的快照保存到磁盘上来实现。这是怎样工作的：</p><ul><li>Redis 会 fork 一个子进程。</li><li>子进程会写入整个数据集到磁盘上（到 RDB 文件），以捕获数据在该时刻的快照。</li></ul><p>可以配置 RDB 的保存频率。例如，您可以配置 Redis 在过去 15 分钟内至少发生了一次更改时保存到磁盘上。</p><p>RDB 的快照非常适合备份。如果您需要重建数据库，具有时间点快照非常有用。</p><h4 id="AOF-追加只写文件"><a href="#AOF-追加只写文件" class="headerlink" title="AOF (追加只写文件)"></a>AOF (追加只写文件)</h4><p>AOF 持久化则是记录每次接收到的写操作，然后可以在服务器启动时播放回来。这是怎样工作的：</p><ul><li>当接收到一个命令修改数据集时，它会被追加到 AOF 缓冲区中。</li><li>Redis 经常将 AOF 缓冲区数据写入磁盘上。</li></ul><p>可以配置 AOF 在磁盘上写入数据的频率。</p><p>与 RDB 相比，AOF 文件更耐久，因为它是追加只写的。这意味着即使在写操作期间发生了一次崩溃或电源故障，您也可能会收到命令的完整历史，直到故障之前的短时间内。 而 RDB 则可能会丢失更多数据，这取决于您的保存条件（具体取决于您的配置）。</p><h4 id="RDB-和-AOF-之间的选择"><a href="#RDB-和-AOF-之间的选择" class="headerlink" title="RDB 和 AOF 之间的选择"></a>RDB 和 AOF 之间的选择</h4><p>没有一个全面的答案。这取决于您的应用程序和数据的重要性。某些人喜欢 RDB 因为快速备份可以轻松地移动。其他人喜欢 AOF 因为它提供了更高的耐久性。</p><p>Redis Actually 允许同时使用 RDB 和 AOF！如果启用了两者，Redis 会在迭代数据集时为 AOF 重写生成数据库的快照。</p><p>您可以考虑这是一个混合方法，享受了两种方法的优势。</p><h3 id="主题：Redis-备份"><a href="#主题：Redis-备份" class="headerlink" title="主题：Redis 备份"></a><strong>主题</strong>：Redis 备份</h3><hr><p>没有可靠和定期的备份，数据就面临丢失的风险，特别是在硬件或软件故障时。对 Redis 来说，快照功能，或者 Redis 数据库备份（RDB），提供了一种可靠的备份方式。它提供了一致和压缩的点到时间快照。</p><p>RDB 持久化模型通过在不同的时间间隔上保存数据集来操作，您可以指定这些间隔，例如，每 15 分钟内至少发生了 5 个键的更改，或者每 1 小时内至少发生了 1 个键的更改等等。</p><h4 id="创建备份"><a href="#创建备份" class="headerlink" title="创建备份"></a>创建备份</h4><p>Redis 允许您在任何时候手动生成一个 RDB 文件，使用 <code>SAVE</code> 或 <code>BGSAVE</code> 命令。</p><p><code>SAVE</code> 命令同步执行并会阻塞所有其他客户端，因此对生产环境来说，更好的是使用 <code>BGSAVE</code> 命令，它会分叉一个新进程来保存数据，而您的 Redis 服务器继续为客户端请求服务。</p><p>请注意，这个过程可能会消耗大量的 I/O 和 CPU，取决于数据的大小。</p><h4 id="还原备份"><a href="#还原备份" class="headerlink" title="还原备份"></a>还原备份</h4><p>还原 RDB 文件非常简单，只需要停止 Redis 服务器，替换 RDB 文件并重新启动服务即可。</p><p>启动时，Redis 会从 RDB 文件中加载数据到内存并继续正常操作。在加载数据到内存之前，写入新数据到 Redis 存储或从存储中读取数据都不能进行。</p><p>了解备份是 Redis 的关键部分，因为它形成了任何灾难恢复计划的基础。正确和可靠的备份是保护数据并确保应用程序的顺利运行的关键。</p><hr><h3 id="主题：Redis-Sentinel"><a href="#主题：Redis-Sentinel" class="headerlink" title="主题：Redis Sentinel"></a><strong>主题</strong>：Redis Sentinel</h3><hr><p>现在，让我们讨论 Redis 的一个重要方面，Redis Sentinel 系统。它帮助完成两项主要功能——<strong>监控</strong> 和 <strong>自动故障转移</strong>。让我们来详细了解一下。</p><p><strong>监控</strong>：Redis Sentinel 不断地检查主节点和副本实例是否正常运行。它不仅确认实例的可用性（运行中），还验证它们是否能够接受连接并响应查询。</p><p><strong>自动故障转移</strong>：如果主节点失败，Sentinel 系统会自动检测这一点并开始故障转移过程。这个过程包括选择一个副本，提升它为新的主节点，并重新配置其他副本以使用新的主节点。</p><p>这些功能为 Redis 环境提供高可用性和耐性。在下一课中，我们将处理主节点故障的场景，常见的故障原因和 Redis 是如何处理这些事件的。</p><p>值得注意的是 <strong>Quorum</strong>，它表示最少需要多少个 Sentinel 节点同意才能进行故障转移。例如，如果您有五个 Sentinel 节点，Quorum 可能是三个。这意味着至少三个 Sentinel 节点需要同意主节点确实不可用，并且应该进行故障转移。</p><p>Redis Sentinel 为需要高可用性的应用程序提供了很大的价值。在下一课中，我们将处理主节点故障的场景，常见的故障原因和 Redis 是如何处理这些事件的。</p><h3 id="主题：Redis主节点故障——一个概述"><a href="#主题：Redis主节点故障——一个概述" class="headerlink" title="主题：Redis主节点故障——一个概述"></a><strong>主题</strong>：Redis主节点故障——一个概述</h3><hr><p>Redis主节点故障虽然不常见，但可能会对未经配置的Redis架构造成挑战。了解故障的可能原因并为其制定处理策略是至关重要的。</p><p>主节点故障可能的原因包括：</p><ol><li><strong>硬件故障</strong>：这可能是硬件损坏或硬盘的磨损。偶尔，内存组件也可能会失败，导致服务器崩溃。</li><li><strong>网络中断</strong>：网络连接中断可能会导致主节点（或任何节点）与其他节点失去联系。这可能是暂时的问题或永久性问题，取决于基础设施的特性。</li><li><strong>磁盘满错误</strong>：Redis可能会关闭以防止数据不一致性。</li><li><strong>软件错误/服务器过载</strong>：软件BUG或服务器过载可能会导致崩溃，导致主节点故障。</li></ol><p>当主节点故障时，关键问题是确保无中断的服务。这就是Redis哨兵系统和Redis复制的地方。</p><p>如果发现故障，哨兵系统将开始自动故障转移过程。故障转移过程包括提升副本并将其配置为新主节点，其他副本将被自动重配置以使用此新主节点。</p><p>了解故障的可能原因并了解后续恢复机制是维持高可用性的关键。</p><p>在下一课中，我们将深入探讨Redis主节点数据恢复过程后主节点故障。</p><hr><h3 id="主题：Redis主节点数据恢复"><a href="#主题：Redis主节点数据恢复" class="headerlink" title="主题：Redis主节点数据恢复"></a><strong>主题</strong>：Redis主节点数据恢复</h3><hr><p>当Redis主节点因某些未预见的事件而崩溃时，恢复数据从备份中变得至关重要，以确保平稳的运行。</p><p>作为我们前面所学的，哨兵系统在主节点故障时会开始自动故障转移过程。其中一个副本将被提升为新主节点，其他副本将被自动重配置以使用此新主节点。</p><p>但是，我们也需要考虑如何恢复原始主节点并将其添加回系统，一恢复并同步后，可以重新配置。</p><p>现在，在故障期间写入的数据是否会丢失取决于持久性配置：</p><ol><li><strong>AOF (追加只写文件)</strong> 持久性配置：在AOF中，所有写操作都会记录，如果主节点故障，AOF文件将继续记录这些操作，直到主节点恢复并与此副本同步。</li><li><strong>RDB (Redis数据库备份)</strong> 持久性配置：在RDB中，在配置的间隔内进行快照。因此，在两个快照之间写入的数据可能会丢失，如果故障发生。</li></ol><p>简而言，处理Redis主节点故障的机制主要取决于配置、哨兵系统和持久性设置。您可以根据使用场景和数据安全要求选择最适合的策略。</p><h3 id="主题：复习和评估"><a href="#主题：复习和评估" class="headerlink" title="主题：复习和评估"></a><strong>主题</strong>：复习和评估</h3><hr><p>我们已经详细探讨了 Redis 各方面的多个方面。让我们回顾我们所学的核心概念：</p><ol><li><strong>Redis 架构</strong>：我们开始了解 Redis 的底层架构。</li><li><strong>Redis 复制</strong>：研究了 Redis 数据复制的概念并了解了它是如何实现的。</li><li><strong>Redis 持久性</strong>：深入了解 Redis 数据持久化的过程并了解它是为什么重要的。</li><li><strong>Redis 备份</strong>：学习了如何在 Redis 中建立备份并了解了它们在数据恢复中的角色。</li><li><strong>Redis Sentinel</strong>：了解了 Redis Sentinel 的原理并了解它在维持高可用性方面的作用。</li><li><strong>主节点故障</strong>：讨论了 Redis 主节点故障的可能原因。</li><li><strong>主节点数据恢复</strong>：了解了 Redis 主节点故障时的详细过程。</li></ol><p>现在，重要的是回顾并重新评估我们的理解。这就是交互性评估的地方。它们为我们提供了一种机会来检查我们的理解、应用所学知识并纠正任何遗漏。</p><p>例子问题：假设您正在为应用设置数据存储系统。您决定使用 Redis 并需要配置它。您有两台服务器可用。如何确保数据安全和高可用性？</p><hr><p>现在，让我们测试你的知识。</p><h4 id="问题-1："><a href="#问题-1：" class="headerlink" title="问题 1："></a>问题 1：</h4><p>根据你所学的 Redis 内部结构，描述 Redis 架构的基本组成部分。</p><h4 id="问题-2："><a href="#问题-2：" class="headerlink" title="问题 2："></a>问题 2：</h4><p>解释 Redis Sentinel 的角色并说明它是如何帮助维持 Redis 基础设施的高可用性的。</p><h4 id="问题-3："><a href="#问题-3：" class="headerlink" title="问题 3："></a>问题 3：</h4><p>Redis 在主节点故障时会采取哪些步骤？</p><p>对于每个问题，请分享你的答案。</p><p><strong>示例问题</strong>是：假设您正在为应用程序设置数据存储系统，并决定使用 Redis。需要配置它。您有两台服务器可用。如何确保数据安全和高可用性？</p><p>为了确保数据安全和高可用性，您可以按以下步骤设置 Redis环境：</p><ol><li><strong>使用两台服务器</strong>：在两台服务器上安装 Redis。其中一台将作为主服务器，另一台将作为从服务器（slave）。</li><li><strong>数据持久性</strong>：在两台服务器上配置数据持久性机制。这将确保数据更改不会丢失，提供数据安全性。例如，您可能会选择 RDB 以获取较低的数据库备份程度，但更少的资源使用，或者 AOF 以获取更高的数据库备份程度，但更多的资源使用。</li><li><strong>主从复制</strong>：将第二台服务器设置为主服务器的副本。这意味着主服务器上写入的数据也会写入副本。这在主服务器（设计为主服务器）出现故障时尤其重要。</li><li><strong>Redis 哨兵</strong>：为了维持高可用性，请使用 Redis 哨兵。哨兵将监视两台服务器，并在主服务器出现故障时提升副本为新主服务器。</li><li><strong>配置您的应用程序</strong>：配置您的应用程序以将写入操作发送到主服务器，并将读取操作均衡分配到两台服务器上。</li></ol><p>这些步ZZ将为高可用性（通过主从复制和 Redis 哨兵）和数据安全性（通过数据持久性机制）提供平衡。</p><p><strong>问题 1</strong>：Redis 架构的基本构件包括：</p><ul><li><strong>Redis 客户端</strong>：这些是发送命令给 Redis 以执行数据存储操作的应用程序或用户。</li><li><strong>Redis 服务器</strong>：这是 Redis 安装和运行的地方。它负责在内存中存储数据并执行操作。</li><li><strong>数据结构</strong>：Redis 支持多种数据结构，包括字符串、列表、集合、有序集合等。每种结构都有特定的命令相关联。</li><li><strong>数据库持久性</strong>：Redis 提供两种数据库持久性机制——RDB 和 AOF。RDB 在特定时间间隔内拍摄数据集。AOF 记录每次写入服务器接收到的操作。</li><li><strong>复制</strong>：这是设置主从节点以确保数据冗余的过程。如果主节点失败，其中一个从节点将被提升为新主节点，并且其他从节点将被重新配置以使用新主节点。</li></ul><hr><p><strong>问题 2</strong>：Redis 哨兵（如果配置）可识别主节点的故障。它将开始故障转移过程。Redis 哨兵系统将选举一个副本并将其提升为新主节点，并且其他副本将被重新配置以使用新主节点。应用程序也会被通知关于新主节点以重定向其查询。</p><hr><p><strong>问题 3</strong>：当 Redis 主节点失败时，发生以下步骤：</p><ol><li>Redis 哨兵（如果配置）检测主节点的故障。</li><li>一台哨兵开始故障转移，其他哨兵确认此操作。</li><li>Redis 哨兵将选举一个副本并将其提升为新主节点。</li><li>其他副本将被重新配置以使用新主节点。</li><li>在解决问题后，失败的主节点将加入回来作为副本到当前主节点。它需要对新主节点进行完全同步。</li></ol><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/redis-interview3/">https://programmerscareer.com/redis-interview3/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 面试：简述 Redis 中如何防止缓存雪崩和缓存击穿</title>
      <link href="/zh-cn/redis-interview4/"/>
      <url>/zh-cn/redis-interview4/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>聚焦缓存防护方面，让我们一起深入探讨和掌握它</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题1-1：详细研究缓存穿透"><a href="#主题1-1：详细研究缓存穿透" class="headerlink" title="主题1.1：详细研究缓存穿透"></a><strong>主题</strong>1.1：详细研究缓存穿透</h1><p>缓存穿透（Cache Penetration），也称为缓存错误或缓存突破，是指请求直接命中数据库，而不是缓存。这通常发生在请求查询未存储在我们的缓存中的数据时。</p><p>想象一下，一个购物网站，用户可以搜索产品。缓存可能包含受欢迎搜索项目，以提高检索速度。然而，罕见的产品搜索者可能会导致系统必须从数据库中查询。这是缓存穿透的一个例子。</p><p>虽然这可能不会造成严重的问题，但考虑一下高量的流量查询未缓存的项目。这可能会导致数据库的大量加载，并最终导致数据库崩溃。</p><p>甚至更严重的缓存穿透是当攻击者可以精确地预测特定请求不会被缓存时发生的情况，并在我们的系统上发起这些请求，使数据库成为主要的命中点，并最终导致系统崩溃。</p><p>缓存穿透是应用程序的流畅性和有效性所必需的。幸运的是，Redis提供了强大的策略来避免缓存穿透，并在本主题中探讨它们。</p><h1 id="主题-1-2-Redis-中防止缓存穿透的策略"><a href="#主题-1-2-Redis-中防止缓存穿透的策略" class="headerlink" title="主题 1.2: Redis 中防止缓存穿透的策略"></a><strong>主题 1.2</strong>: Redis 中防止缓存穿透的策略</h1><p>Redis 提供了强大的策略来防止缓存穿透，确保系统在高负载下的高效性。这些策略主要集中在减少直接命中数据库的情况下。</p><p>一个常见的策略是<strong>默认缓存值</strong>。当请求未找到数据时，不要让请求直接命中数据库，而是在缓存层处理它，并返回默认值。这意味着数据库不会受到缓存穿透的影响，并且可以防止缓存穿透。</p><p>另一个强大的策略是<strong>Bloom 过滤器</strong>。Bloom 过滤器是一种概率数据结构，可以用来测试数据集中的元素是否是集合的一部分。这意味着它可以快速识别数据请求是否存在于我们的数据库或缓存中。如果 Bloom 过滤器说数据项不存在，我们可以立即返回默认值，而不必查询我们的缓存或数据库。</p><p>在设置这些策略时，需要考虑权衡。Bloom 过滤器可能会导致误报。然而，这通常会大大超越小错误概率的好处。</p><h1 id="主题1-3：深入探讨缓存崩溃"><a href="#主题1-3：深入探讨缓存崩溃" class="headerlink" title="主题1.3：深入探讨缓存崩溃"></a><strong>主题</strong>1.3：深入探讨缓存崩溃</h1><p>缓存崩溃是一种系统故障，发生在大量缓存项目同时过期，并且多个请求为这些数据项命中数据库，可能导致数据库崩溃或变得不可用，因为高负载。</p><p>想象一下，当网站缓存每日特惠时，所有缓存项目都在午夜过期。当时钟显示 12:00 时，所有缓存项目都变得无效。第一组用户在午夜之后试图访问这些特惠时，系统必须从数据库中获取新的特惠并填充缓存。</p><p>然而，想象一下，当数百万用户同时试图访问这些特惠时，这可能会导致数据库被大量请求所淹，使其变得不可用或崩溃——这是缓存崩溃的效果。</p><p>虽然缓存崩溃可能会令人恐惧，但我们可以采用各种策略来防止它发生。了解这些技术可以使我们设计的系统更加坚固和可靠。</p><h1 id="主题-1-4-使用-Redis-防止缓存崩溃"><a href="#主题-1-4-使用-Redis-防止缓存崩溃" class="headerlink" title="主题 1.4: 使用 Redis 防止缓存崩溃"></a><strong>主题 1.4</strong>: 使用 Redis 防止缓存崩溃</h1><p>防止缓存崩溃的效果是防止大量请求同时命中数据库。Redis 提供了许多实用的策略来实现这一点。</p><p>第一种技术是使用<strong>TTL (Time To Live) 延迟</strong>。不要为所有缓存项目设置相同的 TTL 值。我们可以轻微延迟或随机化它们的 TTL 值。这引入了差异，从而降低了多个项目同时过期的风险。</p><p>另一个主要策略是使用<strong>缓存预热</strong>。缓存预热是加载数据到缓存之前进行的实践。例如，如果我们知道某些缓存项目很可能很快过期，我们可以在低峰期预先刷新它们，以避免崩溃期间的峰值。</p><p>最后，可能值得考虑使用<strong>回退缓存</strong>。在这种方法中，即使缓存项目已过期，仍然返回过期的值，同时更新缓存的后台进程。这可以防止突然数据库加载，因为同时发生的缓存错误。</p><p>要记住的是，没有单一策略可以在每个场景中作为银弹。实际的实现可能需要根据使用案例的特定性组合这些策略。</p><p>中文翻译：</p><h1 id="主题1-5：Redis事务与缓存预防"><a href="#主题1-5：Redis事务与缓存预防" class="headerlink" title="主题1.5：Redis事务与缓存预防"></a><strong>主题1.5</strong>：Redis事务与缓存预防</h1><p>Redis不仅仅是内存数据库，还可以支持事务——一系列命令按顺序执行，除非遇到命令中的错误。</p><p>Redis事务使用两步过程：</p><ol><li><strong>命令排队</strong>：使用 <code>MULTI</code> 命令来排队命令。在这一步中，Redis仅仅记录所有在这个事务中的命令。</li><li><strong>命令执行</strong>：当 <code>EXEC</code> 命令被发出时，Redis就执行所有在事务中排队的命令，按照排队的顺序执行。</li></ol><p>Redis事务用于确保所有缓存操作（例如读取、写入或更新）是原子的——这意味着它们全部执行或不执行。这是维持缓存一致性的关键，并可以帮助缓解脏读的影响，也可以帮助缓解缓存渗透的影响。</p><p>让我们来看一个例子。假设你正在实现一个排行榜系统并想以原子方式更新玩家的分数。下面是如何使用事务来实现这一点的：</p><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MULTI  </span><br><span class="line">    GET player_score  </span><br><span class="line">    INCR player_score  </span><br><span class="line">EXEC</span><br></pre></td></tr></tbody></table></figure><p>通过将 GET 和 INCR 命令包装在一个事务中，我们可以确保如果其他客户端读取分数，他们总是会得到一致的值。</p><p>使用 Redis 事务与缓存预防技术，无论是防止渗透还是避免崩溃，都可以显著提高缓存层的一致性和可靠性。</p><h1 id="主题1-6：Redis-缓存预防在实际应用中的应用"><a href="#主题1-6：Redis-缓存预防在实际应用中的应用" class="headerlink" title="主题1.6：Redis 缓存预防在实际应用中的应用"></a><strong>主题1.6</strong>：Redis 缓存预防在实际应用中的应用</h1><p>Redis 和其缓存预防技术在许多实际应用中被广泛使用，以处理大量负载而不崩溃后端数据库。下面是一些例子：</p><ul><li><strong>电子商务网站</strong>：网站像 Amazon 一样使用 Redis 来缓存产品详细信息和推荐。Redis 的缓存预防技术对处理大量并发用户的能力至关重要，特别是在节日期间。</li><li><strong>社交媒体平台</strong>：平台像 Twitter 和 Instagram 一样使用 Redis 来缓存用户数据和信息流。Redis 的高并发处理能力使其成为这些平台的理想选择。</li><li><strong>排行榜系统</strong>：在游戏平台上，用户分数和排名被实时更新并需要被多个客户端同时访问。Redis 的原子事务能力确保分数在所有客户端中的一致性，即使处理大量并发用户。</li><li><strong>在线票务服务</strong>：在高需求事件期间，票务服务可能会遇到数据库故，如果不处理正确。Redis 的缓存管理能力可以有效地防止这些情况。</li></ul><p>在所有这些例子中，缓存优化技术，例如缓存时间的分层、缓存预热和使用备用值，被广泛使用来防止缓存渗透和缓存崩溃。</p><h1 id="主题1-7：回顾和评估"><a href="#主题1-7：回顾和评估" class="headerlink" title="主题1.7：回顾和评估"></a><strong>主题1.7</strong>：回顾和评估</h1><p><strong>缓存渗透</strong> 发生在频繁请求未知数据时，每次请求都会到达后端数据库，因为缓存中不可用。这可能会导致过多的和不必要的数据库负载。Redis 提供了多种防止它的机制，例如 NULL 缓存和 Bloom 过滤器。</p><p><strong>缓存崩溃</strong> 发生在多个缓存数据同时过期时，导致数据库的大量请求。Redis 提供了策略，例如 TTL 分层、缓存预热和备用缓存，来处理缓存崩溃。</p><p><strong>Redis 事务</strong> 在多次读取或写入操作期间起着重要的作用，通过排队多个命令并以原子方式执行它们，Redis 事务可以防止脏读并提供更高的可靠性。</p><p>Redis 和防止缓存渗透和崩溃的技术在高流量、实际应用中被广泛使用，例如电子商务网站、社交媒体平台、实时排行榜系统和在线票务服务。</p><p>让我们开始评估。</p><p><strong>问题1</strong></p><p>以你自己的语言描述什么是缓存渗透。为什么它是一个问题，Redis 是如何帮助防止它的？</p><p><strong>问题2</strong></p><p>描述一场实际场景，在这场场景中，Redis 事务可能会有用。在这种场景中，如何通过使用事务来促进数据一致性？</p><p><strong>问题3</strong></p><p>考虑一场高流量的电子商务网站，并描述如何有效地处理缓存崩溃使用 Redis。</p><p><strong>答案1</strong></p><p>缓存渗透是指频繁请求未知数据时，每次请求都会到达后端数据库，因为缓存中不可用。这可能会导致过多的和不必要的数据库负载，并降低性能。Redis 帮助防止缓存渗透主要通过 NULL 缓存，在数据库返回 NULL 值时存储“NULL”关键字的情况下。</p><p><strong>答案2</strong></p><p>在 Twitter 上，当用户点赞一条推文时，推文的总喜欢数和用户的喜欢推文都需要更新。这场场景需要多次写操作，如果不处理原子方式，可能会导致数据不一致。Redis 事务可以将多个写命令排队并以原子方式执行，以维持数据的整性和一致性。</p><p><strong>答案 3</strong></p><p>在高流量的电子商务网站，例如 Amazon，缓存崩溃可能会发生，当多个缓存产品详细信息或用户推荐过期时。Redis 有效地处理这种情况，通过 TTL 分层，每个键值对在缓存中有不同的过期时间，或者通过缓存预热，在旧缓存过期之前刷新缓存中的最常访问数据。这可以防止数据库的突然增加。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/redis-interview4/">https://programmerscareer.com/redis-interview4/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 面试：简述 Redis 持久化中 RDB 以及 AOF 方案的优缺点</title>
      <link href="/zh-cn/redis-interview5/"/>
      <url>/zh-cn/redis-interview5/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>让我们用重点研究 Redis 的 RDB 和 AOF 持久性方案来学习 Redis。</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：Redis-架构"><a href="#主题：Redis-架构" class="headerlink" title="主题：Redis 架构"></a><strong>主题</strong>：Redis 架构</h1><p>想象一种系统，轻量和高效，专为快速存储和检索数据而设计。请允许我介绍名为 Redis 的奇迹！</p><p>Redis（Remote Dictionary Server）是一种内存数据结构存储。它可以用作数据库、缓存和消息代理。“内存”部分意味着它主要存储数据在 RAM 中，这使数据操作变得非常快速，因为从和写入主内存可以以更快的速度进行。</p><p>其结构基于服务器-客户端架构。这意味着每个 Redis 设置都有一个 Redis 服务器和一个或多个 Redis 客户端；想象一场对话，客户端不断请求，服务器回复。</p><p>我们有几个组件在 Redis 架构中处于作用：</p><ul><li><strong>Redis 客户端</strong>：它们可以是不同的应用程序或同一应用程序的多个实例。他们要求，服务器响应。</li><li><strong>Redis 服务器</strong>：服务器管理数据存储并响应客户端的命令。</li><li><strong>Redis 数据</strong>：Redis 的核心是数据存储，这是我们的 Redis 架构的关键部分。</li></ul><p>现在，正如我们所看到的，Redis 是一个内存数据结构存储。然而，Redis 的一个重要特性是它可以在磁盘上持久化数据。它可以记录每次客户端传递的写操作，因此为内存数据库提供了高级数据安全性。</p><p>这就是 Redis 架构的简要概述！</p><h1 id="主题：Redis-持久性概述"><a href="#主题：Redis-持久性概述" class="headerlink" title="主题：Redis 持久性概述"></a><strong>主题</strong>：Redis 持久性概述</h1><p>Redis，一种内存数据结构存储，用于处理 lightning-fast 的数据操作。然而，由于它存储数据在 RAM 中，因此数据持久性问题成为了关注的焦点。Redis 是如何确保数据的长期存在性？</p><p>Redis 为此提供了两种方法来确保数据持久性：<strong>RDB（Redis 数据库）</strong>和<strong>AOF（追加只写文件）</strong>。</p><ul><li><strong>RDB 持久性</strong>：这种方法在特定时间点对数据集进行一次点击保存并将其保存在磁盘上以二进制格式进行保存。这些“快照”是紧凑的并且加载速度很快，因此 RDB 是一个出色的备份选项。</li><li><strong>AOF 持久性</strong>：它记录所有来自服务器的写命令并将其保存在一个文件中。当服务器重新启动时，它使用这个文件来重建数据的状态。由于所有执行的命令都被 Redis 保存，您可以根据服务器的数据持久性级别来同步文件，每次写入命令，每秒或几乎不经常。</li></ul><p>两种方法都有自己的优缺点，选择使用哪种方法完全取决于您的特定使用情况。在某些情况下，两种方法的组合可能是一个理想的解决方案。<br>在下一节中，我们将详细讨论这些持久性技术，这将为您提供更深的了解，并帮助您作出更明智的决定。</p><h1 id="主题：Redis-RDB-持久性"><a href="#主题：Redis-RDB-持久性" class="headerlink" title="主题：Redis RDB 持久性"></a><strong>主题</strong>：Redis RDB 持久性</h1><p>让我们来讲述 <strong>RDB 持久性</strong> 的故事。RDB（Redis 数据库）是 Redis 的一个非常方便的持久性格式。在这种方法中，Redis 服务器在特定时间点创建数据集的点击保存。想象一下，这就像创建定期的数据备份，在某些场景下非常有用。</p><p>RDB 的操作非常简单。在配置的间隔内，Redis 父进程会 fork 一个子进程。父进程继续为客户端服务，而子进程开始在磁盘上写 RDB 文件。这样，数据库就可以继续处理客户端请求，而创建快照的同时。</p><p>当子进程完成保存 RDB 文件时，它会替换旧的快照。子进程然后退出并向父进程发送成功信号。如果在保存过程中出现错误，子进程会向父进程发送错误信号。</p><p>RDB 持久性有自己的优势：</p><ul><li>它是为灾难恢复而设计的。您可以配置 Redis 在每分钟或每几秒内创建快照。如果发生灾难性事件，您最多只会丢失一分钟的数据。</li><li>快照是以分秒内的速度创建的，并且是完整的。</li></ul><p>RDB 快照生成过程非常快速并不会影响 Redis 服务器为写请求处理的性能。此外，它创建了紧凑的文件，Redis 可以很快地在服务器启动时消耗它们，减少了停机时间。</p><p>然而，与所有其他技术一样，RDB 持久性也有自己的缺点：</p><ul><li>RDB 是一个点到时间的快照系统，这意味着它不会记录每个单独的写操作。因此，在发生崩溃或故障时，您可能会丢失未包含在最后一次快照中的数据。</li><li>尽管是自动过程，快照生成可能会对大型数据库资源密集，导致服务的降级期间。</li></ul><p>在这些信息的基础上，很明显，虽然 RDB 在数据备份和灾难恢复方面有许多优势，但它可能不是应用程序需要高数据持久性的最佳解决方案。</p><p>与两面的故事一样，这只是我们持久性故事的一半。在下一课中，我们将探讨 AOF（追加只写文件）持久性的内容和外容。</p><h1 id="主题：Redis-AOF持久化"><a href="#主题：Redis-AOF持久化" class="headerlink" title="主题：Redis AOF持久化"></a><strong>主题</strong>：Redis AOF持久化</h1><p>现在我们已经对 Redis 的 RDB 持久化有了深入的理解，让我们来关注另一种方法：<strong>追加只写文件（AOF）</strong>。</p><p>与 RDB 持久化不同，AOF 采用了更全面的方法。每次执行写命令时，Redis 都会记录它们。真的，每一个。这些命令然后保存到一个<strong>追加只写文件</strong>中，因此得名。</p><p>当 Redis 重新启动时，它使用这个文件来还原其以前的状态。命令按顺序执行，以重新创建数据。</p><p>AOF 持久化的一个优点是其持久性。由于每次写操作都会记录，您有了所有变化的详细帐户。它也许会让你兴奋地知道，Redis 提供了可调的持久性级别：</p><ul><li>您可以设置 Redis 在写入命令时同步此日志文件</li><li>或者，Redis 可以在每秒钟同步此文件</li><li>或者，您可能会相信您的电源供应的稳定性并非常频繁地同步！</li></ul><p>想象一下！完全控制您的数据库持久性方法！</p><p>然而，AOF 持久化也有自己的优缺点。在下一课中，我们将比较 RDB 和 AOF，比较其强项，并帮助您了解何时使用哪一个。</p><h1 id="主题：Redis-RDB-与-AOF-持久化"><a href="#主题：Redis-RDB-与-AOF-持久化" class="headerlink" title="主题：Redis RDB 与 AOF 持久化"></a><strong>主题</strong>：Redis RDB 与 AOF 持久化</h1><p>当谈到 Redis 和数据持久性时，RDB 和 AOF 是两个英雄。然而，他们各有自己的优势和劣势。</p><p>首先，RDB 持久化创建在特定时间间隔内定期创建的数据集的快照。因此，在意外关闭时，您可以还原数据到最后一次快照。</p><p>然而，这可能意味着写入后的数据将永远丢失！虽然 RDB 文件创建快速并不消耗太多内存，但处理较大数据库时可能会导致输入/输出操作的减慢。</p><p>另一方面，AOF 持久化记录每次收到的写命令。这可能有好处。因为所有数据都会立即记录下来，所以没有丢失的数据。但是，日志文件可能会变得非常大，并且可能会引入延迟。</p><p>最终，RDB 和 AOF 之间的选择取决于您的使用场景。如果您不能忍受任何数据丢失，AOF 是最好的选择。但是，如果数据可以轻松重建并且需要更快的备份和恢复，那么 RDB 可能是更好的选择。</p><p>在许多情况下，同时使用 RDB 和 AOF 可能会为您提供两者的好处。您将获得 AOF 持久性和 RDB 快速备份和数据恢复的好处。</p><p>中文翻译：</p><h1 id="主题：实现-Redis-持久化"><a href="#主题：实现-Redis-持久化" class="headerlink" title="主题：实现 Redis 持久化"></a><strong>主题</strong>：实现 Redis 持久化</h1><p>Redis 的持久化配置灵活性是其强项之一。根据需要，您可以选择 RDB、AOF 或者两者。下面是如何实现它们：</p><ol><li><strong>实现 RDB 持久化</strong>：启用 RDB 持久化主要涉及配置 Redis 配置文件（<code>redis.conf</code>）中保存数据的频率。这是通过 <code>save</code> 配置直接指令来控制的。语法是 <code>save &lt;seconds&gt; &lt;changes&gt;</code>，其中 <code>&lt;seconds&gt;</code> 指定了一定数量的秒数，<code>&lt;changes&gt;</code> 指定了最小数量的更改。您可以在 <code>redis.conf</code> 文件中为更细的控制具有多个 <code>save</code> 直接指令。</li><li><strong>实现 AOF 持久化</strong>：要启用 AOF 持久化，您需要更新 <code>appendonly</code> 配置直接指令在 <code>redis.conf</code> 文件中为 <code>yes</code>。另一个重要的直接指令是 <code>appendfsync</code>，它定义了数据写入 AOF 文件的频率。它可以设置为 <code>always</code>（每次写入时 fsync）、<code>everysec</code>（每秒 fsync）或 <code>no</code>（只有 Redis 决定 fsync）。</li><li><strong>使用 RDB 和 AOF 同时</strong>：两种持久性方法可以同时使用，只需在 <code>redis.conf</code> 文件中启用其相应的直接指令。您将获得 RDB 的点到时快照和 AOF 的持久性。</li></ol><p>而且，就是这样！根据应用程序的需要，您已经配置了 Redis 持久性。在困惑时，请记住 RDB 和 AOF 持久性之间的主要差异和其应用场景。</p><h1 id="主题：回和评估"><a href="#主题：回和评估" class="headerlink" title="主题：回和评估"></a><strong>主题</strong>：回和评估</h1><p>我们在这些课程中讨论了许多内容：</p><ol><li><strong>Redis 架构</strong>：我们深入探讨了 Redis，特别是作为内存数据结构存储的情况。</li><li><strong>Redis 持久化概述</strong>：我们讨论了 Redis 处理数据持久化的方式并讨论了其中的一些交换。</li><li><strong>Redis RDB 持久化</strong>：我们探讨了 RDB 持久化方案，其工作原理和其可能的优势。</li><li><strong>Redis AOF 持久化</strong>：我们类似地研究了 AOF 持久化方案和其应用场景。</li><li><strong>Redis RDB vs. AOF</strong>：我们比较了这两种持久性方法，特别是在性能、数据安全和应用场景方面。</li><li><strong>实现 Redis 持久化</strong>：我们将我们的知识应用到不同的场景中，链接了不同类型的持久性。</li></ol><p>我希望这些课程清楚地解释了 Redis、RDB 和 AOF。现在，是时候看看你已经学到了。请耐心地回答以下问题。不要担心，如果你不能回答所有问题，真正的学习通常发生在找答案的过程中，而不是展示你已经知道的！</p><ol><li><strong>描述 AOF 和 RDB 持久化之间的基本差异。</strong></li><li><strong>在哪些情况下您会更喜欢使用 AOF，并在哪些情况下会选择 RDB？请提供具体的例子。</strong></li><li><strong>使用这些持久性方法可能会遇到哪些潜在的缺点？</strong></li></ol><p>请慢下来并输入答案。</p><ol><li><strong>描述AOF和RDB持久性之间的基本差异。</strong></li></ol><p>Redis提供了两种持久性方法：RDB（Redis数据库）和AOF（追加只写文件）。它们在保存数据方面的主要差异在于何时和如何保存数据。</p><ul><li>_RDB_：这种方法在特定时间间隔内捕获数据集的一次快照。这种方法对备份和重新启动时的快速恢复很有帮助。</li><li>_AOF_：这种方法记录每次服务器接收到的写操作，提供了更耐久的持久性方法。AOF日志记录使Redis更具耐力性，因为它维护了所有操作的完整日志。</li></ul><ol><li><strong>在哪些情况下会更倾向于使用AOF，在哪些情况下会更倾向于使用RDB？请提供具体的例子。</strong></li></ol><p>你的选择取决于特定的项目和你所倾向的权衡。</p><ul><li>_RDB_：如果你正在构建一个缓存层，其中数据可以被重新缓存或重新计算从另一个存储中，RDB的更快的备份和恢复时间是明显的优势。</li><li>_AOF_：如果你正在构建一个应用程序，其中每次写操作都是关键的——例如，一个消息或合作应用程序——AOF的增加耐力性将是更合适的选择。</li></ul><ol><li><strong>使用这些持久性方法可能会有哪些潜在的缺点？</strong></li></ol><p>每种持久性方法都有自己的缺点：</p><ul><li>_RDB_：在捕获快照时，Redis会复制服务器进程，这可能会对系统造成负担。此外，如果Redis在快照之间发生崩溃，可能会丢失重要的数据。此外，更大的数据库可能需要更长的时间和更多的I/O来创建RDB快照。</li><li>_AOF_：日志文件可能会变得非常大，因为它记录了每个操作。此外，AOF日志通常要比等效的RDB快照更大，并且在Redis重新启动时可能会更慢。</li></ul><p>请记，这些答案只是指导。在处理真实的项目时，您的特定上下文和要求可能会导致不同的结论。</p><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/redis-interview5/">https://programmerscareer.com/redis-interview5/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 面试：Redis 有几种数据结构？Zset 是如何实现的？</title>
      <link href="/zh-cn/redis-interview6/"/>
      <url>/zh-cn/redis-interview6/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><p>你曾被提过类似问题在面试中问过吗？或者将来会遇到，让我们一起探索和掌握它！</p><span id="more"></span><blockquote class="colorquote warning"><p>感谢您阅读这篇文章。更多面试问题:<br><a href="https://programmerscareer.com/zh-cn/software-interview-set/">https://programmerscareer.com/zh-cn/software-interview-set/</a></p></blockquote><h1 id="主题：1-1-详细研究-Redis-数据结构"><a href="#主题：1-1-详细研究-Redis-数据结构" class="headerlink" title="主题：1.1 详细研究 Redis 数据结构"></a><strong>主题</strong>：1.1 详细研究 Redis 数据结构</h1><p>Redis 是一个开源的内存数据结构存储，为我们提供了一组强大和高性能的数据结构。今天的旅程开始于深入探索这些多样的数据结构并了解其功能。</p><p>Redis 中的数据结构是预构建的模式，用于管理和组织数据，并允许快速的读写操作。 Redis 提供了多种类型的数据结构，每一种数据结构都适合不同类型的数据管理需求。这些包括：</p><ol><li><strong>字符串</strong>：最简单的 Redis 数据结构。它们是二进制安全的，可以包含任何类型的数据。</li><li><strong>列表</strong>：这些是简单的字符串列表，按插入顺序排序。</li><li><strong>集合</strong>：这是一个不重复的字符串集合。</li><li><strong>哈希</strong>：哈希是表示对象的完美选择。它们是字符串字段和字符串值的映射。</li><li><strong>排序集（Zsets）</strong>：每个 Zset 成员都与一个分数相关，该分数用于排序集元素从最小到最大分数。</li><li><strong>位数组（Bitmaps）</strong>：它们提供了操作数组的位的功能。</li><li><strong>HyperLogLogs</strong>：这是一个概率数据结构，用于估计集合的卡inality。</li><li><strong>地理空间数据（Geosets）</strong>：它们允许您存储纬度、经度和相关名称。</li><li><strong>流</strong>：它们是日志数据类型，用于追加新项目，例如日志或消息。</li></ol><p>数据结构的选择取决于数据的性质和有效地操作数据的类型。</p><p>了解数据结构并选择正确的一种可以大大提高应用的性能，使 Redis 成为我们的技术堆栈中的一个不可或缺的工具。</p><h1 id="主题：1-2-Redis-支持多少数据结构"><a href="#主题：1-2-Redis-支持多少数据结构" class="headerlink" title="主题：1.2 Redis 支持多少数据结构"></a><strong>主题</strong>：1.2 Redis 支持多少数据结构</h1><p>我们先学习了，Redis 不仅仅是一个简单的键值存储，它更像是数据结构服务器。可能会问，Redis 实际上支持多少种数据结构呢？</p><p>答案是，Redis 重要地支持<strong>八</strong>种不同类型的数据结构：</p><ol><li><strong>字符串</strong></li><li><strong>列表</strong></li><li><strong>集合</strong></li><li><strong>排序集（Zsets）</strong></li><li><strong>哈希</strong></li><li><strong>Bitmaps</strong></li><li><strong>HyperLogLogs</strong></li><li><strong>地理空间数据（Geosets）</strong></li><li><strong>流</strong></li></ol><p>每种这些数据结构都有其独特的身份，为特定的目的服务，并提供不同的功能，因此允许 Redis 处理一系列数据管理任务的宽范围，具有出色的速度和一致性。</p><h1 id="主题：1-3-了解-Redis-中的有序集（Zset）"><a href="#主题：1-3-了解-Redis-中的有序集（Zset）" class="headerlink" title="主题：1.3 了解 Redis 中的有序集（Zset）"></a><strong>主题</strong>：1.3 了解 Redis 中的有序集（Zset）</h1><p>在 Redis 中，<strong>排序集（Zset）</strong> 是 Set 和 Hash 的合成体。它们采用这两种数据类型的独特方面，使这种混合结构变得非常灵活。</p><p>有序集是，本质上说，是一个 Set，它确保每个元素都是唯一的。然而，它还与每个元素相关联的分数，就像是一个哈希。这些分数用于排序集元素，从最小分数到最大分数。</p><p>这可能听起来很简单，但它有重要的后果。Redis 可以为有序集的元素按分数顺序提供有用的资源，为数据范围查询提供了值得的帮助。</p><p>想象一下游戏中的排行榜，其中你必须显示顶级表现者以升序或降序顺序排列。有序集是这种用例的理想数据结构，因为你可以直接获取排序的数据。</p><p>这就是有序集的概述！随着我们进一步的探索，我们将为您展示如何在 Redis 中实现和操作有序集！</p><h1 id="主题：1-4-在-Redis-中实现有序集"><a href="#主题：1-4-在-Redis-中实现有序集" class="headerlink" title="主题：1.4 在 Redis 中实现有序集"></a><strong>主题</strong>：1.4 在 Redis 中实现有序集</h1><p>我们先学习，有序集在 Redis 中是如何工作的。有序集是通过与每个元素相关联的分数相关联的方式来区分的。然而，我们还没有深入研究它们在 Redis 中的实现。所以让我们来解开这个谜题！</p><p>Redis 在内部使用两种数据结构来存储有序集：</p><ol><li><strong>HashTable</strong>，其中元素是键，分数是值。</li><li><strong>跳表</strong>或<strong>排序集</strong>，其中每个节点是我们的有序集中的元素。</li></ol><p>当有序集非常小，其长度最多为 128 项，并且每个集合中的每个元素都在一个小整数范围内时，有序集被存储为<strong>ziplist</strong>的列表表示。</p><p>值得注意的是，决定使用 HashTable 还是跳表/排序集并不会影响有序集的功能；它只是为了性能的交换。</p><p>Redis 根据有序集的内容自动切换这些内部数据结构，优化读取、写入或两者的组合，根据需要！</p><h1 id="主题：1-5-Redis-中的-Zset-实践"><a href="#主题：1-5-Redis-中的-Zset-实践" class="headerlink" title="主题：1.5 Redis 中的 Zset 实践"></a><strong>主题</strong>：1.5 Redis 中的 Zset 实践</h1><p>在 Redis 中，可以对 Zset 进行各种操作：</p><ol><li><strong>zadd</strong>：此命令允许向 Zset 中添加元素，并为每个元素分配一个分数。下面是如何使用它的示例：</li></ol><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zadd myZset 1 "a"</span><br></pre></td></tr></tbody></table></figure><ol start="2"><li><strong>zrange</strong>：此命令检索有序的元素，根据其分数进行排序。下面是如何使用它的示例：</li></ol><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zrange myZset 0 -1</span><br></pre></td></tr></tbody></table></figure><ol start="3"><li><strong>zrem</strong>：此命令用于从 Zset 中删除特定的元素：</li></ol><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zrem myZset "a"</span><br></pre></td></tr></tbody></table></figure><ol start="4"><li><strong>zrank</strong>：此命令返回元素的排名，从 0 开始计数。要找到元素 “a” 的排名，请执行以下操作：</li></ol><figure class="highlight plaintext hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zrank myZset "a"</span><br></pre></td></tr></tbody></table></figure><p>请记住，Redis 对语法非常宽容。它不区分大小写并且在某些情况下甚至不需要关闭引号！</p><h1 id="主题：1-6-Redis-高级主题"><a href="#主题：1-6-Redis-高级主题" class="headerlink" title="主题：1.6 Redis 高级主题"></a><strong>主题</strong>：1.6 Redis 高级主题</h1><p>经过了解各种数据结构和命令后，现在是时候深入探讨 Redis 的高级主题了！💪</p><p>让我们先讨论 Redis 的 <strong>持久性</strong>。Redis 提供两种持久性方法：</p><ol><li><strong>RDB</strong>（Redis 数据库备份）：此持久性方法定期创建数据集的快照。</li><li><strong>AOF</strong>（追加只写文件）：此持久性方法记录每次写操作接收到的服务器，重新运行它们可以重新创建数据集。</li></ol><p>两种持久性方法都有其优缺点，并且选择通常取决于使用场景的要求。</p><p>接下来是 Redis <strong>事务</strong>。Redis 事务允许执行一组命令作为一个单步。它使用 ‘MULTI’ 来指示开始和 ‘EXEC’ 来指示结束。</p><p>另一个值得讨论的重要方面是 Redis <strong>安全性</strong>。默认情况下，Redis 没有身份验证或安全层。然而，Redis 允许设置密码，客户必须使用它来进行身份验证并被授予访问权限。</p><p>请记住，Redis 不支持加密连接，并建议在需要数据加密时使用 SSL 代理。</p><p>最后，让我们讨论 Redis <strong>发布/订阅</strong> 模型。在这种模型中，发布者发送消息到特定的频道，不关心或者不在乎订阅者。相反，订阅者侦听特定的频道，不关心或者不在乎发布者。这导致了高度解耦合和可伸缩的系统。</p><h1 id="主题：1-7-Redis-在实际应用中的应用"><a href="#主题：1-7-Redis-在实际应用中的应用" class="headerlink" title="主题：1.7 Redis 在实际应用中的应用"></a><strong>主题</strong>：1.7 Redis 在实际应用中的应用</h1><p>Redis 在各种实际应用中发，由于其出色的特性，是一个理想的选择。让我们来看看一些例子：</p><ol><li><strong>缓存</strong>：由于其高速和丰富的数据类型，Redis 是为网站应用程序实现缓存的理想选择。它显著加快了应用程序的响应时间。</li><li><strong>会话存储</strong>：需要在多个用户请求之间维护网站的信息的网站通常使用 Redis 进行会话存储。Redis 提供的数据类型使它成为一个理想的候选者。</li><li><strong>消息队列系统</strong>：使用 Redis 的列表和发布/订阅模型可以创建消息队列系统。列表在 Redis 中可以用作队列，在其中您可以使用原子操作，例如 LPUSH 和 RPOP，来推和弹出元素。</li><li><strong>排行榜和计数</strong>：Redis 非常适合管理排行榜，特别是如果您需要在实时中管理它们。排序集数据结构是为解决这些问题而设计的。</li><li><strong>实时分析</strong>：您可以使用 Redis 进行实时分析，例如计算或分析统计数据以进行即时查看。</li></ol><p>请记住，Redis 的灵活性不限于这些应用。它还可以用作主数据库、作业管理系统、搜索引擎等等！</p><h1 id="主题：1-8-回顾和评估"><a href="#主题：1-8-回顾和评估" class="headerlink" title="主题：1.8 回顾和评估"></a><strong>主题</strong>：1.8 回顾和评估</h1><p>让我们花些时间来回顾和练习我们在前面几节中学到的内容。总是有好处的重新访问主题并开始实施它们，以巩固我们的理解。</p><p>直到现在，我们学习了 Redis 中各种数据类型，为每种数据结构执行了手动操作，深入探讨了高级主题，并看到了 Redis 在实际应用中的应用。</p><p>一个好的方法是为我们选择一个实际问题并试图使用 Redis 来解决它。您可以试图为网站应用程序实现一个缓存解决方案或设置一个简单的消息队列系统。使用我们学习的 Redis 命令与不同的数据类型和结构交互。</p><p>现在让我们测试你的 Redis 知识！</p><p>1️⃣ <strong>基本问题</strong>（难度：3/10）：Redis 支持六种数据类型，它们分别是 STRING、LIST、SET、ZSET（有序集合）、HASH、和 STREAM。</p><p>2️⃣ <strong>中级问题</strong>（难度：6/10）：在哪种情况下会使用 Redis List 而不是 Redis Set？当数据的顺序重要时，你会使用 Redis List，因为 Redis List 会根据元素被添加的顺序来维护元素的顺序。在另一方面，Redis Set 是一个无序的集合。例如，如果你需要存储一系列的项目并希望它们按时间顺序显示（例如，博文的评论时间线），你会使用 Redis List。</p><p>3️⃣ <strong>高级问题</strong>（难度：9/10）：如何在网站应用程序中使用 Redis 进行缓存？请简要描述一下它的工作原理：</p><ul><li>当请求被发送到你的网站应用程序时，先检查请求的数据是否在 Redis 缓存中可用，通过请求参数作为键来尝试检索它。</li><li>如果数据在 Redis 缓存中可用（命中缓存），则从缓存中检索数据并返回它作为响应。</li><li>如果数据不在 Redis 缓存中可用（未命中缓存），则从主数据库中检索数据。</li><li>在从主数据库中检索数据后，将其保存到 Redis 缓存中，并为其设置过期时间，以防止它无限地占用缓存的内存。然后返回数据作为响应。</li><li>如果正确地执行，这允许经常请求的数据来自 Redis 缓存，显著缩短响应时间并降低主数据库的负载。</li></ul><blockquote class="colorquote danger"><p>English post: <a href="https://programmerscareer.com/redis-interview6/">https://programmerscareer.com/redis-interview6/</a><br>作者：<a href="https://twitter.com/WesleyWei0316">Wesley Wei – Twitter</a> <a href="https://wesley-wei.medium.com/">Wesley Wei – Medium</a><br>注意：本文为作者原创，转载请注明出处。  </p></blockquote></body></html>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> interview </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hello-world</title>
      <link href="/hello-world/"/>
      <url>/hello-world/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><h2 id="Start-at-the-beginning"><a href="#Start-at-the-beginning" class="headerlink" title="Start at the beginning"></a>Start at the beginning</h2><p>I have also written a blog before, but I have not started writing for more than 2 years, and I am ready to pick it up again. </p><p>I have changed to a new blog system, the most important part may be to support bilingual. blogging at the same time, but also to exercise my English.</p></body></html>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nothing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>新的开始</title>
      <link href="/zh-cn/hello-world/"/>
      <url>/zh-cn/hello-world/</url>
      
        <content type="html"><![CDATA[<html><head></head><body><h2 id="从头开始"><a href="#从头开始" class="headerlink" title="从头开始"></a>从头开始</h2><p>之前也曾写过博客, 但工作的这2年多一直未曾再动笔, 这里准备重新捡起来. </p><p>换了一个新的博客系统, 最主要可能就是支持双语, 写博客的同时, 也能锻炼自己的英语水平.</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 测试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
